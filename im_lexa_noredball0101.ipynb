{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLyThA97hKdQ",
        "outputId": "64ab8c15-9ff6-4fdf-a832-ab1312c3ded7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Google Driveのマウント\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive') # , force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaRyWHkMi1j5",
        "outputId": "f1f58231-6127-4e0e-b5b8-28acdbff4e27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0.2)\n",
            "Collecting gymnasium-robotics\n",
            "  Using cached gymnasium_robotics-1.3.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting mujoco<3.2.0,>=2.2.0 (from gymnasium-robotics)\n",
            "  Using cached mujoco-3.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium-robotics) (1.26.4)\n",
            "Collecting gymnasium>=1.0.0 (from gymnasium-robotics)\n",
            "  Using cached gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting PettingZoo>=1.23.0 (from gymnasium-robotics)\n",
            "  Using cached pettingzoo-1.24.3-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: Jinja2>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium-robotics) (3.1.4)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from gymnasium-robotics) (2.36.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0->gymnasium-robotics) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0->gymnasium-robotics) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium>=1.0.0->gymnasium-robotics)\n",
            "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0.3->gymnasium-robotics) (3.0.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.10/dist-packages (from mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (1.11.0)\n",
            "Collecting glfw (from mujoco<3.2.0,>=2.2.0->gymnasium-robotics)\n",
            "  Downloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (3.1.7)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio->gymnasium-robotics) (11.0.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (6.4.5)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (3.21.0)\n",
            "Downloading gymnasium_robotics-1.3.1-py3-none-any.whl (26.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.1/26.1 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mujoco-3.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pettingzoo-1.24.3-py3-none-any.whl (847 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m847.8/847.8 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: glfw, farama-notifications, gymnasium, PettingZoo, mujoco, gymnasium-robotics\n",
            "Successfully installed PettingZoo-1.24.3 farama-notifications-0.0.4 glfw-2.8.0 gymnasium-1.0.0 gymnasium-robotics-1.3.1 mujoco-3.1.6\n"
          ]
        }
      ],
      "source": [
        "!pip install omegaconf\n",
        "# !pip install gymnasium\n",
        "!pip install gymnasium-robotics\n",
        "# !pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qjs3Dlf0lRVc"
      },
      "outputs": [],
      "source": [
        "#config.py\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class WorldModelConfig:\n",
        "    emb_dim: int = 1024\n",
        "    z_dim: int = 32\n",
        "    num_classes: int = 32\n",
        "    h_dim: int = 600\n",
        "    hidden_dim: int = 600\n",
        "    num_layers_za2hidden: int = 1\n",
        "    num_layers_h2z: int = 1\n",
        "    mlp_hidden_dim: int = 400\n",
        "    min_std: float = 0.1\n",
        "    kl_balance_alpha: float = 0.8\n",
        "    kl_loss_scale: float = 0.1\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ExplorerConfig:\n",
        "    num_emsembles: int = 10\n",
        "    emsembles_offset: int = 1\n",
        "    emsembles_target_mode: str = 'z'\n",
        "    mlp_hidden_dim: int = 400\n",
        "    min_std: float = 0.1\n",
        "    discount: float = 0.99\n",
        "    lambda_: float = 0.95\n",
        "    actor_entropy_scale: float = 1e-4\n",
        "    slow_critic_update: int = 100\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class AchieverConfig:\n",
        "    num_positives: int = 256\n",
        "    neg_sampling_factor: int = 0.1\n",
        "    mlp_hidden_dim: int = 400\n",
        "    min_std: float = 0.1\n",
        "    discount: float = 0.99\n",
        "    lambda_: float = 0.95\n",
        "    actor_entropy_scale: float = 1e-4\n",
        "    slow_critic_update: int = 100\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LEXAModelConfig:\n",
        "    world_model: WorldModelConfig = WorldModelConfig()\n",
        "    explorer: ExplorerConfig = ExplorerConfig()\n",
        "    achiever: AchieverConfig = AchieverConfig()\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataConfig:\n",
        "    buffer_size: int = 2e6\n",
        "    batch_size: int = 50\n",
        "    seq_length: int = 50\n",
        "    imagination_horizon: int = 15\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LearningConfig:\n",
        "    seed_steps: int = 5000\n",
        "    num_steps: int = 1e7\n",
        "    expl_episode_freq: int = 2\n",
        "    world_model_lr: float = 2e-4\n",
        "    explorer_actor_lr: float = 4e-5\n",
        "    explorer_critic_lr: float = 1e-4\n",
        "    achiever_actor_lr: float = 4e-5\n",
        "    achiever_critic_lr: float = 1e-4\n",
        "    epsilon: float = 1e-5\n",
        "    weight_decay: float = 1e-6\n",
        "    grad_clip: float = 100\n",
        "    update_freq: int = 4\n",
        "    eval_episode_freq: int = 5\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class EnvConfig:\n",
        "    task: str = 'FrankaKitchen-v1'\n",
        "    img_size: int = 128\n",
        "    action_repeat: int = 2\n",
        "    time_limit: int = 1000\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class WandbConfig:\n",
        "    logging: bool = False\n",
        "    name: str = 'lexa'\n",
        "    group: str = ''\n",
        "    project: str = 'LEXA'\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    model: LEXAModelConfig = LEXAModelConfig()\n",
        "    env: EnvConfig = EnvConfig()\n",
        "    data: DataConfig = DataConfig()\n",
        "    learning: LearningConfig = LearningConfig()\n",
        "    wandb: WandbConfig = WandbConfig()\n",
        "    device: str = 'cuda'\n",
        "    seed: int = 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCemWxTHrtJz"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtaG_0HVnFcg"
      },
      "source": [
        "### model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "enlGlMzrnZkb"
      },
      "outputs": [],
      "source": [
        "#model.utils.py\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.distributions as td\n",
        "from torch.distributions.utils import _standard_normal\n",
        "from einops import rearrange\n",
        "\n",
        "\n",
        "class TruncatedNormal(td.Normal):\n",
        "    def __init__(self, loc: torch.Tensor, scale: torch.Tensor, low: float = -1.0, high: float = 1.0, eps: float = 1e-6) -> None:\n",
        "        super().__init__(loc, scale, validate_args=False)\n",
        "        self.low = low\n",
        "        self.high = high\n",
        "        self.eps = eps\n",
        "\n",
        "    def _clamp(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        clamped_x = torch.clamp(x, self.low + self.eps, self.high - self.eps)\n",
        "        x = x - x.detach() + clamped_x.detach()\n",
        "        return x\n",
        "\n",
        "    def sample(self, clip: float | None = None, sample_shape: torch.Size = torch.Size()) -> torch.Tensor:\n",
        "        shape = self._extended_shape(sample_shape)\n",
        "        eps = _standard_normal(shape, dtype=self.loc.dtype, device=self.loc.device)\n",
        "\n",
        "        eps *= self.scale\n",
        "        if clip is not None:\n",
        "            eps = torch.clamp(eps, -clip, clip)\n",
        "        x = self.loc + eps\n",
        "        return self._clamp(x)\n",
        "\n",
        "\n",
        "def compute_lambda_target(rewards: torch.Tensor, discount: float, values: torch.Tensor, lambda_: float):\n",
        "    V_lambda = torch.zeros_like(rewards)\n",
        "\n",
        "    for t in reversed(range(rewards.shape[0])):\n",
        "        if t == rewards.shape[0] - 1:\n",
        "            V_lambda[t] = rewards[t] + discount * values[t]\n",
        "        else:\n",
        "            V_lambda[t] = rewards[t] + discount * ((1-lambda_) * values[t+1] + lambda_ * V_lambda[t+1])\n",
        "\n",
        "    return V_lambda\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zZkXKZ49nTUH"
      },
      "outputs": [],
      "source": [
        "#network.py\n",
        "\n",
        "from typing import Literal\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Normal, OneHotCategoricalStraightThrough, Independent, Bernoulli\n",
        "\n",
        "# from .utils import TruncatedNormal\n",
        "\n",
        "\n",
        "class RSSM(nn.Module):\n",
        "    def __init__(self,\n",
        "                 z_dim=30,\n",
        "                 num_classes=20,\n",
        "                 h_dim=200,\n",
        "                 hidden_dim=200,\n",
        "                 emb_dim=32,\n",
        "                 action_dim=9,\n",
        "                 num_layers_za2hidden=1,\n",
        "                 num_layers_h2z=1,\n",
        "                 min_std=0.1):\n",
        "        super(RSSM, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.h_dim = h_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.num_layers_za2hidden = num_layers_za2hidden\n",
        "        self.num_layers_h2z = num_layers_h2z\n",
        "        self.num_classes = num_classes\n",
        "        self.min_std = min_std\n",
        "\n",
        "        self.za2hidden = nn.Sequential(\n",
        "            *([nn.Sequential(nn.Linear(self.z_dim + self.action_dim, self.hidden_dim), nn.ELU())] + \\\n",
        "            [nn.Sequential(nn.Linear(self.hidden_dim, self.hidden_dim), nn.ELU()) for _ in range(self.num_layers_za2hidden - 1)])\n",
        "        )\n",
        "        self.transition = nn.GRUCell(self.hidden_dim, self.h_dim)\n",
        "\n",
        "        self.prior_hidden = nn.Sequential(\n",
        "            *([nn.Sequential(nn.Linear(self.h_dim, self.hidden_dim), nn.ELU())] + \\\n",
        "            [nn.Sequential(nn.Linear(self.hidden_dim, self.hidden_dim), nn.ELU()) for _ in range(self.num_layers_h2z - 1)])\n",
        "        )\n",
        "        self.prior_logits = nn.Linear(self.hidden_dim, self.z_dim * self.num_classes)\n",
        "\n",
        "        self.posterior_hidden = nn.Sequential(\n",
        "            *([nn.Sequential(nn.Linear(self.h_dim + self.emb_dim, self.hidden_dim), nn.ELU())] + \\\n",
        "            [nn.Sequential(nn.Linear(self.hidden_dim, self.hidden_dim), nn.ELU()) for _ in range(self.num_layers_h2z - 1)])\n",
        "        )\n",
        "        self.posterior_logits = nn.Linear(self.hidden_dim, self.z_dim * self.num_classes)\n",
        "\n",
        "    def recurrent(self, z, action, h):\n",
        "        hidden = self.za2hidden(torch.concat([z, action], dim=1))\n",
        "        next_h = self.transition(hidden, h)\n",
        "        return next_h\n",
        "\n",
        "    def prior(self, h, detach=False):\n",
        "        hidden = self.prior_hidden(h)\n",
        "        logits = self.prior_logits(hidden)\n",
        "        logits = logits.reshape(logits.shape[0], self.z_dim, self.num_classes)\n",
        "        prior = Independent(OneHotCategoricalStraightThrough(logits=logits), 1)\n",
        "        if detach:\n",
        "            detach_prior = Independent(OneHotCategoricalStraightThrough(logits=logits.detach()), 1)\n",
        "            return prior, detach_prior\n",
        "        return prior\n",
        "\n",
        "    def posterior(self, h, emb, detach=False):\n",
        "        hidden = self.posterior_hidden(torch.concat([h, emb], dim=1))\n",
        "        logits = self.posterior_logits(hidden)\n",
        "        logits = logits.reshape(logits.shape[0], self.z_dim, self.num_classes)\n",
        "        posterior = Independent(OneHotCategoricalStraightThrough(logits=logits), 1)\n",
        "        if detach:\n",
        "            detach_posterior = Independent(OneHotCategoricalStraightThrough(logits=logits.detach()), 1)\n",
        "            return posterior, detach_posterior\n",
        "        return posterior\n",
        "\n",
        "\n",
        "class ConvEncoder(nn.Module):\n",
        "    def __init__(self, input_size, emb_dim):\n",
        "        super(ConvEncoder, self).__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LayerNorm([32, input_size // 2, input_size // 2]),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LayerNorm([64, input_size // 4, input_size // 4]),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LayerNorm([128, input_size // 8, input_size // 8]),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LayerNorm([256, input_size // 16, input_size // 16]),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear((input_size // 16) ** 2 * 256 , emb_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvDecoder(nn.Module):\n",
        "    def __init__(self, img_size, z_dim, num_classes, h_dim):\n",
        "        super(ConvDecoder, self).__init__()\n",
        "\n",
        "        self.img_size = img_size\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(z_dim * num_classes + h_dim, (img_size // 16) ** 2 * 256),\n",
        "            nn.LayerNorm([(img_size // 16) ** 2 * 256,]),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.LayerNorm([128, img_size // 8, img_size // 8]),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.LayerNorm([64, img_size // 4, img_size // 4]),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.LayerNorm([32, img_size // 2, img_size // 2]),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, z, h):\n",
        "        x = torch.concat([z, h], dim=1)\n",
        "        out = self.fc(x)\n",
        "        out = out.reshape(out.shape[0], 256, self.img_size // 16, self.img_size // 16)\n",
        "        out = self.net(out)\n",
        "        dist = Independent(Normal(out, 1), 3)\n",
        "        return dist\n",
        "\n",
        "\n",
        "class Discount(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, h_dim, hidden_dim=256):\n",
        "        super(Discount, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(z_dim * num_classes + h_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, z, h):\n",
        "        logits = self.net(torch.concat([z, h], dim=1))\n",
        "        dist = Independent(Bernoulli(logits=logits), 1)\n",
        "        return dist\n",
        "\n",
        "\n",
        "class ExprolerStatePredictor(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, h_dim, target_dim, min_std, hidden_dim=256):\n",
        "        super(ExprolerStatePredictor, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.min_std = min_std\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.target_dim = target_dim\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(z_dim * num_classes + h_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.mean_fc = nn.Linear(hidden_dim, target_dim)\n",
        "        self.std_fc = nn.Linear(hidden_dim, target_dim)\n",
        "\n",
        "    def forward(self, z, h):\n",
        "        h = self.net(torch.concat([z, h], dim=1))\n",
        "        mean = self.mean_fc(h)\n",
        "        std = self.std_fc(h) + self.min_std\n",
        "        return Independent(Normal(mean, std), 1)\n",
        "\n",
        "\n",
        "class ExplorerActor(nn.Module):\n",
        "    def __init__(self, action_dim, z_dim, num_classes, h_dim, hidden_dim=256, min_std=0.1):\n",
        "        super(ExplorerActor, self).__init__()\n",
        "\n",
        "        self.action_dim = action_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.min_std = min_std\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(z_dim * num_classes + h_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.mean_fc = nn.Linear(hidden_dim, action_dim)\n",
        "        self.std_fc = nn.Linear(hidden_dim, action_dim)\n",
        "\n",
        "    def forward(self, z, h, train=True):\n",
        "        h = self.net(torch.concat([z, h], dim=1))\n",
        "        mean = F.tanh(self.mean_fc(h))\n",
        "        std = 2 * F.sigmoid(self.std_fc(h) / 2) + self.min_std\n",
        "        dist = Independent(TruncatedNormal(mean, std, -1, 1), 1)\n",
        "        if train:\n",
        "            action = dist.rsample()\n",
        "            log_prob = dist.log_prob(action.detach())\n",
        "            entropy = dist.entropy()\n",
        "            return action, log_prob, entropy\n",
        "        else:\n",
        "            action = dist.mean\n",
        "            return action, None, None\n",
        "\n",
        "\n",
        "class ExplorerCritic(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, h_dim, hidden_dim=256):\n",
        "        super(ExplorerCritic, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(z_dim * num_classes + h_dim, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, z, h):\n",
        "        return self.net(torch.concat([z, h]), dim=1)\n",
        "\n",
        "\n",
        "class State2Emb(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, h_dim, emb_dim, hidden_dim=256):\n",
        "        super(State2Emb, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(z_dim * num_classes + h_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.mean_fc = nn.Linear(hidden_dim, emb_dim)\n",
        "        self.std_fc = nn.Linear(hidden_dim, emb_dim)\n",
        "\n",
        "    def forward(self, z, h):\n",
        "        h = self.net(torch.concat([z, h], dim=1))\n",
        "        mean = self.mean_fc(h)\n",
        "        std = self.std_fc(h)\n",
        "        return Independent(Normal(mean, std), 1)\n",
        "\n",
        "\n",
        "class AchieverDistanceEstimator(nn.Module):\n",
        "    def __init__(self, emb_dim, hidden_dim=256):\n",
        "        super(AchieverDistanceEstimator, self).__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.state2emb = nn\n",
        "\n",
        "        self.current_fc = nn.Sequential(nn.Linear(emb_dim, hidden_dim),\n",
        "                                        nn.GELU())\n",
        "        self.goal_fc = nn.Sequential(nn.Linear(emb_dim, hidden_dim),\n",
        "                                     nn.GELU())\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, current_emb, goal_emb):\n",
        "        cur_h = self.current_fc(current_emb)\n",
        "        goal_h = self.goal_fc(goal_emb)\n",
        "        return self.net(torch.concat([cur_h, goal_h]), dim=1)\n",
        "\n",
        "\n",
        "class AchieverCritic(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, h_dim, emb_dim, hidden_dim=256):\n",
        "        super(AchieverCritic, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.state_fc = nn.Sequential(nn.Linear(z_dim * num_classes + h_dim, hidden_dim),\n",
        "                                      nn.GELU())\n",
        "        self.goal_fc = nn.Sequential(nn.Linear(emb_dim, hidden_dim),\n",
        "                                     nn.GELU())\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, z, h, goal_emb):\n",
        "        state_h = self.state_fc(torch.concat([z, h]), dim=1)\n",
        "        goal_h = self.goal_fc(goal_emb)\n",
        "        return self.net(torch.concat([state_h, goal_h]), dim=1)\n",
        "\n",
        "\n",
        "class AchieverActor(nn.Module):\n",
        "    def __init__(self, action_dim, z_dim, num_classes, h_dim, emb_dim, hidden_dim=256, min_std=0.1):\n",
        "        super(AchieverActor, self).__init__()\n",
        "\n",
        "        self.action_dim = action_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.min_std = min_std\n",
        "\n",
        "        self.state_fc = nn.Sequential(nn.Linear(z_dim * num_classes + h_dim, hidden_dim),\n",
        "                                      nn.GELU())\n",
        "        self.goal_fc = nn.Sequential(nn.Linear(emb_dim, hidden_dim),\n",
        "                                     nn.GELU())\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.mean_fc = nn.Linear(hidden_dim, action_dim)\n",
        "        self.std_fc = nn.Linear(hidden_dim, action_dim)\n",
        "\n",
        "    def forward(self, z, h, goal_emb, train=True):\n",
        "        state_h = self.state_fc(torch.concat([z, h], dim=1))\n",
        "        goal_h = self.goal_fc(goal_emb)\n",
        "        h = self.net(torch.concat([state_h, goal_h], dim=1))\n",
        "        mean = F.tanh(self.mean_fc(h))\n",
        "        std = 2 * F.sigmoid(self.std_fc(h) / 2) + self.min_std\n",
        "        dist = Independent(TruncatedNormal(mean, std, -1, 1), 1)\n",
        "        if train:\n",
        "            action = dist.rsample()\n",
        "            log_prob = dist.log_prob(action.detach())\n",
        "            entropy = dist.entropy()\n",
        "            return action, log_prob, entropy\n",
        "        else:\n",
        "            action = dist.mean\n",
        "        return action, None, None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dygRTxcYn3Nu"
      },
      "outputs": [],
      "source": [
        "#worldmodel.py\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import kl_divergence\n",
        "from einops import rearrange\n",
        "\n",
        "# from .network import RSSM, ConvEncoder, ConvDecoder, Discount\n",
        "\n",
        "\n",
        "class WorldModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 img_size,\n",
        "                 emb_dim,\n",
        "                 action_dim,\n",
        "                 z_dim,\n",
        "                 num_classes,\n",
        "                 h_dim,\n",
        "                 hidden_dim,\n",
        "                 num_layers_za2hidden,\n",
        "                 num_layers_h2z,\n",
        "                 mlp_hidden_dim,\n",
        "                 min_std,\n",
        "                 kl_balance_alpha,\n",
        "                 kl_loss_scale,\n",
        "                 device):\n",
        "        super(WorldModel, self).__init__()\n",
        "\n",
        "        self.img_size = img_size\n",
        "        self.action_dim = action_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_layers_za2hidden = num_layers_za2hidden\n",
        "        self.num_layers_h2z = num_layers_h2z\n",
        "        self.mlp_hidden_dim = mlp_hidden_dim\n",
        "        self.min_std = min_std\n",
        "        self.kl_balance_alpha = kl_balance_alpha\n",
        "        self.kl_loss_scale = kl_loss_scale\n",
        "        self.device = device\n",
        "\n",
        "        self.rssm = RSSM(\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            hidden_dim = hidden_dim,\n",
        "            emb_dim = emb_dim,\n",
        "            action_dim = action_dim,\n",
        "            num_layers_za2hidden = num_layers_za2hidden,\n",
        "            num_layers_h2z = num_layers_h2z,\n",
        "            min_std = min_std\n",
        "        )\n",
        "        self.encoder = ConvEncoder(\n",
        "            input_size = img_size,\n",
        "            emb_dim = emb_dim\n",
        "        )\n",
        "        self.decoder = ConvDecoder(\n",
        "            img_size = img_size,\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim\n",
        "        )\n",
        "\n",
        "    def train(self, observations, actions):\n",
        "        batch_size, seq_length, *_ = observations.shape\n",
        "        observations = rearrange(observations, 'b t c h w -> t b c h w')\n",
        "        actions = rearrange(actions, 'b t d -> t b d')\n",
        "\n",
        "        embs = self.encoder(rearrange(observations, 't b c h w -> (t b) c h w'))\n",
        "        embs = rearrange(embs, '(t b) d -> t b d')\n",
        "\n",
        "        z = torch.zeros(batch_size, self.z_dim*self.num_classes, device=self.device)\n",
        "        h = torch.zeros(batch_size, self.h_dim, device=self.device)\n",
        "\n",
        "        zs = torch.empty(seq_length - 1, batch_size, self.z_dim*self.num_classes, device=self.device)\n",
        "        hs = torch.empty(seq_length - 1, batch_size, self.h_dim, device=self.device)\n",
        "\n",
        "        kl_loss = 0\n",
        "        for t in range(seq_length - 1):\n",
        "            h = self.rssm.recurrent(z, actions[t], h)\n",
        "            next_prior, detach_next_prior = self.rssm.prior(h, detach=True)\n",
        "            next_posterior, detach_next_posterior = self.rssm.posterior(h, embs[t+1], detach=True)\n",
        "            z = next_posterior.rsample().flatten(1)\n",
        "            hs[t] = h\n",
        "            zs[t] = z\n",
        "            kl_loss += self.kl_balance_alpha * torch.mean(kl_divergence(detach_next_posterior, next_prior)) + \\\n",
        "                       (1 - self.kl_balance_alpha) * torch.mean(kl_divergence(next_posterior, detach_next_prior))\n",
        "        kl_loss = kl_loss / (seq_length - 1)\n",
        "\n",
        "        flatten_hs = hs.view(-1, self.h_dim)\n",
        "        flatten_zs = zs.view(-1, self.z_dim * self.num_classes)\n",
        "\n",
        "        obs_dist = self.decoder(flatten_zs, flatten_hs)\n",
        "\n",
        "        obs_loss = -torch.mean(obs_dist.log_prob(rearrange(observations[1:], 't b c h w -> (t b) c h w')))\n",
        "\n",
        "        wm_loss = obs_loss + self.kl_loss_scale * kl_loss\n",
        "        return wm_loss, (zs, hs), OrderedDict(wm_loss=wm_loss.item(), obs_loss=obs_loss.item(), kl_loss=kl_loss.item())\n",
        "\n",
        "    def imagine(self, action, z, h):\n",
        "        next_h = self.rssm.recurrent(z, action, h)\n",
        "        next_prior = self.rssm.prior(next_h)\n",
        "        next_z = next_prior.rsample().flatten(1)\n",
        "        return next_h, next_z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w2NJDBCWnL3o"
      },
      "outputs": [],
      "source": [
        "#achiever_reward.py\n",
        "\n",
        "from typing import Literal\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange\n",
        "\n",
        "# from .network import AchieverDistanceEstimator, State2Emb\n",
        "\n",
        "\n",
        "class LatentDistanceReward(nn.Module):\n",
        "    def __init__(self,\n",
        "                 z_dim,\n",
        "                 num_classes,\n",
        "                 h_dim,\n",
        "                 emb_dim,\n",
        "                 mlp_hidden_dim,\n",
        "                 device):\n",
        "        super(LatentDistanceReward, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.mlp_hidden_dim = mlp_hidden_dim\n",
        "        self.device = device\n",
        "\n",
        "        self.state2emb = State2Emb(\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            emb_dim = emb_dim,\n",
        "            hidden_dim = mlp_hidden_dim\n",
        "        )\n",
        "\n",
        "        self.distance_estimator = AchieverDistanceEstimator(\n",
        "            emb_dim = emb_dim,\n",
        "            hidden_dim = mlp_hidden_dim\n",
        "        )\n",
        "\n",
        "    def imagine_compute_reward(self, current_z, current_h, goal_z, goal_h):\n",
        "        current_emb = self.state2emb(current_z, current_h)\n",
        "        goal_emb = self.state2emb(goal_z, goal_h)\n",
        "        distance = self.distance_estimator(current_emb, goal_emb)\n",
        "        return -distance\n",
        "\n",
        "    def compute_reward(self, z, h, goal_emb):\n",
        "        current_emb = self.state2emb(z, h)\n",
        "        distance = self.distance_estimator(current_emb, goal_emb)\n",
        "        return -distance\n",
        "\n",
        "    def train_state2emb(self, zs, hs, target_embs):\n",
        "        embs_dist = self.state2emb(zs, hs)\n",
        "        loss = -torch.mean(embs_dist.log_prob(target_embs))\n",
        "        return loss\n",
        "\n",
        "    def train_distance_estimator(self, zs, hs, num_positives, neg_sampling_factor, batch_length):\n",
        "        def get_future_goal_idxs(seq_len, bs):\n",
        "            cur_idx_list = []\n",
        "            goal_idx_list = []\n",
        "            for cur_idx in range(seq_len):\n",
        "                for goal_idx in range(cur_idx, seq_len):\n",
        "                    cur_idx_list.append(np.concatenate([np.ones((bs,1), dtype=np.int32)*cur_idx, np.arange(bs).reshape(-1,1)], axis = -1))\n",
        "                    goal_idx_list.append(np.concatenate([np.ones((bs,1), dtype=np.int32)*goal_idx, np.arange(bs).reshape(-1,1)], axis = -1))\n",
        "\n",
        "            return np.concatenate(cur_idx_list,0), np.concatenate(goal_idx_list,0)\n",
        "\n",
        "        def get_future_goal_idxs_neg_sampling(num_negs, seq_len, bs):\n",
        "            cur_idxs = np.random.randint((0,0), (seq_len, bs), size=(num_negs,2))\n",
        "            goal_idxs = np.random.randint((0,0), (seq_len, bs), size=(num_negs,2))\n",
        "            for i in range(num_negs):\n",
        "                goal_idxs[i,1] = np.random.choice([j for j in range(bs) if j//batch_length != cur_idxs[i,1]//batch_length])\n",
        "            return cur_idxs, goal_idxs\n",
        "\n",
        "        zs, hs = zs.detach(), hs.detach()\n",
        "\n",
        "        current_idxs, goal_idxs = get_future_goal_idxs(zs.shape[0], zs.shape[1])\n",
        "        idx = np.random.choice(np.arange(len(current_idxs)), num_positives, replace=False)\n",
        "        current_idx, goal_idx = current_idxs[idx], goal_idxs[idx]\n",
        "        current_zs, current_hs = zs[current_idx[:,0], current_idx[:,1]], hs[current_idx[:,0], current_idx[:,1]]\n",
        "        goal_zs, goal_hs = zs[goal_idx[:,0], goal_idx[:,1]], hs[goal_idx[:,0], goal_idx[:,1]]\n",
        "        current_embs, goal_embs = self.state2emb(current_zs, current_hs).mean, self.state2emb(goal_zs, goal_hs).mean\n",
        "        target_distance = (goal_idx[:,0] - current_idx[:,0]) / zs.shape[0]\n",
        "        pred_distance = self.distance_estimator(current_embs, goal_embs)\n",
        "        loss = F.mse_loss(pred_distance, target_distance)\n",
        "\n",
        "        num_negatives = num_positives * neg_sampling_factor\n",
        "        current_idx, goal_idx = get_future_goal_idxs_neg_sampling(num_negatives, zs.shape[0], zs.shape[1])\n",
        "        current_zs, current_hs = zs[current_idx[:,0], current_idx[:,1]], hs[current_idx[:,0], current_idx[:,1]]\n",
        "        goal_zs, goal_hs = zs[goal_idx[:,0], goal_idx[:,1]], hs[goal_idx[:,0], goal_idx[:,1]]\n",
        "        current_embs, goal_embs = self.state2emb(current_zs, current_hs).mean, self.state2emb(goal_zs, goal_hs).mean\n",
        "        target_distance = torch.ones(num_negatives, 1, device=self.device) * zs.shape[0]\n",
        "        pred_distance = self.distance_estimator(current_embs, goal_embs)\n",
        "        loss += F.mse_loss(pred_distance, target_distance)\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-37bqKebnC1g"
      },
      "outputs": [],
      "source": [
        "#achiever.py\n",
        "\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.distributions as td\n",
        "from einops import rearrange\n",
        "\n",
        "# from .network import AchieverActor, AchieverCritic\n",
        "# from .worldmodel import WorldModel\n",
        "# from .achiever_reward import LatentDistanceReward\n",
        "# from .utils import compute_lambda_target\n",
        "\n",
        "\n",
        "class Achiever(nn.Module):\n",
        "    def __init__(self,\n",
        "                 world_model: WorldModel,\n",
        "                 instrinsic_reward,\n",
        "                 action_dim,\n",
        "                 z_dim,\n",
        "                 num_classes,\n",
        "                 h_dim,\n",
        "                 emb_dim,\n",
        "                 mlp_hidden_dim,\n",
        "                 min_std,\n",
        "                 discount,\n",
        "                 lambda_,\n",
        "                 actor_entropy_scale,\n",
        "                 device):\n",
        "        super(Achiever, self).__init__()\n",
        "\n",
        "        self.world_model = world_model\n",
        "\n",
        "        self.action_dim = action_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.mlp_hidden_dim = mlp_hidden_dim\n",
        "        self.discount = discount\n",
        "        self.lambda_ = lambda_\n",
        "        self.actor_entropy_scale = actor_entropy_scale\n",
        "        self.device = device\n",
        "\n",
        "        self.actor = AchieverActor(\n",
        "            action_dim = action_dim,\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            emb_dim = emb_dim,\n",
        "            hidden_dim = mlp_hidden_dim,\n",
        "            min_std = min_std\n",
        "        )\n",
        "        self.critic = AchieverCritic(\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            emb_dim = emb_dim,\n",
        "            hidden_dim = mlp_hidden_dim\n",
        "        )\n",
        "        self.target_critic = AchieverCritic(\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            emb_dim = emb_dim,\n",
        "            hidden_dim = mlp_hidden_dim\n",
        "        )\n",
        "        self.target_critic.load_state_dict(self.critic.state_dict())\n",
        "\n",
        "        self.instrinsic_reward = instrinsic_reward\n",
        "\n",
        "    def train(self, init_zs: torch.Tensor, init_hs: torch.Tensor, goal_observations: torch.Tensor, horison_length, num_positives, neg_sampling_factor, batch_seq_length):\n",
        "        goal_observations = rearrange(goal_observations, 'b t c h w -> (t b) c h w')\n",
        "        shuffle_idx = torch.randperm(goal_observations.shape[0])\n",
        "        goal_observations = goal_observations[shuffle_idx]\n",
        "        goal_embs = self.world_model.encoder(goal_observations)\n",
        "\n",
        "        zs = init_zs.detach() # (batch_size * seq_length, z_dim * num_classes)\n",
        "        hs = init_hs.detach() # (batch_size * seq_length, h_dim)\n",
        "\n",
        "        imagined_zs = torch.empty(horison_length, *init_zs.shape, device=self.device)\n",
        "        imagined_hs = torch.empty(horison_length, *init_hs.shape, device=self.device)\n",
        "        imagined_action_log_probs = torch.empty(horison_length, init_zs.shape[0], device=self.device)\n",
        "        imagined_action_entropys = torch.empty(horison_length, init_zs.shape[0], device=self.device)\n",
        "\n",
        "        for t in range(horison_length):\n",
        "            actions, action_log_probs, action_entropys = self.actor(zs.detach(), hs.detach(), goal_embs)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                hs, zs = self.world_model.imagine(actions, zs, hs)\n",
        "\n",
        "            imagined_hs[t] = hs.detach()\n",
        "            imagined_zs[t] = zs.detach()\n",
        "            imagined_action_log_probs[t] = action_log_probs\n",
        "            imagined_action_entropys[t] = action_entropys\n",
        "\n",
        "        flatten_hs = imagined_hs.view(-1, self.h_dim).detach() # (horison_length * batch_size * seq_length, h_dim)\n",
        "        flatten_zs = imagined_zs.view(-1, self.z_dim * self.num_classes).detach() # (horison_length * batch_size * seq_length, z_dim * num_classes)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            rewards = self.instrinsic_reward.compute_reward(flatten_zs, flatten_hs, goal_embs).view(horison_length, -1) # (horison_length, batch_size * seq_length)\n",
        "            target_values = self.target_critic(flatten_zs, flatten_hs, goal_embs).view(horison_length, -1) # (horison_length, batch_size * seq_length)\n",
        "\n",
        "        lambda_target = compute_lambda_target(rewards, self.discount, target_values, self.lambda_)\n",
        "\n",
        "        objective = imagined_action_log_probs * ((lambda_target - target_values).detach())\n",
        "        actor_loss = -torch.sum(torch.mean(objective + self.actor_entropy_scale * imagined_action_entropys, dim=1))\n",
        "\n",
        "        value_mean = self.critic(flatten_zs.detach(), flatten_hs.detach()).view(horison_length, -1)\n",
        "        value_dist = td.Independent(td.Normal(value_mean, 1),  1)\n",
        "        critic_loss = -torch.mean(value_dist.log_prob(lambda_target.detach()).unsqueeze(-1))\n",
        "\n",
        "        distance_estimator_loss = self.instrinsic_reward.train_distance_estimator(imagined_zs, imagined_hs, num_positives, neg_sampling_factor, batch_seq_length)\n",
        "\n",
        "        return actor_loss, critic_loss, distance_estimator_loss, OrderedDict(ach_actor_loss=actor_loss.item(), ach_critic_loss=critic_loss.item(), distance_estimator_loss=distance_estimator_loss.item())\n",
        "\n",
        "    def update_critic(self):\n",
        "        self.target_critic.load_state_dict(self.critic.state_dict())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ijd1tc6_or_q"
      },
      "outputs": [],
      "source": [
        "#explorer_reward.py\n",
        "from typing import Literal\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange\n",
        "\n",
        "# from .network import ExprolerStatePredictor\n",
        "\n",
        "\n",
        "class EmsembleReward(nn.Module):\n",
        "    def __init__(self,\n",
        "                 z_dim,\n",
        "                 num_classes,\n",
        "                 h_dim,\n",
        "                 min_std,\n",
        "                 mlp_hidden_dim,\n",
        "                 device,\n",
        "                 num_emsembles = 10,\n",
        "                 offset = 1,\n",
        "                 target_mode: Literal['z', 'h', 'zh'] = 'z'):\n",
        "        super(EmsembleReward, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.min_std = min_std\n",
        "        self.num_emsembles = num_emsembles\n",
        "        self.offset = offset\n",
        "        self.target_mode = target_mode\n",
        "        self.mlp_hidden_dim = mlp_hidden_dim\n",
        "        self.device = device\n",
        "\n",
        "        if target_mode == 'z':\n",
        "            self.target_dim = z_dim * num_classes\n",
        "        elif target_mode == 'h':\n",
        "            self.target_dim = h_dim\n",
        "        elif target_mode == 'zh':\n",
        "            self.target_dim = z_dim * num_classes + h_dim\n",
        "\n",
        "        self.emsembles = nn.ModuleList()\n",
        "        for _ in range(num_emsembles):\n",
        "            self.emsembles.append(\n",
        "                ExprolerStatePredictor(\n",
        "                    z_dim = z_dim,\n",
        "                    num_classes = num_classes,\n",
        "                    h_dim = h_dim,\n",
        "                    min_std = min_std,\n",
        "                    hidden_dim = mlp_hidden_dim,\n",
        "                    target_dim = self.target_dim\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def compute_reward(self, z, h):\n",
        "        input_ = torch.concat([z, h], dim=1)\n",
        "        preds = torch.empty(self.num_emsembles, z.shape[0], self.target_dim, device=self.device)\n",
        "        for n in range(self.num_emsembles):\n",
        "            f = self.emsembles[n]\n",
        "            preds[n] = f(input_).mean\n",
        "        var = torch.std(preds, dim=0)\n",
        "        reward = torch.sum(var, dim=1)\n",
        "        return reward\n",
        "\n",
        "    def train(self, zs, hs):\n",
        "        input_ = torch.concat([zs, hs], dim=2)\n",
        "\n",
        "        if self.target_mode == 'z':\n",
        "            target = zs\n",
        "        elif self.target_mode == 'h':\n",
        "            target = hs\n",
        "        elif self.target_mode == 'zh':\n",
        "            target = input_\n",
        "\n",
        "        input_ = rearrange(input_[:-self.offset].detach(), 't b d -> (t b) d')\n",
        "        target = rearrange(input_[self.offset:].detach(), 't b d -> (t b) d')\n",
        "\n",
        "        loss = 0\n",
        "        for f in self.emsembles:\n",
        "            dist = f(input_)\n",
        "            loss += -torch.mean(dist.log_prob(target))\n",
        "        return loss, OrderedDict(emsemble_loss=loss.item())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XY9zGP7yoKFA"
      },
      "outputs": [],
      "source": [
        "#explorer.py\n",
        "\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.distributions as td\n",
        "from einops import rearrange\n",
        "\n",
        "# from .network import ExplorerActor, ExplorerCritic\n",
        "# from .worldmodel import WorldModel\n",
        "# from .explorer_reward import EmsembleReward\n",
        "# from .utils import compute_lambda_target\n",
        "\n",
        "\n",
        "class Explorer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 world_model: WorldModel,\n",
        "                 instrinsic_reward,\n",
        "                 action_dim,\n",
        "                 z_dim,\n",
        "                 num_classes,\n",
        "                 h_dim,\n",
        "                 mlp_hidden_dim,\n",
        "                 min_std,\n",
        "                 num_emsembles,\n",
        "                 emsembles_offset,\n",
        "                 emsembles_target_mode,\n",
        "                 discount,\n",
        "                 lambda_,\n",
        "                 actor_entropy_scale,\n",
        "                 device):\n",
        "        super(Explorer, self).__init__()\n",
        "\n",
        "        self.world_model = world_model\n",
        "\n",
        "        self.action_dim = action_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.mlp_hidden_dim = mlp_hidden_dim\n",
        "        self.min_std = min_std\n",
        "        self.num_emsembles = num_emsembles\n",
        "        self.emsembles_offset = emsembles_offset\n",
        "        self.emsembles_target_mode = emsembles_target_mode\n",
        "        self.discount = discount\n",
        "        self.lambda_ = lambda_\n",
        "        self.actor_entropy_scale = actor_entropy_scale\n",
        "        self.device = device\n",
        "\n",
        "        self.actor = ExplorerActor(\n",
        "            action_dim = action_dim,\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            hidden_dim = mlp_hidden_dim,\n",
        "            min_std = min_std\n",
        "        )\n",
        "        self.critic = ExplorerCritic(\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            hidden_dim = mlp_hidden_dim\n",
        "        )\n",
        "        self.target_critic = ExplorerCritic(\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            hidden_dim = mlp_hidden_dim\n",
        "        )\n",
        "        self.target_critic.load_state_dict(self.critic.state_dict())\n",
        "\n",
        "        self.instrinsic_reward = instrinsic_reward\n",
        "\n",
        "    def train(self, init_zs: torch.Tensor, init_hs: torch.Tensor, horison_length):\n",
        "        zs = init_zs.detach() # (batch_size * seq_length, z_dim * num_classes)\n",
        "        hs = init_hs.detach() # (batch_size * seq_length, h_dim)\n",
        "\n",
        "        imagined_zs = torch.empty(horison_length, *init_zs.shape, device=self.device)\n",
        "        imagined_hs = torch.empty(horison_length, *init_hs.shape, device=self.device)\n",
        "        imagined_action_log_probs = torch.empty(horison_length, init_zs.shape[0], device=self.device)\n",
        "        imagined_action_entropys = torch.empty(horison_length, init_zs.shape[0], device=self.device)\n",
        "\n",
        "        for t in range(horison_length):\n",
        "            actions, action_log_probs, action_entropys = self.actor(zs.detach(), hs.detach())\n",
        "\n",
        "            with torch.no_grad():\n",
        "                hs, zs = self.world_model.imagine(actions, zs, hs)\n",
        "\n",
        "            imagined_hs[t] = hs.detach()\n",
        "            imagined_zs[t] = zs.detach()\n",
        "            imagined_action_log_probs[t] = action_log_probs\n",
        "            imagined_action_entropys[t] = action_entropys\n",
        "\n",
        "        flatten_hs = imagined_hs.view(-1, self.h_dim).detach() # (horison_length * batch_size * seq_length, h_dim)\n",
        "        flatten_zs = imagined_zs.view(-1, self.z_dim * self.num_classes).detach() # (horison_length * batch_size * seq_length, z_dim * num_classes)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            rewards = self.instrinsic_reward.compute_reward(flatten_zs, flatten_hs).view(horison_length, -1) # (horison_length, batch_size * seq_length)\n",
        "            target_values = self.target_critic(flatten_zs, flatten_hs).view(horison_length, -1) # (horison_length, batch_size * seq_length)\n",
        "\n",
        "        lambda_target = compute_lambda_target(rewards, self.discount, target_values, self.lambda_)\n",
        "\n",
        "        objective = imagined_action_log_probs * ((lambda_target - target_values).detach())\n",
        "        actor_loss = -torch.sum(torch.mean(objective + self.actor_entropy_scale * imagined_action_entropys, dim=1))\n",
        "\n",
        "        value_mean = self.critic(flatten_zs.detach(), flatten_hs.detach()).view(horison_length, -1)\n",
        "        value_dist = td.Independent(td.Normal(value_mean, 1),  1)\n",
        "        critic_loss = -torch.mean(value_dist.log_prob(lambda_target.detach()).unsqueeze(-1))\n",
        "\n",
        "        return actor_loss, critic_loss, OrderedDict(exp_actor_loss=actor_loss.item(), exp_critic_loss=critic_loss.item())\n",
        "\n",
        "    def update_critic(self):\n",
        "        self.target_critic.load_state_dict(self.critic.state_dict())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rQKNQtrBo5Ho"
      },
      "outputs": [],
      "source": [
        "#replay_buffer.py\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# class ReplayBuffer:\n",
        "#     def __init__(self,\n",
        "#                  capacity,\n",
        "#                  observation_shape,\n",
        "#                  action_dim):\n",
        "#         self.capacity = capacity\n",
        "#         self.observation_shape = observation_shape\n",
        "#         self.action_dim = action_dim\n",
        "\n",
        "#         self.observations = np.zeros((capacity, *observation_shape), dtype=np.float32)\n",
        "#         self.actions = np.zeros((capacity, action_dim), dtype=np.float32)\n",
        "#         self.done = np.zeros((capacity, 1), dtype=bool)\n",
        "\n",
        "#         self.idx = 0\n",
        "#         self.if_filled = False\n",
        "\n",
        "#     def push(self, observation, action, done):\n",
        "#         self.observations[self.idx] = observation\n",
        "#         self.actions[self.idx] = action\n",
        "#         self.done[self.idx] = done\n",
        "\n",
        "#         if self.idx == self.capacity - 1:\n",
        "#             self.is_filled = True\n",
        "#         self.idx = (self.idx + 1) % self.capacity\n",
        "\n",
        "#     def sample(self, batch_size, seq_length):\n",
        "#         episode_borders = np.where(self.done)[0]\n",
        "#         sampled_indexes = []\n",
        "#         for _ in range(batch_size):\n",
        "#             cross_border = True\n",
        "#             while cross_border:\n",
        "#                 initial_index = np.random.randint(len(self) - seq_length + 1)\n",
        "#                 final_index = initial_index + seq_length - 1\n",
        "#                 cross_border = np.logical_and(initial_index <= episode_borders,\n",
        "#                                               episode_borders < final_index).any()\n",
        "#             sampled_indexes += list(range(initial_index, final_index + 1))\n",
        "\n",
        "#         sampled_observations = self.observations[sampled_indexes].reshape(\n",
        "#             batch_size, seq_length, *self.observations.shape[1:])\n",
        "#         sampled_actions = self.actions[sampled_indexes].reshape(\n",
        "#             batch_size, seq_length, self.actions.shape[1])\n",
        "#         sampled_done = self.done[sampled_indexes].reshape(\n",
        "#             batch_size, seq_length, 1)\n",
        "#         return sampled_observations, sampled_actions, sampled_done\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.capacity if self.is_filled else self.idx\n",
        "\n",
        "#     def save(self, dir):\n",
        "#         dir = Path(dir)\n",
        "#         np.save(dir / \"observations\", self.observations)\n",
        "#         np.save(dir / \"actions\", self.actions)\n",
        "#         np.save(dir / \"done\", self.done)\n",
        "\n",
        "#     def load(self, dir):\n",
        "#         dir = Path(dir)\n",
        "#         self.observations = np.load(dir / \"observations\")\n",
        "#         self.actions = np.load(dir / \"actions\")\n",
        "#         self.done = np.load(dir / \"done\")\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "class ReplayBuffer:\n",
        "    def __init__(self,\n",
        "                 capacity,\n",
        "                 observation_shape,\n",
        "                 action_dim):\n",
        "        self.capacity = capacity\n",
        "        self.observation_shape = observation_shape\n",
        "        self.action_dim = action_dim\n",
        "\n",
        "        self.observations = np.zeros((capacity, *observation_shape), dtype=np.float32)\n",
        "        self.actions = np.zeros((capacity, action_dim), dtype=np.float32)\n",
        "        self.done = np.zeros((capacity, 1), dtype=bool)\n",
        "\n",
        "        self.idx = 0\n",
        "        self.if_filled = False  # 修正: 正しいフィールド名を使用\n",
        "\n",
        "    def push(self, observation, action, done):\n",
        "        self.observations[self.idx] = observation\n",
        "        self.actions[self.idx] = action\n",
        "        self.done[self.idx] = done\n",
        "\n",
        "        # インデックス更新とバッファが満杯になったかのフラグ更新\n",
        "        if self.idx == self.capacity - 1:\n",
        "            self.if_filled = True\n",
        "        self.idx = (self.idx + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size, seq_length):\n",
        "        episode_borders = np.where(self.done)[0]\n",
        "        sampled_indexes = []\n",
        "        for _ in range(batch_size):\n",
        "            cross_border = True\n",
        "            while cross_border:\n",
        "                initial_index = np.random.randint(len(self) - seq_length + 1)\n",
        "                final_index = initial_index + seq_length - 1\n",
        "                cross_border = np.logical_and(initial_index <= episode_borders,\n",
        "                                              episode_borders < final_index).any()\n",
        "            sampled_indexes += list(range(initial_index, final_index + 1))\n",
        "\n",
        "        sampled_observations = self.observations[sampled_indexes].reshape(\n",
        "            batch_size, seq_length, *self.observations.shape[1:])\n",
        "        sampled_actions = self.actions[sampled_indexes].reshape(\n",
        "            batch_size, seq_length, self.actions.shape[1])\n",
        "        sampled_done = self.done[sampled_indexes].reshape(\n",
        "            batch_size, seq_length, 1)\n",
        "        return sampled_observations, sampled_actions, sampled_done\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.capacity if self.if_filled else self.idx  # 修正: 正しいフィールドを使用\n",
        "\n",
        "    def save(self, dir):\n",
        "        dir = Path(dir)\n",
        "        np.save(dir / \"observations\", self.observations)\n",
        "        np.save(dir / \"actions\", self.actions)\n",
        "        np.save(dir / \"done\", self.done)\n",
        "\n",
        "    def load(self, dir):\n",
        "        dir = Path(dir)\n",
        "        self.observations = np.load(dir / \"observations.npy\")\n",
        "        self.actions = np.load(dir / \"actions.npy\")\n",
        "        self.done = np.load(dir / \"done.npy\")\n",
        "\n",
        "    def debug_info(self, n=5):\n",
        "        \"\"\"\n",
        "        リプレイバッファのデバッグ情報を取得します。\n",
        "        :param n: 表示するサンプル数\n",
        "        :return: デバッグ情報の辞書\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'current_size': len(self),\n",
        "            'latest_observations': self.observations[max(0, self.idx - n):self.idx].tolist(),\n",
        "            'latest_actions': self.actions[max(0, self.idx - n):self.idx].tolist(),\n",
        "            'latest_done_flags': self.done[max(0, self.idx - n):self.idx].tolist()\n",
        "        }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TRtwWmSElWRJ"
      },
      "outputs": [],
      "source": [
        "#lexa.py\n",
        "\n",
        "from typing import Union, Literal\n",
        "import functools\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from gymnasium import Env\n",
        "\n",
        "# from config import Config\n",
        "# from model.worldmodel import WorldModel\n",
        "# from model.explorer import Explorer\n",
        "# from model.explorer_reward import EmsembleReward\n",
        "# from model.achiever import Achiever\n",
        "# from model.achiever_reward import LatentDistanceReward\n",
        "# from replay_buffer import ReplayBuffer\n",
        "\n",
        "\n",
        "class LEXA:\n",
        "    def __init__(self, cfg: Config, env: Env):\n",
        "        self.cfg = cfg\n",
        "        self.env = env\n",
        "        self.device = torch.device(self.cfg.device)\n",
        "\n",
        "        self.world_model = WorldModel(\n",
        "            img_size = cfg.env.img_size,\n",
        "            emb_dim = cfg.model.world_model.emb_dim,\n",
        "            action_dim = self.env.action_space.shape[0],\n",
        "            z_dim = cfg.model.world_model.z_dim,\n",
        "            num_classes = cfg.model.world_model.num_classes,\n",
        "            h_dim = cfg.model.world_model.h_dim,\n",
        "            hidden_dim = cfg.model.world_model.hidden_dim,\n",
        "            num_layers_za2hidden = cfg.model.world_model.num_layers_za2hidden,\n",
        "            num_layers_h2z = cfg.model.world_model.num_layers_h2z,\n",
        "            mlp_hidden_dim = cfg.model.world_model.mlp_hidden_dim,\n",
        "            min_std = cfg.model.world_model.min_std,\n",
        "            kl_balance_alpha = cfg.model.world_model.kl_balance_alpha,\n",
        "            kl_loss_scale = cfg.model.world_model.kl_loss_scale,\n",
        "            device = self.device\n",
        "        ).to(self.device)\n",
        "        self.explorer_reward = EmsembleReward(\n",
        "            z_dim = cfg.model.world_model.z_dim,\n",
        "            num_classes = cfg.model.world_model.num_classes,\n",
        "            h_dim = cfg.model.world_model.h_dim,\n",
        "            min_std = cfg.model.world_model.min_std,\n",
        "            mlp_hidden_dim = cfg.model.explorer.mlp_hidden_dim,\n",
        "            device = self.device,\n",
        "            num_emsembles = cfg.model.explorer.num_emsembles,\n",
        "            offset = cfg.model.explorer.emsembles_offset,\n",
        "            target_mode = cfg.model.explorer.emsembles_target_mode,\n",
        "        ).to(self.device)\n",
        "        self.explorer = Explorer(\n",
        "            world_model = self.world_model,\n",
        "            instrinsic_reward = self.explorer_reward,\n",
        "            action_dim = self.env.action_space.shape[0],\n",
        "            z_dim = cfg.model.world_model.z_dim,\n",
        "            num_classes = cfg.model.world_model.num_classes,\n",
        "            h_dim = cfg.model.world_model.h_dim,\n",
        "            mlp_hidden_dim = cfg.model.explorer.mlp_hidden_dim,\n",
        "            min_std = cfg.model.explorer.min_std,\n",
        "            num_emsembles = cfg.model.explorer.num_emsembles,\n",
        "            emsembles_offset = cfg.model.explorer.emsembles_offset,\n",
        "            emsembles_target_mode = cfg.model.explorer.emsembles_target_mode,\n",
        "            discount = cfg.model.explorer.discount,\n",
        "            lambda_ = cfg.model.explorer.lambda_,\n",
        "            actor_entropy_scale = cfg.model.explorer.actor_entropy_scale,\n",
        "            device = self.device\n",
        "        ).to(self.device)\n",
        "        self.achiever_reward = LatentDistanceReward(\n",
        "            z_dim = cfg.model.world_model.z_dim,\n",
        "            num_classes = cfg.model.world_model.num_classes,\n",
        "            h_dim = cfg.model.world_model.h_dim,\n",
        "            emb_dim = cfg.model.world_model.emb_dim,\n",
        "            mlp_hidden_dim = cfg.model.achiever.mlp_hidden_dim,\n",
        "            device = self.device\n",
        "        ).to(self.device)\n",
        "        self.achiever = Achiever(\n",
        "            world_model = self.world_model,\n",
        "            instrinsic_reward = self.achiever_reward,\n",
        "            action_dim = self.env.action_space.shape[0],\n",
        "            z_dim = cfg.model.world_model.z_dim,\n",
        "            num_classes = cfg.model.world_model.num_classes,\n",
        "            h_dim = cfg.model.world_model.h_dim,\n",
        "            emb_dim = cfg.model.world_model.emb_dim,\n",
        "            mlp_hidden_dim = cfg.model.achiever.mlp_hidden_dim,\n",
        "            min_std = cfg.model.achiever.min_std,\n",
        "            discount = cfg.model.achiever.discount,\n",
        "            lambda_ = cfg.model.achiever.lambda_,\n",
        "            actor_entropy_scale = cfg.model.achiever.actor_entropy_scale,\n",
        "            device = self.device\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.wm_opt = optim.Adam(self.world_model.parameters(),\n",
        "                                 lr = cfg.learning.world_model_lr,\n",
        "                                 eps = cfg.learning.epsilon,\n",
        "                                 weight_decay = cfg.learning.weight_decay)\n",
        "        self.exp_reward_opt = optim.Adam(self.explorer_reward.parameters(),\n",
        "                                         lr = cfg.learning.world_model_lr,\n",
        "                                         eps = cfg.learning.epsilon,\n",
        "                                         weight_decay = cfg.learning.weight_decay)\n",
        "        self.exp_actor_opt = optim.Adam(self.explorer.actor.parameters(),\n",
        "                                        lr = cfg.learning.explorer_actor_lr,\n",
        "                                        eps = cfg.learning.epsilon,\n",
        "                                        weight_decay = cfg.learning.weight_decay)\n",
        "        self.exp_critic_opt = optim.Adam(self.explorer.critic.parameters(),\n",
        "                                         lr = cfg.learning.explorer_critic_lr,\n",
        "                                         eps = cfg.learning.epsilon,\n",
        "                                         weight_decay = cfg.learning.weight_decay)\n",
        "        self.ach_reward_opt = optim.Adam(self.achiever_reward.parameters(),\n",
        "                                        lr = cfg.learning.achiever_critic_lr,\n",
        "                                        eps = cfg.learning.epsilon,\n",
        "                                        weight_decay = cfg.learning.weight_decay)\n",
        "        self.ach_actor_opt = optim.Adam(self.achiever.actor.parameters(),\n",
        "                                        lr = cfg.learning.achiever_actor_lr,\n",
        "                                        eps = cfg.learning.epsilon,\n",
        "                                        weight_decay = cfg.learning.weight_decay)\n",
        "        self.ach_critic_opt = optim.Adam(self.achiever.critic.parameters(),\n",
        "                                         lr = cfg.learning.achiever_critic_lr,\n",
        "                                         eps = cfg.learning.epsilon,\n",
        "                                         weight_decay = cfg.learning.weight_decay)\n",
        "\n",
        "        self.agent = Agent(self.world_model, self.explorer, self.achiever, self.device)\n",
        "\n",
        "    def train(self, observations, actions):\n",
        "        observations = torch.from_numpy(observations).to(self.device)\n",
        "        actions = torch.from_numpy(actions).to(self.device)\n",
        "\n",
        "        wm_loss, (zs, hs), wm_metrics = self.world_model.train(observations, actions)\n",
        "        emsemble_loss, emsemble_metrics = self.explorer_reward.train(zs, hs)\n",
        "        self.wm_opt.zero_grad(True)\n",
        "        wm_loss.backward()\n",
        "        clip_grad_norm_(self.world_model.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.wm_opt.step()\n",
        "        self.exp_reward_opt.zero_grad(True)\n",
        "        emsemble_loss.backward()\n",
        "        clip_grad_norm_(self.explorer_reward.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.exp_reward_opt.step()\n",
        "\n",
        "        zs = zs.view(-1, self.cfg.model.world_model.z_dim * self.cfg.model.world_model.num_classes)\n",
        "        hs = hs.view(-1, self.cfg.model.world_model.h_dim)\n",
        "\n",
        "        exp_actor_loss, axp_critic_loss, exp_metrics = self.explorer.train(zs, hs, self.cfg.data.imagination_horizon)\n",
        "        self.exp_actor_opt.zero_grad(True)\n",
        "        exp_actor_loss.backward()\n",
        "        clip_grad_norm_(self.explorer.actor.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.exp_actor_opt.step()\n",
        "        self.exp_critic_opt.zero_grad(True)\n",
        "        axp_critic_loss.backward()\n",
        "        clip_grad_norm_(self.explorer.critic.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.exp_critic_opt.step()\n",
        "\n",
        "        ach_actor_loss, ach_critic_loss, de_loss, ach_metrics = self.achiever.train(zs, hs, observations,\n",
        "                                                                                    self.cfg.data.imagination_horizon,\n",
        "                                                                                    self.cfg.model.achiever.num_positives,\n",
        "                                                                                    self.cfg.model.achiever.neg_sampling_factor,\n",
        "                                                                                    self.cfg.data.seq_length)\n",
        "        self.ach_actor_opt.zero_grad(True)\n",
        "        ach_actor_loss.backward()\n",
        "        clip_grad_norm_(self.achiever.actor.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.ach_actor_opt.step()\n",
        "        self.ach_critic_opt.zero_grad(True)\n",
        "        ach_critic_loss.backward()\n",
        "        clip_grad_norm_(self.achiever.critic.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.ach_critic_opt.step()\n",
        "        self.ach_reward_opt.zero_grad(True)\n",
        "        de_loss.backward()\n",
        "        clip_grad_norm_(self.achiever_reward.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.ach_reward_opt.step()\n",
        "\n",
        "        return wm_metrics | emsemble_metrics | exp_metrics | ach_metrics\n",
        "\n",
        "    @staticmethod\n",
        "    def load(checkpoint):\n",
        "        cfg = checkpoint['config']\n",
        "        env = checkpoint['env']\n",
        "        output = LEXA(cfg, env)\n",
        "        output.world_model.load_state_dict(checkpoint['world_model'])\n",
        "        output.explorer_reward.load_state_dict(checkpoint['exp_reward'])\n",
        "        output.explorer.load_state_dict(checkpoint['explorer'])\n",
        "        output.achiever_reward.load_state_dict(checkpoint['ach_reward'])\n",
        "        output.achiever.load_state_dict(checkpoint['achiever'])\n",
        "        output.wm_opt.load_state_dict(checkpoint['wm_opt'])\n",
        "        output.exp_reward_opt.load_state_dict(checkpoint['exp_reward_opt'])\n",
        "        output.exp_actor_opt.load_state_dict(checkpoint['exp_actor_opt'])\n",
        "        output.exp_critic_opt.load_state_dict(checkpoint['exp_critic_opt'])\n",
        "        output.ach_reward_opt.load_state_dict(checkpoint['ach_reward_opt'])\n",
        "        output.ach_actor_opt.load_state_dict(checkpoint['ach_actor_opt'])\n",
        "        output.ach_critic_opt.load_state_dict(checkpoint['ach_critic_opt'])\n",
        "        return output\n",
        "\n",
        "    def save(self, path):\n",
        "        path = Path(path)\n",
        "        path.mkdir(parents=True, exist_ok=True)\n",
        "        torch.save(\n",
        "            {\n",
        "                'world_model': self.world_model.state_dict(),\n",
        "                'exp_reward': self.explorer_reward.state_dict(),\n",
        "                'explorer': self.explorer.state_dict(),\n",
        "                'ach_reward': self.achiever_reward.state_dict(),\n",
        "                'achiever': self.achiever.state_dict(),\n",
        "                'wm_opt': self.wm_opt.state_dict(),\n",
        "                'exp_reward_opt': self.exp_reward_opt.state_dict(),\n",
        "                'exp_actor_opt': self.exp_actor_opt.state_dict(),\n",
        "                'exp_critic_opt': self.exp_critic_opt.state_dict(),\n",
        "                'ach_reward_opt': self.ach_reward_opt.state_dict(),\n",
        "                'ach_actor_opt': self.ach_actor_opt.state_dict(),\n",
        "                'ach_critic_opt': self.ach_critic_opt.state_dict(),\n",
        "                'config': self.cfg,\n",
        "                'env': self.env,\n",
        "            },\n",
        "            path\n",
        "        )\n",
        "\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, world_model: WorldModel, explorer: Explorer, achiever: Achiever, device: torch.device):\n",
        "        self.world_model = world_model\n",
        "        self.explorer = explorer\n",
        "        self.achiever = achiever\n",
        "        self.device = device\n",
        "\n",
        "        self.h = torch.zeros(1, self.world_model.h_dim, device=self.device)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def __call__(self, observation, mode: Literal['explorer', 'achiever'], goal=None, train=True):\n",
        "        observation = torch.from_numpy(observation).unsqueeze(0).to(self.device)\n",
        "\n",
        "        if mode == 'explorer':\n",
        "            policy = self.explorer.actor\n",
        "        elif mode == 'achiever':\n",
        "            policy = self.achiever.actor\n",
        "            assert goal is not None, 'goal must be provided in achiever mode'\n",
        "            goal = torch.from_numpy(goal).to(self.device)\n",
        "            goal_emb = self.world_model.encoder(goal)\n",
        "            policy = functools.partial(policy, goal_emb=goal_emb)\n",
        "\n",
        "        obs_emb = self.world_model.encoder(observation)\n",
        "        z_posterior = self.world_model.rssm.posterior(self.h, obs_emb)\n",
        "        z = z_posterior.sample().flatten(1)\n",
        "        action, _, _ = policy(z, self.h, train=train)\n",
        "\n",
        "        self.h = self.world_model.rssm.recurrent(z, action, self.h)\n",
        "\n",
        "        return action.squeeze().cpu().numpy()\n",
        "\n",
        "    def reset(self):\n",
        "        self.h = torch.zeros(1, self.world_model.h_dim, device=self.device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2U5AzQqim2uz"
      },
      "outputs": [],
      "source": [
        "#utils.py\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from einops import rearrange\n",
        "\n",
        "\n",
        "def preprocess_obs(obs):\n",
        "    height, width = obs.shape[0], obs.shape[1]\n",
        "    obs = Image.fromarray(obs)\n",
        "    obs = obs.convert(\"RGB\")\n",
        "    obs = np.array(obs).reshape(height, width, 3)\n",
        "    obs = obs.astype(np.float32)\n",
        "    obs = rearrange(obs, 'h w c -> c h w')\n",
        "    normalized_obs = obs / 255.0 - 0.5\n",
        "    return normalized_obs\n",
        "\n",
        "\n",
        "def fix_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr_nk1HZwPTn"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS45lLZVjdew",
        "outputId": "5c86c799-15ad-4563-8ed6-67187a9b3a7f"
      },
      "outputs": [],
      "source": [
        "# !sudo apt install -y xvfb\n",
        "# !pip install pyvirtualdisplay\n",
        "# 仮想ディスプレイのセットアップ\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "display = Display(visible=0, size=(1024, 768))\n",
        "display.start()\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "import mujoco\n",
        "import glfw\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nk1_dB2491os"
      },
      "outputs": [],
      "source": [
        "# import cv2\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# def preprocess_obs(obs, target_size=(128, 128)):\n",
        "#     \"\"\"\n",
        "#     観測データを指定された形状にリサイズします。\n",
        "#     :param obs: 入力観測データ (H, W, C) または (C, H, W)\n",
        "#     :param target_size: リサイズ先の形状 (W, H)\n",
        "#     :return: リサイズされた観測データ\n",
        "#     \"\"\"\n",
        "#     if obs.shape[0] == 3:  # チャネルが先頭にある場合 (C, H, W)\n",
        "#         obs = np.transpose(obs, (1, 2, 0))  # (H, W, C) に変換\n",
        "\n",
        "#     resized = cv2.resize(obs, target_size, interpolation=cv2.INTER_AREA)\n",
        "#     resized = np.transpose(resized, (2, 0, 1))  # (C, H, W) に戻す\n",
        "#     return resized.astype(np.float32) / 255.0 - 0.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ii__-AWlrQXa"
      },
      "outputs": [],
      "source": [
        "#envs.franka_kitchen\n",
        "from itertools import combinations\n",
        "import numpy as np\n",
        "from gymnasium import Env\n",
        "from gymnasium.spaces import Box\n",
        "from gymnasium.wrappers import AddRenderObservation, TimeLimit\n",
        "from gymnasium_robotics.envs.franka_kitchen.kitchen_env import KitchenEnv\n",
        "\n",
        "\n",
        "class FrankaKichenEnv(Env):\n",
        "    def __init__(self,\n",
        "                 img_size,\n",
        "                 action_repeat,\n",
        "                 time_limit,\n",
        "                 seed):\n",
        "        self._seed = seed\n",
        "        self._action_repeat = action_repeat\n",
        "        self._base_env = KitchenEnv(render_mode='rgb_array',\n",
        "                                    width=img_size,\n",
        "                                    height=img_size,\n",
        "                                    default_camera_config=dict(distance=1.86, lookat=[-0.3, .5, 2.], azimuth=90, elevation=-60))\n",
        "        self._env = TimeLimit(self._base_env, time_limit)\n",
        "\n",
        "        self.observation_space = Box(0, 255, (img_size, img_size, 3), dtype=np.uint8)\n",
        "        self.action_space = self._env.action_space\n",
        "\n",
        "        self.action_space.seed(seed)\n",
        "        self.observation_space.seed(seed)\n",
        "\n",
        "        self.obs_element_goals, self.obs_element_indices, self.goal_configs = get_kitchen_benchmark_goals()\n",
        "        self.goals = list(range(len(self.obs_element_goals)))\n",
        "        self.goal_idx = -1\n",
        "\n",
        "        self._env.reset(seed=self._seed)\n",
        "        self.init_qpos = self._base_env.data.qpos.copy()\n",
        "        self.init_qvel = self._base_env.data.qvel.copy()\n",
        "        self.goal_rendered = False\n",
        "\n",
        "    def reset(self):\n",
        "        self._env.reset(seed=self._seed)\n",
        "        self.goal_rendered = False\n",
        "        return self._env.render()\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0\n",
        "        for step in range(self._action_repeat):\n",
        "            state, reward, terminated, truncated, info = self._env.step(action)\n",
        "            terminated = self.compute_success()\n",
        "            done = truncated or terminated\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        obs = self._env.render()\n",
        "        return obs, total_reward, done, info\n",
        "\n",
        "    def render(self):\n",
        "        return self._env.render()\n",
        "\n",
        "    def close(self):\n",
        "        return self._env.close()\n",
        "\n",
        "    def set_goal_idx(self, idx):\n",
        "        assert idx in self.goals\n",
        "        self.goal_idx = idx\n",
        "\n",
        "    def get_goal_obs(self):\n",
        "        if self.goal_idx == -1:\n",
        "            return None\n",
        "\n",
        "        if self.goal_rendered:\n",
        "            return self.rendered_goal_obs\n",
        "\n",
        "        element_indices = self.obs_element_indices[self.goal_idx]\n",
        "        element_values = self.obs_element_goals[self.goal_idx]\n",
        "\n",
        "        backup_qpos = self._base_env.data.qpos.copy()\n",
        "        backup_qvel = self._base_env.data.qvel.copy()\n",
        "\n",
        "        qpos = self.init_qpos.copy()\n",
        "        qpos[element_indices] = element_values\n",
        "        self._base_env.robot_env.set_state(qpos, np.zeros_like(self.init_qvel))\n",
        "\n",
        "        goal_obs = self._env.render()\n",
        "\n",
        "        self._base_env.robot_env.set_state(backup_qpos, backup_qvel)\n",
        "\n",
        "        self.goal_rendered = True\n",
        "        self.rendered_goal_obs = goal_obs\n",
        "        return goal_obs\n",
        "\n",
        "    def compute_success(self):\n",
        "        if self.goal_idx == -1:\n",
        "            return False\n",
        "\n",
        "        qpos = self._base_env.data.qpos.copy()\n",
        "\n",
        "        element_indices = self.obs_element_indices[self.goal_idx]\n",
        "        element_values = self.obs_element_goals[self.goal_idx]\n",
        "        goal_qpos = self.init_qpos.copy()\n",
        "        goal_qpos[element_indices] = element_values\n",
        "\n",
        "        per_obj_success = {\n",
        "            'bottom_burner' : ((qpos[9]<-0.38) and (goal_qpos[9]<-0.38)) or ((qpos[9]>-0.38) and (goal_qpos[9]>-0.38)),\n",
        "            'top_burner':    ((qpos[13]<-0.38) and (goal_qpos[13]<-0.38)) or ((qpos[13]>-0.38) and (goal_qpos[13]>-0.38)),\n",
        "            'light_switch':  ((qpos[17]<-0.25) and (goal_qpos[17]<-0.25)) or ((qpos[17]>-0.25) and (goal_qpos[17]>-0.25)),\n",
        "            'slide_cabinet' :  abs(qpos[19] - goal_qpos[19])<0.1,\n",
        "            'hinge_cabinet' :  abs(qpos[21] - goal_qpos[21])<0.2,\n",
        "            'microwave' :      abs(qpos[22] - goal_qpos[22])<0.2,\n",
        "            'kettle' : np.linalg.norm(qpos[23:25] - goal_qpos[23:25]) < 0.2\n",
        "        }\n",
        "        task_objects = self.goal_configs[self.goal_idx]\n",
        "\n",
        "        success = 1\n",
        "        for _obj in task_objects:\n",
        "            success *= per_obj_success[_obj]\n",
        "\n",
        "        return bool(success)\n",
        "\n",
        "    def get_kitchen_benchmark_goals():\n",
        "\n",
        "        object_goal_vals = {'bottom_burner' :  [-0.88, -0.01],\n",
        "                            'light_switch' :  [ -0.69, -0.05],\n",
        "                            'slide_cabinet':  [0.37],\n",
        "                            'hinge_cabinet':   [0., 0.5],\n",
        "                            'microwave'    :   [-0.5],\n",
        "                            'kettle'       :   [-0.23, 0.75, 1.62, 0.99, 0., 0., -0.06]}\n",
        "\n",
        "        object_goal_idxs = {'bottom_burner' :  [9, 10],\n",
        "                            'light_switch' :  [17, 18],\n",
        "                            'slide_cabinet':  [19],\n",
        "                            'hinge_cabinet':  [20, 21],\n",
        "                            'microwave'    :  [22],\n",
        "                            'kettle'       :  [23, 24, 25, 26, 27, 28, 29]}\n",
        "\n",
        "        base_task_names = [ 'bottom_burner', 'light_switch', 'slide_cabinet', 'hinge_cabinet', 'microwave', 'kettle' ]\n",
        "\n",
        "\n",
        "        goal_configs = []\n",
        "        #single task\n",
        "        for i in range(6):\n",
        "          goal_configs.append( [base_task_names[i]])\n",
        "\n",
        "        #two tasks\n",
        "        for i,j  in combinations([1,2,3,5], 2) :\n",
        "          goal_configs.append( [base_task_names[i], base_task_names[j]] )\n",
        "\n",
        "        obs_element_goals = [] ; obs_element_indices = []\n",
        "        for objects in goal_configs:\n",
        "            _goal = np.concatenate([object_goal_vals[obj] for obj in objects])\n",
        "            _goal_idxs = np.concatenate([object_goal_idxs[obj] for obj in objects])\n",
        "\n",
        "            obs_element_goals.append(_goal)\n",
        "            obs_element_indices.append(_goal_idxs)\n",
        "\n",
        "        return obs_element_goals, obs_element_indices, goal_configs\n",
        "\n",
        "\n",
        "    def debug_environment(self):\n",
        "        \"\"\"\n",
        "        環境の属性とプロパティをデバッグ出力します。\n",
        "        \"\"\"\n",
        "        print(\"Attributes of _base_env:\")\n",
        "        print(dir(self._base_env))\n",
        "\n",
        "        if hasattr(self._base_env, 'unwrapped'):\n",
        "            print(\"\\nAttributes of _base_env.unwrapped:\")\n",
        "            print(dir(self._base_env.unwrapped))\n",
        "\n",
        "        if hasattr(self._base_env.unwrapped, 'model'):\n",
        "            model = self._base_env.unwrapped.model\n",
        "            print(\"\\nModel properties:\")\n",
        "            print(dir(model))\n",
        "\n",
        "        if hasattr(self._base_env.unwrapped, 'data'):\n",
        "            data = self._base_env.unwrapped.data\n",
        "            print(\"\\nData properties:\")\n",
        "            print(dir(data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "j7sstYf13kuk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Z4Jfh6SEyVrn"
      },
      "outputs": [],
      "source": [
        "#gymnasium_robotics.envs.maze.maps\n",
        "\n",
        "\"\"\"A collection of maze map structures for the Gymnasium-Robotics PointMaze environments.\n",
        "\n",
        "The code is inspired by the D4RL repository hosted on GitHub (https://github.com/Farama-Foundation/D4RL), published in the paper\n",
        "'D4RL: Datasets for Deep Data-Driven Reinforcement Learning' by Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, Sergey Levine.\n",
        "\n",
        "Original Author of the code: Justin Fu\n",
        "\n",
        "The modifications made involve organizing the code into different files: `maps.py`, `maze_env.py`, `point_env.py`, and `point_maze_env.py`.\n",
        "As well as adding support for the Gymnasium API.\n",
        "\n",
        "This project is covered by the Apache 2.0 License.\n",
        "\"\"\"\n",
        "\n",
        "RESET = R = \"r\"  # Initial Reset position of the agent\n",
        "GOAL = G = \"g\"\n",
        "COMBINED = C = \"c\"  # These cells can be selected as goal or reset locations\n",
        "\n",
        "\n",
        "EMPTY_MAZE = [\n",
        "    [1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "OPEN = [\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "OPEN_DIVERSE_G = [\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, R, G, G, G, G, 1],\n",
        "    [1, G, G, G, G, G, 1],\n",
        "    [1, G, G, G, G, G, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "OPEN_DIVERSE_GR = [\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, C, C, C, C, C, 1],\n",
        "    [1, C, C, C, C, C, 1],\n",
        "    [1, C, C, C, C, C, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "# Maze specifications for dataset generation\n",
        "U_MAZE = [\n",
        "    [1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "MEDIUM_MAZE = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 1, 1, 0, 0, 1],\n",
        "    [1, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 1, 0, 0, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 0, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 1, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "MEDIUM_MAZE_DIVERSE_G = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, R, 0, 1, 1, 0, 0, 1],\n",
        "    [1, 0, 0, 1, 0, 0, G, 1],\n",
        "    [1, 1, 0, 0, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, G, 1, 0, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 1, G, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "MEDIUM_MAZE_DIVERSE_GR = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, C, 0, 1, 1, 0, 0, 1],\n",
        "    [1, 0, 0, 1, 0, 0, C, 1],\n",
        "    [1, 1, 0, 0, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, C, 1, 0, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 1, C, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "LARGE_MAZE = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1],\n",
        "    [1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "LARGE_MAZE_DIVERSE_G = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, R, 0, 0, 0, 1, G, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 0, G, 0, 1, 0, 0, G, 1],\n",
        "    [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1],\n",
        "    [1, 0, G, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, G, 0, G, 1, 0, G, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "LARGE_MAZE_DIVERSE_GR = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, C, 0, 0, 0, 1, C, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 0, C, 0, 1, 0, 0, C, 1],\n",
        "    [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1],\n",
        "    [1, 0, C, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, C, 0, C, 1, 0, C, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "J8NiXhdUzmuM"
      },
      "outputs": [],
      "source": [
        "#core.py\n",
        "\n",
        "from abc import abstractmethod\n",
        "from typing import Optional\n",
        "\n",
        "import gymnasium as gym\n",
        "from gymnasium import error\n",
        "\n",
        "\n",
        "class GoalEnv(gym.Env):\n",
        "    r\"\"\"A goal-based environment.\n",
        "\n",
        "    It functions just as any regular Gymnasium environment but it imposes a required structure on the observation_space. More concretely,\n",
        "    the observation space is required to contain at least three elements, namely `observation`, `desired_goal`, and `achieved_goal`.\n",
        "    Here, `desired_goal` specifies the goal that the agent should attempt to achieve. `achieved_goal` is the goal that it currently achieved instead.\n",
        "    `observation` contains the actual observations of the environment as per usual.\n",
        "\n",
        "    - :meth:`compute_reward` - Externalizes the reward function by taking the achieved and desired goal, as well as extra information. Returns reward.\n",
        "    - :meth:`compute_terminated` - Returns boolean termination depending on the achieved and desired goal, as well as extra information.\n",
        "    - :meth:`compute_truncated` - Returns boolean truncation depending on the achieved and desired goal, as well as extra information.\n",
        "    \"\"\"\n",
        "\n",
        "    def reset(\n",
        "        self,\n",
        "        *,\n",
        "        seed: Optional[int] = None,\n",
        "        options: Optional[dict] = None,\n",
        "    ):\n",
        "        \"\"\"Reset the environment.\n",
        "\n",
        "        In addition, check if the observation space is correct by inspecting the `observation`, `achieved_goal`, and `desired_goal` keys.\n",
        "        \"\"\"\n",
        "        super().reset(seed=seed)\n",
        "        # Enforce that each GoalEnv uses a Goal-compatible observation space.\n",
        "        if not isinstance(self.observation_space, gym.spaces.Dict):\n",
        "            raise error.Error(\n",
        "                \"GoalEnv requires an observation space of type gym.spaces.Dict\"\n",
        "            )\n",
        "        for key in [\"observation\", \"achieved_goal\", \"desired_goal\"]:\n",
        "            if key not in self.observation_space.spaces:\n",
        "                raise error.Error(\n",
        "                    'GoalEnv requires the \"{}\" key to be part of the observation dictionary.'.format(\n",
        "                        key\n",
        "                    )\n",
        "                )\n",
        "\n",
        "    @abstractmethod\n",
        "    def compute_reward(self, achieved_goal, desired_goal, info):\n",
        "        \"\"\"Compute the step reward. This externalizes the reward function and makes it dependent on a desired goal and the one that was achieved.\n",
        "\n",
        "        If you wish to include additional rewards that are independent of the goal, you can include the necessary values\n",
        "        to derive it in 'info' and compute it accordingly.\n",
        "\n",
        "        Args:\n",
        "            achieved_goal (object): the goal that was achieved during execution\n",
        "            desired_goal (object): the desired goal that we asked the agent to attempt to achieve\n",
        "            info (dict): an info dictionary with additional information\n",
        "\n",
        "        Returns:\n",
        "            float: The reward that corresponds to the provided achieved goal w.r.t. to the desired\n",
        "            goal. Note that the following should always hold true:\n",
        "\n",
        "                ob, reward, terminated, truncated, info = env.step()\n",
        "                assert reward == env.compute_reward(ob['achieved_goal'], ob['desired_goal'], info)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def compute_terminated(self, achieved_goal, desired_goal, info):\n",
        "        \"\"\"Compute the step termination. Allows to customize the termination states depending on the desired and the achieved goal.\n",
        "\n",
        "        If you wish to determine termination states independent of the goal, you can include necessary values to derive it in 'info'\n",
        "        and compute it accordingly. The envirtonment reaches a termination state when this state leads to an episode ending in an episodic\n",
        "        task thus breaking .\n",
        "\n",
        "        More information can be found in: https://farama.org/New-Step-API#theory\n",
        "\n",
        "        Termination states are\n",
        "\n",
        "        Args:\n",
        "            achieved_goal (object): the goal that was achieved during execution\n",
        "            desired_goal (object): the desired goal that we asked the agent to attempt to achieve\n",
        "            info (dict): an info dictionary with additional information\n",
        "\n",
        "        Returns:\n",
        "            bool: The termination state that corresponds to the provided achieved goal w.r.t. to the desired\n",
        "            goal. Note that the following should always hold true:\n",
        "\n",
        "                ob, reward, terminated, truncated, info = env.step()\n",
        "                assert terminated == env.compute_terminated(ob['achieved_goal'], ob['desired_goal'], info)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def compute_truncated(self, achieved_goal, desired_goal, info):\n",
        "        \"\"\"Compute the step truncation. Allows to customize the truncated states depending on the desired and the achieved goal.\n",
        "\n",
        "        If you wish to determine truncated states independent of the goal, you can include necessary values to derive it in 'info'\n",
        "        and compute it accordingly. Truncated states are those that are out of the scope of the Markov Decision Process (MDP) such\n",
        "        as time constraints in a continuing task.\n",
        "\n",
        "        More information can be found in: https://farama.org/New-Step-API#theory\n",
        "\n",
        "        Args:\n",
        "            achieved_goal (object): the goal that was achieved during execution\n",
        "            desired_goal (object): the desired goal that we asked the agent to attempt to achieve\n",
        "            info (dict): an info dictionary with additional information\n",
        "\n",
        "        Returns:\n",
        "            bool: The truncated state that corresponds to the provided achieved goal w.r.t. to the desired\n",
        "            goal. Note that the following should always hold true:\n",
        "\n",
        "                ob, reward, terminated, truncated, info = env.step()\n",
        "                assert truncated == env.compute_truncated(ob['achieved_goal'], ob['desired_goal'], info)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BTwO5-Hc3k7A"
      },
      "outputs": [],
      "source": [
        "#gymnasium_robotics.envs.maze.maze_v4.py\n",
        "\n",
        "\n",
        "\"\"\"A maze environment with Gymnasium API for the Gymnasium-Robotics PointMaze environments.\n",
        "\n",
        "The code is inspired by the D4RL repository hosted on GitHub (https://github.com/Farama-Foundation/D4RL), published in the paper\n",
        "'D4RL: Datasets for Deep Data-Driven Reinforcement Learning' by Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, Sergey Levine.\n",
        "\n",
        "Original Author of the code: Justin Fu\n",
        "\n",
        "The modifications made involve organizing the code into different files: `maps.py`, `maze_env.py`, `point_env.py`, and `point_maze_env.py`.\n",
        "As well as adding support for the Gymnasium API.\n",
        "\n",
        "This project is covered by the Apache 2.0 License.\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "import tempfile\n",
        "import time\n",
        "import xml.etree.ElementTree as ET\n",
        "from os import path\n",
        "from typing import Dict, List, Optional, Union\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# from gymnasium_robotics.core import GoalEnv\n",
        "# from gymnasium_robotics.envs.maze.maps import COMBINED, GOAL, RESET, U_MAZE\n",
        "\n",
        "\n",
        "class Maze:\n",
        "    r\"\"\"This class creates and holds information about the maze in the MuJoCo simulation.\n",
        "\n",
        "    The accessible attributes are the following:\n",
        "    - :attr:`maze_map` - The maze discrete data structure.\n",
        "    - :attr:`maze_size_scaling` - The maze scaling for the continuous coordinates in the MuJoCo simulation.\n",
        "    - :attr:`maze_height` - The height of the walls in the MuJoCo simulation.\n",
        "    - :attr:`unique_goal_locations` - All the `(i,j)` possible cell indices for goal locations.\n",
        "    - :attr:`unique_reset_locations` - All the `(i,j)` possible cell indices for agent initialization locations.\n",
        "    - :attr:`combined_locations` - All the `(i,j)` possible cell indices for goal and agent initialization locations.\n",
        "    - :attr:`map_length` - Maximum value of j cell index\n",
        "    - :attr:`map_width` - Mazimum value of i cell index\n",
        "    - :attr:`x_map_center` - The x coordinate of the map's center\n",
        "    - :attr:`y_map_center` - The y coordinate of the map's center\n",
        "\n",
        "    The Maze class also presents a method to convert from cell indices to `(x,y)` coordinates in the MuJoCo simulation:\n",
        "    - :meth:`cell_rowcol_to_xy` - Convert from `(i,j)` to `(x,y)`\n",
        "\n",
        "    ### Version History\n",
        "    * v4: Refactor compute_terminated into a pure function compute_terminated and a new function update_goal which resets the goal position. Bug fix: missing maze_size_scaling factor added in generate_reset_pos() -- only affects AntMaze.\n",
        "    * v3: refactor version of the D4RL environment, also create dependency on newest [mujoco python bindings](https://mujoco.readthedocs.io/en/latest/python.html) maintained by the MuJoCo team in Deepmind.\n",
        "    * v2 & v1: legacy versions in the [D4RL](https://github.com/Farama-Foundation/D4RL).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        maze_map: List[List[Union[str, int]]],\n",
        "        maze_size_scaling: float,\n",
        "        maze_height: float,\n",
        "    ):\n",
        "\n",
        "        self._maze_map = maze_map\n",
        "        self._maze_size_scaling = maze_size_scaling\n",
        "        self._maze_height = maze_height\n",
        "\n",
        "        self._unique_goal_locations = []\n",
        "        self._unique_reset_locations = []\n",
        "        self._combined_locations = []\n",
        "\n",
        "        # Get the center cell Cartesian position of the maze. This will be the origin\n",
        "        self._map_length = len(maze_map)\n",
        "        self._map_width = len(maze_map[0])\n",
        "        self._x_map_center = self.map_width / 2 * maze_size_scaling\n",
        "        self._y_map_center = self.map_length / 2 * maze_size_scaling\n",
        "\n",
        "    @property\n",
        "    def maze_map(self) -> List[List[Union[str, int]]]:\n",
        "        \"\"\"Returns the list[list] data structure of the maze.\"\"\"\n",
        "        return self._maze_map\n",
        "\n",
        "    @property\n",
        "    def maze_size_scaling(self) -> float:\n",
        "        \"\"\"Returns the scaling value used to integrate the maze\n",
        "        encoding in the MuJoCo simulation.\n",
        "        \"\"\"\n",
        "        return self._maze_size_scaling\n",
        "\n",
        "    @property\n",
        "    def maze_height(self) -> float:\n",
        "        \"\"\"Returns the un-scaled height of the walls in the MuJoCo\n",
        "        simulation.\n",
        "        \"\"\"\n",
        "        return self._maze_height\n",
        "\n",
        "    @property\n",
        "    def unique_goal_locations(self) -> List[np.ndarray]:\n",
        "        \"\"\"Returns all the possible goal locations in discrete cell\n",
        "        coordinates (i,j)\n",
        "        \"\"\"\n",
        "        return self._unique_goal_locations\n",
        "\n",
        "    @property\n",
        "    def unique_reset_locations(self) -> List[np.ndarray]:\n",
        "        \"\"\"Returns all the possible reset locations for the agent in\n",
        "        discrete cell coordinates (i,j)\n",
        "        \"\"\"\n",
        "        return self._unique_reset_locations\n",
        "\n",
        "    @property\n",
        "    def combined_locations(self) -> List[np.ndarray]:\n",
        "        \"\"\"Returns all the possible goal/reset locations in discrete cell\n",
        "        coordinates (i,j)\n",
        "        \"\"\"\n",
        "        return self._combined_locations\n",
        "\n",
        "    @property\n",
        "    def map_length(self) -> int:\n",
        "        \"\"\"Returns the length of the maze in number of discrete vertical cells\n",
        "        or number of rows i.\n",
        "        \"\"\"\n",
        "        return self._map_length\n",
        "\n",
        "    @property\n",
        "    def map_width(self) -> int:\n",
        "        \"\"\"Returns the width of the maze in number of discrete horizontal cells\n",
        "        or number of columns j.\n",
        "        \"\"\"\n",
        "        return self._map_width\n",
        "\n",
        "    @property\n",
        "    def x_map_center(self) -> float:\n",
        "        \"\"\"Returns the x coordinate of the center of the maze in the MuJoCo simulation\"\"\"\n",
        "        return self._x_map_center\n",
        "\n",
        "    @property\n",
        "    def y_map_center(self) -> float:\n",
        "        \"\"\"Returns the x coordinate of the center of the maze in the MuJoCo simulation\"\"\"\n",
        "        return self._y_map_center\n",
        "\n",
        "    def cell_rowcol_to_xy(self, rowcol_pos: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Converts a cell index `(i,j)` to x and y coordinates in the MuJoCo simulation\"\"\"\n",
        "        x = (rowcol_pos[1] + 0.5) * self.maze_size_scaling - self.x_map_center\n",
        "        y = self.y_map_center - (rowcol_pos[0] + 0.5) * self.maze_size_scaling\n",
        "\n",
        "        return np.array([x, y])\n",
        "\n",
        "    def cell_xy_to_rowcol(self, xy_pos: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Converts a cell x and y coordinates to `(i,j)`\"\"\"\n",
        "        i = math.floor((self.y_map_center - xy_pos[1]) / self.maze_size_scaling)\n",
        "        j = math.floor((xy_pos[0] + self.x_map_center) / self.maze_size_scaling)\n",
        "        return np.array([i, j])\n",
        "\n",
        "    @classmethod\n",
        "    def make_maze(\n",
        "        cls,\n",
        "        agent_xml_path: str,\n",
        "        maze_map: list,\n",
        "        maze_size_scaling: float,\n",
        "        maze_height: float,\n",
        "    ):\n",
        "        \"\"\"Class method that returns an instance of Maze with a decoded maze information and the temporal\n",
        "           path to the new MJCF (xml) file for the MuJoCo simulation.\n",
        "\n",
        "        Args:\n",
        "            agent_xml_path (str): the goal that was achieved during execution\n",
        "            maze_map (list[list[str,int]]): the desired goal that we asked the agent to attempt to achieve\n",
        "            maze_size_scaling (float): an info dictionary with additional information\n",
        "            maze_height (float): an info dictionary with additional information\n",
        "\n",
        "        Returns:\n",
        "            Maze: The reward that corresponds to the provided achieved goal w.r.t. to the desired\n",
        "            goal. Note that the following should always hold true:\n",
        "            str: The xml temporal file to the new mjcf model with the included maze.\n",
        "        \"\"\"\n",
        "        tree = ET.parse(agent_xml_path)\n",
        "        worldbody = tree.find(\".//worldbody\")\n",
        "\n",
        "        maze = cls(maze_map, maze_size_scaling, maze_height)\n",
        "        empty_locations = []\n",
        "        for i in range(maze.map_length):\n",
        "            for j in range(maze.map_width):\n",
        "                struct = maze_map[i][j]\n",
        "                # Store cell locations in simulation global Cartesian coordinates\n",
        "                x = (j + 0.5) * maze_size_scaling - maze.x_map_center\n",
        "                y = maze.y_map_center - (i + 0.5) * maze_size_scaling\n",
        "                if struct == 1:  # Unmovable block.\n",
        "                    # Offset all coordinates so that maze is centered.\n",
        "                    ET.SubElement(\n",
        "                        worldbody,\n",
        "                        \"geom\",\n",
        "                        name=f\"block_{i}_{j}\",\n",
        "                        pos=f\"{x} {y} {maze_height / 2 * maze_size_scaling}\",\n",
        "                        size=f\"{0.5 * maze_size_scaling} {0.5 * maze_size_scaling} {maze_height / 2 * maze_size_scaling}\",\n",
        "                        type=\"box\",\n",
        "                        material=\"\",\n",
        "                        contype=\"1\",\n",
        "                        conaffinity=\"1\",\n",
        "                        rgba=\"0.7 0.5 0.3 1.0\",\n",
        "                    )\n",
        "\n",
        "                elif struct == RESET:\n",
        "                    maze._unique_reset_locations.append(np.array([x, y]))\n",
        "                elif struct == GOAL:\n",
        "                    maze._unique_goal_locations.append(np.array([x, y]))\n",
        "                elif struct == COMBINED:\n",
        "                    maze._combined_locations.append(np.array([x, y]))\n",
        "                elif struct == 0:\n",
        "                    empty_locations.append(np.array([x, y]))\n",
        "\n",
        "        # Add target site for visualization\n",
        "        ET.SubElement(\n",
        "            worldbody,\n",
        "            \"site\",\n",
        "            name=\"target\",\n",
        "            pos=f\"0 0 {maze_height / 2 * maze_size_scaling}\",\n",
        "            size=f\"{0.2 * maze_size_scaling}\",\n",
        "            rgba=\"1 0 0 0\",\n",
        "            type=\"sphere\",\n",
        "        )\n",
        "\n",
        "        # Add the combined cell locations (goal/reset) to goal and reset\n",
        "        if (\n",
        "            not maze._unique_goal_locations\n",
        "            and not maze._unique_reset_locations\n",
        "            and not maze._combined_locations\n",
        "        ):\n",
        "            # If there are no given \"r\", \"g\" or \"c\" cells in the maze data structure,\n",
        "            # any empty cell can be a reset or goal location at initialization.\n",
        "            maze._combined_locations = empty_locations\n",
        "        elif not maze._unique_reset_locations and not maze._combined_locations:\n",
        "            # If there are no given \"r\" or \"c\" cells in the maze data structure,\n",
        "            # any empty cell can be a reset location at initialization.\n",
        "            maze._unique_reset_locations = empty_locations\n",
        "        elif not maze._unique_goal_locations and not maze._combined_locations:\n",
        "            # If there are no given \"g\" or \"c\" cells in the maze data structure,\n",
        "            # any empty cell can be a gaol location at initialization.\n",
        "            maze._unique_goal_locations = empty_locations\n",
        "\n",
        "        maze._unique_goal_locations += maze._combined_locations\n",
        "        maze._unique_reset_locations += maze._combined_locations\n",
        "\n",
        "        # Save new xml with maze to a temporary file\n",
        "        with tempfile.TemporaryDirectory() as tmp_dir:\n",
        "            temp_xml_name = f\"ant_maze{str(time.time())}.xml\"\n",
        "            temp_xml_path = path.join(path.dirname(tmp_dir), temp_xml_name)\n",
        "            tree.write(temp_xml_path)\n",
        "\n",
        "        return maze, temp_xml_path\n",
        "\n",
        "\n",
        "class MazeEnv(GoalEnv):\n",
        "    def __init__(\n",
        "        self,\n",
        "        agent_xml_path: str,\n",
        "        reward_type: str = \"dense\",\n",
        "        continuing_task: bool = True,\n",
        "        reset_target: bool = True,\n",
        "        maze_map: List[List[Union[int, str]]] = U_MAZE,\n",
        "        maze_size_scaling: float = 1.0,\n",
        "        maze_height: float = 0.5,\n",
        "        position_noise_range: float = 0.25,\n",
        "        **kwargs,\n",
        "    ):\n",
        "\n",
        "        self.reward_type = reward_type\n",
        "        self.continuing_task = continuing_task\n",
        "        self.reset_target = reset_target\n",
        "        self.maze, self.tmp_xml_file_path = Maze.make_maze(\n",
        "            agent_xml_path, maze_map, maze_size_scaling, maze_height\n",
        "        )\n",
        "\n",
        "        self.position_noise_range = position_noise_range\n",
        "\n",
        "    def generate_target_goal(self) -> np.ndarray:\n",
        "        assert len(self.maze.unique_goal_locations) > 0\n",
        "        goal_index = self.np_random.integers(\n",
        "            low=0, high=len(self.maze.unique_goal_locations)\n",
        "        )\n",
        "        goal = self.maze.unique_goal_locations[goal_index].copy()\n",
        "        return goal\n",
        "\n",
        "    def generate_reset_pos(self) -> np.ndarray:\n",
        "        assert len(self.maze.unique_reset_locations) > 0\n",
        "\n",
        "        # While reset position is close to goal position\n",
        "        reset_pos = self.goal.copy()\n",
        "        while (\n",
        "            np.linalg.norm(reset_pos - self.goal) <= 0.5 * self.maze.maze_size_scaling\n",
        "        ):\n",
        "            reset_index = self.np_random.integers(\n",
        "                low=0, high=len(self.maze.unique_reset_locations)\n",
        "            )\n",
        "            reset_pos = self.maze.unique_reset_locations[reset_index].copy()\n",
        "\n",
        "        return reset_pos\n",
        "\n",
        "    def reset(\n",
        "        self,\n",
        "        *,\n",
        "        seed: Optional[int] = None,\n",
        "        options: Optional[Dict[str, Optional[np.ndarray]]] = None,\n",
        "    ):\n",
        "        \"\"\"Reset the maze simulation.\n",
        "\n",
        "        Args:\n",
        "            options (dict[str, np.ndarray]): the options dictionary can contain two items, \"goal_cell\" and \"reset_cell\" that will set the initial goal and reset location (i,j) in the self.maze.map list of list maze structure.\n",
        "\n",
        "        \"\"\"\n",
        "        super().reset(seed=seed)\n",
        "\n",
        "        if options is None:\n",
        "            goal = self.generate_target_goal()\n",
        "            # Add noise to goal position\n",
        "            self.goal = self.add_xy_position_noise(goal)\n",
        "            reset_pos = self.generate_reset_pos()\n",
        "        else:\n",
        "            if \"goal_cell\" in options and options[\"goal_cell\"] is not None:\n",
        "                # assert that goal cell is valid\n",
        "                assert self.maze.map_length > options[\"goal_cell\"][0]\n",
        "                assert self.maze.map_width > options[\"goal_cell\"][1]\n",
        "                assert (\n",
        "                    self.maze.maze_map[options[\"goal_cell\"][0]][options[\"goal_cell\"][1]]\n",
        "                    != 1\n",
        "                ), f\"Goal can't be placed in a wall cell, {options['goal_cell']}\"\n",
        "\n",
        "                goal = self.maze.cell_rowcol_to_xy(options[\"goal_cell\"])\n",
        "\n",
        "            else:\n",
        "                goal = self.generate_target_goal()\n",
        "\n",
        "            # Add noise to goal position\n",
        "            self.goal = self.add_xy_position_noise(goal)\n",
        "\n",
        "            if \"reset_cell\" in options and options[\"reset_cell\"] is not None:\n",
        "                # assert that goal cell is valid\n",
        "                assert self.maze.map_length > options[\"reset_cell\"][0]\n",
        "                assert self.maze.map_width > options[\"reset_cell\"][1]\n",
        "                assert (\n",
        "                    self.maze.maze_map[options[\"reset_cell\"][0]][\n",
        "                        options[\"reset_cell\"][1]\n",
        "                    ]\n",
        "                    != 1\n",
        "                ), f\"Reset can't be placed in a wall cell, {options['reset_cell']}\"\n",
        "\n",
        "                reset_pos = self.maze.cell_rowcol_to_xy(options[\"reset_cell\"])\n",
        "\n",
        "            else:\n",
        "                reset_pos = self.generate_reset_pos()\n",
        "\n",
        "        # Update the position of the target site for visualization\n",
        "        self.update_target_site_pos()\n",
        "        # Add noise to reset position\n",
        "        self.reset_pos = self.add_xy_position_noise(reset_pos)\n",
        "\n",
        "        # Update the position of the target site for visualization\n",
        "        self.update_target_site_pos()\n",
        "\n",
        "    def add_xy_position_noise(self, xy_pos: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Pass an x,y coordinate and it will return the same coordinate with a noise addition\n",
        "        sampled from a uniform distribution\n",
        "        \"\"\"\n",
        "        noise_x = (\n",
        "            self.np_random.uniform(\n",
        "                low=-self.position_noise_range, high=self.position_noise_range\n",
        "            )\n",
        "            * self.maze.maze_size_scaling\n",
        "        )\n",
        "        noise_y = (\n",
        "            self.np_random.uniform(\n",
        "                low=-self.position_noise_range, high=self.position_noise_range\n",
        "            )\n",
        "            * self.maze.maze_size_scaling\n",
        "        )\n",
        "        xy_pos[0] += noise_x\n",
        "        xy_pos[1] += noise_y\n",
        "\n",
        "        return xy_pos\n",
        "\n",
        "    def compute_reward(\n",
        "        self, achieved_goal: np.ndarray, desired_goal: np.ndarray, info\n",
        "    ) -> float:\n",
        "        distance = np.linalg.norm(achieved_goal - desired_goal, axis=-1)\n",
        "        if self.reward_type == \"dense\":\n",
        "            return np.exp(-distance)\n",
        "        elif self.reward_type == \"sparse\":\n",
        "            return (distance <= 0.45).astype(np.float64)\n",
        "\n",
        "    def compute_terminated(\n",
        "        self, achieved_goal: np.ndarray, desired_goal: np.ndarray, info\n",
        "    ) -> bool:\n",
        "        if not self.continuing_task:\n",
        "            # If task is episodic terminate the episode when the goal is reached\n",
        "            return bool(np.linalg.norm(achieved_goal - desired_goal) <= 0.45)\n",
        "        else:\n",
        "            # Continuing tasks don't terminate, episode will be truncated when time limit is reached (`max_episode_steps`)\n",
        "            return False\n",
        "\n",
        "    def update_goal(self, achieved_goal: np.ndarray) -> None:\n",
        "        \"\"\"Update goal position if continuing task and within goal radius.\"\"\"\n",
        "\n",
        "        if (\n",
        "            self.continuing_task\n",
        "            and self.reset_target\n",
        "            and bool(np.linalg.norm(achieved_goal - self.goal) <= 0.45)\n",
        "            and len(self.maze.unique_goal_locations) > 1\n",
        "        ):\n",
        "            # Generate a goal while within 0.45 of achieved_goal. The distance check above\n",
        "            # is not redundant, it avoids calling update_target_site_pos() unless necessary\n",
        "            while np.linalg.norm(achieved_goal - self.goal) <= 0.45:\n",
        "                # Generate another goal\n",
        "                goal = self.generate_target_goal()\n",
        "                # Add noise to goal position\n",
        "                self.goal = self.add_xy_position_noise(goal)\n",
        "\n",
        "            # Update the position of the target site for visualization\n",
        "            self.update_target_site_pos()\n",
        "\n",
        "    def compute_truncated(\n",
        "        self, achieved_goal: np.ndarray, desired_goal: np.ndarray, info\n",
        "    ) -> bool:\n",
        "        return False\n",
        "\n",
        "    def update_target_site_pos(self, pos):\n",
        "        \"\"\"Override this method to update the site qpos in the MuJoCo simulation\n",
        "        after a new goal is selected. This is mainly for visualization purposes.\"\"\"\n",
        "        raise NotImplementedError\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nJrY82ddynPi"
      },
      "outputs": [],
      "source": [
        "#gymnasium_robotics.envs.utils.mujoco_utils.py\n",
        "\n",
        "from typing import Dict, Tuple, Union\n",
        "\n",
        "import numpy as np\n",
        "from gymnasium import error\n",
        "\n",
        "try:\n",
        "    import mujoco\n",
        "    from mujoco import MjData, MjModel, mjtObj\n",
        "except ImportError as e:\n",
        "    raise error.DependencyNotInstalled(f\"{e}. (HINT: you need to install mujoco\")\n",
        "\n",
        "MJ_OBJ_TYPES = [\n",
        "    \"mjOBJ_BODY\",\n",
        "    \"mjOBJ_JOINT\",\n",
        "    \"mjOBJ_GEOM\",\n",
        "    \"mjOBJ_SITE\",\n",
        "    \"mjOBJ_CAMERA\",\n",
        "    \"mjOBJ_ACTUATOR\",\n",
        "    \"mjOBJ_SENSOR\",\n",
        "]\n",
        "\n",
        "\n",
        "def robot_get_obs(model, data, joint_names):\n",
        "    \"\"\"Returns all joint positions and velocities associated with a robot.\"\"\"\n",
        "    if data.qpos is not None and joint_names:\n",
        "        names = [n for n in joint_names if n.startswith(\"robot\")]\n",
        "        return (\n",
        "            np.squeeze(np.array([get_joint_qpos(model, data, name) for name in names])),\n",
        "            np.squeeze(np.array([get_joint_qvel(model, data, name) for name in names])),\n",
        "        )\n",
        "    return np.zeros(0), np.zeros(0)\n",
        "\n",
        "\n",
        "def ctrl_set_action(model, data, action):\n",
        "    \"\"\"For torque actuators it copies the action into mujoco ctrl field.\n",
        "\n",
        "    For position actuators it sets the target relative to the current qpos.\n",
        "    \"\"\"\n",
        "    if model.nmocap > 0:\n",
        "        _, action = np.split(action, (model.nmocap * 7,))\n",
        "\n",
        "    if len(data.ctrl) > 0:\n",
        "        for i in range(action.shape[0]):\n",
        "            if model.actuator_biastype[i] == 0:\n",
        "                data.ctrl[i] = action[i]\n",
        "            else:\n",
        "                idx = model.jnt_qposadr[model.actuator_trnid[i, 0]]\n",
        "                data.ctrl[i] = data.qpos[idx] + action[i]\n",
        "\n",
        "\n",
        "def mocap_set_action(model, data, action):\n",
        "    \"\"\"Update the position of the mocap body with the desired action.\n",
        "\n",
        "    The action controls the robot using mocaps. Specifically, bodies\n",
        "    on the robot (for example the gripper wrist) is controlled with\n",
        "    mocap bodies. In this case the action is the desired difference\n",
        "    in position and orientation (quaternion), in world coordinates,\n",
        "    of the target body. The mocap is positioned relative to\n",
        "    the target body according to the delta, and the MuJoCo equality\n",
        "    constraint optimizer tries to center the welded body on the mocap.\n",
        "    \"\"\"\n",
        "    if model.nmocap > 0:\n",
        "        action, _ = np.split(action, (model.nmocap * 7,))\n",
        "        action = action.reshape(model.nmocap, 7)\n",
        "\n",
        "        pos_delta = action[:, :3]\n",
        "        quat_delta = action[:, 3:]\n",
        "\n",
        "        reset_mocap2body_xpos(model, data)\n",
        "        data.mocap_pos[:] = data.mocap_pos + pos_delta\n",
        "        data.mocap_quat[:] = data.mocap_quat + quat_delta\n",
        "\n",
        "\n",
        "def reset_mocap_welds(model, data):\n",
        "    \"\"\"Resets the mocap welds that we use for actuation.\"\"\"\n",
        "    if model.nmocap > 0 and model.eq_data is not None:\n",
        "        for i in range(model.eq_data.shape[0]):\n",
        "            if model.eq_type[i] == mujoco.mjtEq.mjEQ_WELD:\n",
        "                model.eq_data[i, :7] = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
        "    mujoco.mj_forward(model, data)\n",
        "\n",
        "\n",
        "def reset_mocap2body_xpos(model, data):\n",
        "    \"\"\"Resets the position and orientation of the mocap bodies to the same\n",
        "    values as the bodies they're welded to.\n",
        "    \"\"\"\n",
        "\n",
        "    if model.eq_type is None or model.eq_obj1id is None or model.eq_obj2id is None:\n",
        "        return\n",
        "    for eq_type, obj1_id, obj2_id in zip(\n",
        "        model.eq_type, model.eq_obj1id, model.eq_obj2id\n",
        "    ):\n",
        "        if eq_type != mujoco.mjtEq.mjEQ_WELD:\n",
        "            continue\n",
        "\n",
        "        mocap_id = model.body_mocapid[obj1_id]\n",
        "        if mocap_id != -1:\n",
        "            # obj1 is the mocap, obj2 is the welded body\n",
        "            body_idx = obj2_id\n",
        "        else:\n",
        "            # obj2 is the mocap, obj1 is the welded body\n",
        "            mocap_id = model.body_mocapid[obj2_id]\n",
        "            body_idx = obj1_id\n",
        "\n",
        "        assert mocap_id != -1\n",
        "        data.mocap_pos[mocap_id][:] = data.xpos[body_idx]\n",
        "        data.mocap_quat[mocap_id][:] = data.xquat[body_idx]\n",
        "\n",
        "\n",
        "def get_site_jacp(model, data, site_id):\n",
        "    \"\"\"Return the Jacobian' translational component of the end-effector of\n",
        "    the corresponding site id.\n",
        "    \"\"\"\n",
        "    jacp = np.zeros((3, model.nv))\n",
        "    mujoco.mj_jacSite(model, data, jacp, None, site_id)\n",
        "\n",
        "    return jacp\n",
        "\n",
        "\n",
        "def get_site_jacr(model, data, site_id):\n",
        "    \"\"\"Return the Jacobian' rotational component of the end-effector of\n",
        "    the corresponding site id.\n",
        "    \"\"\"\n",
        "    jacr = np.zeros((3, model.nv))\n",
        "    mujoco.mj_jacSite(model, data, None, jacr, site_id)\n",
        "\n",
        "    return jacr\n",
        "\n",
        "\n",
        "def set_joint_qpos(model, data, name, value):\n",
        "    \"\"\"Set the joint positions (qpos) of the model.\"\"\"\n",
        "    joint_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_JOINT, name)\n",
        "    assert joint_id != -1, f\"Joint with name '{name}' is not part of the model!\"\n",
        "    joint_type = model.jnt_type[joint_id]\n",
        "    joint_addr = model.jnt_qposadr[joint_id]\n",
        "\n",
        "    if joint_type == mujoco.mjtJoint.mjJNT_FREE:\n",
        "        ndim = 7\n",
        "    elif joint_type == mujoco.mjtJoint.mjJNT_BALL:\n",
        "        ndim = 4\n",
        "    else:\n",
        "        assert joint_type in (mujoco.mjtJoint.mjJNT_HINGE, mujoco.mjtJoint.mjJNT_SLIDE)\n",
        "        ndim = 1\n",
        "\n",
        "    start_idx = joint_addr\n",
        "    end_idx = joint_addr + ndim\n",
        "    value = np.array(value)\n",
        "    if ndim > 1:\n",
        "        assert value.shape == (\n",
        "            end_idx - start_idx\n",
        "        ), f\"Value has incorrect shape {name}: {value}\"\n",
        "    data.qpos[start_idx:end_idx] = value\n",
        "\n",
        "\n",
        "def set_joint_qvel(model, data, name, value):\n",
        "    \"\"\"Set the joints linear and angular (qvel) of the model.\"\"\"\n",
        "    joint_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_JOINT, name)\n",
        "    assert joint_id != -1, f\"Joint with name '{name}' is not part of the model!\"\n",
        "    joint_type = model.jnt_type[joint_id]\n",
        "    joint_addr = model.jnt_dofadr[joint_id]\n",
        "\n",
        "    if joint_type == mujoco.mjtJoint.mjJNT_FREE:\n",
        "        ndim = 6\n",
        "    elif joint_type == mujoco.mjtJoint.mjJNT_BALL:\n",
        "        ndim = 3\n",
        "    else:\n",
        "        assert joint_type in (mujoco.mjtJoint.mjJNT_HINGE, mujoco.mjtJoint.mjJNT_SLIDE)\n",
        "        ndim = 1\n",
        "\n",
        "    start_idx = joint_addr\n",
        "    end_idx = joint_addr + ndim\n",
        "    value = np.array(value)\n",
        "    if ndim > 1:\n",
        "        assert value.shape == (\n",
        "            end_idx - start_idx\n",
        "        ), f\"Value has incorrect shape {name}: {value}\"\n",
        "    data.qvel[start_idx:end_idx] = value\n",
        "\n",
        "\n",
        "def get_joint_qpos(model, data, name):\n",
        "    \"\"\"Return the joints position and orientation (qpos) of the model.\"\"\"\n",
        "    joint_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_JOINT, name)\n",
        "    assert joint_id != -1, f\"Joint with name '{name}' is not part of the model!\"\n",
        "    joint_type = model.jnt_type[joint_id]\n",
        "    joint_addr = model.jnt_qposadr[joint_id]\n",
        "\n",
        "    if joint_type == mujoco.mjtJoint.mjJNT_FREE:\n",
        "        ndim = 7\n",
        "    elif joint_type == mujoco.mjtJoint.mjJNT_BALL:\n",
        "        ndim = 4\n",
        "    else:\n",
        "        assert joint_type in (mujoco.mjtJoint.mjJNT_HINGE, mujoco.mjtJoint.mjJNT_SLIDE)\n",
        "        ndim = 1\n",
        "\n",
        "    start_idx = joint_addr\n",
        "    end_idx = joint_addr + ndim\n",
        "\n",
        "    return data.qpos[start_idx:end_idx].copy()\n",
        "\n",
        "\n",
        "def get_joint_qvel(model, data, name):\n",
        "    \"\"\"Return the joints linear and angular velocities (qvel) of the model.\"\"\"\n",
        "    joint_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_JOINT, name)\n",
        "    assert joint_id != -1, f\"Joint with name '{name}' is not part of the model!\"\n",
        "    joint_type = model.jnt_type[joint_id]\n",
        "    joint_addr = model.jnt_dofadr[joint_id]\n",
        "\n",
        "    if joint_type == mujoco.mjtJoint.mjJNT_FREE:\n",
        "        ndim = 6\n",
        "    elif joint_type == mujoco.mjtJoint.mjJNT_BALL:\n",
        "        ndim = 4\n",
        "    else:\n",
        "        assert joint_type in (mujoco.mjtJoint.mjJNT_HINGE, mujoco.mjtJoint.mjJNT_SLIDE)\n",
        "        ndim = 1\n",
        "\n",
        "    start_idx = joint_addr\n",
        "    end_idx = joint_addr + ndim\n",
        "\n",
        "    return data.qvel[start_idx:end_idx].copy()\n",
        "\n",
        "\n",
        "def get_site_xpos(model, data, name):\n",
        "    site_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_SITE, name)\n",
        "    assert site_id != -1, f\"Site with name '{name}' is not part of the model!\"\n",
        "    return data.site_xpos[site_id]\n",
        "\n",
        "\n",
        "def get_site_xvelp(model, data, name):\n",
        "    site_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_SITE, name)\n",
        "    assert site_id != -1, f\"Site with name '{name}' is not part of the model!\"\n",
        "    jacp = get_site_jacp(model, data, site_id)\n",
        "    xvelp = jacp @ data.qvel\n",
        "    return xvelp\n",
        "\n",
        "\n",
        "def get_site_xvelr(model, data, name):\n",
        "    site_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_SITE, name)\n",
        "    assert site_id != -1, f\"Site with name '{name}' is not part of the model!\"\n",
        "    jacp = get_site_jacr(model, data, site_id)\n",
        "    xvelp = jacp @ data.qvel\n",
        "    return xvelp\n",
        "\n",
        "\n",
        "def set_mocap_pos(model, data, name, value):\n",
        "    body_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_BODY, name)\n",
        "    assert body_id != -1, f\"Body with name '{name}' is not part of the model!\"\n",
        "    mocap_id = model.body_mocapid[body_id]\n",
        "    data.mocap_pos[mocap_id] = value\n",
        "\n",
        "\n",
        "def set_mocap_quat(model: MjModel, data: MjData, name: str, value):\n",
        "    body_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_BODY, name)\n",
        "    assert body_id != -1, f\"Body with name '{name}' is not part of the model!\"\n",
        "    mocap_id = model.body_mocapid[body_id]\n",
        "    data.mocap_quat[mocap_id] = value\n",
        "\n",
        "\n",
        "def get_site_xmat(model: MjModel, data: MjData, name: str):\n",
        "    site_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_SITE, name)\n",
        "    assert site_id != -1, f\"Site with name '{name}' is not part of the model!\"\n",
        "    return data.site_xmat[site_id].reshape(3, 3)\n",
        "\n",
        "\n",
        "def extract_mj_names(\n",
        "    model: MjModel, obj_type: mjtObj\n",
        ") -> Tuple[Union[Tuple[str, ...], Tuple[()]], Dict[str, int], Dict[int, str]]:\n",
        "\n",
        "    if obj_type == mujoco.mjtObj.mjOBJ_BODY:\n",
        "        name_addr = model.name_bodyadr\n",
        "        n_obj = model.nbody\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_JOINT:\n",
        "        name_addr = model.name_jntadr\n",
        "        n_obj = model.njnt\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_GEOM:\n",
        "        name_addr = model.name_geomadr\n",
        "        n_obj = model.ngeom\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_SITE:\n",
        "        name_addr = model.name_siteadr\n",
        "        n_obj = model.nsite\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_LIGHT:\n",
        "        name_addr = model.name_lightadr\n",
        "        n_obj = model.nlight\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_CAMERA:\n",
        "        name_addr = model.name_camadr\n",
        "        n_obj = model.ncam\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_ACTUATOR:\n",
        "        name_addr = model.name_actuatoradr\n",
        "        n_obj = model.nu\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_SENSOR:\n",
        "        name_addr = model.name_sensoradr\n",
        "        n_obj = model.nsensor\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_TENDON:\n",
        "        name_addr = model.name_tendonadr\n",
        "        n_obj = model.ntendon\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_MESH:\n",
        "        name_addr = model.name_meshadr\n",
        "        n_obj = model.nmesh\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"`{}` was passed as the MuJoCo model object type. The MuJoCo model object type can only be of the following mjtObj enum types: {}.\".format(\n",
        "                obj_type, MJ_OBJ_TYPES\n",
        "            )\n",
        "        )\n",
        "\n",
        "    id2name = {i: None for i in range(n_obj)}\n",
        "    name2id = {}\n",
        "    for addr in name_addr:\n",
        "        name = model.names[addr:].split(b\"\\x00\")[0].decode()\n",
        "        if name:\n",
        "            obj_id = mujoco.mj_name2id(model, obj_type, name)\n",
        "            assert 0 <= obj_id < n_obj and id2name[obj_id] is None\n",
        "            name2id[name] = obj_id\n",
        "            id2name[obj_id] = name\n",
        "\n",
        "    return tuple(id2name[id] for id in sorted(name2id.values())), name2id, id2name\n",
        "\n",
        "\n",
        "class MujocoModelNames:\n",
        "    \"\"\"Access mjtObj object names and ids of the current MuJoCo model.\n",
        "\n",
        "    This class supports access to the names and ids of the following mjObj types:\n",
        "        mjOBJ_BODY\n",
        "        mjOBJ_JOINT\n",
        "        mjOBJ_GEOM\n",
        "        mjOBJ_SITE\n",
        "        mjOBJ_CAMERA\n",
        "        mjOBJ_ACTUATOR\n",
        "        mjOBJ_SENSOR\n",
        "\n",
        "    The properties provided for each ``mjObj`` are:\n",
        "        ``mjObj``_names: list of the mjObj names in the model of type mjOBJ_FOO.\n",
        "        ``mjObj``_name2id: dictionary with name of the mjObj as keys and id of the mjObj as values.\n",
        "        ``mjObj``_id2name: dictionary with id of the mjObj as keys and name of the mjObj as values.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model: MjModel):\n",
        "        \"\"\"Access mjtObj object names and ids of the current MuJoCo model.\n",
        "\n",
        "        Args:\n",
        "            model: mjModel of the MuJoCo environment.\n",
        "        \"\"\"\n",
        "        (\n",
        "            self._body_names,\n",
        "            self._body_name2id,\n",
        "            self._body_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_BODY)\n",
        "        (\n",
        "            self._joint_names,\n",
        "            self._joint_name2id,\n",
        "            self._joint_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_JOINT)\n",
        "        (\n",
        "            self._geom_names,\n",
        "            self._geom_name2id,\n",
        "            self._geom_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_GEOM)\n",
        "        (\n",
        "            self._site_names,\n",
        "            self._site_name2id,\n",
        "            self._site_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_SITE)\n",
        "        (\n",
        "            self._camera_names,\n",
        "            self._camera_name2id,\n",
        "            self._camera_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_CAMERA)\n",
        "        (\n",
        "            self._actuator_names,\n",
        "            self._actuator_name2id,\n",
        "            self._actuator_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_ACTUATOR)\n",
        "        (\n",
        "            self._sensor_names,\n",
        "            self._sensor_name2id,\n",
        "            self._sensor_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_SENSOR)\n",
        "\n",
        "    @property\n",
        "    def body_names(self):\n",
        "        return self._body_names\n",
        "\n",
        "    @property\n",
        "    def body_name2id(self):\n",
        "        return self._body_name2id\n",
        "\n",
        "    @property\n",
        "    def body_id2name(self):\n",
        "        return self._body_id2name\n",
        "\n",
        "    @property\n",
        "    def joint_names(self):\n",
        "        return self._joint_names\n",
        "\n",
        "    @property\n",
        "    def joint_name2id(self):\n",
        "        return self._joint_name2id\n",
        "\n",
        "    @property\n",
        "    def joint_id2name(self):\n",
        "        return self._joint_id2name\n",
        "\n",
        "    @property\n",
        "    def geom_names(self):\n",
        "        return self._geom_names\n",
        "\n",
        "    @property\n",
        "    def geom_name2id(self):\n",
        "        return self._geom_name2id\n",
        "\n",
        "    @property\n",
        "    def geom_id2name(self):\n",
        "        return self._geom_id2name\n",
        "\n",
        "    @property\n",
        "    def site_names(self):\n",
        "        return self._site_names\n",
        "\n",
        "    @property\n",
        "    def site_name2id(self):\n",
        "        return self._site_name2id\n",
        "\n",
        "    @property\n",
        "    def site_id2name(self):\n",
        "        return self._site_id2name\n",
        "\n",
        "    @property\n",
        "    def camera_names(self):\n",
        "        return self._camera_names\n",
        "\n",
        "    @property\n",
        "    def camera_name2id(self):\n",
        "        return self._camera_name2id\n",
        "\n",
        "    @property\n",
        "    def camera_id2name(self):\n",
        "        return self._camera_id2name\n",
        "\n",
        "    @property\n",
        "    def actuator_names(self):\n",
        "        return self._actuator_names\n",
        "\n",
        "    @property\n",
        "    def actuator_name2id(self):\n",
        "        return self._actuator_name2id\n",
        "\n",
        "    @property\n",
        "    def actuator_id2name(self):\n",
        "        return self._actuator_id2name\n",
        "\n",
        "    @property\n",
        "    def sensor_names(self):\n",
        "        return self._sensor_names\n",
        "\n",
        "    @property\n",
        "    def sensor_name2id(self):\n",
        "        return self._sensor_name2id\n",
        "\n",
        "    @property\n",
        "    def sensor_id2name(self):\n",
        "        return self._sensor_id2name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "by4KHCH_3wdS"
      },
      "outputs": [],
      "source": [
        "#ant_maze_v5.py\n",
        "\n",
        "import sys\n",
        "from os import path\n",
        "from typing import Dict, List, Optional, Union\n",
        "\n",
        "import numpy as np\n",
        "from gymnasium import spaces\n",
        "from gymnasium.envs.mujoco.ant_v5 import AntEnv\n",
        "from gymnasium.utils.ezpickle import EzPickle\n",
        "\n",
        "# from gymnasium_robotics.envs.maze.maps import U_MAZE\n",
        "# from gymnasium_robotics.envs.maze.maze_v4 import MazeEnv\n",
        "# from gymnasium_robotics.utils.mujoco_utils import MujocoModelNames\n",
        "\n",
        "\n",
        "class AntMazeEnv(MazeEnv, EzPickle):\n",
        "\n",
        "    metadata = {\n",
        "        \"render_modes\": [\n",
        "            \"human\",\n",
        "            \"rgb_array\",\n",
        "            \"depth_array\",\n",
        "        ],\n",
        "        \"render_fps\": 50,\n",
        "    }\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        render_mode: Optional[str] = None,\n",
        "        maze_map: List[List[Union[str, int]]] = U_MAZE,\n",
        "        reward_type: str = \"sparse\",\n",
        "        continuing_task: bool = True,\n",
        "        reset_target: bool = False,\n",
        "        xml_file: Union[str, None] = None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        if xml_file is None:\n",
        "            # Get the ant.xml path from the Gymnasium package\n",
        "            ant_xml_file_path = path.join(\n",
        "                path.dirname(sys.modules[AntEnv.__module__].__file__), \"assets/ant.xml\"\n",
        "            )\n",
        "        else:\n",
        "            ant_xml_file_path = xml_file\n",
        "        super().__init__(\n",
        "            agent_xml_path=ant_xml_file_path,\n",
        "            maze_map=maze_map,\n",
        "            maze_size_scaling=4,\n",
        "            maze_height=0.5,\n",
        "            reward_type=reward_type,\n",
        "            continuing_task=continuing_task,\n",
        "            reset_target=reset_target,\n",
        "            **kwargs,\n",
        "        )\n",
        "        # Create the MuJoCo environment, include position observation of the Ant for GoalEnv\n",
        "        self.ant_env = AntEnv(\n",
        "            xml_file=self.tmp_xml_file_path,\n",
        "            exclude_current_positions_from_observation=False,\n",
        "            render_mode=render_mode,\n",
        "            reset_noise_scale=0.0,\n",
        "            **kwargs,\n",
        "        )\n",
        "        self._model_names = MujocoModelNames(self.ant_env.model)\n",
        "        self.target_site_id = self._model_names.site_name2id[\"target\"]\n",
        "\n",
        "        self.action_space = self.ant_env.action_space\n",
        "        obs_shape: tuple = self.ant_env.observation_space.shape\n",
        "        self.observation_space = spaces.Dict(\n",
        "            dict(\n",
        "                observation=spaces.Box(\n",
        "                    -np.inf, np.inf, shape=(obs_shape[0] - 2,), dtype=\"float64\"\n",
        "                ),\n",
        "                achieved_goal=spaces.Box(-np.inf, np.inf, shape=(2,), dtype=\"float64\"),\n",
        "                desired_goal=spaces.Box(-np.inf, np.inf, shape=(2,), dtype=\"float64\"),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.render_mode = render_mode\n",
        "        EzPickle.__init__(\n",
        "            self,\n",
        "            render_mode,\n",
        "            maze_map,\n",
        "            reward_type,\n",
        "            continuing_task,\n",
        "            reset_target,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    def reset(self, *, seed: Optional[int] = None, **kwargs):\n",
        "        super().reset(seed=seed, **kwargs)\n",
        "\n",
        "        self.ant_env.init_qpos[:2] = self.reset_pos\n",
        "\n",
        "        obs, info = self.ant_env.reset(seed=seed)\n",
        "        obs_dict = self._get_obs(obs)\n",
        "        info[\"success\"] = bool(\n",
        "            np.linalg.norm(obs_dict[\"achieved_goal\"] - self.goal) <= 0.45\n",
        "        )\n",
        "\n",
        "        return obs_dict, info\n",
        "\n",
        "    def step(self, action):\n",
        "        ant_obs, _, _, _, info = self.ant_env.step(action)\n",
        "        obs = self._get_obs(ant_obs)\n",
        "\n",
        "        reward = self.compute_reward(obs[\"achieved_goal\"], self.goal, info)\n",
        "        terminated = self.compute_terminated(obs[\"achieved_goal\"], self.goal, info)\n",
        "        truncated = self.compute_truncated(obs[\"achieved_goal\"], self.goal, info)\n",
        "        info[\"success\"] = bool(np.linalg.norm(obs[\"achieved_goal\"] - self.goal) <= 0.45)\n",
        "\n",
        "        if self.render_mode == \"human\":\n",
        "            self.render()\n",
        "\n",
        "        # Update the goal position if necessary\n",
        "        self.update_goal(obs[\"achieved_goal\"])\n",
        "\n",
        "        return obs, reward, terminated, truncated, info\n",
        "\n",
        "    def _get_obs(self, ant_obs: np.ndarray) -> Dict[str, np.ndarray]:\n",
        "        achieved_goal = ant_obs[:2]\n",
        "        observation = ant_obs[2:]\n",
        "\n",
        "        return {\n",
        "            \"observation\": observation.copy(),\n",
        "            \"achieved_goal\": achieved_goal.copy(),\n",
        "            \"desired_goal\": self.goal.copy(),\n",
        "        }\n",
        "\n",
        "    def update_target_site_pos(self):\n",
        "        self.ant_env.model.site_pos[self.target_site_id] = np.append(\n",
        "            self.goal, self.maze.maze_height / 2 * self.maze.maze_size_scaling\n",
        "        )\n",
        "\n",
        "    def render(self):\n",
        "        return self.ant_env.render()\n",
        "\n",
        "    def close(self):\n",
        "        super().close()\n",
        "        self.ant_env.close()\n",
        "\n",
        "    @property\n",
        "    def model(self):\n",
        "        return self.ant_env.model\n",
        "\n",
        "    @property\n",
        "    def data(self):\n",
        "        return self.ant_env.data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xSc_wfjI5DJE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "AU26AZroN07L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "50V4qSC8xtyA"
      },
      "outputs": [],
      "source": [
        "class AntMazeEnv(MazeEnv, EzPickle):\n",
        "    metadata = {\n",
        "        \"render_modes\": [\n",
        "            \"human\",\n",
        "            \"rgb_array\",\n",
        "            \"depth_array\",\n",
        "        ],\n",
        "        \"render_fps\": 50,\n",
        "    }\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        render_mode: Optional[str] = None,\n",
        "        maze_map: List[List[Union[str, int]]] = None,\n",
        "        reward_type: str = \"sparse\",\n",
        "        continuing_task: bool = True,\n",
        "        reset_target: bool = False,\n",
        "        xml_file: Union[str, None] = None,\n",
        "        max_episode_steps: int = 1000,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        if xml_file is None:\n",
        "            ant_xml_file_path = path.join(\n",
        "                path.dirname(sys.modules[AntEnv.__module__].__file__), \"assets/ant.xml\"\n",
        "            )\n",
        "        else:\n",
        "            ant_xml_file_path = xml_file\n",
        "\n",
        "        super().__init__(\n",
        "            agent_xml_path=ant_xml_file_path,\n",
        "            maze_map=maze_map,\n",
        "            maze_size_scaling=4,\n",
        "            maze_height=0.5,\n",
        "            reward_type=reward_type,\n",
        "            continuing_task=continuing_task,\n",
        "            reset_target=reset_target,\n",
        "            **kwargs,\n",
        "        )\n",
        "        self.ant_env = AntEnv(\n",
        "            xml_file=self.tmp_xml_file_path,\n",
        "            exclude_current_positions_from_observation=False,\n",
        "            render_mode=\"rgb_array\",\n",
        "            reset_noise_scale=0.0,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        # ゴール位置のサイト ID を取得\n",
        "        self._model_names = MujocoModelNames(self.ant_env.model)\n",
        "        self.target_site_id = self._model_names.site_name2id[\"target\"]\n",
        "\n",
        "        self.action_space = self.ant_env.action_space\n",
        "\n",
        "        self.observation_space = spaces.Dict(\n",
        "            dict(\n",
        "                observation=spaces.Box(low=0, high=255, shape=(256, 256, 3), dtype=np.uint8),\n",
        "                achieved_goal=spaces.Box(low=-np.inf, high=np.inf, shape=(2,), dtype=np.float32),\n",
        "                desired_goal=spaces.Box(low=-np.inf, high=np.inf, shape=(2,), dtype=np.float32),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.render_mode = render_mode\n",
        "        EzPickle.__init__(\n",
        "            self,\n",
        "            render_mode,\n",
        "            maze_map,\n",
        "            reward_type,\n",
        "            continuing_task,\n",
        "            reset_target,\n",
        "            max_episode_steps,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    def reset(self, *, seed: Optional[int] = None, **kwargs):\n",
        "        \"\"\"\n",
        "        環境をリセットし、初期状態を返す\n",
        "        \"\"\"\n",
        "        # MazeEnv のリセットを呼び出して初期化\n",
        "        super().reset(seed=seed, **kwargs)\n",
        "\n",
        "        # ゴールと初期位置を反映\n",
        "        self.ant_env.init_qpos[:2] = self.reset_pos\n",
        "        self.ant_env.reset(seed=seed)\n",
        "\n",
        "        self.update_target_site_pos()\n",
        "\n",
        "        return self._get_obs()\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        1ステップ実行\n",
        "        \"\"\"\n",
        "        _, _, _, _, info = self.ant_env.step(action)\n",
        "        obs = self._get_obs()\n",
        "        achieved_goal = self.ant_env.data.qpos[:2]\n",
        "        reward = self.compute_reward(achieved_goal, self.goal, {})\n",
        "        terminated = self.compute_terminated(achieved_goal, self.goal, {})\n",
        "        truncated = False\n",
        "        info = {\"success\": terminated}\n",
        "        return obs, reward, terminated, truncated, info\n",
        "\n",
        "    def _get_obs(self) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"\n",
        "        現在の観測を取得\n",
        "        \"\"\"\n",
        "        import mujoco\n",
        "        from mujoco.glfw import glfw\n",
        "\n",
        "        width, height = 256, 256\n",
        "        rgb_array = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "        depth_array = np.zeros((height, width), dtype=np.float32)\n",
        "\n",
        "        # GLFW の初期化\n",
        "        if not glfw.init():\n",
        "            raise RuntimeError(\"Failed to initialize GLFW\")\n",
        "\n",
        "        # GLFW ウィンドウの作成（オフスクリーン用）\n",
        "        glfw.window_hint(glfw.VISIBLE, glfw.FALSE)  # ウィンドウを非表示にする\n",
        "        window = glfw.create_window(width, height, \"MuJoCo Offscreen\", None, None)\n",
        "        if not window:\n",
        "            glfw.terminate()\n",
        "            raise RuntimeError(\"Failed to create GLFW window\")\n",
        "\n",
        "        # OpenGL コンテキストを現在のスレッドに設定\n",
        "        glfw.make_context_current(window)\n",
        "\n",
        "        # MuJoCo 描画コンテキストの作成\n",
        "        context = mujoco.MjrContext(self.ant_env.model, mujoco.mjtFontScale.mjFONTSCALE_150)\n",
        "\n",
        "        # カメラ設定\n",
        "        camera = mujoco.MjvCamera()\n",
        "        mujoco.mjv_defaultCamera(camera)\n",
        "        camera.lookat[:] = [0, 0, 0]\n",
        "        camera.distance = 16.0  # 必要に応じて調整\n",
        "        camera.azimuth = 90\n",
        "        camera.elevation = -90\n",
        "\n",
        "        # シーン設定\n",
        "        scene = mujoco.MjvScene(self.ant_env.model, maxgeom=1000)\n",
        "        mujoco.mjv_updateScene(\n",
        "            self.ant_env.model,\n",
        "            self.ant_env.data,\n",
        "            mujoco.MjvOption(),\n",
        "            None,\n",
        "            camera,\n",
        "            mujoco.mjtCatBit.mjCAT_ALL,\n",
        "            scene,\n",
        "        )\n",
        "\n",
        "        # 描画\n",
        "        mujoco.mjr_render(\n",
        "            mujoco.MjrRect(0, 0, width, height),\n",
        "            scene,\n",
        "            context,\n",
        "        )\n",
        "\n",
        "        # ピクセルデータを取得\n",
        "        mujoco.mjr_readPixels(rgb_array, depth_array, mujoco.MjrRect(0, 0, width, height), context)\n",
        "\n",
        "        # GLFW を終了\n",
        "        glfw.terminate()\n",
        "\n",
        "        # ゴールと観測データを取得\n",
        "        achieved_goal = self.ant_env.data.qpos[:2]\n",
        "\n",
        "        return {\n",
        "            \"observation\": rgb_array,\n",
        "            \"achieved_goal\": achieved_goal,\n",
        "            \"desired_goal\": self.goal,\n",
        "        }\n",
        "\n",
        "\n",
        "    def update_target_site_pos(self):\n",
        "        \"\"\"\n",
        "        ゴール位置を MuJoCo シミュレーションに反映\n",
        "        \"\"\"\n",
        "        pos = self.goal  # ゴール位置を設定\n",
        "        self.ant_env.model.site_pos[self.target_site_id] = np.append(\n",
        "            pos, self.maze.maze_height / 2 * self.maze.maze_size_scaling\n",
        "        )\n",
        "\n",
        "    def render(self):\n",
        "        \"\"\"\n",
        "        人間向けレンダリング\n",
        "        \"\"\"\n",
        "        return self.ant_env.render(mode=\"human\")\n",
        "\n",
        "    def close(self):\n",
        "        super().close()\n",
        "        self.ant_env.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "MQXYNegWBbqg",
        "outputId": "73577824-7011-4cd6-ed14-0c778b88dcb1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# カスタム迷路を指定\n",
        "custom_map = [\n",
        "    [1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1],\n",
        "]\n",
        "# 環境を作成\n",
        "env = AntMazeEnv(maze_map=custom_map, max_episode_steps=1000)\n",
        "\n",
        "# 環境をリセット\n",
        "obs = env.reset()\n",
        "\n",
        "# 1ステップ実行\n",
        "action = env.action_space.sample()\n",
        "obs, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "# エピソード終了フラグ\n",
        "done = terminated or truncated\n",
        "\n",
        "# 観測画像を表示\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(obs[\"observation\"])\n",
        "plt.title(f\"Reward: {reward}, Done: {done}\")\n",
        "plt.show()\n",
        "\n",
        "# 環境を閉じる\n",
        "env.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F15HhMQcpbzA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJcaBEY1pb1e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFqYlKfMpb4G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KU7-DWH0pb6g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "TBDYebIw2blV",
        "outputId": "d10d02ae-7372-4496-cc47-a90ee2dcf09f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGhCAYAAADbf0s2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAADXhUlEQVR4nOz9eZQk2VnYDf9urLln7VVd1dXL9DpLz65ZtaIRkpBAfMg2fJbfYwPH+MUyNgjbL3OOwR8ytgzHiw5GBpsjZOxjjM1rA8ZYAltGEpJGs49mn+6Znum9qru23DPW+/0RldVZVblFZFZ1VVf8+lRXVuS9z33iRsR94nnixn2ElFISExMTExOzA1FutAIxMTExMTHtiI1UTExMTMyOJTZSMTExMTE7lthIxcTExMTsWGIjFRMTExOzY4mNVExMTEzMjiU2UjExMTExO5bYSMXExMTE7FhiIxUTExMTs2OJjVRMTExMzI7lhhmpL3zhCxw6dIhEIsGDDz7IU089daNUiYmJiYnZodwQI/Wf//N/5jOf+Qz/8B/+Q5577jnuuusuPvzhD3P16tUboU5MTExMzA5F3IgFZh988EHe9a538Wu/9msA+L7P7OwsP/VTP8XP/dzPda3v+z6XL18mm80ihNhqdWNiYmJiBoyUklKpxPT0NIrS3l/StlEnAGzb5tlnn+Xxxx9f26YoCo899hhPPPFEyzqWZWFZ1trfly5d4rbbbttyXWNiYmJitpYLFy6wf//+tt9vu5FaWFjA8zwmJyfXbZ+cnOT1119vWedzn/scv/iLv7hp+1DaiD2pmJiYmF2IlJKVik02m+1YbtuNVBQef/xxPvOZz6z9XSwWmZ2dRQgRG6mYmJiYXUy3MXzbjdTY2BiqqjI/P79u+/z8PFNTUy3rmKaJaZrboV5MTExMzA5i22f3GYbBfffdx1e/+tW1bb7v89WvfpWHH354u9WJiYmJidnB3JBw32c+8xn+6l/9q9x///088MADfP7zn6dSqfCjP/qjN0KdmJiYmJgdyg0xUj/8wz/MtWvX+IVf+AXm5ua4++67+cpXvrJpMkVMTExMzN7mhrwn1S/FYpF8Ps9wxownTsTExMTsQqSULJctCoUCuVyubbl47b6YmJiYmB1LbKRiYmJiYnYssZGKiYmJidmxxEYqJiYmJmbHEhupmJiYmJgdS2ykYmJiYmJ2LLGRiomJiYnZseyKBWa3AkVRyGSzpFIpBNHetZJIPM/D9Vx838e2bey6RehXz1YXyhVCYOgGqXQKXdMj6QTgy0AX13PxPQ/bdvBcN7QcRVVRVRVFEZhmgoSZ6Ou9NMd1qNfreL6H53p4rhu6r4SioOsaqqqhqiqmaaKp0U9jX/rUajUsq470JZ7vI30/tBxN1zETJoqioKkauqb31Ve2Y1MpV3AcGwkQ4XVGoSgkkwnMRPA+oaqoKEKNrJOUkmq1SqVaidRHDQzTIJ1Oo+kaINb+hdYn6Blc16VSLq9L5xMWIRRS6RSpVApFRL9396WPL30kEqtuUavW8D0vsjxN18lkMphG9LVLg3HKxfU8fN/HqtexLTu0HCEEQhGAwPf9vvYrDHvWSGWyWR770Id54MGH0LRo3SClZHFlgfmFK9TqNc6eOcuZ18+EPgFUVSWRSKBpGocOHeLRR9/D5GTrxXZ7oVav8fb5s8xfu0K5VOadN99h4dpCKBlCCHL5HEPDQySSCW6/9Q5uPXk7hmFE0klKyeUrl3j5tZcoFldYXlrh6txVHNsJJSeZTDIzO83w6AhDQ8OcOHqS8bGJSDoB1Go1Xvjuc7zy6stYlkW5VKZWrYUynkIIpvdPc+zWY2QyGcZHJ5ie3I+hR+srgPPnz/G1r/8ZFy6cx/d9PM9D+uEMVTqd5q777+LYyWOYhslQephUIhPZeNq2zVNPPcm3vvXnVKvVSDIAbjl6C+/54HuYmp5CRUPHRAkZ1AkMlI/EZ35+nq/92dd44/U3wt8grpJIJHj44Ud56KGHSSQSkWQAWE6dsl3CcW1Ov/oGTz/xDMVCMbK8/fv384EPfJCjR49FluF6Losr11guLlEulXn1pVd5+8238UPeaOiGTiIR3KhWy2VKhWJoGVHYs0YqlUrxwIMP8Zc/9X+hRxx4fd/n/JV3OP32axRKBRRV4/KlOYQS7gI2DINMNoNpGBw7eSsf/4Ef5PjxE5F0AiiWCjz13Hc4/dbrLFxboFyuUipXQslQFIXhsVGm90+Ty+V49/vfz4e+58Mkk8lIOkkpefnVF1ESKlfmL3P5wiUqlRq1ag2g5zvp7FCOA0cOM3twP9PT+/nAuz/ILYeORtIJgtVLjJTJSqlAuVJGUReQiNBGat/sDPc8cB+j46McPXic24+fIplIRdbr+eef5e1z77BcWMFzPRzHCT0g5IaHOHXvXbzng+8hk8wwPTrLSG4UIkYOarUaUsBLr7xMP0PT7OGDfO/HP8KJ209gYJIgjUJYD0/i4yLxOHP6DOcvXOTcufNEXT4nm8ly7/3v4of/v58ik8lElAJlq8RS5Ro1u8rX/vRrnDl9FtsJH8VosG9mPx/68Ed45JF3R5ZhOzbvXD7LxblzLC4sUi5XmbtyFS+kJ5RIJshkMyiKgpSSSqkcG6mtRCDQNA3dMCJ7B77vo+s6qqathZw8z8MNGVpTFAXf8/FWD7imaZF1AlZ1UlFUBSEC19xzvbXwSK86eZ6HlEEtVVHQDb0vT0rTdIQShHZ8X671VZhQT+PCEoqCqqhomo6uRw+t6bqOIpQgTLPqsbghw5CKUJC+RFGDUJ+maeh69PMKQFU1pJR4bhBOdl039IDgeR5CCHRdRzdWf/ToiUI9z0UIJdI53kxwLmiYhomOgY6OGnIokkgkChIfTdORvsQNeY434zb1VT/nuCF1DEfHw0BR++8r3/dRFbWvcxwh0XUNTQ9C5BKJ67qhjJRA4Hkevhecg41xYTvYs0Zq0EgktmVTKpQol8qh6ppm8Mwg4SSo12p4fn+xXimDk9t1XWzbplquUiwUQw28qqqSyWaoVqrouoHjOJGeizTj+x6ObWNZQay+VChRWfXwejVUiqpQr9VxbGfVmPR3JyelDPqoUqVSrlAqliisFAhzBQohqFar+K4fXLwDuHo9z6NSCY6b53rYth0+PKPrOI6DIhSEUPpe51JKsOoWpUKR4kr0EFatXAMXNDQU1MjPhAUqoCA9qFZqwXGLih/sW79LmQqhoK4+y/Vcj3Kx3FdfVUqVvozcRnzfp1atUVwphvakbNsGCaqmDqSveiU2UoNCguM41Gv1tRBWr/iej2EGd2+27YR+9tBKGd/31zyoer1OtRIuBKkogTGwLAvbslc9sT61ksHdruM42JZNrVoL3VeJZALbttfu6vq/UIK7SsuysOpWcPwqIZ9JKQKrbuH7DX36v3h9z8OqB+eS67rYVngjlU6n8dzAQ1CUASzELCWu41Cr1kKfT81YlgU+KKihn0WtJ/DKpS+wLacvnTQ1MOj9HjshgmtHVVR8z6deC3/tNVOv10Mbk05IGdxMVyvVSHINw0DVVBzHiY3UbiXKgds+xzkCcu2/AclqfIwmc6v7KvCEQraxhSr1MxDs2PNqVa1+zOZm76v/m5WBMqjkDDv0EG4n8XtSMTExMYNkJ2cP2sm6tSE2UjExMTFbwU4zCGLD711CbKRiYmJiBsouswI7nNhIxew+RNNPTMyOYoeelLvUi4LYSMXEDI7YcMasEnVa/ZayA1XqhdhIxXRGrP0Xs6uJj2HM7jwHYiMV0xGBQMSGateyfvHW+BjuVRpnQdTFfG8ksZGK6Y3ddV7HbCA+fHuZ3X30YyMVs+3sxru5mMGy/vjH50JMe2IjFbOtxMNRTLOBis+HmG7s2WWRJMHyN4017qLgy/VrxymKgqoFKw2HQVuto6wmGGzoFRV/VadGkjJVVVE1NdQSK4qqrOqkoCjBvYz0o+vVWDVZiECeoiqomhqprxRldbFUcX0Zo6jLB/lSghBB36vB8dM0Ldwq6Iqybj8kIGX086ohQ1HUtVxnqqYi/HBDuqZpCCFWz/VVnaSPkNFMQ6Ov1s6niChq0/mERMHvK/WHRAbJJjUt8lJQ6mpf+X2c4xD0ceN8FAywr/o6x1fHqdXqwTilhrpDaGSNaFyziqIg2J5Vm/askfI8j8WVBc5feQddj5YFV0rJwvICtuuAojB9YD8PvfdhrHqLDKEdTghN00ilUmi6xvSh/SxXljl78WxPdVtRq9VwpEc6l2XM97nz/ruZmJ7q7YxabUsIwfDIMCNjI0H2YkPhwvyFvtJPlOolhsdHEIZCIpUiPzQcOptqKpPi8NHDjE+Ok8qmWSov887ldyLrVK1WSeXT3Hbn7dTrdQ6tFKiUKpsGu07hSSEEB285SHYoj2YYVK0qF69eRO8h6WE7uTWvzvFTJ9AzOr7nh04fApDNZhmdHKdaq+N5EukpFEOu0N+Mbdtkx3I89P5HqVSiyzl+60mqTp2Lc5cRUkFBix7+FVCsl7jl1qO8z/lAZJ2SiSRDk8NcWbzCcnU58uhr+zZ1t4LjOmSGcrzr3Q9ybHklsl4HDx7CES7nrpyLLMPzXJZLBRzPQzMMTtxxci2FTzNtDbwMznHDMEikEggE77x1ltOvvI5Vr0fWq1eE3K6lbAdIsVgkn88znDEjpx8YHh3hB3/4h3j/934PasTMvAC262DZQUI6y7Ko16zN6SPE9Q+ttA08HmU1fbxOKp2+ni1YdKq5sZmgjC99bMdezUHkYVt2+OX+BaiKiqoGnksiES59fKtyjuNQt+qrK5h7OK4besV3RVHQTR1NU1EVFdNM9J0+vl6rU7fqQf6mppw5zV0uNm7YgGGspo9XVTQ1yHO11gcduqzdcXVsh3KlhG0HK3NHuUoVRSGVTq5lU1WE2le6jrX08ZUyfh8r9ZumQTabRTd0+lk0vrEvrutSKpWo9zFgKoognc6QTqfX5EYbGgPvECT1Wp1KuYLnRffMdF0nm8muZUmIhATPd/FkkN3ZsSxcx97U75uM1IY/g9X0FTzX5Zv/58/58h/8McU+0qNIKVkuWxQKBXK5XNtye9aT8n2fWr1GoVhYC4WFDxUIEAKhqCAEyVSKTCbbflAS3Y2N67hUa03L6Ive6gVFgzKKUNaS3AlhkEqlex+cWiwuLaXEsR0KxULPfSQCpdehaRqmaa6F66IOmD7+Wkh0XV9FQAiBaZrkh/Kb+3idkeqsayNpopQS23GoVKtByKeHfVyT3XRDEuTzyoYOhzYjWU0s6XlraVs8N3xfNcLGAoFu6IyOjfVl7Hzfx3Ed7IpzPSFnSIMghAhC0aqCIhTSmTS5fPuBrhsSieu4lKtlWM3H5vt+aAOqqEHYUSgCVdMYGR3tq688L8glVivWro9RIXUSQgQJD7UgTJfNZdE33Zh3MFAbvnIch3QmvfYYYKvZs0bKtm3OnjmLsnoXblv2aj6Z3lFWQ3xHTh4jmUoxnBtmdGgUVdkwsIQY7M6ePct3nvwOc3Nzm+r2gkCQzWW5+113c+T4EXRNJ22mMTUznKAmrLrF008/zTPPPNNzeK7VhXns+DHe8573MDY2BgTGNCw+Pg4OHh7zl+d57jvPce7t6KGQVCrFQw89xL333hs57AtQtaoUq0Vsx+bM62d4+YWXg1xZPRy/xjkhVp/3CEWwf/9+Hn30UfZP74+sk+M6zF2bY3FlkUq5wptvvMncpblwBkEEfZTOpDFNk5MnT3LH7XeQMBOR9VpcXuStt9+iWCqyvLjMpQuXqNfCeUGGYTAxNUF+OE8ul+PE0RNMTk5GDhvajs0bp9/g9JnT1Ot1CssFSsVSaOM5NjHGoSOHSGfSjI+OMz01TcKI3lfzV+d56rtPceHihSA3XC18finDNDh+23FuOXoLekJnODfKcDZPyzvSVrQwUsO5kc3j3Baxd41U3eLMa2e4fGkOz/UoFUuhE/CpqspD73uEmYMHyGSyjA6NcuzAMYwenkW049LZSzz9zad54YUXIsuY3j/NoSOHGB4dJmWmmMhOkDWzvQtonLurJ2exWOTLl77MV/7wK5RKpUg6CSH4vo99Hz/w0R/g2MFjwd15hAHFx6dGDRub5YVlnnvqOb75Z9+MpBPA6Ogot95yK4enD5NMJiPJkFKyWFqERShXy1w6f4k/+aM/YWlhKdRNhqqo6IaOpmk88MADfOi9H+Lo7NFIOgFUa1UKhQK1ao1rV6/x5J8/yfNPP48fIpuxEILRsVEmpyfJZrPMjM0wOzFLPpePrJe0Jc8uPsuly5d46/RbPPPEMywvL4eSkclkuP2u2zl4+CAzMzPcf/v9HJ09GtlIVaoVXnz2RV56/iUKKwXOv3Oeyxcvh5pEIRCcuP0EqqoyMTXB5PAkByYOkMtG9/DqhTqnXz7NE995AqtuUVgphH6Om81lURSFA4cOoCoqo/kxZidnI3t4tm0zmh/ry8sPw541Uo204aJSxXVdyuUytUp4IxWkUQ5OZFVRMXQD04jmtTRmBNWqtdAp6JupVCp4noeqqmiqhq7pGLoR+aTUNR3XcamUK33pZdUtVKFiGMbau1JhBxV39Z8kCKXV6/W+dEqYCTzXW+ujKEgp0TU9mLUolMh9pSgKhmkE51XNQkHp64bHcRwEwWxRz/Wo1WqhvYNGODRXyaFrwSQOXe2vr4LnGkGGZqtuUS6VKRdDHkMJtWoNy7JwHRdFKBha9HPc1mykL7HqFrVaLTh+xXLomX7VShXHcda8HU3T+jqGiqKsZdJtHD/bssPJEIEM5GooWVHXztdI+BJV7WOyS0ji96RuQuIXZWNiYm4WYiN1ExMbq5iYmN1ObKRuUtYexseGKiYmZhcTG6lBsJOT8O1EnWK2jfhmJWa3Exupftmp1/4ONZrx4rLbT9zfMbuZ2EgNhHgQiIkJw042nDtZt71IbKQGwG5NJhYTcyPYiddJY4WUxsLF/awSETNYYiMVExNzQ9hpxirIQh19ua6YrSE2UjExA2KnDboxMTcDsZG6iYlndsXEbC/N11x83Q2G2EjFxAyQeGCKic+BwbJn1+5rZBg1DANFUTBNE9/1Q6Xr0FazuA4yhq0oCoZh9JU/xjANFKGspY6Imq20gRBBVk7DDK9X8wrfmq4hFYmHF6whRoQFKmWQFsOTwdpouq5jmtFXeDdN83rurn6QjV8yOK9MI7Reihoce1ULFpoVygDOq9U0L4qiBH2VMEPl8BJKsHafbujouh5kiu1XLRGc54qioOkaRiJ8XzV0amS1HsQ12Mjuq2s6hmFgJszrucV6QYBu6Ncz10ZcRHmdSCHQ9UAf3/cxE2ZomYZphM7Eu5PYs0ZKEYJEIkEmm8H3/GCBStMIlatF1dQga+0A86poukYml2FoeCiyjGwui6qpeJ6H54XP1bMRIQSJZIL8UH4tnXWo+qsPpJOZJJ7qYWGhoaGghL7gGokJHd9BCkkqnWJoZCi0Tg3yw/ngwu9zkJME+a186aObOvl8PtwAx2pCR0NH1VTSmXT/xlMEi4s2Bt90Js3Q8FDoBWZzQzkymSAhYGNx4H5QRGCcdEMnmUySz+dD50hKZ9Kk02nMhBncaEY4L9chghueZDIZZCDOZRkaHgq3wKwIrj3DNND1wFj1axhUVSWZTpLNX098GHaB2Uw2EyS+3KVWas8aKVa9A9Mw8Hwf0zFDexyKqqLpmz2pfoxCw5NKJKPnoDHMwDv0fR/pyzV9+tFL0zTMhInjhsu51UAg0AwNXwRekLIaaY7i5fm+v2YAdEPvq69M0wzuMumvf2Tjnww8KTNhhtar4e2omrp2DPtOnC2uZ1RtnFdRVkE3TGPNgCL666uGJ6Wq6pp3F7avzISJrm/2pKLq1fA2NV1D04PknGbCDC2v4bUoanBz0FiFPioNT8o0TZDBfoddvdxMmC09qah6bXcq9z1rpAzD4NDhwxw/eSsA9Vod2w65BL4imD60H0M3cF2Xt86+xcW3Loa+Y2lcHIqicOnSJY4fP87o6GgoGc1kchlSyRSLVxdZlIuce/0cRLAtiWSCZCqJ4zgYpsEjDz8Suo8aCAQH9h9g7vIcVt3CrtrUi3WkFzIjqyYwcgZqUqVcKHP86HHSejqSTgCJRALf83n6madRFIV6vY5jR+gsHUgGocix0TEeeugh6tVwifwaYVVFVRgbHeONN95gcWFxLQtxWHx8bGGTyqQYlaOcuvMUo/nw51UmmyE/lMcwDGzL5utf+3pfCSLrbp1MNsMtqVvIZrJkkpnQaXLMhMnM7Ayj46OYusmZ02e4dP5SZI/Y8zzK5TK3nrgV27I5MHOAlaWV0AP5xPQEswdmyeQyFEoFvvHn30AV0fMuFYoFxsfGeejBh3Ach1qlhuu6oWQYpsHs7CyqqlK36rz66iucfumN0LqomoqmaXiey5tvnok8FoRFyL5v1bafYrFIPp9nOBM9TDM2Ps6P/vhf5+M/8INBx/teqFg9BHciy5VlrhavUavVeP7J53n6m0+HTp5oGAaZXAbDMDh+7Dgf+tCHmJmZCSWjmZpV49zlc8wvzrO0uMR3n/ou58+eDyVDURQmpibYN7OPdDrNnafu5M477sQwIj4rk3DxykVeeu0lVoorXLlwhbfeeCt0X2XzWW67+zZmDs4wlBvixOETjI+MR9MJqNVqPPnUk7zw3ReC5IDXrlFYLoT2Nk7ccYIH3/sgQyNDjOZGmRyaRNfCDeSNsCgC3jzzJn/43/+Qt958KwhvOk5oQ5UfzvPBj32QB97zAIZmkBRJTBH++V3j2att2/zpn/wpf/RHfxQ5+SXAnffeyV/6v/4Sh48exrd83Kob+mZFURQSiQS6oXP+3Hl+9z/9Lk8++WRknVKpFB///o/zfR/7PpKJIOTnOm5oT99XfTzdw8XlyW88yR//v3/M4rXFyHodOXKET/6FT3Lq1Km1UHfYIdv3fVbqKxTrRQorBZ74P9/kpWdeDH0+JZNJ0tkgbfyVixc59/bZvgyVlJLlskWhUCCXa58YcuCe1Oc+9zn+23/7b7z++uskk0keeeQRfvmXf5kTJ06slanX6/zsz/4sv/u7v4tlWXz4wx/mX//rf83k5OSg1WmLrulMTk5x/PiJyAOv7/ucvXiWpeoynucxNzfHC999IXQCN8M0GBoeIpFMMDIywszMDHeeujOSTgDLK8vMLcxRLBS5Nn+N1197nddefi2UDEVRmDkwQ7FSZHh4mPvuvY9bT95KOh3Na5FSYrkWy99a5sLFC7z95tu8+PyLVMqVUHJGRkdI5pKouoqpmszsm+HEsRORb1aWl5d54jtPcPrMaYrFIlcuXWHh2kKomIYQAjWhcvKukyTTSXK5HCdPniSdjO7hrayscOnSJZ57/jk8z8O27NCDyvjEOPe9+z5M0ySbzrJ/dD+j2dHIfVWpVHAch5deeonFxegD79BYcK5P7ZtCR8fEjDaJZpXCcoHLly/z7LPPRpaRz+d57LHHmJ2ZDZ6RNWgyCK1Oiea+lFJScSos1hapWTWqtSqvvPIKly5ciqyXqqrkc3lOnjjZ/bi1MV6WY/PmhTcpXynjODbnz5/nheefD52GPpVOkR/Ko2oq9WoVJ6RHF5WBT0H/+te/zqc//Wm+853v8L/+1//CcRy+93u/l0rl+mD0Mz/zM/zRH/0Rv/d7v8fXv/51Ll++zA/90A8NWpXtZXc+k4yJiemE70D5Miy8BguvIq+9grz6CnL5LDgdbrBuyHggwVqB4ptQOAP1BZDhw8Q7jYF7Ul/5ylfW/f3v/t2/Y2JigmeffZb3vve9FAoFvvjFL/I7v/M7fM/3fA8AX/rSl7j11lv5zne+w0MPPTRolbaenZyqIyZmB7JrZpq5dVh4HZZOw+ojAd+XiMwUyoGHQE/vnGWUpITqZVh4AXwXRm4Ho30Ybbew5RMnCoUCACMjIwA8++yzOI7DY489tlbm5MmTHDhwgCeeeKKlkbIsC8uy1v4uFotbrHUIdsj5GROz29iphmrdbFjPRdaLyNJVpPShMVtWM8G1AR/kDbxDXQvxSaT0wK1BfTnwAN3a6vc7s597ZUuNlO/7/PRP/zSPPvood9xxBwBzc3MYhsHQ0NC6spOTk8zNzbWU87nPfY5f/MVf3EpV+2KnXmw7lri7YnYwvu+zUlyhVClRLy5y+btnWHzzNTIJnZOzo0yNZFDsCkrhLMIrg5GF9BRoqRujsLUMlTlw67jL57GLZZASPe8QfQ7mzmFLjdSnP/1pXn75Zb75zW/2Jefxxx/nM5/5zNrfxWKR2dnZftUbKLGh6hGx4Xc/cuIQa8wW4Hou84vznL98nuVr1/j215/nlWeeZnYsy1/50CnG8ymoF2HhZSiZkJkFPX2DjJSE6lWYfxasAnaxRGmlgBQa6VEHzY89qbb8rb/1t/gf/+N/8I1vfIP9+/evbZ+amsK2bVZWVtZ5U/Pz80xNTbWUZZpmX0vfxMTExPSKlDJ4J6leo1KvUahYLJYssqkElqcgFQ0J+E4VIS0wyuDZIF2QHlv1umvjfTmJRABKoEXw3MwuIa0Svmvj+wKpqEi5u41Tg4EbKSklP/VTP8Xv//7v87WvfY3Dhw+v+/6+++5D13W++tWv8slPfhKAN954g/Pnz/Pwww8PWp2YmG1DbPgX052d3E+CYOm0W06cJJFMMTWSY+LWu9APzCLtMrXCefzKCpp/jUTiNdT6PAgd1OgroHSiVq+xsLxArV4jo9iMKVUM4SLLV/BrFaTroqYnSI9MgpbEGD2AUDUIuTzXTmPgRurTn/40v/M7v8Mf/uEfks1m154z5fP5tXW6fvzHf5zPfOYzjIyMkMvl+Kmf+ikefvjh3TmzLyYmJjS7xZAnkilO3HEHR06cIJ/NMXnr7RhT09jLF6kuzlNbqpC0fXTNRa0kIDmByB4DMfi18qq1KucunWO5sMw+rUxWX8AQFr7r4Np1pBBoI1OYBx4BI4NQdVC0wMvbxQzcSP36r/86AO9///vXbf/Sl77EX/trfw2Af/kv/yWKovDJT35y3cu8MTExMTcaQZAhQdf0YMkyVcNP+CTSaYSWwFUMXMXAV0xQTSQKrl1HES6+mkV4FqqiIqTLIEN/wdqQPlJ6SM8GaqBY4AOqDkJD6EkUI40wo79IvtPYknBfNxKJBF/4whf4whe+MOjmY2JiYvpCVVXGR8bRVR3Lsbi2eI1CqYBt21y5eoVSpYQhbbLjx8mPHcStLrG09BbetUW0PCQxSOgJUvWrKP7gVmVIJXQOTA8xPqKSqYNRXATXQslMoOUOILU0Sm5fYLBuIvbsArMxMTExrVBVlbHhMUaGRqjWqliWRbFUxHZsrly7grKgMJTLkz98nKHhEVYuvs6Vd96ifHWJkbrLUFJimEZgpGS0rAGtSCYN9u8bRsoEypKNUtfAE4jMBOr0fZAYAqGCEn2JqZ1IbKRiYmJimhCrCVFVgpCfaZgkzASe7+F67uqPh+35WJ7EQ0UYKdREFqEYeLaLi4+pKUyMD2H5UK1alMs1/JCLWCM9hFsDu4wi6ijCAuEEC9rpyWBShJ4KXi7Wbs4Z0LGRGgC74QHwzUQ8g6534j7qD13XmRqfIp1KU7fqzF2bo1AqUKvXuHDlAgvLCxjSIX/4PkYP3YlXmWdh8Qy+VWJmZoKf+ImPUaw7fOtbr/C//tezlEq9rfqvqgJFCDSvglh4BS6YoPlgeqBK8BMwfjugQ3IMtK2ZUbgTiI3UgIgHzu0l7uveifsqOpqqMTYyxujIKKVyiWK5SKFUwLIt5q7NIRCMj44xecttDOeGWDz7PNfefo3aSoHJYwe49/tuQ+o6vi/55jdf7slICQGqoqAqAtWrIZbfhCsSDA0yieB3+hCMHANjhCCz5cDXCt8x7Fkj5UufWr1GsVRA1/XVJbBC5mmRklqthi99hCLI5rLs27+PXDkXalDQDZ1sPotpmmRyGWpWjeWV5XA71ESxXMSXPoZpkM6kGZ8aD/L/tMw10FqGoihM7ptkZCx4TQBB8PDYjTidVYLt2CSSCXL5HKNjo8zMzlCtVkOJGRoaYnhkmFQ6hW7o1Oo1Voor0XQCSpUSmqExOj5KIpkI0tynkuFSdSiCsfGxIAOqquK4ztpAFoa1c0aA4zoMjw6z/8D+IJ+UHT6f1PDoMKlUKkj14diUK2VUGf55hRBBnqt6rY6RMJienSaVib66wsjYCJ7vUalUUKSC5muIkC+eNnQSQuB4DkMjQ8wemo08mS6TzWAmTSrVCkJZFbNhElipXKRYLFIsFNdNENNVnUKphKJqVGwHS+g4agIfDcX1EIpgOG1wcP8I6YSOL1R8NDZdfEEqMRQkOg6a9Ng3miWZ0ECVOFJStzxcB5A26BUwuk+ScFyHul0HGTxvGxkZZv/B/WvZrTfSKoeWQJBIJsjkMiiKwvLCIlatihshGWdY9mzSw+GREf4/P/wX+cBjH0TV1CAleYQOd6SHLYMBZGV5hZWllXV5WpoHnnY0YuBCEaSTaUaHRkmY0d13X/pYnoXjOzi2Q7FQDJ1cUAiBYRpBenVVJZPMkEllUKLcsa3uu+VYVGoVXM+lXq9Tq9au91Wb/tlo7DVNI5vLkkgkUFWVpJ5EU7WWZXvB8z1KlRLlanltMHed1jOyOslPZ9MMjw4H6d9R0SLc/zUPvNValWtL16jWqiCDWbNhL1Vd1xmfHGd4ZBgAaUukK0Ml8hOItYysUkquLV7j6sLV0Nlhm8nn88zMzpBOpXFtF6tmtR0w29Gc9LBaq3Lx0sW+buxUVWVyfJKJsQkURcH3PeSGfEvFUonXXnudK5fXrzE6NjbGsRPHghV07DJ+dRHh2Uxk4eCwRFcl5+aXefPSAnXHp6qOUFVG8JszJTV5T4pdJbH0DnplgbHRLPfcfYjpfcMsVuH1az7LNQlaFswxUHp4DiWCZIxSkXiuS3FphXKx1Db/FLQ2VKqiomoqnufx9Lef5Gtf+SqlYvTklzcs6eFuwfVc5q9d4fRbr6OoCq7rhjZSQgjSuSy54WF0Q+fI8SMMjw6jqsHd6rpBrcX41vje931cx8XzPRavLXL29FmKhegrvRumwdTMFMOjwxiGQX4oH3gHLXeitV5SShzbwapbOI7DxXMXOX32dM+DU6t9HxkdYfbQLKlUCjNpkkqn1vqqVyPlOi7lUhmrblEulbl4/iKFlULbNruhGzqHbjnE8VPH0TQN3dCD1OibbnLbC5RSUi6XWV5axrZtlheWuTp/ta2xa4cQAkVREEIwPDrMqftOMTw6HGwXSugbMsdxuDZ3LdDLsllaXIo0qOi6jmEa6LrO/gP7uevBu9B7uINvR2G5wMXzF1laWqJeq1MsFEMbPVVVSWfSJJIJ0pk0t99zOyOjI5GXqXMdlwvnLnDu/LngWnQdfHf9zLxiocTpN85w5dJ6I7UwvoCLS344TyqVZGh4CCOlUfMWqc5dIYnDLZN5Tp26C3STgrafFXU/vtDWjIEQoKsqmqqg1pZJnnsOY/EdlISOMZ6HdIJKzeXtJYvLyx6IFSQrPffV6PgoQyNDJJJJDt17gJGRoY7n05qRarJVvufjem6wrN3SEt/+sz/vqf1+2bNGyvc8yqUyC9cWEEJg2zaeGy5TpVAEY75PJp9DCANd00mZqbU7e1gd3Lol1PQlrhYYyWW5zNLCEteuXouyWwCkM2lGx0cxjMATSppJUmab8Ew74ynBFja60LEUC6tmMX9lvud00ZsGdRFkQzZUg0wqs6aXoiidvcyNRkpx8V0fRShUK1VWlleYa7qzDetNJZIJZqZnSBpJDMNA0zU0ffNl0VGuBFd30TQNz/Oo1WpcvXKVer0eShdFKCiqgqIogVHyBSkjtc7DCoMqVRSh4LkelmWxtLjEwtWFUB6ZEMHSQMl00D8TkxOYmolpRJ9JVlEq2JZNrVqjUChwbe7aulQ8vaDrOiNjI2Rz2aC/UEgaychGysHBczyKK0Vsy8ax6ji2dX29PF9SLldYXtps6BVVYX5unmq1Ghgo04RUEl8zUNNjaKqPpmuorkTiBt4Wi/ho6LqCrqkIAZpUUaWC4lbBd/A8n1rNYf5KAUstcWnR5eLFKnMr4Qy6buiYCZP8UB4BaKpOQk+2PZ82eVGrf/qqj+d5qGjoqrFtebT2rJGybYd33nyHcrmK7/tUy9XQg4qqqtx5/92MT02SSqVJm2kmMhPBnXgPNAY+iUSu5qm5ePoi333qu7z++uuh96nB+NQ4+/bvCzwoM8lYboxMIhNaju/7+J5PuVzma5e+xjf+9zfWZVgOgxCC97znPbzv4fdxaPIQiqqgaVroE93zPdLJNLZnU1wp8up3X+W5p58L2ogwQg0NDXFo5hATj0yQSCTWPJkwekkpEV4QogOYuzzHn/+fP1/z8HpFURR0XUdRFe666y4evOdBxlJjAJEGhBo1rnhXqNfqLC8u891nvstrL78W2kjlh/KMjY+RzqSZHJ4ke0820vnUoOgXWVlYYe7qHBfPXeTlF14O7eGlUimOnDjC9P5ppianuO3obYwkRyLrVKNGebHM6VdPU61UKK+sUC0VcV2PumVh2UHofHmlRHVD6NwwDN45+w66oXP4yGHuf/h+RsdGGJ+eInXkXrIJA6X8Dv7Km3iuRa28SLH8BgiF8eE0w/lUYGh1FaEpuPUalcICVrnO5ZUaXz99lbPXyhTKFueulChVwj0XTmVSvPeD72VqegqBQlJLkTOHezin1p8ncjXsbOsWaTODIrbnfaw9a6Q812Xh2gKlcgXP9SgWilQr4R7iq5rKxPQUrusihMDUTLKJLIZuRFfMgfNvn+e1l1+LLKJUKlGr1kimAg8qk8iQNbOR5SmeQnkluICjJpwUQnDiyAmSWpLR3GhkXXx8NDRsbFRF5fLFy7z2UvS+Ghsbo1qokkvkSCbbhER7oG7UMQwDy7EorhQ5/dppFq8thpKhKAqGaaBpGmNDY+BAxohuDIQrEFLgOA6VcoUL71zg1RdfDW2kxibGqJQr5HI5KoUKCSVBWo++7I4mNarlKoXlAnOX5jj92mmWF8M9T8pkM5gJE0M3SBpJFFfpSyfhCKxKEC0oFYusXLtGcXEJx3UpV6pUa3V8X+K4Hl6Hd52EEBy79RjJVBJPTWNMHCORTuNfrODNv4Zfq2AvlqgtllAUgeoNkxZ5FFWAroKmYlsOhWqZquUyv1TmqZcu8txb16jX6qwsrYT2OnP5HLffeTu+5yMQ6IpBUktF9oR0DExt8GsTtmPPGqlmJOEeJjdVbDmbKOrBH9gcljZi+nHP+9Wtuf4gwgSDvEAaut3w49Ysb1XkjkhN3uI8H1RfRbruOtQfRH8FqTpc6paN63q4zROhhEARjXX0Ntd1bIdSoUQymaRara6m1oBi1WLpahGnVsRyXExdRdNUtISBSJoIVQmMlK4iFBUjVSfpeJimjqI0RVwGuBZg1L7a7jMyNlIxMTExTfi+pFKzWCqUVidTBTcNQoCmKkhF4kuJ6/mbDFW5VOb82+cpFUrMjM/gOi6+L3lnboVnnn8bu1rklulhjkwPYyYMUiM5GB0CTQmmk+sqWt0m50vSusZcycIw9vYwvbf3PiYmJmYDEonjutTqNlL66KqKqgb+gxBBWBbfR/hik2fo2A6FlQLSl1TKFXzPR0rJSrnO21dWsKsFxofSJAydZNJAT5qIdAJUdc1IKaqKmU6A65JIGKjKzfuibi/ERiomJuaG0XfYdotjT1IGL+0LP2hLEYFhEgTLFqEAq2U2Uq/XWVhewJMOpUoZz/fX5Hm+j+9JfNcD2wF11WPzVaRlI20XXA/p+R3fZ9oLxEYqJiZm2xnIUk2izecB4/k+vi/Wwn2Kcv2zROL7Eumtf0YlpWS5uMyZt8+QzaaZu3YF13WQSDzPx3E8bMclWbeR1TpCUcBSQBFgu/hVC1l38GwXGXZR2puM2EjdjIim3zvguXtMzJayDd6URCJYP39EiODdNmQwa27jpAbbtimUCri+Q7VWW/O2pJR4vgxCgZ4HrotUFPAFKALpeEjXw3d95Gq4cC8TG6mYmJiYXpCspdoQsDbrLlgpRCBksHq5piio6vUfTVXIpAzGh1LgKChCsFyqUbNdpKnD6gvcQhUIRcG1HEqLJeqlGvPLFer24BIn7kZiIxUTczMjNvyOiYwEPM/H84NnU5pQULg+6w9A19TVH2Xtx9BVRnNJMvuG8e06ihBcXCiiayqW5+PVbRRVCdbuUwW1usPF+RWWVqqcXyhTrkVc1PkmITZSMTE3O7GBGhiNZAlrSRMa60eLxjtUAqEERkxZfadKFQTvRSVNpOZTt1xqloPj+tRqFjVTWzVQwfOumuVQrliUqhZVy0FC4JUp6s54b26biY1Uv8R3qjGrxHmb9g6S4LmSlI1p6ZuPu+ZWSVXmSStJjIzEOD6N79lcubDAyoUFapaDZbtculZanfbu4/o+mqKQSeoMZRNoqRQfGN/HPZ7CuXNX+POvP8fly9HX9dyNxEbqJuZmHTQb+7ST9m0n6RKz9UgJruevPZvSRbBIbFMJDLtIpnSePCb52RFGDh/Gk5Ky41M7O0e1YrFQrLJcquG4PoVynXLNZnwoxWP33cLsRJ79w8M8eOttJCYm+Na3XuTMG+/ERmov0UiNoCiBK62EfGlOUVfTJwzQm2rWKSqNRVKbl9cJy7qZSiJY8b0fvYQQCCXoK391NlRje0jF1ummiD77Sr1ev1luJKPTtJRRlL5q6NLILTaQ86lJiFAEiqqEmtIshFjTK8pK7G2Uur6ye8Tzam21eCV8CpO2aq3q1DinFLUHnVa9KEUNJkSoqoKx+qMrEkPa6BIMTaCnEigShK7joeBKQc32KdZcHNejUHOp1D3SDqBoJBIJUukUYyM5shPDjI/myGZSJJMmvi9xXa+nmX+D7KMbwZ41Uoqqks1lGR4bxfd8MtkM9Vr4VdCHR4ZR+0i6txEzYTIxNcHMgZnIMib3TWKYBo7tYAs7UjJHAG/1nyMc0vk007PT5Ertk5N1QghBfjSPLWzKbhld6JiqGbrPfOljOzY1r4aPz/BYkL22fcOdj8vIyAiZXKZvg+D7QRoDz/NIpVNM758mlQqXvVZRFHQjWAV9bGKsr3QYwOoAqqCpwYA3NjHG7IHZ0AvMDo0MMT45TiabIZ1J93VTAMF1k0gGA/Dw8DDT+6fJZMItpJvKpBgdGyWXy5FJZ3rOPNAOIYLMs8PDwyiqQq0WrHTezqA3QnzKqmFTlcDgHpke4aHbJhnLp5jdl2PqllGSSZ2qSHDtnTq2K7lWTSDzM2gJh1yyjjJqo6o6+aEx0pk8+UyC22+ZYHwiD8KleLVIcWERs17jYx9+lHvvu5PLVxZ49bW3KRYrLXM/NZPOpsnmssGNzy5kzxopVVUYGs6zb/8+pJTUqjVsy27vebQY7BRVYXR8NEg5MaBwTzKVZN/MPoqV6EkPR8ZGME0Tq26hCz101tMGHh516tiKTWYkw4HDB0KvFL+GgOGJYSzFouAUSKtpdEUPnenX933qVp2KVcGXPmMTYxw6cqhju0K0D3vm83lyQzkQjXdhoi+c6nounueRyWaYPTS7lhG3V4Qi0DQNRVWYmp7CTPRnpARBxmdd10kmk0xOTVI+Wg7nXQuCm7mRIBV9Jpfpe7BTVZVkKkk6m2ZkfIQDhw5QKYdLAZNIJpiYmmBoeIhsLjsQI5VKpxgZG8FIBFkMkqlkWyOlKAJdDTLpBqdM0Cd3H8rz0bunmR5OkhjLkZwZA11j4aLLK29WqdZ96vUUcuQAmi8ZlpK8L8lkstx39/0cP3IcTVUxjSABYnnhAhef+xNWLr9BamIff+mHHiM5Ms7Tz7zKf/6v/5sLF+aDrM20j5okU0lyQ7ld603tWSMlhEIimQzSFkswdRPbduhkpTYeY0VRSCZTa0ulWHWLYrGIroW7YJrDKI7jkE6nGR4ON8A1k8vlUFUVx3GwFItyuYzihbz7FeAIB1uxqdVqqKpKPp+PfncvIJFI4DgO1WoVqUikIlEJl5PG8R2qVpW6Ww+8llSqc1+JziHFbDYbpGuvVnEcZy1Ve9gwaaVSwXEcfM9H13Xy+fy65Je90Aj1KWqQGt2ygtTaDcK+1GnZQVblRp6qTCbD8PBwaE8qk8mQzWbXUpmUSqXQCUKbqdfrqJpKIpEgnU6TH8qHNjKJRIJsJksqlcLQjU19FRbLtpC+JJ1OgwDbspGexJetb/BURaBrKqoikNIHzwUkQ+kE+ZROPqXjawqW4+L6UKzUWV6pU6v7OJ6P6/rrwsu+FCAUVE0HIbBcsFyfmi1xPPA9gSpUsqkkmVya4Xya4VyKUi4FQiBRaRcOMJMmiUQCIQS+9KnX6xSLBUTIG8TAFgscx6Zer2/bS8ZC7sLXmYvFIvl8nuGMGfnuYGh4mI9/4gd59/vfh6ooQcpor9uFt/k5gWIqKEkVX0oWryyycHEhdNpwTdNIJBNomoZhGKQyqf7uDAUIUyB0gVWzWLy0SHmlHG5wUgTpfJrMSCa4Gxc6uujvblUqEk/1kEjKK2VW5ldwQ76oaCQNRveNkhnOgA/YQIfD1i0zspQS27FxHAfP9SgVS9QqtfAhsYkhpg5OYSQM3JqLWw2/nE1z+vharcbSwhK1Wg3pSzzPCx22NRMm+4/sZ2J2At/zqa5UscrhchEBGKZBIpEAYH5unrlLc4FBj8joxCiHTx4mm89SK9coLhVDnweappHL50ilU1TKFc6+eTZ01uGN8qb3TzO9f3rtpqVeaz8QN0J8ihDI2hL+8lmoF5kZSXL7bI5MQuOVyyt88615Vio211Zcriy6OO7qLD7PW7eMkmma7J/ez/jY+DpvfnwozT3H9jEzlsP3bRyvhO/bFApFLs/NU6tbkBhHpvaD2voGUigCI2NgpA0cy+bq+XmW55fCnZ9CoOs6iYSJLyXPPfM0f/71P6NcCpesshkpJcvl4OYil2v/GGHPelIJM8Htt93O9z72EQxdj7SGoy99Lsxd4Mz5MxRKBZ55+hm+8odfoVwqh5Jjmia5oRyJRIKHHn6In/wbP8mtt94aXqFViqUiTz7/JG+89QbzV+b5xv/+BqdfPR1KhqIqTO+f5sDhA+SH8nz8Ix/nox/+KKlkuOcsDaSUvPjKi/zPP/mfXJ67zLmz53jlu6+EDvMMjw7zroffxS3HbmFmeoYPvPsDHD18NJJOAIVigf/y//4X/vjLf0ypVGL+8jyL1xZDDXaKonDvg/fykR/4CBNTExyZPcJtx24jaUZPovjU00/x+//193n66afxPA/bCv9scWxijL/8Y3+ZI3ccIZ1MM3nrJPlUPnxIc9UbrVVrfPG3vsgXv/hFlpaWwslo4n3f8z7+7gN/l1N3nUKVKqqvosjwz7kaBv3VV1/lP3zpP/DlL385spHK5XL83z/5f/OJ7/8E2Ww2CKH1KEsuv433jkAWL6HrKmbSQAJvnJ3jP/zutzh/tYDvSxprxQY5qtan+RAiCM1ufN533733cPLxn2P23vezeOF1Tn/7D1m5cpbx8RzvOTlBJpOE/AkYexcY+Zb62a7NO1fe4eLViywvLfNnf/Z/+Nb/+SZ+15vy9aTSKbL5HKqqUC4WqVUjhv5DsmeNlBACXTdIJpIYRrRMur7vYxhG4M1JsKwgtFYKeXdh2RaKpuB6Lo7tYBgG6VT0LKO2Y6MIBc/z1sJrYXVSFIVKuUKtWiNhBnfRyUQy9GSABlJKdE3HdV2surWmU1gjpRs6tVoN27bxvaD/k8lkZI/asiyklFSrVSqVCqVSiWKpGCrc17jzdl0X3/eDZy6JZGSDDsGdfb1eD0JrEY1UIpXAdV0UEYQRTdMklYyekdX3fHzPj3SON1Ov14O7e8NAQ8PAIFi7IRqqqmJZVuSs0RCc743zqeE1dsT3wLfB9/B1ia8LfF1BGDroCXwEtq9SrtqUy9cnZMnVPFStclG1olypUrddbF/ioSBUE1VPomkGuqKgK6CooOggDAlCA8Wg+dmEaqvBIwgBcjXcV149r8Lg+V6wMoYW9Herld+3gj1rpGJ2MfHCubueXf9emVOGlTehtgTVZaQVGG3XyOKMHMTVEli5OXx1c4hcUQTaqlH2fLm2HmArqrUqZ8+fZezVMQzpMnbsPqaO3o1iLVAqv015ZZFU7R3yqGiJNKSmIXOwbehvNxIbqZjdxTalZ4jZena1oXIqsPwmFM+B64FjBaE8PUM9fwDLzGFlXkEqLYyUECiqQBJ4Nn4Ht71Wr3Hh8gXyb+aZmphk5ra7GB8Zo3D+ReaeP4u1ssKIJ8kYFlpy1QNMzcRGKiYmJmYv4Lou5VKBarWKpipk0yYJUwe7hGfXkLYNKGCkEahgZPAVHR8FXwazftd5Shve/Q/W/IMOM8jxfT94FOC6WI5D3bFxUVATefS0jWLoSM/Dc2yEVUFYBYTngGaC2kPococTG6mYmJiYNpRLBb75Z/+bl777LKP5JO9711GOHxrHrZaoLs/jlMto2UmS++5AS40iNB1XSeC43uqPj9P07EcQpPVQV981ayypJKXE82TH5zzVWpV3Lr7D1aWrpBXJ0NEHMYSPWr2MWz6LVyujOe+g1y2EnoChW2DoyJb30VYTG6mYmJiYNlSrVV767rP86f/4fQ7sy3Ny+CGO54/g1y1qpRXqlTqJtEly+CjK6EGwK/j1JTy7jucHkyQ8r9nwSHSh0PCnlNVl1aQU+NLr+DpF3aoztzCHpmnsm9jHzIFbyaWz2JdeoL78Nn61hnDm0a3lwIvS05A/xG6Pi8dGKiYmJqYJ3/OoV4pYtRKVpXmyps+BfXkmRzMIJOVyFd8TCDOPrg6hpUcQmsnqXH3WjEIbp0hK8GWwuoloiv0Ff6+v1DwRUyLXpsY7rkO5VgUExZUCS1eWcavLjA9n2GeoCNXHq5XwVuawpIJrhVxpZAcRG6mY7Wd339i152bdrz2GY9e48PozXHjjeaRX57YZhVN/8SEUICkEZ9+aI5GbYPSW+8kMT6OaWdRk63eUWuH5PlIGHpSqBEsrCYLEiRtTfmhq68VhS+USb73zFqqq8uYLL/L8156hVlzmvfcc4uOPniSraVTmTlO8dBEHlaqSQYror0TcSGIjFRMzSOLp8bsez3VYvPIO5155klRS5d67D3Ps2BEqZYuzpy9zdX6FvDrGWG6W1MztoeVLCd7qsydFXM+cKASoGwxS8MLyRgHBu2b1eh3f93nt7Qt888VzlFeW2Deew3I8MtLDKs5TWqrgCA176DDkDkTpjhtObKRidh27eupyzI7E933KlTLXFq6iCZ+F5QJLxSo1S+HKtQLJtInnCURyhPy+UdKjM2hm4Jk0PJ0oq120Cv01e066pjGUG2JibAJf+nj+5vQc6WyGfbP7qQ7l0BIZriyWqdZsLMsJltNS1Egr6uwUYiM1ABo5pXbaKsM3a9JDiA1VzGDxPI9Lly/w7AtPoSB5/fUznH3nKromKNYczr6zQG5kgpP3fQ9HDp1EM1Ok8hN9X/Oe7+PL9uG+dCrNscPHuO/O+yiUCpy/fJ5y5fqya0IIZg4c4H0f/l4cy8KsXuWbL11Elx5TI2n2jWQQurZti8FuBbGRGhDxoLn9xH0eMyh86VMsFbg8dwkhfeYWlri6UkEToCColOtMumluTU0wciAI8Q3iplSurrovgFbLF+q6wejIKNOT0+i6ztzCHDStJCaEIDc0RDafR/oe829YnH/rdaRdR1NgPJdC1Xpfh3AnEhupHUA82MbE3BiCF2pXkxauGh1dN9h/4DBDqQyaIhjJJcmlTIbGp8jkhoJ6A46aSFbDfn7jrwDf99cMjKEbjORH1qeAkcHU9Eq1gislQ2OTmLfeg/Bdpidy5CfyCE3HNoeo7LBIT6/ERupmJX6AH7PKzRz27RdFEWiqspYbCgSJZIoTj7yP6Yl9qKqKoSloqopumORGxrdMF8/38f31x6l5Idp0Ms3h2cO43mpaExlMS5+/Ns/bF97Glz4Hj93B9IPvw9B0EqZG0tBwfQ9rcYGVlcXoyokNP9vInjZSjXcOorrCrepFucNqJD1cG0xktIew1xVrFn5dftgcSY1nbddf++ivryRynT6R+orW9foNZzTrJBDrEtL1WndNl8a/QeoU9bxqHlFWB7V+3peJqkur+o3+afRXv0Q5x4NEkwrqatoPQbAC/fjUNMdP3oHaJnFlu3Zk07+wz6ll4/hs3LbalqZp5DK5Dd/LIKmpoiAQZIdGmDl8Yi1zAQRZEbSaDYUgvYpYe5+rB5omczQ/e28MDdsRRNyzRspxHC5dvshLr76Ipmn4nh9k2AyBlFCql3AcB03TOH7iON/38e/Drtuh5Gi6RiKdQDd09u/fz8UrF6k79e4V22A7NpZjMTI2gq7rvPd97+XWY+HyUwkhyI3mGJ4YJpFIIBXJiy+/GDrrcAOJ5OriVaZmpsgMZRgfG+fgzEFsK1xfJdNJDh47yNjkGJl0hguXLlAqhkgbseHatCyLZDbJg48+GGRWXipSKYRLH4KAA7ccYHxinGQqSaFY4MVXXkRTwl1eawZYwOLyInfffTfjY+N4vofruKGNXjqbZmZmhlqthmM7lJfKaDK8TqqmomkajuOQG8rx0Y9+lGofuYSOnjiKZVmcP38e13ZxqkFG4zAoSpC9WDd0VkornLrzFKoaLsszBBl21dX0E1P7p/CkpFyt8s75c9Tr9qb8Tt2QqsQ3fHx8RkdG+dCHPkRxJXoKkenpacrVMi+89EIg3/cBuTYrUErJwtICF69cxHZsXNulWq5iaNfTD/nSp2yX8T2fZCLJXXffTS6ZW5XVIyJIfplKBznS3jx9mldefIl6rRZ533pueq9m5s1kszz8vndz5z13IxSBYzu4bu/ZQYNYtsLw+AgT+/dhmiZD6SGG08OoyuaLpVO4pZGx1hc+c5fnePmFl1leWm7daA8kkgkOHT3ExPQEhmqQN/MktZAJ+ATYwsZSghTkb73+FmffOBs663CzvKnpKY7dfoxsLospTBIkQucR8vCoeBUs36KwXOCt195i8WoPYYw2fWcmTE7ccYIjJ46gKRqqo6J4SuhbxKpbpWgVsT2buYtznD97fp0B7incJoJkk4pQGB8b587b7mRsdGzNsw57qXq+x2JlkWKtSL1W59L5SyxdC5+sMJFMkEoF2aJnp2c5tP9Q5JsVgHKtzNzSHFWrSnGlyPyV+dA3K7quMzI2QjaXJZVIMTMxw1B2KJSMYOgIvALHdXjz7Td589yb2I4TjAeO2/082BC1yA/nmdo/RSKVYCg9xERuAr1Fuo5eWS4s89qZ17i6cBV8ie+5wcrpvsTxfKQfrD5h2VaQ3043MAwDpSk1vGZoTB+YZnJ6EkM3GE2PkEvkej4n1z4qIBSJ49r899//A377i7/F4kL0EGKcmbcLnu9RKKxwZf4yALZlh0qJHSwUqSAMhdF9EyiKwtjYGEcPHsU0Ni+T3+mE8PCwsPBkkNxupbjChYsXWjXaE7l8jv2H95NKp8gkMxyaPMRobjSUQfelT9ktU3SKVKoV3nz9Ta5cuUK93sHD6yBeEKSjz+ayTExOkEvkGEuPhb6A63adK4UrrFRXqNfqLBeWuXCpRV/1qGMmk+GOe+9g9uAsCSNBggQmZqhnOFJK5pfnefvK28iqpFavcWXuCtVqNZScRnZWoQhSqRRTU1McP3q85/obqdaruG+5LBYXqdaqLCwscPny5dAhsWQqSTabJZFIcPSWoxw/fjxyUk4pJRcuX+DC1QusrKywuLDI5SuXqYW8IzcMA0c6WK7F+Og4k1OTHD10NPJNa92qs1Rcxn/7DJZlsbKyQrFQ7NxXLb6qO3VSuRS+9Jkem+bo0aNk09lIOgG8c/4dXnjlBS5fuYz0fXzPQfo+nufjuH5PiQdN0yQ7nGVcjqPrOvv2TXNg6kAoLzEIYPpIXGzLYnx8fP0Eji1k7xop12NleYXLFy7h+5JatYZt2T3FxhsDj6IqJFIpDh87snZxRHlILRBoaCgo2FWbKxeu8Pabb7cq2BOjY6PcftftmAkT0zRR1PBZTwUCXeik1BS+4lNeKfPO2Xcih3mEEIyNjWEKk1wiR1KPlk1XURSSiSSe8LimXOPa/DXOnjnboxKbN+XzecrLZXRfx8BAJXzICIL90zQNTdMol8qce/vcujBkL+eEEAJN11AUhVwyh1W3Iumyhgze/3Edl3q1ztzlOd46/VY4L1EEqdWHR4dJp9KUiqXQGYI34rou1UqVYrHIwtUFzp09R7lU7l6xiUQjd5KEhJ7AsXu/wWyF9CWVcoWFawuUSiWuzl9l4dpCeyPVZrPjOIxNjAXhUdvp+7mkbdksXF3g0vlLuK6DVavhuu5qht/evOtUOsXk9CTS7/N5JIJgQn7ws11suZH6p//0n/L444/zd/7O3+Hzn/88ECzp8bM/+7P87u/+LpZl8eEPf5h//a//NZOTk1utzhqe63J17iqVSg3P8ygVStSq4e7mVE0lPzSM47rBQ1ihoKCENlIq6lrYyypavPXGW7z4/IuhZDQzMzvDex97L6l0iqSZRNOiHWZTNdEVHalIVuZXePXFVyOn6BZCMDs9S4IEY+mxwGsQ4Q2CoiqkU2n0pI4qVC68c4HvPvfdSDoBjI2NsfLBFUw/CD9GnQWnqiq6oaO7OoXlAq+99BqL18KFQhoyNE0jm8hSqYR8NrYBicR1XWzbplwq8/Zbb/Pisy/ih3j2KoRgdGyUqZkpctkcy3cuh047vhHHcSgWiiwtLnHxwkVeefGV1uHtDmSymbWbHEM1sKz+DLrv+xQLRS5duMTKygrn3j7HpQuXQj0rE0JgWzazB2cxDAOrbgWGoQ/q9TqXLlzi9Oung2emKwWs1dBorwYwm8ty+OhhPM/ra6JY43Za4K0aqe2Z5relRurpp5/m3/ybf8Odd965bvvP/MzP8Md//Mf83u/9Hvl8nr/1t/4WP/RDP8S3vvWtrVRnHVJKHNuhVg3uTCqVCrVKSCOlqljW5hMxykDXmFHmez61ao1KOfoAVa1W8TwPVVVX1/6KPjNMEQoqKq7tUilX+tLLrtsoKH3F6BshMR0dgcCqW33plEwkcWwHZfVfdMVAEUFfu060vlIUBcM0UFWVeq0eejJBS2TgJXieR71Wp1wqhw/3JZPUq3UMzQhC4n0+xQ68ABfXddeOX6UUrq8Egnqtjm0HYfp+vTsIPDzLsqjX61QrVSqlSmi5tVVPx/O84B2nPjvL932sukWtWqNWq1EqlUM/v1NVNfA0+/aimj9v3zz0LfPZyuUyn/rUp/jN3/xNhoeH17YXCgW++MUv8i/+xb/ge77ne7jvvvv40pe+xLe//W2+853vbJU6Hbmp3yO5SXcrJiZmb7BlRurTn/40H/vYx3jsscfWbX/22WdxHGfd9pMnT3LgwAGeeOKJrVKnLTe1cbpJdy1m9yOa/sXEdGJLwn2/+7u/y3PPPcfTTz+96bu5uTkMw2BoaGjd9snJSebm5lrKsyxrXcw56nORmJiYmJjdxcA9qQsXLvB3/s7f4T/+x/9IIpHoXqEHPve5z5HP59d+ZmdnByI3ZncT34XHxNz8DNxIPfvss1y9epV77713bUru17/+dX71V38VTdOYnJzEtm1WVlbW1Zufn2dqaqqlzMcff5xCobD2c+FCiPdiYm464jBROBp9FfdZzG5k4OG+D37wg7z00kvrtv3oj/4oJ0+e5P/5f/4fZmdn0XWdr371q3zyk58E4I033uD8+fM8/PDDLWWaZvC+T8weQkrABdZPdxb4CGwELoYuGc4nmRjvkrq7w9g8OpojndIQ2CB7mBLfUpZEEQ6a6mFokkxGZ3w8hyrCrc6hKAqGYaBqKkNDSXTdB6JPrRbY6LpPIiFIJzWGh1NMTORDz+4bGcsyMpImm02RSqoIYYNspVdvcjXVJZVQyKR18vkE42M5dKV5Fl13OelshuGhJLmsSSaloaseyDrIsIY4aEvIOgkD8lkTvCSlkQx2Jddidl8H3YRgZChFJqmRNhUMzUeRFnjdZg23l6kJh1xGZ3QohZVQMYSHHXK6fTaXJpfWSGg+huKhYoFXBb8XH6WFbr5DUpeMDiXx7GgvdUOwoO5yufu+DNxIZbNZ7rjjjnXb0uk0o6Oja9t//Md/nM985jOMjIyQy+X4qZ/6KR5++GEeeuihQasTs2txwb8GcoHmC0Ug0fBR8DkwUeNH/sK9PPKuDitTi7X/WmyHZDLJu941jKa9A1LbULT3AS9p1BjPVxhK2bz/3bOMZz8W+r276ytOKMxMTzMzUwfealGyN2Og6y4zk3VSySSHZ8YZzz3Mhz5wuLuRavpaCEimkqQzGQzD4PixHAnzAsir7SvJFtua/hzJLXH/nTlO3CK450SKR+4ZpV6rt66zadNq2gpDZ3xinPxwnmwmy+TwEjivAYLWaWhb69L4oPsOdxyBxIePU6/XKa4coFQsre+rTWI3tzM6NsrBw2Ok00lGR8qYzutQMduWDza10U1KJpLX+Ph7ZrjnlgfXpux77sb31Nq9pNvoK4NjJyY5NFLBNFzyjo9YmV9/enfSYwOq53HnrM2Pf/JeqpVK+4It5ci1XzXL4e/+8y93rssNWnHiX/7Lf4miKHzyk59c9zJvzODY/bOnvMBAeW8Hn5v2QwVUAdNjPt//fXfge7cFX7QyMMEii623r36laTqqejHYIJvl9N53CR1MLbgAx+/fxwP3TERI2X29PUVR0HULONeiXK8eC0yN+0yMJZDS5K7b7uv+3k8LA9PIuQSri7Gql9uosTpYbhrwrg+iAhjKSO48mUHKNFJO4HvHVvuqgyFZ91muvpd2fYV4VSmAU2yqt1E5uUml6wOmRENy/CAcnTkcLAHky2DB6XZ1mhVs2h68pL66orqoorhvgSs270NHvWgsf86Y6fPBBybx/XFY1atr/7SQrSoKqlIFUUO4BVg392zDfrQzeKvbFeDWaZdjH7296YZArvvVWnbzJkmxXN85RuprX/vaur8TiQRf+MIX+MIXvrAdzcfsWiSBgbo+sK4ZXQmqAqqhEpit9cZn3R/tDNW6j+sN4Xo6Gyshmn8LFEVF16Msr9SqnXBhsI16CREsZANAp5VHWt3ttv2ulaHbMFi1krO6TVGCPE5BaE4BfUPZje1tNFBrZTZ+lpsHzY1l132Ua98JQFMAQ20hu1G8zb5t1Ek2tjX9tDIindpZlakIiaErgLKhnR51amxeq+tvbrtV+Za6Bggp0ZRg4dqOx63V9qZ2bKe3lUu2bwGmmJhI9OLNtArniaZ3xUJ4k7vV8dxK2oVAW94QNPX7oDLBrru/WBUuBK2Pe0vlaKv32vmxUV4n2R0V7F6kly+2/TzcuSd+bKRibkJ6GDS6VYvy/W4m1L73YKjaCo7YiW1FRjQmPcmLaqjCFtkpJ1ZIPbZJ7T27CrpQFJLJJNmh3No6d4lEgjBrbWmaRiqTQlEUgoXsfTw8XELmXJLQyJiq6Aq5oRwjoyMh9+g6Q0NDaJqG67i4iovne/gtQzSddfKlj+/7OL6DkTQYHhlG01dPmdDnsyCVSeHhUXfqQUZURe1wI+kjGnH+boPiuo/N27qF+Jr+2Lht4ANKmHoby8o229vR6hzuVle27sNmUaI5hCM6bJdB36+FlBr9KdfXbbWtnbxN+7Cqr9y8uUlQdHltiqxtky2+WFev6Y9ObTarKjd8FrTen431Wohbf743hQk36bWx8qZGO7N2nDcp0KZ8m88d2LNGStc1Zg7McPCW4EFpvV4Pvdy/oiocPnoY3dSRSBwcatTwCLdKtC99PD9YoVjP6dx6960ksxuSFPZ4QAWCoZEhsrks5VIZ3/VJJ9NoIQ51Y7Fb27GpW3WqVpXRfaO865F3Xc/700WfVhM2Dh0/RNWvMleYI2EmSKfSLbOpBtM9bDT83hJnNJrqeAffQ/2w9fqiH6PVTDuDFO751WBpGKrGZ4K/ZdN2uaFsL/I2bRKrA7BoetbRqo0e5PVUpMd6DTYZpxBtitV9Es371g+Nvtqo185nzxopVdUYHhlm/8EZhKLgOE6LqZ10HB+EEIxPjqNpKlJKPDwcwue18Qm8Fd/30ZKB8VS1FsNzD4ZBIEilUyQSCay6hSIUbM/Gxm5pODpR82pUrAp1t05mOMPho4exbbvHyMbmQmOTY9jSplAr4CkeutTR2bwierAXLgo+atvrqVMYaasM1KAM2CANYbsOCjsQDXrg2mgsVgfJlmN2H4ZqzUB1Mgit5Ldps6td6cXYNAwMgzFUG+tFOVTr+qpXId3K9HJD0D972EipDA0NMz29H1VRcV23dWqETuOJgFQ2jaqo+L7P/OV5lheWw6fGENfbKRVKDOWGMNUWLy/3aKR0Q0dVVcqlcpBcbqXYMqV9JzkQGE9f+kH+IB9mpmeu91EEQ5VNZ1lZXqFWq6EKtWWCwUYdQ5ccmKgxPeazPmejaPGxeVsbY9XKGG3cFtmj6qdsVIO1cRBu9V0vsjvJgd5DfB22C64Pjs3hoY1Gq528tmU6GZ5mz6GpcjtD2WxQ1nkvPYTE1pzFHgzSxiIbRbet267NjWUaH5uPQzfZLZpaq9eioXbHod0x7NOC7VkjZZomJ46e5APv/iCapiOlHzoZmJSSpfIyV1euUa1Vee47z/H808+HToWt6zqpTApd1zl25Bgf/MAHmdk3s7lgj+NZrV7j7Ytvc/H8RVaWV3j1u69y+eLlUDopQmF4bJixiTFSqRR3n7qbD7z7AxiGEUpOMxcuXeDFV19kpbDCtblrnH/nfNvss8P5JD/yF+7l+7/vjtVp5m3YkSG+QcsbVPs3MMSzZgQan1s8x+lYt9MXTV5aLx5aO1vSrCN0VqyrTj2237WBLXZTdgF71khpqsb42AS3HDqKrkdLwiel5J3L77BUWsb3fM69fY5v/tk316UN7wXTNBkaGSKRTJDUkoyPjHPi2IlIOgGsFFe4cOUChZUCc5fneO7p53jtpddCyVAUhf0H9nPoyCGGh4e5+7a7OXLoCKlUKrJe5VKZxflFLly6wNkzZ/nuc99tmxhwYjzPI+8aX31Rt+k9KJo/bjBQ7QxPN4+pL4MV1TPq15C1vJWOUKeXkM5qnU132K0MTYftXb2YVu1sLNPBw2iUaW5nk0fVqf0uz8s2Nt/Sg2pTr1P7rTd0b3+j8LanRI/eU4+nweaGulTu5cahA3vWSDUTJXMt0Eca5u5E1WmruTF9FcZAdTBOrbb1ZKCiGp5+jmGvRqjXNjqNkK1kdDMGG3RsN4ht3L7OUInVz210a2mYGsdxo8FrNjIbDdVm0a03bNC7lSMTxjBtHJg37U+H9lvS2K9ejHWLuh1l91YkssFpeX70du7G70ndpDQvibR7l0ai9Xm88UXdSDakXwPS6mc30U3vLdyfxnFbO3bd2mrzffONySaZPYjttVDbIl3qruviDTdVodoXLeTstvMtOrEndZOzqw1Ug3bGpcOafJvLNm/uZZBoaR17qNcLYeqGbafDXXjb8hu/63anD5EnVGx6LtXkZbSq12oiRDs5a59h/Qy75n1rI7unZ1dd6rb8ulmPdl5UB4+k2RBvikZs7JOWFXuQ3a5uiOhH2/7pn9iTitlFRDQSoT2obgbqZqfZw9pCL7GX4xL2cLWU2YPsTZ8bRjCqpxXWWwpXPDJb6fRvkdzYSN3M3BTjatNg0TJ00urvdl9FGfF2YyhvUGw0VlvVRJewX+jD1gj79aB/V0PV4/HfFkO1N8/DONwXswvoEuJb93FQIb6ot7bbFQYMG9ZrV7db+XbToCOG/louodTcTJsQ1sZwUtcyrSYxdJLdQkZz+HBjH7SMbIUIJfZSvF0IrWuYbsMXPanVrZ1usjeEIwcY+Ys9qZj2NN1I3pBnW5tuYrcrxLc371i7086rGIBhbnsT0eamI2z7XYv0I6NL3Z12aolWfT4QwQOWFxAbqZi2CK4nldv2i6sRbukWCmr1VWygtoBuobMBGaq1ZgZkqEId2n5khDBy2+Vs3xiBAycO98V0ZOAeVBRxUZc6ihzi66Rk1P4IW69F2Cq0vDB1eynbHPprE0PqdXZf87a17ZJNs+FEk+x1q1R0iWGtC5s1h6I2xtM6yGim1zBcO9EbxXaIAnaNlXVdtqm7iPZ90lS3p1Oil7hef7G/2JOK2X7aRY0GIbf1Hz1UGMRtbsxg3IQeQn/tmtz0uZvMEDLahcfCeGu9hDXb1m37R0S24FzfApGxkYrZ4fRobGIDtY10u8sYkKHqFvpr1+Q6w9KQtVHnKIaqw3735LRHNMKtZGzql5uXONwXs31EvqZuRIgvjLJRQ3mDKjuIkGC7su1mAkYM/XUKB25SZUPor63spnrdXkoNE+1rDusJ1ofH2r5E266hjTq0+75N6G1dO21ihT1F1cKE3jYcnzDVejkle7wMYk8qZufSS1gw9qBuMAPsu5ai2t2gtKsYNmwWosC683ELz7WeunTA5+wOvgRiIxWze4kN1A5hgJ5hqJuSdl/0EZLrKkNsMFZh5ITop+06LSOqt53s2XCfL31qtRrFYhFd11dX6Q4388SXkmq1ii99hBCkUilGR0cxjRYJCztgmia5oRyJRIJkIkmtVmN5eTmUjGZKlRKe76EbOolkgqGhIcbGxkLJUFSFkZER8vk82WwWKSWFYiHIzBsRy7IwEyaZbIZ8Ps/Y2BjJRLJl2dHRHMlkcvOjhFYhvnXPpLYixBf16h10GPBGzPRrFx7qtL1FPK1dAsI1ER3qra1qvlqmOQy3rv0mGW2jaSLcTL+WYcVmGc30GkprEQ/rFnpcV6iXWXzd9q1D0a7DYBt56+qGCSt2aU1uZb6JLaJYLJLP5xnOmJFTR+TyeT70kY/wwMMPBynWbRvXdcMJEYJUPk12NIdQBcVrRQpXC63T0HdA0zTMhImqqfiej+3Y+H6LLMG9yjM08uN5UvkUTt1heW6ZaqEaKl2GoihkchmyQ1mEEFTKFcqlcl8pN5LZJPmxPLqhU14uszK/gmM7LcumUxrvetcwd9+VR9M2GJi2Bmr170306kHtViPVC2Hqtivby3bZYlvT37LFtnUfZesysvm7DWXkhvZli3rrVJMbZLRos/m7Vu3IjXI66NRKv1Y6tGunpf5NMtrW66IXcoOsjfJZX7bFx03yWtVvVQYoluvkH/z/USgUyOVytGPPelKWVeeVV19mpVTAlz7VShXLap0lth2KqnLbnbdz/6MPkh/Kc++993Jo3yEMPXz22oaxfebZZ/jSb3+J02dOh5bRYHR8lI/8wEc4fuo4SSPJxCMT5BLtT4J2SBHctVaqFf7rf/uv/M8v/08q1dZJCrshhOCBRx7gRx79EWYPzqL7OqZvorSJOAtsNO0dVPUi4DV/QZs/2rXc4vMOjWvcFHS5Fe96p95hUsCatxWijVafN+WxauPZhLonCFmhx13pKLufultJW08zGnvWSElfYlkW5UoZ3/eplCttU5m3Q1EV6vU6UkoEAl3XSSaTocN9azpJiaIo1KpBGDIqiWQCz/PQNA3DMIIwYjIZyuuUq/98fBzHwXM9SqUS5Uo5kk5CCKy6haZoJIwEBgYJEm2NFFIF2Tg9u4X4Nn3ZYtugQ3yD9pI6lW0VtmlHu8GhXd1uYat27TfXaxeravP32seNYb1W4noIG7Us0kO4q4doX+twW5tCnYxjc7V1xlL22c7G8OXGehvoKQrXKhzbuWjfZTqwZ42U5/uUS2UUdQHP8ygVS9SqtVAyVFXl0JECnhcuvNcJq25x7eo1rly80pcc27HRTR1N11CUaPNjBCIwIhLKxTJzl+colUrRZAlBcbGI6qgkSaKg0HU1i3YXek+GZjd4UL3qE8bAbAVh78abDVSIut2K9iQ25AOWqJ5dL8VDeTohdW1rqEKyZigH6/0M0oPbs0ZK+j61ag2JwHVdiitFqpVwz200TaNSruB70Z8fbcS2bQorBRYWFiLLSKaTuI6LrgVGqp9U9IIgNFKr1FhaWKJQLESWUylWUDwFgxDh0E2q3wwhvkHpstFb2UqiDDqt6vQbDqSHcb0HSxHKmGyBoWo5gSOsoWolox9uQGiwB/askYIgvLbxJ3T9LTioUsr+zpUN3kcUI7XOy5HX+yqqXpLr9ftaDzBSiK+jkD629/p9p7JR+2JjuC1qSLBb+bAxnF7iZt3CSRvCgC2baQ6VdYkn9eSBhI79bVa3Y/is00OydmXbqNKpfCf92snoydhtQ1yvDfF7UoNAsDNv2Hc9zR0bpe5OQdDfvuyUNqIw4AujpxVFWnzVtlqP8loVDbVLIdoJzSDk7bTz5jqxkYqJ6Ug/F++NMho70VjBthuqTs23XQMvhKEKzaAM1U48tlvHng73xewWwj6H6rdeL3XDfr9dd8/twoDt6kaZEBGlXi8Pmhofe5hVFibMNQgZzXJ6ep7VR+irp6pddi6UjI6FBkx4Qx17Un0i+nvCsqWIHa3dVnKj9/lGt9/MTtLlJmPLMtzeJAyoW2IjNRB2njHYafqEpqtjtB2THKLIiOrRDYqw7d/I5xmi5ce+2ulapAcPN3KX9NGX23YYBtBQGBEDaC42UjE7F7HhZ93GqMIGoVSv3/U78WOQdbfDUPV5XFqK6KFPu+5qhOPS6+5s8qJC9MPGooM4RXuS0aVQLzK28bFnbKRibiJupPe4GzzX3do/bep2fLyx1c8EN8reDcd/dxJPnIi5ydiKWVNhQoiDbr+fh9vdnvr30k7Y7b20H7Ve2JdyN04u6DBRInQ3RzwuYQ5J28o774XbrST2pGJi+mI33kHvRp03cBPsQkxvxEYq5ibgRo1Yu3mkvBG67+b+2gPs0MOzp8N9QgiEEChCQSgCoYhQnrSiKJuXHFpdQmgQekWurwR1G8sQNfTpRy8hgv6JqlfzPvWmx/Uy7ZscwKyyyGW2MsQXtmwv/TmI0F8vdKvbc2wrvOh1hSKutde/AgOrFqpyx30IocA6OVFDs4NlzxopTdeZ3j/NvtkZpB9k2A2bqkNVVQ7echDD0IOcVFaVxdIiuqaHU0aurm2HBB1O3HECNaGGk9HE2PgY6WyacrmMq7sIT1A36j3Xb0xf930fKSWVSoWhiSHufeBeqtVqJJ2EEBw4coCqW2V+eR4hBKqqth13FeGQNGokQnbl9rBDbzkj0YfR2CmEWcG73TOsjtl2I/RPr9W2bBXym4c9a6TMhMmxW49xzwP3oagKvuu3z4bbYUzKDuUxEya+71OsFmGRnlJjbHyPyff9wEwlJA++90FO3nWy57obMRMmw6PDLC8to2ka1VoVw+ht5fE12RI8z8P1XBzHYergFB/5gY90zl7cZeweHx+naBV5+8rbaJqGbugoonVfaarHeL6Cqcke35XcLsNxMxmoBtttqAbUXtRVwDtOtuhWIYx+0arFrGfPGilFUchkMoyNj6GqavtV0DuOSQLN0FFW69u2TblSXgu3daNhENZWYUfiS5+hkSGS6WTXeu1QNRVd17Ftey3XleX07iU20nN4vofneni+h5EwmJia6JzWvstuJ1NJbM9GVmVgpBy9bV/pqk8+ZfcmOPKsvLDciBBfWHmDDv31006ruiHDRl2jhz0Yqm67uyajsTFi/0Tu1j68qLbytz4M1zv96bJnjZSmaoyPTnDk4DE0TVs9R8J1oASqVpVSrYztOJx54wyXLlzCtTt4Gy1QVRXd1FFVlbHRMY4eOUou1z7dezcj5bgOy8VllheWqdVqzF2eo7gSLtOvEIJUOkUmm0HXdfZN7uOW2VvQ1C6nTBvVJJJCscDcxTlq9RrlUpnCcgHXad1XmYzO+989y8T9+1CUTqHP2IMaHLv11n+36j0g1mzrVhi7flgV2qfsPWukdE1nenI/tx8/ha6HSMLXhJQ+F69e5M0Lb1Gt1Xj5hZf50//xp5RL4VKsG6ZBPh+EDR988EEeve9RTp6MHu4rlAo8891nuDp/latXrvLn/+fPOf3a6VA6KYrC9P5pZg/Nks/n+ej3fpTbj95OMtnew+uERPLSKy/x1Hee4srcFc69fY7XXnqNSrnSsvz4eI7x7Md44J4JdD3687nBsBcMVIObZMDfpRHM6O3fvM+29qyREkJg6AbJRKrn5zUb8X0fXTcQQiClpFYNsteWiuFSrJumie/5JJIJatUauqaTTqYj6QRg2UFoz3Vc6vU6hZUCi9cWQ8lQFIVUKsXwyDCaqiF9ScJMkEqmIukkpURTNWzLplqtUiqWWLy22NZIqcINMif3fL1t1Uy/jd9v5YzCVuUHPbuul3bCjrhRwzkhwnNRCkXqwhttbRo6NIjaP/0301eboulDn0Yzfk9qkOylG+4+2PWL38YMkJ1yLoTUY1CPJ9cJ2Sl9sbPYEiN16dIl/spf+SuMjo6STCY5deoUzzzzzNr3Ukp+4Rd+gX379pFMJnnsscc4c+bMVqiyPcTn103KoLyo3chW7+vAR/ntZ8eqvWMVi8TAjdTy8jKPPvoouq7z5S9/mVdffZV//s//OcPDw2tlfuVXfoVf/dVf5Td+4zd48sknSafTfPjDH6Ze7/1dnpjdScOLiu5NCaLdFfRSr12ZqHchYXVtVT7q/oat223ft2P/ByAvVHMh9Wt3eNY+99rPvQps0/5OZdCHe5WBP5P65V/+ZWZnZ/nSl760tu3w4cNrn6WUfP7zn+cf/IN/wCc+8QkA/v2///dMTk7yB3/wB/zIj/zIoFWKiYm52dkJj5Kgx4kLO0XZNuywyRcD96T++3//79x///38xb/4F5mYmOCee+7hN3/zN9e+f/vtt5mbm+Oxxx5b25bP53nwwQd54oknWsq0LItisbjuJyZma28rd/It63YR90HPhF4ubAf2rejRo9tmBm6kzp49y6//+q9z7Ngx/uRP/oSf/Mmf5G//7b/Nb//2bwMwNzcHwOTk5Lp6k5OTa99t5HOf+xz5fH7tZ3Z2dtBqx+w62l1E/YT1usnuVa9+Q3yDkj2Iuv30c1TZEdtpW6TH8KkIV7x3ZbYoDtaxzQ5FOp76W6yjIHR3DNxI+b7Pvffeyz/5J/+Ee+65h5/4iZ/gr//1v85v/MZvRJb5+OOPUygU1n4uXLgwQI1jdh+tnpvE7E4iHrtNN/2rG0QrSxOhnYGcUvF5OQgGbqT27dvHbbfdtm7brbfeyvnz5wGYmpoCYH5+fl2Z+fn5te82YpomuVxu3U9MzNYQDyybGWSfDFBW6OhUSG8ssqo3Mmx2852/AzdSjz76KG+88ca6badPn+bgwYNAMIliamqKr371q2vfF4tFnnzySR5++OFBq7PliKZ/MdvNVoZQtjIMN6hQ2Vbt/1aHFSOGY0PPrguxDzvVc+randsVSrxxbQ58dt/P/MzP8Mgjj/BP/sk/4S/9pb/EU089xb/9t/+Wf/tv/y0AQgh++qd/ml/6pV/i2LFjHD58mJ//+Z9nenqaH/zBHxy0OttKbKhiYnYC2z17rrm97W57N9BfnwzcSL3rXe/i93//93n88cf57Gc/y+HDh/n85z/Ppz71qbUyf//v/30qlQo/8RM/wcrKCu9+97v5yle+QiKRGLQ6MTExMdvATWicdsgubcnafR//+Mf5+Mc/3vZ7IQSf/exn+exnP7sVzd8QBKtZflWlp3xSzTTqKIoSZAnu0yNr6NLIOtyQHUUnoYjrGYj7dBQFgYyGbqqqttXretbjfsIKvYbqtkr2IMpHTb0xyPL91utD9nY2GWqR1i1UbNCi+5EX5jQcWKPr2bMLzG4FqqpiGAaGGW7BWsMw0A0dXdfRNK2v1PENhAiMi6Iq6LoeWidFUdCNQJ9OxiScUoHxU1UVTQ+SHrbTyzCMIHNvTEwodsjtfxR2jOo7RhEgNlIDRSiBdxB2cFW1oI6qrRqDfm1Uk7fSMFRBzqzeTzxVVQNvavVHiP4nhzQ8u4Z31jCALdvXVERLw7iVz/12yjPFjTMDdsKAsZV6bOM+dmvqRq+20FNX7JRzYnvYs0bKdmzOnXuH5557BlXV8DxvLYttGGpeHcdzUDWV2f2zPPTQQ9Rr4dYg1HWddDaNYRiMj49z5swZlpeWQ+vSwPEcqrUqI2MjKIrC3XffzfjweCgZilAYmxhjct9kkEKkVuPJp57snvSwA0uFJcbHxkmn0+RTeXKpXNu+GhpKMjMzE8KD62ZgBmWAwsgZVEhwO0J/W53zYRDt9NP+IFTZythjWAbdnztp39YjZJjb6x1CsVgkn88znDEjh8YSiSTHb7uVg4cOI6WkUqlihVzgVlFUjp86wT0P30smmyWhJEipKZSQM/uFItA0DUVROH36NH/6p3/KpUuXQsloZnh0mPd/9P2cuu8UwheImgAnpBABpmFiJkwsy+JrX/saX//61yMvAiyE4K677uLj3/9xpqamsOoWlUoF32udjl7XfWZm6kxNWay3U23nH7feiY7fh5XXaXu/ZXspH/ZSDVO+XVnZw+deyoeR1+azbPeZ9dsbP63K9iSvqX6ndjZ+bv7dSXbbz63abNVOD3qE3ucNMpv16Va2ZTut5K3/oliuk3/gH1IoFDq++7pnPSnHsblw4TzLhRU816NYKK4m2ev9wtY0DT2jc/t9p1BVlf3T+zkyewRTNyPpJKVkaWmJt958i+eefy6SDID9B/bzwPsfYHh0mJSRYiw1RsbIRDbohUKBL3/5yzzzzDOR100UQjA6OsrY6BjHjx7voYYFvAWcA1obsvU0TwHu9H2nMr3QrZ1+2mwnexDGZlDlo8qI2E5P1ULKjrzL3YzudjLodtvIG2hfRWPPGilJsIST53q4nhv8dt3QcgJPYHAHRPoycuixged5IK8/lxqYXm50vYQQQV/13VWSrXt2tJWyw9Csx04JdGylHtu4j12du628IRiUyG3qrx1y6u1ZI4UMjIHjOLiui23b2JYdSoSqqbiuO9DnrFJKHMcJrUszju0gpQwmKQzIUHmeF6mPGgghVvtqh5z5MTcpG8JUvRRv9TlUxQGxYy6NHaMIsJeNFIF34Pv+up8wCF8MfNCVUkbSpRnf95FSDsxANes0CL0iaND0edCeTlTZUUN5UcoPsmyU8mHqbaHsbkU2nVtdKmwyUC2eCfXEgAf1QRvLgducPvonwk3BlqSPj4mJidmVDGRAj+yeDbjtm4PYSMXsYEKGbmL2Lptm4+2ECQ3xuTsI9nS4L2a3s5Uz+nZiiLGdjEGX3+rBtWvcLpqIttV63J++7Vs7A9VHf+740N/WE3tSMTHr2IVX8ZYzyD65Sfv3Rj/H2jbZ209spGJ2ISEfkMfsYAZw7HZSVLgnY7VTlN0dxOG+mF1KP+80dQu3hZW9XWHFnfSi7iAG4y0Y0LsWH4C8tlG9sPuzXS8hh2ljwKHJAcx+jj2pmJiWxHe7cUiqBTt1XkSrZZyiygj+6EudQYmA2EjFxMTE9MYWzIsYsJDBMIh3P9e9d9afqDjcF3OTsRWht26zCLey/Rv9ou4NfoG3a/kOMgYd+tsW+pihF9YT2kkTPjsQe1Ixu4ztjLfs5Qkau2Ff+zFQAyZ+f3fLiI1UzC7kJr8qY3pg0FZhQOdUX2Ju4Hm9gy+pPRvuE4pCOp0mNzyE53lB4sF0GhniaGmaRjabRVGUYGFYN0g26DrhV1NvRHd8fPLDecYnwiUpbGZ4dBhd13EcB1Wq1Kgh3Agz4QQIBJZtYSZMRsdHMZPR0pAIIchkM3i+R7VeBUnHvhbY6LqLpgbJUjezXTPwNrZzI0J/gyzbS91+Qn9h2hl0M20qdp1kOKCHTVGrhl1zMGLRrWHrp9zvWSOVTCa46/67OHXvXQghcBwHz+2ehqI5hboQgtHJcVLpJJ7vMXdtjkKhsCnNete06yLIhIsAG5sPfuyD3Pfu+0LvU6OdVCrF+OQ41+auoQiFK94VhOyuw0ZZiqKgqiqO47D/yH4+9eOfwnHCZk+8Lm96ZprFyiLuWy6et5oapc35q+s+M5N1psb9NkZqO+lnuvtu44aPehEZtDe1W/vh5mPPGikzYXLs5DHe88H3oOv6WlqLTmw0NhJJtVanVK7geh6LK4ttEyd2MlQNgyCEIJlO8sB7HsA0I3osCDzPo1KusLy0jOd61Gv13ozLBhU1VQv6RlGYmJ3gyO1HQqRzX68TQK1Wo1goslhcxHWC9CjSb91XiYQglUwyMZZA2REGYi8Yqu0amHegARj09Ouw7cYpbNqyZ42UEALTMMkkM+iGjhAKitJpEBJN/wdICZ4nKYsq0pdUyhUWri5sSp7YzZNSFGUtffzo+ChT+6bIprPR9guB7dhUyhVsy8ayLJYXl6mUK90qbiKRSJBMJtF1nUw2QzqZRtXUSDpBkOeqXqtTrVWpV+uUS+W2SRTTSY3DM+NIudFYd1unb6tfpm01626rQ3/d5A2i7qAGyagv8IYI1XV8gbZL+6F3cwB9dcOfU+2m8OFm9qyRUhWVocwI02Oz6Lq+6kV18nY240uJ9BSWV4q4bo03X3+T73zzO9SqtVC66LpOOpPGMAxOnTrFqeOn2D+6P9wONVGpVLh66SqLC4ssLy7zwjMvcOGdC6FkCEUwNjHG1L4pMpkMQ+khJm+djOzhAVSWKlw6f4lrC9eYuzzHO2++Q622ua8EguHhFOPZR7jrtvtA63SabreHczN6VLvIg+pooPqUtzUVtocdNHdk0OxZI6UIlZSZZiQ7iq4bkWT40qdYKq2lRp+7PMcLT79AqVgKJcdMmAwND5FIJhjNj2IIg9HsaCSdAFSpIl1JuVRm4doCr7/yOq+++GooGYqqMHtglkq5wvDwMPffdT/5ZJ5UKhVJJ4lEQ2Pp2hJXLl/hrdNv8eKzL1IulVuWn5jI873fc0tfSRa3jpvJUO3QkakVbec3RNyHm8VA3eTsWSMFrHlPUbPXNk9GkEikvP4TBuk31V29EPrNqNuQ069OSNbVjaxXU/MNub5sn6k3nM7tjMagZtd1W9+vn9BfM4Neu69b3X5m8UXVZcADfUdxPbYVSaXtMow3kp2hbPyeVMxNwo24oHbGRRyN3az7KoMwUAPhJujLHUxspGJi+mI3DlC7UeebkPgw9MSeDvfF7HZazejrJfTWrkzY7c3fRw39ddPrRof4tukF3q71Osjq2kwPegzUYGzV7L9BzFzc5skmA2gu9qRibgLkht83UoedzG7tn93Ut7tB121iQF0Re1IxO591DtN2vA/VszItvgvr1XVrJyzb6SkNQoZs+bH1xkF5RAN8l6rjS8Ah9N1Jtm0n6ULsScXsJmTbP3YQO1GvG61TDwZy21SMYEhCFOujQkwbYiMVs7PZldf6TlL6Rutyo9sfAG1trFz/O2ZLiMN9MTsXuekD4ZYuCtXIgOt1Cv01EzX02M+7TN3qbsX7UyHajByyk92LhCvQPdq4FZMVempnuydRDOrduZDhW2JPKmbH0+uFtBPvZiU37v2tndgffbBubGs10IU1OLJpW/iBs39CtBPWQN1kxJ5UzE1Ew3sJ601tNYOatNFrGzuFAenU1bi0aKfTo6e2zzZDGo7Iu9ePgepT3pbK2BpiIzUgRJAhECHCL7MkFLFWr2vuqTD6cF2f0Do16jT2aYCD6zq5bfQKvmvxxbrxvtVMu2YD1c449GI0ul20vYTyWpXvNQwYhn48ga0K/fUw662tiDahv1bGZdP3XQxWV4+snWIdvg/V5X3ED1t+FdKDbKlGG536ivCFDd+2JzZSg0IEyQZHxkYwzHAL1pqmSW4oh2maZLIZtI6rfvegihComoqu6yQSCfJDecYmxkKdLIqqMDw6TC6fI5PNYJhG3+sJappGIpkgmUqSy+UYHRslmUy2LDsyliWZSl6fdR666SiVtssDa2Vc+5GzU2jl2XRyaVpsCzPo9WSb24QGQ9n1kDcBvdi+qCHLde2EMbK9FN1p51NAbKQGhBCCdCbN1PQU1Uo1VF3d0MlkAkOQH8oPxEhpmoZhGiTTScbGx4J8UmGMlKIwPjkeGKpsjkQy0beRUjWVVCpFNptleHSYqZkp6tV6y7IjI2nSmcz1Njvaj1beSSPsR6eKPcjaStodkI3t78zBYz2hLEfrMttioDoUCSWjB3k9VY1qoJo/92OgGh7pzj3H9qyRklJi2za1WhXXdUOvEg7BKt62bSOlDJIomibZXDa0kdF1nXQ6jW7oGIaBbdtUKl2SFHagVguyA+u6jmmYpDNpcrlcKBmKopDNZkmn0mveTrVWjZw6Q0qJ67hr3l06HehktEmTks2mVj3SpgFb0hTiAxqr0Ld8ybfd383b2m3feC50izt2K9upfKu6UUNs/ZbvVq/b9h49KNlqWztj1RzW69aObC273eeoEb5ewmMdP28wDO2+b6dMTwaq2w512tztvOkmJ+yNSmf2rJGqVqs89dSTSAFCKFh1C7eXFOvNCEF2LMfwvhF0XefkyZPMjM3ge+EGckVVMAwDVVOxLZs//ZM/7S3dexuMhMHEgQn2H9jPxOQEE8MTVArhjJ4QgnQ2TTYXZAievzLPb/3Wb4Xet2Z5uaEcs9OzHLvlGMVikeVTy233M5VUOX40h6oq9O/dbKd3tNcI6UG1NFC9NCFbDOBhPZtWBq9N3W7N9KxLF4MW2iPsoZkwMraUwbS5Z41UpVrhW9/6c1565SU816NYLFELGaZTNZWH3/8oH/2hjzE6Nsap208xOzEb2pMSTTmtvvGNb/DPfuef8dKLL4WS0cz07DQ/9ukf464H78LUTLL3ZEmoifA6KQJFUSiVSvzmb/4mv/XF36JUCpfQcU2eEHzkIx/hZ//uz3L8+HGkL/F8r60HqwgH0ziPql4GfDoamo42qPHlRs8qpn9CGqhWZXq9ae/bQDX/3YeBkt32OYSO/RioUEV6uWkYFBu8xAGwZ42U9H2q1So+4LouxZVi6GdJqqZSqVTw/fXhPlOPlmJdSommaZRLZZaWliLJAEhn07iui24E4b5MIkNaT0d+puQ6Lq7jsry8TLFYjKxXtVpF13TSqXT3wtICubEfJTQlmlw3u09u3La6vVGvr9XOW11wgwjrRak7iHphyrcr24uBamWMmre1M1Yb5LQKi7Uqui6U1q5M1PDYRp1aFO/VWHXz5MIYrNARvl5DfiG/77XNCJHA+GXemJ3NujvgToXCCIzpj23woNbKtGorRPNy9QSSHU6kUAanXTu9fI7abxuLS3q6MG6SUz02UjG7g4FecDfJ1XtD2GYDtcnrCNN880A+CAPVY1ix0+cwM/E6NdYtnNaT6C24DrZA5J4N98XsQiTdZ/dtCge2m90nWf+sCrqH+JrLbHVYL2rSw60MGW5TiG9dM3Lz53btrRm1Dm2206+r6B4sUVcD1eb71hvab+5q6HoIH3aS0aoP28qLGD4MQexJxexgutwFbywW+sueYokxwLZ5UKHqddFl4+Ht6jX1IjqM29SGfu4jutbtQXgvRmYHMXAj5XkeP//zP8/hw4dJJpMcOXKEf/SP/tG6WVxSSn7hF36Bffv2kUwmeeyxxzhz5sygVYnZ1WwcFPu5mHb+hbiz2YUGqlPxbvU2iW4VYttmA9UTvfZDjyHDrWg/AgM3Ur/8y7/Mr//6r/Nrv/ZrvPbaa/zyL/8yv/Irv8K/+lf/aq3Mr/zKr/Crv/qr/MZv/AZPPvkk6XSaD3/4w9TrrVcfiNnDSFj3wLlxN7l2sTWFg9Zta1V2ndCmbbLN9rYK9VE2bN1By+ulXqvvOg3Erfp8o6Fpd0za1Gt1zFqp29KgyM5lWnZVlz7sySb1co5F1UX2/HUX4dHKt/u+1fEesLEa+DOpb3/723ziE5/gYx/7GACHDh3iP/2n/8RTTz0FgJSSz3/+8/yDf/AP+MQnPgHAv//3/57JyUn+4A/+gB/5kR8ZtEoxu5V114QkWHFW0nrZoF6m13eq22gofo9qM2EHoI0GKkQ7zce7m5BWRdZ+dzAOYenFQLUd29sZ3agKhP96exm8MgP3pB555BG++tWvcvr0aQC++93v8s1vfpOPfvSjALz99tvMzc3x2GOPrdXJ5/M8+OCDPPHEEy1lWpZFsVhc9xOzV2ge8AYx8LSq280L2ctso4EK02ZHx26ABqqXNrs102n6e+RGe2y7m8hBskXr/w3ck/q5n/s5isUiJ0+eRFVVPM/jH//jf8ynPvUpAObm5gCYnJxcV29ycnLtu4187nOf4xd/8RcHrWrMjqd5sNm40Kykt9l9dN7e1bNqR9RUHRsZxIU9aKPd6rtNlqDFx43beinT9KFRp919xLpy3XRs55W1+r7Pdjo107qB3java6ZbgU7th2gzzPeRyoYPCw7ck/ov/+W/8B//43/kd37nd3juuef47d/+bf7ZP/tn/PZv/3ZkmY8//jiFQmHt58KFCwPUOGZXIOX12HeH8bLPRpp+71XPSrJ5/7chxNcpHNZWlQ46dtSh13a69UUPYbiBOFCtQoZ75/wcuCf19/7e3+Pnfu7n1p4tnTp1inPnzvG5z32Ov/pX/ypTU1MAzM/Ps2/fvrV68/Pz3H333S1lmqaJaUZbaihmt7NxUOgldccg2tuLz6l6uFvvVm8gIb5eikSOvfXYTsMw9GGgotJ1n7fKc96ZDNyTqlarKMp6saqqrqV4OHz4MFNTU3z1q19d+75YLPLkk0/y8MMPD1qdmN2O3PCzthHWxfrX3Y2v/siQ2zc13EmJjdu63Ta3K99NTpiyUdqEzm22kbf2caOB6tLPrer1dEw6lW8ls0PZVrq2aqcX+7ROTqsCbZpp+0Wb49nWPrUR3lJ0p3OlVeV28lp1fg/iem1+AwP3pL7/+7+ff/yP/zEHDhzg9ttv5/nnn+df/It/wY/92I8BwWrYP/3TP80v/dIvcezYMQ4fPszP//zPMz09zQ/+4A8OWp2Y3UzLk1oS5FdZ/XLt81Z4O+3kNiu2m7ysiKNEL/JCiZZN5Xup2GUQbwycm2R2GfB7/aIXY9V7gQ6ENVD9i94NDNxI/at/9a/4+Z//ef7m3/ybXL16lenpaf7G3/gb/MIv/MJamb//9/8+lUqFn/iJn2BlZYV3v/vdfOUrXyGRCJdOYqcSJYHidnAj9WpegT2MHkEtue6vtQFpXdbeJqO1Vrl5EO22enqrdpq3tdZssyEL08edDFzYwTtM2T4Gz1bGJcxSR608ojDlWzfUNJC3G9Flx81t9erZm+qiX8s2223s4fiEMbSyaXu7ay+y4W5zHAZoFQdupLLZLJ///Of5/Oc/37aMEILPfvazfPaznx108z1jmAa3HLuFA7ccQvqSWqWGXbdDyVAUheO3ncQ0TTzfY2FpAd/2UYUaThkBilBAQN2pc9d9dzE8PtyheOe795GxEfJDeQrLBcqiTEEW0GT4Q62qKqqmUq/VGZ0c5f0ffD+1Wi20HAiO+fFbj1OqlTh/+Tye62E7NtJvfTJrqsdofomhjOR69LjhRV3/s62t6ImmSuvqhxXWyriFbD80UQ1UH+20NFARZfVkoNpXbV22ywDdSebatlBWqY3cHoxpt20d5Yf+IiI9GqhBeHodEHKn3vZ3oFgsks/nGc6YkXMkjY6N8sM/+pf53o9/JEhS6BLk1uuBZiNRdepUrBqu51FYKrCyuILnel3rNaMoCqqmoigKmWyGiakJkqlkxzqdDJXne1StKpZtYVs2KwsrVMubc2V1kiGEIJFMkEwlUTWVXC5HPpdHKKKrkWyHZVmUy2Uc16FaqVIsFHE9t6UuqYTC/XfmuPNkBk1r/q552rlYtwnEde9q3fYNf4Td3pIwfdCp7KCM1FYZrY3GI4zR2uBttRvcusmQ7T43y9kos0V7G2W3ei620ePYJLuF7htXRGkpo1ObG3Vs029Sbv6+F4923bPbHvuip7IbjVQ7vWi5vViuk3/oFykUCuRyOdqxZ1dB13SNqekpTtx+AtMw0dBQUMPdP/uSi3OXeevc29hVh2KpyKXLl7qmft84ICuKgqZrKIrCLUdu4fDRw+yb3te2fLttDSqVCq+//jpLS0vUqjXmrs5RWC6EkiGEIJVOkc6mSSQSzMzOcOquUxiG0bVuK6SUnL9wnhdeeIGVlRWKxSJLi0u4bmsjlUnrnLhFIGWa9aG6hkCaQnw0hf5kU5mQ70y1fZdqY+ONRrvRbiXzqOHBdoS4y+9ZTqtNPQyI3YxYL8ajrVHpQa+WBrCdLhu/72IEuvVzt0G/Y/lW34eUEZoByNwGH2fPGikQqGgYmOgYKKgoISY7CsBHIqSClOB7PsuLy5w9c5Z6LdwahJqmkUgm0HSNbCaLb/vo6B3a7mwgFKng2i71Wp1CocDFcxeZuzSHbDr7uskQimB4eJiR8RHS6TS1cg3FV9D6OGU8y6O4UmRxYZGFqwtcvHARq2611CefT3DPiRRSTrB+EqqkZYhuzWiJpu3NBQZBWHntyg9Sr0ENEt3ktDMoYeTKPtTt5S69h6rdCoSwST2117ZeF4HdjHAUtt6ebAl71kgJBDomCdLo6CE9g6Csgo+CBjJY/f3ShUs8/cTTlIvlULoYpkF+KI+ZMMkmsnhVD5Po74VpvoZVsygWilybu8bLL7zM6ddOh5KhKArT+6c5cOgA+aE8p06eQvM1DIxIOkkkTs1h/so8l69c5tzZc7zy4itUypWW5cfHcjxyzyi+d4zN9rqVoZKrnlDjShRbZKjC0slQtaPVKhg3kj4MVDcPJmz7kXXpRXb3JgchujcD1c2rG5QuO589baQUFBRU1Ijd4HPdA5BSUq/VWVlaoVQshZLTeFE5kUxQrVaRnkQl5OSLJoQU+J6P67pYlkWpWGJ5cTmUDEVRyGQyVMoVdF3HtV2EFKG8zWYkEt/zsS2bWq1GuVRmeWmZSqm1kdIVn3qtvnqNtgrJtQrrNbatGqu1MKAkfOivWZsWyy+1JaxBalW3XfkBh/LaFmk3cA8ixNf0XS8hvq6uTSfvrEtIrp2Oob2pbqG/nr4IIaMXwobyQnjSoenBU+1AnPQwZocT5eJoHnBajDw9DY4DUmW3MNB9bzZCGytG7MR1g1sra9JLE22MSdRVJdq2MeATZUeed/2EbsMRG6mYHUyvV0GrcvL6eDFIQ7UXiRLia2mgBtB+yxlurcqGMI4t9b3BJ0IXO7yX2LPhvpidjZQSx/Go1azVl3+DUJgQAkVVgqnwQkFV1E3LcF2nxdT1DZ+llLiuh7c6FV5KiVw3Mmyc5t4aRVFQVQ0hgkknilDo7e2I1oU8z8dxnLXlxK7T+6glBKiahqqqCK7rE+6tjevtSQmu6+K6TnBM2hp62dpYrH5UVAV9dTZrsG0taL6qIO1lNyyKYM1Q+TLoq+uvfrRrv01YcvX80jUNTdeu98+6maI0PfvcIGR1u1ytI1ffZfE8D9dxV/uqjQHspJMMzit99Ri27B9Ba9lN2yUSKX2kL5ESPM/F87zufbRBpti4yW9cKW32oXljCxWr9c6zoBvERipmR1Kr2Xzz26/j+T66ptK4RJKpJNOz0wyPDpPL5Dh88DAjQyNBpU2DbysDs76QZdd55dVXOH3mNJZlUymXqVZr6y+qLoO6EIJ9M/s4euIY6UyakfwI46Pj6Fqvl9fmBubmLvHtbz/LpcuXkb6P53mhVwxJpZOcuvsUR04cxdB0MskMCT3RfYfWWD8oup7D888/z1NPP3X9pe5NKskW29cXOnjoIA+/52EmJyfXngq3a7q13PVfLl67xre++S3OvHmmY7stZa5uM02D+++/n/vuuw/TMLrX2/RnsM3xbKp2FcdzeOvNN3n+qRcol8psGqhbydqou4R9+/bx6KOPcvjQoXD71YTveSwVlihUClQrFc68dpYL75xvOp+6he6CL3VNxzANFEXBdRxc2958Trb1ZDe3U7NiIxWzi6lULf7s6y/zxJOn1935D4+M8MAj7+KW40fYPy3ID48xPHo08vy9ul3g2ee/zR/98dOUSiXmLs+xtLAUyiAoiuC+B+7jI58YZnJS4cjBJMP5g+ha9GW+Ll5c4L/83rM8/fTTeJ6HbdktvKrOjI2P8Zd/bITE2B1kkhlUdYqE3n4lk44IcNwaTz79VX7t177C0tJSiMrrLf77PvBeZk9+kOHpQ6vvJxqIUE8e1h+bayuS3//j1/nyl78ceemvXC7LT4pj3HH/McxENpIMkFh2mRVvkZpb44nXX+RL/+FbXLl0JaI8uPeee5i59WMcuvOeyOe469gsrLzFueI5rl21+fKfvc23v/6twJvqRFNXChHcIGZzWTRVpV6rUatUkCHPyWa8NqvNbCQ2UjE7EikllYpFpWKt2+6jUyjVqVQdanUfz9cAI2wMq6kdnVrNZ6VQpVissLRY5tpCIdSzACEEy4UqtZpH3ZY4rkBKHfp4jcBxBYVCjYWFYmQjJVSTStXBdRVcX1nVyaClJ9VD90npUq26LC6WWFyMnh17pVjDcRWkMJBoSAzoYzar66kUSxbXFqLr5LgK1bof6KJEvLmQEikcPHQ8XKqWz+JKhYWlcK+kNLNSsrBdNdAp4jmOp+CiY/sqdVdQqNgsLFfwuxmpDaRsiSv1YKm0ao1qudqXker1hiKeOBETMyAkG59nxbQj7quYXomNVExMzA0jNlQx3YiNVExMTExMT9yIm4rYSMXsSuI78JiYG8N2X3uxkYrZtcSGKmbHITf83LRs387t6dl9cvVMCrM6eDuEEBiGQTqbDj0N1jRNUukUiWSChJno8HJq77oEL5eq6LpOKpUik82EkqGoCqnMqk6JBJqmRc7dtSZTUdD14F2LRDJBJpsJ3d+ZTAYzYaLr+kB0Egh0QyeZTOK6Lulsmnq9HnIKukIymURV1dWXePtf0FZVVZKpJJlsJpjdZ9r4XriZVOlMGk3X8Nde5Aw/sDSuDR8fX/jopk4mm8GyrS4125NIJlZf1nYQighulUN2mZQST3r40sfHx0yYZHKZyGNno688PFzfDY4jIvSxlFLir77Xpqoq6XQ69LXXTDKVRNEUfPxAnz4WS5ZIhBCYpkkmmwk9uy+ZSpJKp1A1Fd91EaK6LaZqzxqp4OLz8XGRKAiuvzAalsYqCBNTE9x+5+3UquGy1+qGTjqdRtd1Zg7MkEhEf7+moU8ikQheLB0b4ciJI5iJFtOhO+yuoiiMjo0yMTVBNpMll88FA0ofmAmTkbERHOkEiwYIETqtSSaXYf+B/YyMjpDL59D19ilNekFVVUZGRzh05BDVapWR0RGKxWK4KeiK4NDRQ2SyGXQzmKLbr6FKp9PccvQWKlYF3/evr1zQAw3DksvnyA/lcWwHWws/hb2Bi4uNja3YDE8Oc9tdt1EstJju3Yt6AmYPzeL4DsuFZTJGBjNlomrhpqB70qNklag5NerU2XdwH3fde1fk96TS6TT5iTxlrwwOJNUkCTX8deh5HrVqjWqtSjqT5sRtJxifHO+tcgvVbzlxC2bOxMJCQVl9ryzcTay/+k9Kia5rzByY4dTdd4Q+H4yEQTKVRCC4fP4i1VIZO6Shi8KeNVIAEh+Jt7qMiRLtLmW1iqIo5IfzHDx8EMsKd5epaRpmwkTTNEbHR9GN/gZeIQLvIJFMkM1lmd4/jaEb68NjPSzzk8vlGBoeIpVKkUqn+h54Dd0gm8tiudbaBWnbdigZyVSSsfExstksqVQq9OC2EUVRyOayTE5NUrfqZHIZatVaqMFOCMHkvkkSyQS6pq8uYdMfiWSCqekpirVi4DW44VackEjS6TTpTHp1KSM3spHy8HBwcIRDZjjDwcMHKZdbvPvTo3pjE2OBkamUUKWKnwyvly99ak6NYr2Ijc3IxAiHjx7u3EcdvkokE6SGUtT8GoqnoCkaCaIZKcuyqNfrmAmTmQMz5IbaZ53tpuO+/fswkgYODurqv/ZVW++gbKz0IEHVVEbHRjl0y6HgfBC9hc0FAk0PxikpJZVSCVXdnqdFe9ZIua7L/Pw8Z06fQdN0pAfSD+naIynWS/z/23vzILmu8z77OXfrvXv2DcAAIMGdIEgC4ibJFk3QJKVPlGxFihg6ZhKVVJbFshRVxbTjyEkqUahKXKlEikqqpCpS5YtixfpKoiVaiymCEkkJAkkQIAkQG4l9mRkAM9PT613P98ft7ukezABzewbADHAeVKN7bt++/Z7T957fOe859309L3QPZLNZVq5YecHMvDPRdR3LstB1nZgV4+iRo7Nm0p0vru9SrZTJpFMYmsZA/wAJKzH7znMUWQhBOpUmk81gmRalYok9b+9ZUAM8WZwkGU/S291L3Ixj6VbkuorFY/T29JLtyGIYBsePH2fyzGTbNrmui23b9PX24bouuUyOarUa+Wberp4uEskEhmkwOTnJ3r170bVodSXEtHvpzPgZUqkUq1asCl1IfhBpDk4iicViJOIJXMelGBQ5cvgIY8fHItkEEBgBvhm6wTzHY2BgAMee0bmIUF+dHZ1UK1Umzk5QnigzeWoycmqagIAqVRwcClMFsukswyuHz19H53nLNE2EFIycGAld0oGFFUTPnVbxKkw5Uzi+g2mYDA4M0pXrmv8BZtjYke3g7Jmz7N+3Hy3Q0HwNIaO1U37gM1GawA9CF2RXZxfCq91MK+Z/VhmGgWmZyEBy+vgoWsTzu12EbHd8fBmZmpoil8vRmY613btPJBLcfNt6rlm3DhlIKuUqdtUhytWmaRrX3LSOW99zG6l0irSVJh1Lo4vojZOmh3MZ7xx4hy0/38LJkycjlmiazq4OPrD5vay/4xYEGoGrIb1Zej0XqDrTNDFNE9u2eenFl/jVS7+KPEps5tb1t/LQIw/RP9CP64TiELV3r+kaZsJEt3SOHTnGz3/8cw7sPdC2TclUkt/67d/i7nvuxjAMPM+7cLiYWai7xFzfZdfru3jlxVfmTOg4F0KEvVVd11m1ahXv/633s3LVykYw16gLRTzf42zhLPlSnkK+wO7Xd3P04NHI8zbpXJpsd5ZYPMaN193IrTfdSsxqP5rGeH6cwycOUygVODNyhsP7D1MpRXORx+IxBlcP0tXXRTad5bq119HX09f2nI3jOux/dz/73t1HtVplYnSC/Nl8ZPdh/4p+1t2yjkwuQ3eum6He0Isxb2Z83djpMba9uo2jx47iOR6VUgXP9SLZFIvHuOXOW7j+luuJxWJ0pTrJxDON1Gvz9NI25ro9z+PZv/1b/t9vf4vxs2cj2dKMlJKJok0+nyebnXu0edWOpGzbZt/efRw5chTP88lP5imXypGOYRgGv+3ez7r115PNZenv72fdynXRTsoZnDp+im3btrF9+/a2j7F6zSru2HQzfd1dxKwE6UQXMTPV9vHy+Tw/GPsBP/nJT8L5mjaojxL+4Sf+IevWrGvbloAAFxcPj7FTY7z++us8//fPt3283t5e7rzjTq679jqSiWTbxzlbOMup8VMUygWOnzjOz/7+Z5wZOxPpGJquEbPC+Zn3vve9fPQjH+X29be3bVO5UmbHnh2MnBnh9OnTbNu2jVd+/QpynjHTIPzdevp6GFw5SDabZe3QWm664SY6ch1t27X3wF7eevstjh0/xoG9B9j64lbGz0aJBRjOTW64cwNr161leOUw733Pe9l4+8a2bSqVSuzfv5/db+xmcmKSw+8e5vjR45E6UUIIbl5/M7FMjIGhAVb0ruDmG24ml821bdcbb7zBwQMHeemll6hWw6SqUTuK2VyWWCbGNTdcQzqdZtXKYdYMrWm7g+84Dq+/8iqmsbBpifly1YoUUEvL0P5S5pmfE7WU5e3++O0MagXnDog02ZSgtjnx7ALmlBY64G7+/ELsqPeUF7LKqRkpw1Vv7azkaj6GEGL6fJBt1pesp1WYjha9GCsFm4/fzqk+My3Hguuqqfter//oB5r+rEROnxft1lfTx9oN2XRumhcW1B60HBs5+/HnaddstGuXaPr/UnBVi9SVgM65P6KJugHuUqPu2VI0uOLvkbq0KJFa5mhwzuL5uRbTz+xRLWovXQEosVIsPlf7OaVEahkimB4pzSYznudxduwsRw4eIRFP0dVhk0pmW/Y1TYtkMo0xj/uMhBCYuk7CsnBME8/38RYQol+hUFwmlqHeKZFahtRdfLPNRwFUK1UO7DlAIpEgnU4zPLyaru7uln1yHV2sXLWW9HxECkhYFh3JJMJ1KVSreAtY5ae4uplOOr4MW8x5IJv+LRWa7VluC7qVSC1DBHO79CC8oTA/mWf05CjlbJl0Oo1utIbrMUwL3587ikGLK1AIDF0nZhhYhoGhafWM4gpFWyylBvyqYZlWuRKpZULdxdfs6lsIjlNl/OxpqpWm+1MExONJ0ukMut50akiJ53nYjoPnusSEoDsWw5eSsudhK9ff0uWqCHaquJJRIrVM0FjcVXuVconjxw5PhzYRgNDo6x0kFou3iJQkvDeiVCpRLZfpjMfJxuM4QcBIpbKgG3wVigWhBPiKR4nUEmTmXFPdvWcwv7sThASkDCNfB2FU5iAIajoUuv1838f3W29eFprAznZM7193+UmJrEV2DoIAHYjrOpoQ6GqFoEKhuIgokVpiJIAhYJxw1GQ0PZvQmAuqdx7DWO7hswv4QMx1sUdGGREaE4k4xbNnSWWzZHJZhq9ZQ66zY9bvllJSLpcYGz2BZcVIpTKkM613ywdSUnZdNCFwpcS+BFGQFQrF1YsSqSVGGriGUHgsIEk4itKZFimfaWHymx5loAIEjk318FGOjIwhdZ0gZhGYJqvWrCaVSc8pUgCFQp5qpYyuGwwMriSRbM2FE0hJwXEouS4BUFlmK4UUCsXyQonUZUIGAb7nIWsjkbrTTHMckkFABogBKVpFCkKB8pkWKa/2XF9U4QWSQtXGcT0CTaOq63iaoCOXpVou4zgOmhBoun5OgkXf9/B9D13T8TyX2Rz+vpT4MkxwopZMKBSKi4kSqctEaWKCI6++ytnDhzGlJCkDTCk5+/Yeus6EgUlNIE4oUPXIEkBDHAJCgfJqr0tAtfb3zNc2YOSn2L99J6MnTtHZ28M1168j29F+8MvLyVK7D0XRBurnU8wDJVKXieKZM7z5ox+x/xe/IBEE9PoeySAgKJfpGx+nh+nRU33peX20VReo+jyUW/u7QihMfu21U3vka39XJibY9ettlA2D626+kZ6+3mUrUnWUUCkUVzZXrUgJoRGPx8mkM3i+DwEYukmU7p1uGCTiCTQhkFLiuA7lchnXmD2Rn5CgBQFCSuzJSezxcewzZ9CCAMdzMYMAzfOIeX7Lir6ZIZCaRaruCgya9qkvZdAAXUpsJAEC1/NxvTIVoDxVoFIsUS6VwlV8ohbBvfYtuqZTLpcpFYvYVRuhaWQymZabfANCgZxvdpt4PI7v+1TtamPVYVQCEeBrPr7wCWRAMpEkl2tfaDOZDJquhYkOxbkRv+eDRGJXbTzfQwYS0zTJZrJ4TrS8P5qmhckvDZ14Io7ruZRK0XJSNVOulvF9H03TMAyDZCqsq6hZh7PZLOl0mlQyhdAElUoF8wKRSs7XeXAcp5HoM5FIkM1mCfxo50IqnSKVSoXZkE0Txw1vkWg3OHelXEEiSSQSOI5DJpMhl8tFPkdTqRSWZWEYBkEQUKlUMPT2m1nHdYhZMTKZDKZpIn0ZOZt1OpMmZoW596QMcByHcrmEENFvaBECHMfFcZxLFrniqk16mMlm+e37H+DOTe9BCIFdtSNniRUCOvo66VnVh2EaOCUHu2DPma/HcD06JyZJF0tUT59m7Fe/Yurgu8QDSZfvk5ABugRLSnQp0WgdRc0mUs3uviqhW88DikJQFQIHmBCCMqHb7xRQAJL9vfTechPxzg50y8SIx9Gasu5qmkZXVw+9fQNomk6pVKJULBHMOF3qizjmQ3dvmLY6mUpSKpaYyk/hedEactMyyXZnSaQTFPIFjhw4sqDMvLqh0z/YT09fDxCGlDon6+w8iKfjpDpTCF1w+sRpTh48ietEPZ8Euq4jNEE8HifXmWuk65ZB9JQWQhNYaQsjYeBUHcaOjZE/HT3jcyKVIJPNoOt643G+6+5CdgpDoMU00KE0WWL81DiuHa2uDNMg15cj2ZFESIFwxXTvrA0kMuwACR/f9ylNlCjlS5E7LKmOFN1D3Vhxi8AJ8Ks+0m+/ifV9n2qliuu6+F74OmpSTt3Q6V7RTWd/JwKBX/YIbB9m+Z3OZ6mu65imge/7vPSLX/DjH/6QfL79DOIq6eEFSCaT3HvvffzDx/5R2ENpIweQlJKTZ05y6OQhSuUS+/bvY9eOXWGvfBYSlSqrjxyjb/Q0cT+g27FZ5XlYQCaQxKTE1DQShoFeCz00LU6yRaQkomV1X4tISUk+CCgFAY6U6EFASUoStX1TQP7kCNvHzlDSNKxUgnguh97UOxZCkEgmSadTpNIZPvjoo3z8sX9EMjmdGDBKbUkkh44cYtvr2xifGOf06dOcOHoi8o3AqXSKNdeuobe/l96uXh7c/CArBlZEOkYzpXKJl7a+xMtbX6ZSqZCfzFMqliKPNlavXc0tt99CNpvl+nXX88Hf+WDb2WuFEOw/sJ8f/OgHHHj3AIEf4HvhyDEK6Uya99z3Hm7ecDPJeJJ77riHrkxX9FxconYPnW3z8+d/zt/95O8oFAtz7n6+TMICwbob17H5Q5tZsWoFKSNFR7wDU4uWQM+XPoWgQDWocurEKX72w5+x+43dbffuE8kEmx/ezO889Dsk40lMaWIGZuS6ypfzjORHKNtl3n7jbX71i18xNdleolCAa6+5lo///sdZv35923nKHM/h8MnDHBs7RqFQ4O033+LwgYPnjBLDQ891fIFlmcQTcRBw6MC72M6luYn/qhUpTWjEYjFSqTSW1V4m3SAIiBfjCE00XD75fJ5KU6ghQbiU3AS8ik2Qz0OhgJASs/aeJcGUEkPK8H4oITDEdGqxmZdJeJ9UKFL10Vbzir/6d7q1E9okPL5V3w7onof0PHzCeSsME2E2nQ5C1BpFiRAaAhG6fNKtS9Lni5QSy7IaLtFioUg+n59T0OfC8zxKpRKZagbf90OX7Qw3ZBREzVVbLBYpl8tM5acoTBUizXUJIegudeO5HkEQYBgG6XSaRDzRlk0AlmU1RNMPfHw3ukgFQYDrumiahmmYJJNJsplspLpqDgar6zpBEDA1NUV+ao4edD0Z4Xnqr1KpoOs68XichJUgk8xgGdGuQS/wkK5E88OyVatVJicm256jdF0X3/dJxBMkU0nixLGwIomUlBJPeFhVCzdw8XyPQqHAxOREWzYBlMtlDNMgnUq3fY7bjo0VsxBCNFyQk5OT57oy5+hYQNi5sGLh9SuEoFqtEkTI8LwQrlqRWmxkIMlP5jl6+Cil4vQ8Qgy4lvAG3ZTnMZwv0O95xIAOwpt3DRneD2UQikhCCAwtvDxE4zwQDbWqBZSYHknVEp0acnqOSKt9t12LFmFKSaz2XqL2XVUgA1Qcm8LUFK6mNcQOIfBcDyTouoHrugteouC6LoWpAhMTE4yNjHHk4BHKpfKFP9hErjNHV3cX6UyaSqaC7y3sZuIgCChMFRgbGaNYKDI2Osbk+GS0kZQmQnsqFVLpFH7gL9hfX61WGT05ypGDR/B9H9dxI8+PdHZ3UiqWMHQD3Tj3doMo1LPp5ifzHDl0hInxuRveCwnFwMAAutBJJVPE9bCTFxVNaCT0BIZmYAUWE6MTHHr3UOTj1MlkMhTHi1iBRZw4OvqFPzSbXXo4r+hJD7tqc+LoCUZHRtu2qyPdQaVcufCO80ASxuA8c/pM47yKQjwRJ51Jo2ka+Yk8wSW6kV+J1CIhpaQwVeDU8VMUpqZdIWngOqAfSCMZCCSDhBWfJBzlGIBVGz2ZyFCkar0mTRAq0owFC/WoE4GYHkHpInT11e+ZsghFypUSrTZyc2vbNcIVf0ngrOMy4bhUhMCr7YMQCASGaWDFYuHc0QIbXtd1w7moqSnOnDnDieMnKBWiLQwol8usuWYNvaXetvzzMwlkQKlY4uzps0xNTXHqxCnOnj4bWaSGVg5h2+HiiXYWhMzEsR3OnD7DyeMn8TwPx3YiH9e2bSrlyrzmkeaDDCSFfIGTx05y9uzZto8zcdMEmtBIJpKYmGhtRKQUCOJ6PBzxBBb5s3lOHD3Rtk25XI7yVBkzMLFoz7MC4VyuaZmY0sS2bUZHRjl57GTbx1sxsAK7unC3Wr3j4Hsek+OTnDh2MrLIJFNJMrkMhmFQLZUW5TyfD0qkFglJOLFdj3s3vT0UomTtEWdamOqP2RZItMTua2pc6u68+sCq7vKrr/STQoCUjVV/9WXsJqGYWYSjqbqr0a291glXAtYFsF6muvvGdR0q1TK6oWOaJrputNXoSSkbj8APIp/oQRC0HGPB1NS+/rvJQOIHfqQJNyFFw67FQhKeS/V4iTPPq/kQ+Au3aaa7a7ZzPCqNhUXi3OPP2y4xu13tEgRB4zdv16a5jrugulqs87x+PNr/DevXR+MaXDSrzo8SqYuMAfQQhjpK1l5nmHbH1YPG1m/YnU+fcmaq+Ppn6jH+6osp6oKWqW2P1bbX772qNG3L17aXCOeomk/fIAiYGD/D4UMHyGaz9PT009nVq9LPLwOW4k3PzfYsNdsWkyVVtpkBP5cRSqQuMjqQAwYJR1EZwjmheuqNmckL58q2OxMx4xmmo1LUF0P4tW0e0/dc2bXPBDVbdEKxSjF9c/A5CzWCgEIhz+jIcSqVHIlEko7OnnlYqVDMzpJqwK8mlmG1K5G6CNRHL2mgG8gy7eJrHjHNFIOWv2eOUmpDfjHH+7Lp/XoMv/qj2fVXj6be/LCaHnOlA6m7My/lMF+hUCiUSF0ELGA9cDvhKOpmQsEyCd1r9WjmkaaL5+FaqwuUFIJ67Ayd6YgQkumo6hCu7qvPS3XWXjvns0tleb0wqn4UikUl8rKaF198kQ9/+MMMDQ0hhOCZZ55peV9KyV/+5V8yODhIIpFg8+bNHDhwoGWf8fFxHn/8cbLZLB0dHXzqU5+iWCwuqCBLCQNYAdxJKFRDhK6++kileR7pYszqaIQr/eojpfoCjbpIxmr2JGqPJKG7L1l7b9aTQjW8F0bVkUKx6EQWqVKpxIYNG/j6178+6/v/8T/+R7761a/yzW9+k23btpFKpXjooYdabtp8/PHH2b17N8899xzPPvssL774Ip/5zGfaL8USpB7BPEEoTnV3W7M4zSlQrUv7ph+a1vqobydc7VR/NB+i2fXX7PIzZryui9jM1YYXDdWgKxSKeRDZ3ffII4/wyCOPzPqelJL/8l/+C//qX/0rPvKRjwDwv/7X/6K/v59nnnmGT37yk+zZs4ef/vSnvPrqq2zatAmAr33ta3zwgx/kr/7qrxgaGlpAcZYGGuGopJvpuak483XxNUlDs0A1BKm28Ly+LFVKqC8lbVqqWv+u+hL4+rZ66o+AUECpPaeaXsdq77d3O+M8WKBANa9YUzNkiiWLOjUXhfZvQZ+FQ4cOMTIywubNmxvbcrkcd999N1u3bgVg69atdHR0NAQKYPPmzWiaxrZt22Y9rm3bTE1NtTyWOvWsuvVGv9nNN68RymwCJbTp5/pIqr7vbIdgWqxmjqJmjqCaF06cb3HHglEXruJqYJku916KLKpIjYyMANDf39+yvb+/v/HeyMgIfX19Le8bhkFXV1djn5k8/fTT5HK5xmPVqlWLafaiUxeHuijMtlx8zs82u/V0HQwTaZhIM3xgmWDo57r9mkVrDnu0GY/mVX/N22ezKZlM0dnVQ2dnD/FEUt0jpVAoLgmLKlIXiz//8z8nn883HseOHbvcJl2Qehy++r1QF6R5VKQbYJhgWpBIQDIBiSSkkpBMQiwGhhE+dCMUM00PR1jNx6JVLGcbPcWa7Jztvi0ATdfp6u7lmmtvYM3a6+no6FIipVAoLgmLugR9YGAAgNHRUQYHBxvbR0dHuf322xv7jI2NtXzO8zzGx8cbn59JLBYjFmsv7cF8WNSUWuJcF9u8m/OZCyR0HWkYoGlhEE5NC70HQQC+Hz7X3X/I2pBJ1OamWoWqOezSzBFV8+McW0U4korFEmSznS1R0Nuqt5Ypt+hC1xKypunlYoT/EbUfTyAiR0GfLZTOoti0kM7AHB9diF3Ni3PaPkY9+UyTHYsxt1iPaL9QFnyMpo8vZmduMcrWHFKt/QMwr1tiFotFFam1a9cyMDDA888/3xClqakptm3bxmc/+1kA7r33XiYnJ9m+fTsbN24EYMuWLQRBwN13372Y5pyXQAbYbpWiPYUlrbYuPikljm8DEl3T6enr4cZbbkSbKtB/Zpz4+ARWEDRWzbUy47tEmHoDTUMKEYYl0jQwTYSuIzUNdG36U0FQe7jhs6wtpmgkx6vd3CsEQtPQgqAli+/MOarmpeo6oGthKpMwPUcKYQhKXhnc9k5OKSVSl+Q6c1TdKp7r4ThO5AjP2Y4sgysG6ejsIJlO4gmPktt+9tpqUCXVkWLVmlWUSiXS2TT9g/2RGgRN0xheO0wqncK0TAIRUPbKBG70mG31NBfCEqxcu5KbCjeFUdDd6FHQO7o6yHXkcD0X27EpO2ViTvTOXj1eW6VaIdWR4vqbr6c/33/hD87B0PAQvu+Tz+exdAvXcNG1eS7TaawXkviejx/4VLwK/Sv6ufm2m8/Zb76k0ilSHSnylTye5qHrrVHj5yuixUqRUrlExa6QTCW59oZryXXmohnTxPA1w2DCRGkCIQSa0CIrjOM62J6NlBLDNBhcMchN62+Klg1ZQCweI5UKszOfPjXKyWoF17n4QWYji1SxWOSdd95p/H3o0CF27txJV1cXw8PDfOELX+Df//t/z3XXXcfatWv50pe+xNDQEB/96EcBuOmmm3j44Yf59Kc/zTe/+U1c1+XJJ5/kk5/85CVd2RfIgKJTYLx0Bss10XQdvX5STod1OO8xpJRU/TIBEt3QWXPtmjDidKHI9a+/SfqNXcQcd3aXX32lngCkxK+Ji6ZpBEKEgWINAxIJhFFz6el6aJGmTY+mPH9apPxQuOpRIYSo9+RC4ZNM/+AeoZsvYHrRRP1GYwMwdJ1UKklXTzeZXBZhCSbtSWytvYjMEklgBQysHCCZTdLT18PK1SsjZ+aNxWL09PeQzWbJdeRwhMN4ZbwtmwCqXpWuwS7Wb1yPY4eiGTXHFUBPXw+d3Z3EE3F8zWfSnsQKokXTlkgCWQsKm4BbN95K90A3gQzaChYbi8foG+gLo2hLmExMEujB+bPqzmyMZejpcB0X13XpGuzi/Q+8f/51JJtfhn8MDg3iuA4jp0aIx+OkU2l041yRmlMYagGBK+VKuKjKmWLdLeuIZWJzfueFsCyL7qFuRvOjWFULy7IwrWiJGJFhEs2JyQkcxyHXmeOe991DuRwtHU0zfX19BLGAE+Mn0DQNwzAa4nm++pl+GabnKNklAhkQi8e44eYb6O7ujHw+GYZRSxAbsHvnW5weGY2cfbodIovUa6+9xv3339/4+4tf/CIATzzxBN/+9rf50z/9U0qlEp/5zGeYnJzkfe97Hz/96U+Jx+ONz3znO9/hySef5IEHHkDTND72sY/x1a9+dRGKM3+klLieQ8Up42O19pxaPErnuaClxPVcQCI0QSqdom+wDyOdIpNNY+oGhh6cx5UWuveCQKJRa4RqYhKKTM3Fp+uImkiFo63awgkpGyLX8mgaRUkpG6PEmW69WRdRCIEuBIauYZoW8XgsTGEuJFWngtTbdzn40ieejIc9OsPAsqzIqTZM0ySTzZBIJrBiFl7gUXbabwRcz8WKWXR2deK5HrZj4zleZHdfOpPGioXnUUBA1aniyWgC3IgOLwMCEZDrzDUiTrcTZd00w0yqvu/jeR62a1Nxzj9yna3cnhumCvE8DzNu0jfQh+M48yzUucfPdmTxfZ9yuUwgAzRDQ/fnKVK1TYEfUKqUsKs2ju+QyWUYGBqY8zsvhGEYWHGLsl3GDVzcwMWS052M89nSTMWu4DgOjuNgmRY9fT049jzrahayHVkkklK1dI5IzccuiQxH4p7b6ARnO7LoWnTXaD3lS+AHpNJpNP3SLGkQclEnZC4NU1NT5HI5OtOxtn2+mVyW+x/6He685z1ouham524e/s7jsAJBuiNLR3cXumGgBRpaoGEUS6z64d8x9JPnMKrV2ZeeNzmHg0DiBwGBlEhNI7Cs0L2XTCJyOTDNxkgKQFTKUCyB70G5DKXy9P1SNZeQQIYJE2tzLIgw4GyFMAxSBRgnDDh7BjgGlIRgsr+PsdXDeIk4sXSaeC6LbhpkezrJdHegzdctc25l0dXZxfCqYZKJJK7jYlftyC4sTdewEhaGZVAsFjl29Bj5yXx7NhE2TgP9A/T19CGEwPO8UDgjXhXCEAhTIIVk/Mw4o6dGw6SRkQ4CQgvnt1LJFP29/SQTyXDkIIPINkkkrnTx8XEch4kzEy25zub6TKtJtZxiVijA2XSWXCY3/wSKs9js+A4Vu4Lne1QqFabyU3OOqOdqhHVdJ5VOEYvHMA2TTCJD3IrP7/OzEAQBhVKBQqmA54cJC23bPv8xZtmcTCXJdeawTAtLt4gZsdBF1yZVu8rp8dMUy8UwjYznXzDz8UyRMgyDrp4uOjo70DUNSzOxxFxROudGaAJd0/A8n+d/9vf84G/+PyYnJtorGGGnbKIYZjPPZrNz7nfVxu6rlCu8uvU1Duw/iO/7FKeKVCvR3Dy6rvOe993Ngx9+iK7uboYGhljVtwqrVMbYsRs9Hkf4fkukidkINImo5XfxhAhzCPk+OA5Uq6FbT9dD9x+A7SAcJxQp2wHbbhlJCSEwNA1N0xBChAnvapl+6w6Mek4pn+nFHZquM3zdtdz28Gb0jg6mKhXy5TKVSpU3dr7Jmzvfmn8PegZCCDZv3symP9nEunXrwgstiJ5GQoowRXegBex6cxc///HP+c3Lv2nLJoDOrk4+/alP8+D7HyQej7edvydfzjM2NUa5UuY3L/2GH/z1D86bvXY2NF2r5erSueOOO/jjz/4xt2+4vfF+1LqqVqvsPbiXwycOc3rsNC/87AXe2vFWtISOQtDR1UFffx/pdJqHfvchPnDPB8hkMpFsaebQkUO8tPUlRsZGOHzwMDtf2xm5o5FKpbjh5htYMbyCwYFBHrz/QW6+4ea2VwRUKhX+/vm/59e//DVTU1OcOHaC0VOjF+5EzVgkce3113LP+++hp6+H69Zex8bbNpJJtV9Xe/ftZcvfb+G17a/h2A6FfCHyNZjKpHjg4Qe47wP3kchkuXbltazsW9FGB18gBDiOw7tvH8A0I7pD2+SqFanA95nKT+G4Hp7nMTU5FTmVuW7oXDcxie+Hfv64FSebyWJpJkEsTlBbpVdfVTfXKSGDoLHAQTRHGq+PjOousfrqP99HBkFjDqo+ihJ1oaqvEGR6NVY46SpabDnHLiGIJRJ0dndhdnchCkU8XUcKjUqlyqkTp9qar6mTn8hj6uaCLlofHwcHDw9NaEycneDEsfYzstoVG8d2SCfTJJPJto4hpcTDw6yYaI5GuVTm1Mkww28UNE1ruAyvWX0Npm6Sy7Y/6V4ywtTxvu9jV23OnjnLiWMnIotUtVpFExqO7eC7PplUho5sR1s2SSmJx+K4rku5VCY/kWfkxEhkQU9n0vT295LtyNKV68IyLXLZXNueFUM3kL4kP5lnYmKCsZExTh47GXmkn+3IUi6XcWwHTWhhXeU62rIJIG7FKRaKnB49TbVSZXJiMrL7MJPNUCwUQ3ef0EjEE2SjjIZn4Ng28XhiQSPEKFy1InWxkUwnDrzQZSNEOIwWUhJIifD9UGxcFyqV6Rt7a+4+bDt8+D54XuvqvgvYVH8ETCdH9Aijn9u1Z5ewwezu6WVgcBWlUpk9b+5p+6RWKGZjKSZkvFJZzmHElEhdJOoiMJ94faK2WEEnHOGJ+vyS6zbdCzU9OmoRJ7dpCXr9eDCnYM0mUi6hQNUfDuES9MG+AdauuoZKpcKvX/o1ut7mfNRVgGpwo6Hq69KzXOtbidRFZL6nRH2k1bgFt3HPU20sVhep+t+Ne6SClrmo6QNOj93kjOM2j6bqYhUQjqY8QGoammFgGCaxWJxkMolAYBqmijIxD5ZrQ3C5UPWluBBKpC4CkrDBr6dq14hQ0UEQjpJ8f1qcWqKgM+Pm3Wmfef1yl01iBJIAiUQ0Rk710VOVcJVfgXClXxEYTGcYXrmGjqEhOnOd87/JUqFQKC4CSqQuEvV5HkF4o+y8kTIUKddtdfHNNYqZxa03LVDToyUBLSLlEYpUmVCkJmrPWjrLqpVr6Fu5Cq22QlChUCguF0qkLgZCIJJJRHc3IhYL72WqVlscG7NKzjk35XLBxRDne7/u5pspWA2hEgIP0KwYyWQCYjGS2RyWFbtky0vbRbmJFIqrAyVSFwERi2Hdey8ik0GMj2O+9BJs3z69lDwKFxKrC6zqqwuTJBzZVQhHUAUhmNI0ikKj64YbePD++zH7+xm+4QZS57mxbimgBGr+yKZ/CsVyRInUxSAWw7rzTqwNG2B0FE6fhh075i9SzcJUv+9ptvfncygEPmHA2rpIVYCyEBQ0naKm0X/ttdzzsY/Rfd11YQxDY3mcFqrhVSiufJZHa7TMEEKEoYxMExmL4et6Yzn6haJPzEpbKTEEQgsD1dYfdVefBxBPkOzqQsTjpHp7iaVSWPFzw8ooFBcF1b9QzBMlUheZgHBBQolQoLKEaeUvKkIgdA1hmmEAW03DExpOzY4iEL/mGm750IewVq8mt2oVye7ui22VQtFK8wqfdj+viMRydP0qkbrIBIQr6CYIY+XFuQQiBaBrYZp5IQiEho9oWdGXHhxk7YMP0rlhQ23UpVbxKZYhzTf9Kc7LchOnOkqkLjLCMDD6+ohddx16uUxw9ix2oYAgrPzFkobm61QAQe2+qPr9WjbgJRLEenrIJJOkVq3CSCbRlsn800yW6wWnUFw2luklszxbqGWElk6TffBB4jfcgD8ygv3DH1Lctg1LSnJAYhG/q760HEJxEkJgIzhDzcU3NMTg7/0eyZtuIt7bS2JwcBG/XaFQLFlmhppZRiiRusiIWIz4LbcQv/lmnCNHKG3fzpQQxKUkSej+W4xgQ/Wl5vWsPPWFGlUBUwjyQFdnJx333EPve987983BywA1ilIo2mQZXjpXrUgZpsnKlSsZXLGSIAgoFUphGooIP6Kma6xevQbTNPF9n9GxUar56pxRGtyTpxjPT1LUBBaCMcL5qUQg6fV9klLiSYnQ9ZYkic035NL0embnqB7uKNA0KkLgSkkJOK7BhKYxWanAwYN0ZueXKsM0TSzLolKtkEwlueOOO6hUzp/Z9XysWLGCifwEh48exrEdqtVq5FQIQhcYKQM9plOtVFmzZg133XVX2zZlMhkM0+Ddg+9imiae6+H5EZMVAo50qFDB8Ry6Oru4/fbbKeTPn2BwJkITjXxSK1euZHRslDfferPtHFeu5zJVmCIWj5HryHH99dfXAjRGMQo6Ojro6eshkUgghGDP3j0kEu37AM6MnyGZTjK4YpDAC3BKDsWpYqRjJJIJrrnhGgZXDtKR7WDs9BhvvPFG2zY5roPv+1x7zbWUS2U6M50M9Q9FrvdVa1fR199HriNH1a6yd9/eWZMxzpfjJ47T19vHhg0bcOywnlw3Wsr2RDLBwOAAuqbjei4nThynNFGMHIszTHqo43kuIyOn5kxUudhctZl5u7q7+cQn/xEPPvRwreK9yKnMAVzh4Wguru/y7p53ObD7AHbVnnXfoFrBOXQYb2wMTUoswl7Cas9jc6nMWsfF1DQShoFey/1Uj5w3W2DYeoxAj1CgioSr9yrAUSRjSKY0nQPxGKOGgZnLkl57DVZHxwXLpWkanV2ddPd2Y1kW/b399PX0LSiWX7FS5OzkWWzH5szYGU4cOzFnXc1FMp1kzbo19Az0EDNi5BI54mb7jYDruRw/cZxTo6dwHIf8ZL6Re2e+CCFYsXoF16+/nlQ6hSUs4sTDjMgREEI0ElWOnR7jzV1vcvr0aYIgCDNHRxT0ZCrJLRtv4dobr0VHR9gi7MVEtMm0TGKxGL7v89aut9ixY8eC8oqtWruKTe/bRO9AL17Fw5vyCLyIGZoNjVg2hpWwOHvmLK+8/AoHDxxsvB91tB2zYtx5553ccfsdGKZBpVzBrtrROwe11VGBCDi07xBvvvYmxUI0AW6mr7ePTRs3sXLFSvzAx3O9yOeBRGJjY0ubSrnCwT3vcOLQcaSMchyBZZnEEwlAsn/PHt7YsYNKOVoOvha7VGbe8xOzYqxbdx333fe+tkMASSk5cuoIew/vpTpV5djxY2z9zVZKxdL5PgRaawrEsz7c4vv0eR5x0yRhGBi10VSzSAVNz/XRlc+0cNXjBVak5LTncswPmBSSd4TglK5BsQi73ppX2TRNo3+wnxUrV5DNZVl3zTo+8IEPkIi334N+Y9cb7PnZHk6eOsmJoyfYv3c/lXK0kVmuI0fZKTNcHmbV0Cru3Xgv69aua9umqakpvvf97/HmrjcpFoucGTsTOQGfEIJbi7fSM9SDpmmsWruKDTduWFBdbd++nb/7yd+x/fXtBH6A4zrIIFqD2dnVyeDaQdYn15NOpVndt5reXG/bNlWqFXbv3s1r219jYgFpw++Sd3H//3M/a65dQ0JPkDNyGCJaUxQQYGPj4rJ/336OHjvKSy+91LYrOJPJsH79etbfup50Ot3WMQAmy5OcnDhJqVpi185dvLb9NU6Pnm77eBs2bOCjj36U97///W0fw3Ed9h7ay7vH3sVxHN555wA7tm2PLHbxeJxUOoWmaUycOYvbZpbuqFy1ItVMu6Ox5l6WROJ7PtVKNbJLbMIPOKDryJhFf08PyXXXkcjlWlx+EK4ErMfjq4uUyXTw2FRtH811SIyfxSwW0D0Xv1iiWrUjXcC6pmPbNq7rTvfe5MLqSkqJ7/v4no/jOthVO3JdxeIxPDcc9fqB3/gN2raL0CbXcXGc0AVZrVYj9aA1oeE6LkEQhJ+rfXQhqU2CIMB1XOyqje/7OI4TfSRVTeL7fiMzc5227ZLgeR7VavRzvPHdCFzHRRCOGuvZXSO7nhBoaOjoaIGG53iRf7dmTNPE9/wwX8ACzvH6aFjTNIIgCN3alfZHnY7t4Aehh2cxUuVIKfHcsK4CP9r5BGE9abqG53uXbHpLidRiIaFaqZKfzFOYijYX8a5p8uNkgg7TZOOtt7Ly8T+gd926ec1JWUyPpNKEYpUvFji2eydjRw5ROnOG6m+2M3lqLJpI6TqpdIpyuYxlWbiuu+AFC4Ffu2jtKuVimDq8WIzmCtGERqVcwXVcPM9ru1GqI6XEcRxKpRKlQomp/BST45PRRErTKBVLDTEPIrlRZsfzPIqFIvnJfCjqTY3VfDENMxQEIdCEtuBGTkqJXbWZmgjrqF3KpdBFZJpm6IZswy6BwMAIRcrXqJQq4e/W5jkqfRmKyQJbXiEEuq6j6+EUQiFfYHJisu3jFaeKeO7izf0EQUC5HF57Uac3knYSKSW6oYeu0IidpnZRIrVI1Hvkju3g2NGGwVMIDus68ZhFX08X9i03o6+/rWWfKJexl58g5hQxpYOmCXzDwLajzf1oWjg68FwPz5seSS0EKSWBH86vuK6LbduR68pxnIY9MmhvQUGrUYQjKdfFccPfzrbtSGUVQuC6TSOpRSCQQVhH9ZGUHX0kZds2gR8gEIvSC4dQPNv53VqO4XoIwkl4DS3y3F0drXaXoZACz/Uin+PNOE64cGIxfr96p0AGYQdoIXVVP68WjdpIyrYdgogiZRhGw2Pge5duJKXCDCgUVzBquf7lYTmGH1qqKJG6glEXiQJUg3mpUXW9uCiRUigUCsWSRYmUYk4ksmW12lJD9VgVivmzXMfTSqQU56UuVEvpnm/lvlIoojF9vcx8XvookVLMzTIMRqm4ulCdlSsfJVIKhUKhWLIokVIoFgk545/iKmWpetSWmj3zRImUQqFQLDbLVBCWIkqkFAqFYpFRI+nFQ4mUQqFQLCJ1gVJCtThctbH7JBLP93BcB0TELHA1Ahng+14jOrgVs8hkM5HjpFkxi3QmTSweIxaLEQQBttN+HDLXc0GEQWJNyySZTpLNzZ2vZTY0TSOVSZFIJoglYghN4HruguzypY9hGcTiMZKpJJlsBl2Plp8qnUkTT8QxrTA5oB+EEdXbxfVddF0nkUzg+z6ZbAbHcSLH7kskExiGEcZsk3LBdSWlJJFMkM1l8TyvETOt8f48DMxkM5imWTtPfVzPXVhdeS66qYd15LV/nHgiTiCDsJ4BvfYvKgFBGDMz8InFY2Rz2bZvlUhn0uiGvuDfzXGdRm46wzBIZVJk5plkdDYSyQQSuaDfzXbC+I9hhHeNeCJOJpuNHLsvkUyQyqTQdR3p+1TK5Usiw1etSPm+x9nJ0xw+eRDTPE81iOaXreIjpWSikMcPPAzD4Pqbr0fTtMgBJXVDJxaPYRgGq1auYrI6yTvH3ol0jGaqTpVAD+ju7SYWj/FbD/wWt9x2S6RjCCHI5DLkOnLE4jGsjMXhkcOYRpu5t5AUnSJDw0NkOjP0D/azdt1aXCdaFr54Is7QqiE6uzrJZrKMF8cXVld2lVxvjrvuuwvHcSgWimEaiogiNbBiIMxem0pQdsocPtl+XQFUggp33HMHfav6kIE8J/jpfEQqkUwwtGqIaqVK4AVIVzI+Md62Ta7r0jnQye8++rsLytA8vGYYu2pz9MhRDAxMzLaCzAaEQY8nShPccuctxDKxc/aZ72gmZsXoHurm0MlDWDEr3Fg3KcK5YHs2JbuE67l09XTxwMMPhEk0ozbntd0HBgewsdl7aO8Fdp/7+L7vc3byLEEQEE/Eue3O2+jp7Yqcn8w0TayYhURy4O19vLV9Z+R8cO1w1Wbm7ezu4mOPf5z7H3oAYzaREjNfz3IZSXB9H9t1CYIwn5TnedEnTUXt6LXRj2VZaPoCPLESPH86Urjv+23ljhGaQNPDFA+GYWDoRrRw7DMI/CCMYC6n7YpaV0IINENr5CLSDR1NW1hdua4bpuSWtH3jsqZrGIYR1pmmhRmMF1hXtm1Pp1NoMulCDZ5ENkb39XT0zVl/5xKEc447808pG5HiF9Js6EY4wtc0rRGhPapINUdD8QO/kbpltv3mc47V68o0zbBNac5LGqGoUsrw/JayEe2/XlfzEaqGvbVddU0nFgs7sOf9TOuGc94PgqCWyUCCDMJHROptlOd5/Or5l/jJM3/H1GQ+8nEadqnMvOcnCAKKhSJnz5xF1/XWNAvnCFT95bkXkmFZWPE4mqZhxk10TW879QCAbYc5qdwFDO91Xa+5xRK1a63NdAgivHiDIKBYLDJRnIiYcrqVeDxBNpsNMyFL2mvoGkm2JK7jMpUvYNsXSio3d9k1TSOdTpNJRXfTNiORoftJSqqVCvlSeY4UC+d+h2h6EdogsEyTVCo9a9boeTV2MlwG73temHa8lpDTdRxmr3bZ+n/TPpqmo+saQtOIx+NkM1mE1n5deZ5H1a7WEmB6tTQk0c6FUFQMdCPM3RSPJ87NqBvhkIEMqFaqFAoFZBDg+V7NRTb/YwnAMEN3tqZpmIZJIpMNXcDzFajm75Ohi7VULOE4YcegITS07no+A+suvnjNrrgVxzIMaPN891yXeDyBtkjpXy7EVStSdrXK7jd3UyiWkFJSKVfOddOJmX+2btA0jRtuvZGN92wik83Qle2mO9eDrrdfrW+/vZtfP/8yR48eafsYXd1d3P/Q/ay5cxhTN4kbSSz9XFfIfKlUK2z5+c/ZsmUL1Wr7GVk33H47/8+HH2VwaLDtJbph0+shRcCRw0f45dYt7H1732xf2PQkWrc1XVzpdJrND/4ut73vNizLas8owPaqlJ0ijuvwxvY32PrSVkqFIiCm24KZ2XHF9DklEAgt7M1rmsbq1au5/3ceYHh49Zz1cF5qDdzomVOM589SKBR4c/ubHHr3UGME0jhGU0vc3P7VM82m0ilynTni8Ti3b7iDWzbdQiKRiFxHdUbHRti99y0mJscZGxnj4IFDjUSI8yUWi7FyeCXdvd10dnZx+213sGrlcNs2ObbNjjd2sOeNXZTLZc6eOcvE+ETk2JWDKwa54dYbyOVyDA6sYN3Ka0nEk20vojh+/DhvvrKTd999B9dxKZfLkZMgxhNxNmzcwE3rbyJuxRnsHaKns6ftTpnruOzu2Y2xAHd2FK5akXJsh8PvHmZ05DSe5zE1ORX5Qqm7mjZsvA3T0OnI5FjZvxLTaL+x279rH7u2v8nOHTvaPsbK1Su569730NXVQdxMkI11kjCSbR9vamqKidFxtv7i5chZhxsIQTaeJfvxDMP97TcmkgAfhwCP0eMj7N+1jxef/8Us39fUqWhyp87c3tPdw72b7mNF74oFNbxFu8Bk+SyVapnCRJ4dv9nO2TNna64sWkZJ9dehTeGzIBwB1+cmhStIPZRieKD9uqraFcrlAhP5M1TLZQ7s2cdrW19reA2aXUvNbrEWF5mA7p5u+of6yWQy3HjtTQz1DJLN5tq2yy5XKRdKnBkd4+D+d9j28itMRMz0m86kWX/7ray5Zg3Cg0w8w5qhNW3bVC6X2G6/xuF3DjI5OcmRg0c4cexkpISDArjx1hvp6e3C0DSsQZ0VfSvIZtqvq+J4gZOHT7Bj23aq1Sr5iTz2rHPec4tgJpult6+bm269Acsw6O7oZnhwNUK05yZ3HIeuXHfo0r4EXLUiBaHLz/f9lkckBDMy1gqE0NqeI6m7v+p2tUvghy4BIcQ5j3YQQoRzSN4C7QrCLLELmUMKqI06ag37+eqqUd6ZgtVUD/V5sfqcTTtIKdGa6riRgdj3a3MuNMSoIVA1G2bOx/i+XztGsCCbwmO3poyv11Wza7sxqmpelNH0WgjR+Ezd1bTQuhJCQG3uLwgkge9HXmkWNNkkpQz7Hws6x7XQpmB6/qb+HZHsqncApITafNvCfsPwXAjtqf1+bdRVY5FE4zxtv53SFlDPbX3fJfsmhWJRmOcKNzHjeebri8x5bWsO3CsvsO/CDTn3sYRY8E8iCG8huYS/reLSokRKceVxmQWqmXOi+MnZX8+M+3fRhesKoV5TV1CRFDNQIqW4sriAGF0s3ZpeZDyHwMwYMV0wKoFqdS8LUVbzKS4NSqQWSGujpM7sS0v7MjPbYGthzH8EdN77WlpeL/x8WroheppvRFpKvrpoq/kUFx8lUouEOq8vFQtv2C5WkzjdVZlbhGYbTTX2qa+uW+T765eeQC1NZO0/lWplaaFE6gpkzobwKqJ5xdxCbq5eEDPFqXnAfTUPvq/msisiE1mkXnzxRT784Q8zNDSEEIJnnnmm8Z7rujz11FOsX7+eVCrF0NAQf/iHf8jJkydbjjE+Ps7jjz9ONpulo6ODT33qUxSLxQUX5rKyxC64q7k3OJdALS2nUtMsljz39aL+dGplgWIZE1mkSqUSGzZs4Otf//o575XLZV5//XW+9KUv8frrr/P973+fffv28eijj7bs9/jjj7N7926ee+45nn32WV588UU+85nPtF+Ky82SbwCWvIGLxtwCVZ8DuURSNdcS8xkRHVpeX+oRxlI4LZaCDYolTeSbeR955BEeeeSRWd/L5XI899xzLdv+23/7b9x1110cPXqU4eFh9uzZw09/+lNeffVVNm3aBMDXvvY1PvjBD/JXf/VXDA0NtVEMxawspQZgKc6RX0TRqo9kG0IpQYrw75nbZzPhYo2CL3zcpXTSKBSXYE4qn88jhKCjowOArVu30tHR0RAogM2bN6NpGtu2bbvY5iw+s80zLCWWkk1LTqAuAvM9D2ZZTDFzxLUoP13TTbwt0bhnHektpZNFoQi5qGGRqtUqTz31FI899lgjFPvIyAh9fX2tRhgGXV1djIyMzHoc27ax7elEZFNTU4tqZ7sT6/U0A4try2Ic4yI0wKIpUGrkz7aGImpujNu1dbYRQfN3zP/1ItZVs0lzRc8/z/aLF2pmRoDd2miusa0xmhO1sEfTK92gOS7uRTqvmsyI/PFGgN7Fsmc67NbSYSnZcum5aCLlui6f+MQnkFLyjW98Y0HHevrpp/m3//bfLpJlIUIITMsknoiHWUvdaMn3IBRXy7IWtXHRdJ1EIkEy1X5A2Hgijq7pBH5AoAcLvt1GECY8SyQTeH60CMz1AwghiMUthAaSoGmOKCqSgDAtBhqNLL/nxOdrno+aTaRq+yRTiekcQgsgjNcWEMgAw5j+DRvx+pri9oVfL1ptEQJd07FiFoYRpnvQF5Inq4aodS40XSMWC+uqEVuuvty6NfR5+FT7TwhBIpEgHo83gt+231uZtknX9Ebm6EQy0eiEzvdUTSQTWHELwzTCgLwLvQYFGEZY/7F4jHgyTjKVjBy7r15HuqbX0pkssK40gWWZxONxAJJ28ry5pWYjkayd48tU7C6KSNUF6siRI2zZsqUlodXAwABjY2Mt+3uex/j4OAMDA7Me78///M/54he/2Ph7amqKVatWLchGoQni8TjpTLqREHC23D3nQzd04sn4wpLuzaCecjrXkWv7GOlsmAq7kRNnwSoliMdjZDuy7SVjrF2riVQCoYWpNkBDtHH6SSQ+Ph4eGJBIJ8h15hrfM+vCiSaRaGyvvc7kMsRi7UetbyZMMhlgWiaZbAbf81uFqUmgZtuu62Ejqes6yXQS3ViEKNMiPNd1XSeZSpLryBHIYNoFOGN1YcsQSgJCkM5mSKVSpJLJsFO2wMZO00SY+NAMG99MNjOvfFLNo+dkKkkimSAWjzUSKC4EgWh0xFzXJZ1Jk8llomWvFZBKp8JEk4aOrmkL1XN0TSeeSDSOK6WMnM06lUmF2YaXp0YtvkjVBerAgQO88MILdHd3t7x/7733Mjk5yfbt29m4cSMAW7ZsIQgC7r777lmPGYvFiMXaz4c0O00RimXYQERtFHRdRxCKrOe6OK6L49iR0zI34/semhALaqA0TcP3fRzbQZM6jmFj0n5D7DoOgQzaqiOg0SALJK7rYNtVBDoaPlGvnAAfGxsPG9dzw155zaaWEdOFRlK115qm4wcBjuMsoKGT2LaN4zg4joPvB2F2XkODppGUqLnU6s/T20ObNL2WcbjWEXA9r8XNHRXHscOMtW7YWUGEHSsRiGkdktO3Ksw2ohJC1BIehvb6gY/jOAu0y8UP/FAsqWc1Dn/DCy/rCPcIr70w4rwMAlzPw3Fs2m2JHacpC7IIryHDMCKPpLRaklDfD7N0L7SuQg+PbJwXuq4TGNFs0nUdKSWeG7ZTrhO2UwtJ1eF53iW7xSWySBWLRd55553G34cOHWLnzp10dXUxODjIP/gH/4DXX3+dZ599Ft/3G/NMXV1dWJbFTTfdxMMPP8ynP/1pvvnNb+K6Lk8++SSf/OQnL+nKviAIKBeLDdeHXbUju/w0TePwu4f41ZaXSKVSdOa6Fpz08N133uHUiRNUy9FyWzUzceYsr/56G5Pj45i6RSqWJmbE2z5etVrl9ddeo5DPt33BCQHvHniHHz7zDL29vYTZgmuNeAQCAjwcfDxOnTjF0YOHqdbzgM0139OwoXWbAKQfsG3rr3BtO/JIehpJ1alQtAu4nsP+PQc4MzZGpVxpsasxf9IkUs3bNU2g6waarrFf28OzP3yG1199tU2bwqSHY2dHmMiPUywUOXrwMIXJfGuajpr958asq78QYfbcqo0Vs9j60ssUJqYa7qd2OH1mjP3v7iOfn2RifILCZJ5qpRqhyZMEnsfJo8cpFQqcPj6KW3TZ8cqrtC9SDnv27ubQ/nepVitMTuSplksRR1KC0yOjvP3GW6TSaU68e5x3336HeLz9PGUjI6fYv2cPE2fO4vkedtXG96K53KXvc2DPPjzHIR5PsLtnN1257rZdpJ7n8cq2rdPn90VGyIi+oF/84hfcf//952x/4okn+Df/5t+wdu3aWT/3wgsv8IEPfAAIb+Z98skn+dGPfoSmaXzsYx/jq1/96rnpn+dgamqKXC5HZzq2IF+0poU9VwlNOWDmjwBMy2qki6772RfiDnEch1KpiBvxRGxG1zUSiQRWLJwv08TCbJJSUq6UqZTLBG26DgVgxWKkUkmMhoi3NydV7/t7nke5VMZ1ZksCNx+jBJoQJJJJEonEguookAFShrmEbMfBrlTDXnhdkC5kSpNNAjBMk0QigbmA7KcSiVdLHx8EAY7t4M3SEbvQL6oJgaaHualisTjxWKztXjiA54ejHj8I8D0fz3WbXI7zQwgRzv3oGpqmE4vFFlZXUmI7NrZdDXNcBT6BH0QeKxiGjmla4ehQN8JMywupK8+jXAnPcQnIILpN4e9mYVoWWr3etPY70pIwk3mpVIw80mw5jpRMFG3y+XzLlNBMIovUUmCxREqhUCgUl4f5ipSK3adQKBSKJYsSKYVCoVAsWZRIKRQKhWLJokRKoVAoFEsWJVIKhUKhWLIokVIoFArFkkWJlEKhUCiWLEqkFAqFQrFkUSKlUCgUiiWLEimFQqFQLFmUSCkUCoViyaJESqFQKBRLFiVSCoVCoViyKJFSKBQKxZLloqSPv9icm7RNoVAoFMuJ+bbjy1KkCoUCAJOlNpPdKRQKhWJJUCgUyOVyc76/LJMeBkHAyZMnkVIyPDzMsWPHzps0azkzNTXFqlWrrugygirnlcbVUM6roYxw8coppaRQKDA0NISmzT3ztCxHUpqmsXLlSqampgDIZrNX9EkCV0cZQZXzSuNqKOfVUEa4OOU83wiqjlo4oVAoFIolixIphUKhUCxZlrVIxWIx/vW//tfEYrHLbcpF42ooI6hyXmlcDeW8GsoIl7+cy3LhhEKhUCiuDpb1SEqhUCgUVzZKpBQKhUKxZFEipVAoFIolixIphUKhUCxZlq1Iff3rX2fNmjXE43HuvvtuXnnllctt0oJ4+umnec973kMmk6Gvr4+PfvSj7Nu3r2WfarXK5z73Obq7u0mn03zsYx9jdHT0Mlm8cL7yla8ghOALX/hCY9uVUsYTJ07wB3/wB3R3d5NIJFi/fj2vvfZa430pJX/5l3/J4OAgiUSCzZs3c+DAgctocXR83+dLX/oSa9euJZFIcO211/Lv/t2/a4nFthzL+eKLL/LhD3+YoaEhhBA888wzLe/Pp0zj4+M8/vjjZLNZOjo6+NSnPkWxWLyEpTg/5yuj67o89dRTrF+/nlQqxdDQEH/4h3/IyZMnW45xycoolyHf/e53pWVZ8n/+z/8pd+/eLT/96U/Ljo4OOTo6erlNa5uHHnpIfutb35K7du2SO3fulB/84Afl8PCwLBaLjX3+6I/+SK5atUo+//zz8rXXXpP33HOPvO+++y6j1e3zyiuvyDVr1sjbbrtNfv7zn29svxLKOD4+LlevXi3/yT/5J3Lbtm3y4MGD8mc/+5l85513Gvt85StfkblcTj7zzDPyjTfekI8++qhcu3atrFQql9HyaHz5y1+W3d3d8tlnn5WHDh2S3/ve92Q6nZb/9b/+18Y+y7GcP/7xj+Vf/MVfyO9///sSkD/4wQ9a3p9PmR5++GG5YcMG+Zvf/Ea+9NJLct26dfKxxx67xCWZm/OVcXJyUm7evFn+3//7f+XevXvl1q1b5V133SU3btzYcoxLVcZlKVJ33XWX/NznPtf42/d9OTQ0JJ9++unLaNXiMjY2JgH5y1/+UkoZnjimacrvfe97jX327NkjAbl169bLZWZbFAoFed1118nnnntO/vZv/3ZDpK6UMj711FPyfe9735zvB0EgBwYG5H/6T/+psW1yclLGYjH513/915fCxEXhQx/6kPxn/+yftWz7/d//ffn4449LKa+Mcs5swOdTprffflsC8tVXX23s85Of/EQKIeSJEycume3zZTYhnskrr7wiAXnkyBEp5aUt47Jz9zmOw/bt29m8eXNjm6ZpbN68ma1bt15GyxaXfD4PQFdXFwDbt2/Hdd2Wct94440MDw8vu3J/7nOf40Mf+lBLWeDKKeMPf/hDNm3axMc//nH6+vq44447+B//43803j906BAjIyMt5czlctx9993Lqpz33Xcfzz//PPv37wfgjTfe4OWXX+aRRx4BrpxyNjOfMm3dupWOjg42bdrU2Gfz5s1omsa2bdsuuc2LQT6fRwhBR0cHcGnLuOwCzJ45cwbf9+nv72/Z3t/fz969ey+TVYtLEAR84Qtf4L3vfS+33norACMjI1iW1ThJ6vT39zMyMnIZrGyP7373u7z++uu8+uqr57x3pZTx4MGDfOMb3+CLX/wi//Jf/kteffVV/uRP/gTLsnjiiScaZZntHF5O5fyzP/szpqamuPHGG9F1Hd/3+fKXv8zjjz8OcMWUs5n5lGlkZIS+vr6W9w3DoKura1mWu1qt8tRTT/HYY481AsxeyjIuO5G6Gvjc5z7Hrl27ePnlly+3KYvKsWPH+PznP89zzz1HPB6/3OZcNIIgYNOmTfyH//AfALjjjjvYtWsX3/zmN3niiScus3WLx9/8zd/wne98h//zf/4Pt9xyCzt37uQLX/gCQ0NDV1Q5r2Zc1+UTn/gEUkq+8Y1vXBYblp27r6enB13Xz1nxNTo6ysDAwGWyavF48sknefbZZ3nhhRdYuXJlY/vAwACO4zA5Odmy/3Iq9/bt2xkbG+POO+/EMAwMw+CXv/wlX/3qVzEMg/7+/mVfRoDBwUFuvvnmlm033XQTR48eBWiUZbmfw//iX/wL/uzP/oxPfvKTrF+/nn/8j/8x//yf/3Oefvpp4MopZzPzKdPAwABjY2Mt73uex/j4+LIqd12gjhw5wnPPPdeSpuNSlnHZiZRlWWzcuJHnn3++sS0IAp5//nnuvffey2jZwpBS8uSTT/KDH/yALVu2sHbt2pb3N27ciGmaLeXet28fR48eXTblfuCBB3jrrbfYuXNn47Fp0yYef/zxxuvlXkaA9773vefcPrB//35Wr14NwNq1axkYGGgp59TUFNu2bVtW5SyXy+ckq9N1nSAIgCunnM3Mp0z33nsvk5OTbN++vbHPli1bCIKAu++++5Lb3A51gTpw4AA///nP6e7ubnn/kpZxUZdhXCK++93vylgsJr/97W/Lt99+W37mM5+RHR0dcmRk5HKb1jaf/exnZS6Xk7/4xS/kqVOnGo9yudzY54/+6I/k8PCw3LJli3zttdfkvffeK++9997LaPXCaV7dJ+WVUcZXXnlFGoYhv/zlL8sDBw7I73znOzKZTMr//b//d2Ofr3zlK7Kjo0P+7d/+rXzzzTflRz7ykSW/NHsmTzzxhFyxYkVjCfr3v/992dPTI//0T/+0sc9yLGehUJA7duyQO3bskID8z//5P8sdO3Y0VrbNp0wPP/ywvOOOO+S2bdvkyy+/LK+77roltQT9fGV0HEc++uijcuXKlXLnzp0t7ZFt241jXKoyLkuRklLKr33ta3J4eFhaliXvuusu+Zvf/OZym7QggFkf3/rWtxr7VCoV+cd//Meys7NTJpNJ+Xu/93vy1KlTl8/oRWCmSF0pZfzRj34kb731VhmLxeSNN94o//t//+8t7wdBIL/0pS/J/v5+GYvF5AMPPCD37dt3maxtj6mpKfn5z39eDg8Py3g8Lq+55hr5F3/xFy0N2XIs5wsvvDDrtfjEE09IKedXprNnz8rHHntMptNpmc1m5T/9p/9UFgqFy1Ca2TlfGQ8dOjRne/TCCy80jnGpyqhSdSgUCoViybLs5qQUCoVCcfWgREqhUCgUSxYlUgqFQqFYsiiRUigUCsWSRYmUQqFQKJYsSqQUCoVCsWRRIqVQKBSKJYsSKYVCoVAsWZRIKRQKhWLJokRKoVAoFEsWJVIKhUKhWLIokVIoFArFkuX/Bxq5JK9Uw1sBAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "\n",
        "# カスタム迷路を指定\n",
        "custom_map = [\n",
        "    [1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "# custom_map = [\n",
        "#     [1, 1, 1, 1, 1, 1, 1],\n",
        "#     [1, 0, 0, 1, 0, 0, 1],\n",
        "#     [1, 1, 0, 1, 1, 0, 1],\n",
        "#     [1, 0, 0, 0, 1, 0, 1],\n",
        "#     [1, 0, 1, 0, 0, 0, 1],\n",
        "#     [1, 0, 1, 1, 1, 0, 1],\n",
        "#     [1, 1, 1, 1, 1, 1, 1],\n",
        "# ]\n",
        "\n",
        "env = AntMazeEnv(maze_type='UMaze', maze_map=custom_map, max_episode_steps=1000, seed=40)\n",
        "\n",
        "\n",
        "obs = env.reset()\n",
        "\n",
        "\n",
        "action = env.action_space.sample()\n",
        "obs, reward, done, info = env.step(action)\n",
        "\n",
        "# 画像を確認\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(obs)\n",
        "plt.show()\n",
        "\n",
        "env.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaHb_V-lIv7c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrpPzb85IwEK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgcNlVwskVTe"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "7pjEkP8Y1WD2",
        "outputId": "eb46d9d7-707c-4fa2-cd67-91fd35541da4"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9c4e53c9231c>\u001b[0m in \u001b[0;36m<cell line: 205>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training script...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOmegaConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-9c4e53c9231c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Environment initialized. Setting up LEXA and replay buffer...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mlexa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLEXA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     replay_buffer = ReplayBuffer(cfg.data.buffer_size,\n\u001b[1;32m    118\u001b[0m                                  \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-4788a61f9974>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, env)\u001b[0m\n\u001b[1;32m     93\u001b[0m         ).to(self.device)\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         self.wm_opt = optim.Adam(self.world_model.parameters(),\n\u001b[0m\u001b[1;32m     96\u001b[0m                                  \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld_model_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                                  \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mfused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         )\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;31m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__dynamo_disable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdisable_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlobalStateGuard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompileTimeInstructionCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inductor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minductor_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mShapeGuard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_dispatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_traceable_wrapper_subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m from torch.utils._sympy.functions import (\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mApplication\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloorDiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPythonMod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIsNonOverlappingAndDenseIndicator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCleanDiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloorToInt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCeilToInt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_sympy/functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msympify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m         assuming, Q, ask, register_handler, remove_handler, refine)\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_degree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpquo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mpexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_gcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/polys/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m         GroebnerBasis, poly)\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m from .polyfuncs import (symmetrize, horner, interpolate,\n\u001b[0m\u001b[1;32m     80\u001b[0m         rational_interpolate, viete)\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/polys/polyfuncs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyoptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mallowed_flags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolytools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpoly_from_expr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPoly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m from sympy.polys.specialpolys import (\n\u001b[0m\u001b[1;32m     11\u001b[0m     symmetric_poly, interpolating_poly)\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/polys/specialpolys.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;31m# A few useful polynomials from Wang's paper ('78).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_f_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/polys/rings.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m from sympy.polys.polyutils import (expr_from_dict, _dict_reorder,\n\u001b[1;32m     29\u001b[0m                                    _parallel_dict_from_expr)\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDefaultPrinting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpublic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/printing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpython\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpycode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcodeprinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_ccode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_fcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/printing/pycode.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprecedence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecedence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcodeprinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCodePrinter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m _kw = {\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/printing/codeprinter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefault_sort_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbol\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melementary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplexes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStrPrinter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecedence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecedence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPRECEDENCE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/functions/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mconjugate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolar_lift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiodic_argument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munbranched_argument\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         principal_branch, transpose, adjoint, polarify, unpolarify)\n\u001b[0;32m---> 19\u001b[0;31m from sympy.functions.elementary.trigonometric import (sin, cos, tan,\n\u001b[0m\u001b[1;32m     20\u001b[0m         sec, csc, cot, sinc, asin, acos, atan, asec, acsc, acot, atan2)\n\u001b[1;32m     21\u001b[0m from sympy.functions.elementary.exponential import (exp_polar, exp, log,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "from omegaconf import OmegaConf\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "import logging\n",
        "\n",
        "# ログの設定\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    handlers=[\n",
        "        logging.StreamHandler(sys.stdout)\n",
        "    ]\n",
        ")\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# from config import Config\n",
        "# from lexa import LEXA\n",
        "# from envs.franka_kitchen import FrankaKichenEnv\n",
        "# from replay_buffer import ReplayBuffer\n",
        "# from utils import fix_seed, preprocess_obs\n",
        "\n",
        "base_path = \"/output\"\n",
        "\n",
        "config_dict = {\n",
        "    'model': {\n",
        "        'world_model': {\n",
        "            'emb_dim': 1024,\n",
        "            'z_dim': 32,\n",
        "            'num_classes': 32,\n",
        "            'h_dim': 600,\n",
        "            'hidden_dim': 600,\n",
        "            'num_layers_za2hidden': 1,\n",
        "            'num_layers_h2z': 1,\n",
        "            'mlp_hidden_dim': 400,\n",
        "            'min_std': 0.1,\n",
        "            'kl_balance_alpha': 0.8,\n",
        "            'kl_loss_scale': 0.1,\n",
        "        },\n",
        "        'explorer': {\n",
        "            'num_emsembles': 10,\n",
        "            'emsembles_offset': 1,\n",
        "            'emsembles_target_mode': 'z',\n",
        "            'mlp_hidden_dim': 400,\n",
        "            'min_std': 0.1,\n",
        "            'discount': 0.99,\n",
        "            'lambda_': 0.95,\n",
        "            'actor_entropy_scale': 0.0001,\n",
        "            'slow_critic_update': 100,\n",
        "        },\n",
        "        'achiever': {\n",
        "            'num_positives': 256,\n",
        "            'neg_sampling_factor': 0.1,\n",
        "            'mlp_hidden_dim': 400,\n",
        "            'min_std': 0.1,\n",
        "            'discount': 0.99,\n",
        "            'lambda_': 0.95,\n",
        "            'actor_entropy_scale': 0.0001,\n",
        "            'slow_critic_update': 100,\n",
        "        }\n",
        "    },\n",
        "    'env': {\n",
        "        'task': 'FrankaKitchen-v1',\n",
        "        'img_size': 128,\n",
        "        'action_repeat': 2,\n",
        "        'time_limit': 1000,\n",
        "    },\n",
        "    'data': {\n",
        "        'buffer_size': 200,\n",
        "        'batch_size': 50,\n",
        "        'seq_length': 50,\n",
        "        'imagination_horizon': 15,\n",
        "    },\n",
        "    'learning': {\n",
        "        'seed_steps': 5000,\n",
        "        'num_steps': 200,\n",
        "        'expl_episode_freq': 2,\n",
        "        'world_model_lr': 0.0002,\n",
        "        'explorer_actor_lr': 0.00004,\n",
        "        'explorer_critic_lr': 0.0001,\n",
        "        'achiever_actor_lr': 0.00004,\n",
        "        'achiever_critic_lr': 0.0001,\n",
        "        'epsilon': 0.00001,\n",
        "        'weight_decay': 0.000001,\n",
        "        'grad_clip': 100,\n",
        "        'update_freq': 4,\n",
        "        'eval_episode_freq': 5,\n",
        "    },\n",
        "    'wandb': {\n",
        "        'logging': False,\n",
        "        'name': 'lexa',\n",
        "        'group': '',\n",
        "        'project': 'LEXA',\n",
        "    },\n",
        "    'device': 'cuda',\n",
        "    'seed': 0,\n",
        "}\n",
        "\n",
        "def main(cfg):\n",
        "    logger.info(\"Initializing configuration and environment...\")\n",
        "    cfg = Config(**cfg)\n",
        "    fix_seed(cfg.seed)\n",
        "\n",
        "    # env = FrankaKichenEnv(cfg.env.img_size, cfg.env.action_repeat, cfg.env.time_limit, cfg.seed)\n",
        "    # eval_env = FrankaKichenEnv(cfg.env.img_size, cfg.env.action_repeat, cfg.env.time_limit, cfg.seed)\n",
        "\n",
        "\n",
        "    env = AntMazeEnv(maze_type='UMaze', maze_map=custom_map, max_episode_steps=1000, seed=42)\n",
        "    eval_env = AntMazeEnv(maze_type='UMaze', maze_map=custom_map, max_episode_steps=1000, seed=42)\n",
        "\n",
        "    logger.info(\"Environment initialized. Setting up LEXA and replay buffer...\")\n",
        "    lexa = LEXA(cfg, env)\n",
        "    replay_buffer = ReplayBuffer(cfg.data.buffer_size,\n",
        "                                 (3, cfg.env.img_size, cfg.env.img_size),\n",
        "                                 env.action_space.shape[0])\n",
        "\n",
        "    obs = env.reset()\n",
        "    logger.info(\"Starting seed steps...\")\n",
        "\n",
        "    # seed steps\n",
        "    for step in range(cfg.learning.seed_steps):\n",
        "        action = env.action_space.sample()\n",
        "        next_obs, reward, done, info = env.step(action)\n",
        "        print(\"Original obs shape:\", obs.shape, \"dtype:\", obs.dtype, \"min:\", obs.min(), \"max:\", obs.max())\n",
        "\n",
        "\n",
        "        # 画像を表示 (必要に応じて一定間隔で表示)\n",
        "\n",
        "        if step % 1000 == 0:\n",
        "            plt.figure(figsize=(6, 6))\n",
        "            plt.imshow(obs)\n",
        "            plt.title(\"Original Observation\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "\n",
        "        replay_buffer.push(preprocess_obs(obs), action, done)\n",
        "        obs = next_obs\n",
        "        if done:\n",
        "            obs = env.reset()\n",
        "        if step % 1000 == 0:\n",
        "            logger.info(f\"Completed {step} seed steps.\")\n",
        "\n",
        "    logger.info(\"Seed steps completed. Starting learning steps...\")\n",
        "\n",
        "    # learning steps\n",
        "    obs = env.reset()\n",
        "    goal = None\n",
        "    episodes = 0\n",
        "    best_score = -1\n",
        "    for step in tqdm(range(cfg.learning.num_steps)):\n",
        "        with torch.no_grad():\n",
        "            if episodes % cfg.learning.expl_episode_freq == 0:\n",
        "                mode = 'explorer'\n",
        "            else:\n",
        "                mode = 'achiever'\n",
        "\n",
        "            action = lexa.agent(preprocess_obs(obs), mode, goal)\n",
        "            next_obs, reward, done, info = env.step(action)\n",
        "            replay_buffer.push(preprocess_obs(obs), action, done)\n",
        "            obs = next_obs\n",
        "\n",
        "        if (step + 1) % cfg.learning.update_freq:\n",
        "            logger.debug(\"Updating model...\")\n",
        "            observations, actions, done_flags = replay_buffer.sample(cfg.data.batch_size, cfg.data.seq_length)\n",
        "            metrics = lexa.train(observations, actions)\n",
        "\n",
        "        if (step + 1) % cfg.model.explorer.slow_critic_update:\n",
        "            lexa.explorer.update_critic()\n",
        "        if (step + 1) % cfg.model.achiever.slow_critic_update:\n",
        "            lexa.achiever.update_critic()\n",
        "\n",
        "        if done:\n",
        "            logger.info(f\"Steps: {step + 1}, Episode: {episodes}, Metrics: {metrics}\")\n",
        "            lexa.save(base_path / cfg.wandb.name / f'{step + 1}')\n",
        "            episodes += 1\n",
        "            obs = env.reset()\n",
        "            lexa.agent.reset()\n",
        "            goal, _, _ = replay_buffer.sample(1, 1)\n",
        "            goal = goal.squeeze(1)\n",
        "            if episodes % cfg.learning.eval_episode_freq:\n",
        "                logger.info(\"Evaluating agent...\")\n",
        "                with torch.no_grad():\n",
        "                    success = 0\n",
        "                    for goal_idx in eval_env.goals:\n",
        "                        eval_obs = eval_env.reset()\n",
        "                        eval_env.set_goal_idx(goal_idx)\n",
        "                        goal_obs = eval_env.get_goal_obs()\n",
        "                        eval_done = False\n",
        "                        while not eval_done:\n",
        "                            eval_action = lexa.agent(preprocess_obs(eval_obs), 'achiever', preprocess_obs(goal_obs), train=False)\n",
        "                            eval_obs, eval_reward, eval_done, eval_info = eval_env.step(eval_action)\n",
        "                        if eval_env.compute_success():\n",
        "                            success += 1\n",
        "                    score = success / len(eval_env.goals)\n",
        "                logger.info(f\"Steps: {step + 1}, Episode: {episodes}, Eval Score: {score}\")\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    lexa.save(base_path / cfg.wandb.name / 'best')\n",
        "                lexa.agent.reset()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    logger.info(\"Starting training script...\")\n",
        "    cfg = OmegaConf.create(config_dict)\n",
        "    main(cfg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7UVWpXG5fnB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJbv8u18xmXZ"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6K--s3DAoue"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qvZKvDvDYXq"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_CQDERZkihC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "lexa-kT-BTxXM",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
