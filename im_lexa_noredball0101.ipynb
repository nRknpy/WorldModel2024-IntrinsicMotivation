{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLyThA97hKdQ",
        "outputId": "64ab8c15-9ff6-4fdf-a832-ab1312c3ded7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Google Driveのマウント\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive') # , force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install omegaconf\n",
        "# !pip install gymnasium\n",
        "!pip install gymnasium-robotics\n",
        "# !pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaRyWHkMi1j5",
        "outputId": "f1f58231-6127-4e0e-b5b8-28acdbff4e27"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0.2)\n",
            "Collecting gymnasium-robotics\n",
            "  Using cached gymnasium_robotics-1.3.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting mujoco<3.2.0,>=2.2.0 (from gymnasium-robotics)\n",
            "  Using cached mujoco-3.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium-robotics) (1.26.4)\n",
            "Collecting gymnasium>=1.0.0 (from gymnasium-robotics)\n",
            "  Using cached gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting PettingZoo>=1.23.0 (from gymnasium-robotics)\n",
            "  Using cached pettingzoo-1.24.3-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: Jinja2>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium-robotics) (3.1.4)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from gymnasium-robotics) (2.36.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0->gymnasium-robotics) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0->gymnasium-robotics) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium>=1.0.0->gymnasium-robotics)\n",
            "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0.3->gymnasium-robotics) (3.0.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.10/dist-packages (from mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (1.11.0)\n",
            "Collecting glfw (from mujoco<3.2.0,>=2.2.0->gymnasium-robotics)\n",
            "  Downloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (3.1.7)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio->gymnasium-robotics) (11.0.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (6.4.5)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (3.21.0)\n",
            "Downloading gymnasium_robotics-1.3.1-py3-none-any.whl (26.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.1/26.1 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mujoco-3.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pettingzoo-1.24.3-py3-none-any.whl (847 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m847.8/847.8 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: glfw, farama-notifications, gymnasium, PettingZoo, mujoco, gymnasium-robotics\n",
            "Successfully installed PettingZoo-1.24.3 farama-notifications-0.0.4 glfw-2.8.0 gymnasium-1.0.0 gymnasium-robotics-1.3.1 mujoco-3.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#config.py\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class WorldModelConfig:\n",
        "    emb_dim: int = 1024\n",
        "    z_dim: int = 32\n",
        "    num_classes: int = 32\n",
        "    h_dim: int = 600\n",
        "    hidden_dim: int = 600\n",
        "    num_layers_za2hidden: int = 1\n",
        "    num_layers_h2z: int = 1\n",
        "    mlp_hidden_dim: int = 400\n",
        "    min_std: float = 0.1\n",
        "    kl_balance_alpha: float = 0.8\n",
        "    kl_loss_scale: float = 0.1\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ExplorerConfig:\n",
        "    num_emsembles: int = 10\n",
        "    emsembles_offset: int = 1\n",
        "    emsembles_target_mode: str = 'z'\n",
        "    mlp_hidden_dim: int = 400\n",
        "    min_std: float = 0.1\n",
        "    discount: float = 0.99\n",
        "    lambda_: float = 0.95\n",
        "    actor_entropy_scale: float = 1e-4\n",
        "    slow_critic_update: int = 100\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class AchieverConfig:\n",
        "    num_positives: int = 256\n",
        "    neg_sampling_factor: int = 0.1\n",
        "    mlp_hidden_dim: int = 400\n",
        "    min_std: float = 0.1\n",
        "    discount: float = 0.99\n",
        "    lambda_: float = 0.95\n",
        "    actor_entropy_scale: float = 1e-4\n",
        "    slow_critic_update: int = 100\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LEXAModelConfig:\n",
        "    world_model: WorldModelConfig = WorldModelConfig()\n",
        "    explorer: ExplorerConfig = ExplorerConfig()\n",
        "    achiever: AchieverConfig = AchieverConfig()\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataConfig:\n",
        "    buffer_size: int = 2e6\n",
        "    batch_size: int = 50\n",
        "    seq_length: int = 50\n",
        "    imagination_horizon: int = 15\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LearningConfig:\n",
        "    seed_steps: int = 5000\n",
        "    num_steps: int = 1e7\n",
        "    expl_episode_freq: int = 2\n",
        "    world_model_lr: float = 2e-4\n",
        "    explorer_actor_lr: float = 4e-5\n",
        "    explorer_critic_lr: float = 1e-4\n",
        "    achiever_actor_lr: float = 4e-5\n",
        "    achiever_critic_lr: float = 1e-4\n",
        "    epsilon: float = 1e-5\n",
        "    weight_decay: float = 1e-6\n",
        "    grad_clip: float = 100\n",
        "    update_freq: int = 4\n",
        "    eval_episode_freq: int = 5\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class EnvConfig:\n",
        "    task: str = 'FrankaKitchen-v1'\n",
        "    img_size: int = 128\n",
        "    action_repeat: int = 2\n",
        "    time_limit: int = 1000\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class WandbConfig:\n",
        "    logging: bool = False\n",
        "    name: str = 'lexa'\n",
        "    group: str = ''\n",
        "    project: str = 'LEXA'\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    model: LEXAModelConfig = LEXAModelConfig()\n",
        "    env: EnvConfig = EnvConfig()\n",
        "    data: DataConfig = DataConfig()\n",
        "    learning: LearningConfig = LearningConfig()\n",
        "    wandb: WandbConfig = WandbConfig()\n",
        "    device: str = 'cuda'\n",
        "    seed: int = 0\n"
      ],
      "metadata": {
        "id": "Qjs3Dlf0lRVc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tCemWxTHrtJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model"
      ],
      "metadata": {
        "id": "dtaG_0HVnFcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model.utils.py\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.distributions as td\n",
        "from torch.distributions.utils import _standard_normal\n",
        "from einops import rearrange\n",
        "\n",
        "\n",
        "class TruncatedNormal(td.Normal):\n",
        "    def __init__(self, loc: torch.Tensor, scale: torch.Tensor, low: float = -1.0, high: float = 1.0, eps: float = 1e-6) -> None:\n",
        "        super().__init__(loc, scale, validate_args=False)\n",
        "        self.low = low\n",
        "        self.high = high\n",
        "        self.eps = eps\n",
        "\n",
        "    def _clamp(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        clamped_x = torch.clamp(x, self.low + self.eps, self.high - self.eps)\n",
        "        x = x - x.detach() + clamped_x.detach()\n",
        "        return x\n",
        "\n",
        "    def sample(self, clip: float | None = None, sample_shape: torch.Size = torch.Size()) -> torch.Tensor:\n",
        "        shape = self._extended_shape(sample_shape)\n",
        "        eps = _standard_normal(shape, dtype=self.loc.dtype, device=self.loc.device)\n",
        "\n",
        "        eps *= self.scale\n",
        "        if clip is not None:\n",
        "            eps = torch.clamp(eps, -clip, clip)\n",
        "        x = self.loc + eps\n",
        "        return self._clamp(x)\n",
        "\n",
        "\n",
        "def compute_lambda_target(rewards: torch.Tensor, discount: float, values: torch.Tensor, lambda_: float):\n",
        "    V_lambda = torch.zeros_like(rewards)\n",
        "\n",
        "    for t in reversed(range(rewards.shape[0])):\n",
        "        if t == rewards.shape[0] - 1:\n",
        "            V_lambda[t] = rewards[t] + discount * values[t]\n",
        "        else:\n",
        "            V_lambda[t] = rewards[t] + discount * ((1-lambda_) * values[t+1] + lambda_ * V_lambda[t+1])\n",
        "\n",
        "    return V_lambda\n"
      ],
      "metadata": {
        "id": "enlGlMzrnZkb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#network.py\n",
        "\n",
        "from typing import Literal\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Normal, OneHotCategoricalStraightThrough, Independent, Bernoulli\n",
        "\n",
        "# from .utils import TruncatedNormal\n",
        "\n",
        "\n",
        "class RSSM(nn.Module):\n",
        "    def __init__(self,\n",
        "                 z_dim=30,\n",
        "                 num_classes=20,\n",
        "                 h_dim=200,\n",
        "                 hidden_dim=200,\n",
        "                 emb_dim=32,\n",
        "                 action_dim=9,\n",
        "                 num_layers_za2hidden=1,\n",
        "                 num_layers_h2z=1,\n",
        "                 min_std=0.1):\n",
        "        super(RSSM, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.h_dim = h_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.num_layers_za2hidden = num_layers_za2hidden\n",
        "        self.num_layers_h2z = num_layers_h2z\n",
        "        self.num_classes = num_classes\n",
        "        self.min_std = min_std\n",
        "\n",
        "        self.za2hidden = nn.Sequential(\n",
        "            *([nn.Sequential(nn.Linear(self.z_dim + self.action_dim, self.hidden_dim), nn.ELU())] + \\\n",
        "            [nn.Sequential(nn.Linear(self.hidden_dim, self.hidden_dim), nn.ELU()) for _ in range(self.num_layers_za2hidden - 1)])\n",
        "        )\n",
        "        self.transition = nn.GRUCell(self.hidden_dim, self.h_dim)\n",
        "\n",
        "        self.prior_hidden = nn.Sequential(\n",
        "            *([nn.Sequential(nn.Linear(self.h_dim, self.hidden_dim), nn.ELU())] + \\\n",
        "            [nn.Sequential(nn.Linear(self.hidden_dim, self.hidden_dim), nn.ELU()) for _ in range(self.num_layers_h2z - 1)])\n",
        "        )\n",
        "        self.prior_logits = nn.Linear(self.hidden_dim, self.z_dim * self.num_classes)\n",
        "\n",
        "        self.posterior_hidden = nn.Sequential(\n",
        "            *([nn.Sequential(nn.Linear(self.h_dim + self.emb_dim, self.hidden_dim), nn.ELU())] + \\\n",
        "            [nn.Sequential(nn.Linear(self.hidden_dim, self.hidden_dim), nn.ELU()) for _ in range(self.num_layers_h2z - 1)])\n",
        "        )\n",
        "        self.posterior_logits = nn.Linear(self.hidden_dim, self.z_dim * self.num_classes)\n",
        "\n",
        "    def recurrent(self, z, action, h):\n",
        "        hidden = self.za2hidden(torch.concat([z, action], dim=1))\n",
        "        next_h = self.transition(hidden, h)\n",
        "        return next_h\n",
        "\n",
        "    def prior(self, h, detach=False):\n",
        "        hidden = self.prior_hidden(h)\n",
        "        logits = self.prior_logits(hidden)\n",
        "        logits = logits.reshape(logits.shape[0], self.z_dim, self.num_classes)\n",
        "        prior = Independent(OneHotCategoricalStraightThrough(logits=logits), 1)\n",
        "        if detach:\n",
        "            detach_prior = Independent(OneHotCategoricalStraightThrough(logits=logits.detach()), 1)\n",
        "            return prior, detach_prior\n",
        "        return prior\n",
        "\n",
        "    def posterior(self, h, emb, detach=False):\n",
        "        hidden = self.posterior_hidden(torch.concat([h, emb], dim=1))\n",
        "        logits = self.posterior_logits(hidden)\n",
        "        logits = logits.reshape(logits.shape[0], self.z_dim, self.num_classes)\n",
        "        posterior = Independent(OneHotCategoricalStraightThrough(logits=logits), 1)\n",
        "        if detach:\n",
        "            detach_posterior = Independent(OneHotCategoricalStraightThrough(logits=logits.detach()), 1)\n",
        "            return posterior, detach_posterior\n",
        "        return posterior\n",
        "\n",
        "\n",
        "class ConvEncoder(nn.Module):\n",
        "    def __init__(self, input_size, emb_dim):\n",
        "        super(ConvEncoder, self).__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LayerNorm([32, input_size // 2, input_size // 2]),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LayerNorm([64, input_size // 4, input_size // 4]),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LayerNorm([128, input_size // 8, input_size // 8]),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LayerNorm([256, input_size // 16, input_size // 16]),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear((input_size // 16) ** 2 * 256 , emb_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvDecoder(nn.Module):\n",
        "    def __init__(self, img_size, z_dim, num_classes, h_dim):\n",
        "        super(ConvDecoder, self).__init__()\n",
        "\n",
        "        self.img_size = img_size\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(z_dim * num_classes + h_dim, (img_size // 16) ** 2 * 256),\n",
        "            nn.LayerNorm([(img_size // 16) ** 2 * 256,]),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.LayerNorm([128, img_size // 8, img_size // 8]),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.LayerNorm([64, img_size // 4, img_size // 4]),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.LayerNorm([32, img_size // 2, img_size // 2]),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, z, h):\n",
        "        x = torch.concat([z, h], dim=1)\n",
        "        out = self.fc(x)\n",
        "        out = out.reshape(out.shape[0], 256, self.img_size // 16, self.img_size // 16)\n",
        "        out = self.net(out)\n",
        "        dist = Independent(Normal(out, 1), 3)\n",
        "        return dist\n",
        "\n",
        "\n",
        "class Discount(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, h_dim, hidden_dim=256):\n",
        "        super(Discount, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(z_dim * num_classes + h_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, z, h):\n",
        "        logits = self.net(torch.concat([z, h], dim=1))\n",
        "        dist = Independent(Bernoulli(logits=logits), 1)\n",
        "        return dist\n",
        "\n",
        "\n",
        "class ExprolerStatePredictor(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, h_dim, target_dim, min_std, hidden_dim=256):\n",
        "        super(ExprolerStatePredictor, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.min_std = min_std\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.target_dim = target_dim\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(z_dim * num_classes + h_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.mean_fc = nn.Linear(hidden_dim, target_dim)\n",
        "        self.std_fc = nn.Linear(hidden_dim, target_dim)\n",
        "\n",
        "    def forward(self, z, h):\n",
        "        h = self.net(torch.concat([z, h], dim=1))\n",
        "        mean = self.mean_fc(h)\n",
        "        std = self.std_fc(h) + self.min_std\n",
        "        return Independent(Normal(mean, std), 1)\n",
        "\n",
        "\n",
        "class ExplorerActor(nn.Module):\n",
        "    def __init__(self, action_dim, z_dim, num_classes, h_dim, hidden_dim=256, min_std=0.1):\n",
        "        super(ExplorerActor, self).__init__()\n",
        "\n",
        "        self.action_dim = action_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.min_std = min_std\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(z_dim * num_classes + h_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.mean_fc = nn.Linear(hidden_dim, action_dim)\n",
        "        self.std_fc = nn.Linear(hidden_dim, action_dim)\n",
        "\n",
        "    def forward(self, z, h, train=True):\n",
        "        h = self.net(torch.concat([z, h], dim=1))\n",
        "        mean = F.tanh(self.mean_fc(h))\n",
        "        std = 2 * F.sigmoid(self.std_fc(h) / 2) + self.min_std\n",
        "        dist = Independent(TruncatedNormal(mean, std, -1, 1), 1)\n",
        "        if train:\n",
        "            action = dist.rsample()\n",
        "            log_prob = dist.log_prob(action.detach())\n",
        "            entropy = dist.entropy()\n",
        "            return action, log_prob, entropy\n",
        "        else:\n",
        "            action = dist.mean\n",
        "            return action, None, None\n",
        "\n",
        "\n",
        "class ExplorerCritic(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, h_dim, hidden_dim=256):\n",
        "        super(ExplorerCritic, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(z_dim * num_classes + h_dim, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, z, h):\n",
        "        return self.net(torch.concat([z, h]), dim=1)\n",
        "\n",
        "\n",
        "class State2Emb(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, h_dim, emb_dim, hidden_dim=256):\n",
        "        super(State2Emb, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(z_dim * num_classes + h_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.mean_fc = nn.Linear(hidden_dim, emb_dim)\n",
        "        self.std_fc = nn.Linear(hidden_dim, emb_dim)\n",
        "\n",
        "    def forward(self, z, h):\n",
        "        h = self.net(torch.concat([z, h], dim=1))\n",
        "        mean = self.mean_fc(h)\n",
        "        std = self.std_fc(h)\n",
        "        return Independent(Normal(mean, std), 1)\n",
        "\n",
        "\n",
        "class AchieverDistanceEstimator(nn.Module):\n",
        "    def __init__(self, emb_dim, hidden_dim=256):\n",
        "        super(AchieverDistanceEstimator, self).__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.state2emb = nn\n",
        "\n",
        "        self.current_fc = nn.Sequential(nn.Linear(emb_dim, hidden_dim),\n",
        "                                        nn.GELU())\n",
        "        self.goal_fc = nn.Sequential(nn.Linear(emb_dim, hidden_dim),\n",
        "                                     nn.GELU())\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, current_emb, goal_emb):\n",
        "        cur_h = self.current_fc(current_emb)\n",
        "        goal_h = self.goal_fc(goal_emb)\n",
        "        return self.net(torch.concat([cur_h, goal_h]), dim=1)\n",
        "\n",
        "\n",
        "class AchieverCritic(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, h_dim, emb_dim, hidden_dim=256):\n",
        "        super(AchieverCritic, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.state_fc = nn.Sequential(nn.Linear(z_dim * num_classes + h_dim, hidden_dim),\n",
        "                                      nn.GELU())\n",
        "        self.goal_fc = nn.Sequential(nn.Linear(emb_dim, hidden_dim),\n",
        "                                     nn.GELU())\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, z, h, goal_emb):\n",
        "        state_h = self.state_fc(torch.concat([z, h]), dim=1)\n",
        "        goal_h = self.goal_fc(goal_emb)\n",
        "        return self.net(torch.concat([state_h, goal_h]), dim=1)\n",
        "\n",
        "\n",
        "class AchieverActor(nn.Module):\n",
        "    def __init__(self, action_dim, z_dim, num_classes, h_dim, emb_dim, hidden_dim=256, min_std=0.1):\n",
        "        super(AchieverActor, self).__init__()\n",
        "\n",
        "        self.action_dim = action_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.min_std = min_std\n",
        "\n",
        "        self.state_fc = nn.Sequential(nn.Linear(z_dim * num_classes + h_dim, hidden_dim),\n",
        "                                      nn.GELU())\n",
        "        self.goal_fc = nn.Sequential(nn.Linear(emb_dim, hidden_dim),\n",
        "                                     nn.GELU())\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.mean_fc = nn.Linear(hidden_dim, action_dim)\n",
        "        self.std_fc = nn.Linear(hidden_dim, action_dim)\n",
        "\n",
        "    def forward(self, z, h, goal_emb, train=True):\n",
        "        state_h = self.state_fc(torch.concat([z, h], dim=1))\n",
        "        goal_h = self.goal_fc(goal_emb)\n",
        "        h = self.net(torch.concat([state_h, goal_h], dim=1))\n",
        "        mean = F.tanh(self.mean_fc(h))\n",
        "        std = 2 * F.sigmoid(self.std_fc(h) / 2) + self.min_std\n",
        "        dist = Independent(TruncatedNormal(mean, std, -1, 1), 1)\n",
        "        if train:\n",
        "            action = dist.rsample()\n",
        "            log_prob = dist.log_prob(action.detach())\n",
        "            entropy = dist.entropy()\n",
        "            return action, log_prob, entropy\n",
        "        else:\n",
        "            action = dist.mean\n",
        "        return action, None, None\n"
      ],
      "metadata": {
        "id": "zZkXKZ49nTUH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#worldmodel.py\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import kl_divergence\n",
        "from einops import rearrange\n",
        "\n",
        "# from .network import RSSM, ConvEncoder, ConvDecoder, Discount\n",
        "\n",
        "\n",
        "class WorldModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 img_size,\n",
        "                 emb_dim,\n",
        "                 action_dim,\n",
        "                 z_dim,\n",
        "                 num_classes,\n",
        "                 h_dim,\n",
        "                 hidden_dim,\n",
        "                 num_layers_za2hidden,\n",
        "                 num_layers_h2z,\n",
        "                 mlp_hidden_dim,\n",
        "                 min_std,\n",
        "                 kl_balance_alpha,\n",
        "                 kl_loss_scale,\n",
        "                 device):\n",
        "        super(WorldModel, self).__init__()\n",
        "\n",
        "        self.img_size = img_size\n",
        "        self.action_dim = action_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_layers_za2hidden = num_layers_za2hidden\n",
        "        self.num_layers_h2z = num_layers_h2z\n",
        "        self.mlp_hidden_dim = mlp_hidden_dim\n",
        "        self.min_std = min_std\n",
        "        self.kl_balance_alpha = kl_balance_alpha\n",
        "        self.kl_loss_scale = kl_loss_scale\n",
        "        self.device = device\n",
        "\n",
        "        self.rssm = RSSM(\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            hidden_dim = hidden_dim,\n",
        "            emb_dim = emb_dim,\n",
        "            action_dim = action_dim,\n",
        "            num_layers_za2hidden = num_layers_za2hidden,\n",
        "            num_layers_h2z = num_layers_h2z,\n",
        "            min_std = min_std\n",
        "        )\n",
        "        self.encoder = ConvEncoder(\n",
        "            input_size = img_size,\n",
        "            emb_dim = emb_dim\n",
        "        )\n",
        "        self.decoder = ConvDecoder(\n",
        "            img_size = img_size,\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim\n",
        "        )\n",
        "\n",
        "    def train(self, observations, actions):\n",
        "        batch_size, seq_length, *_ = observations.shape\n",
        "        observations = rearrange(observations, 'b t c h w -> t b c h w')\n",
        "        actions = rearrange(actions, 'b t d -> t b d')\n",
        "\n",
        "        embs = self.encoder(rearrange(observations, 't b c h w -> (t b) c h w'))\n",
        "        embs = rearrange(embs, '(t b) d -> t b d')\n",
        "\n",
        "        z = torch.zeros(batch_size, self.z_dim*self.num_classes, device=self.device)\n",
        "        h = torch.zeros(batch_size, self.h_dim, device=self.device)\n",
        "\n",
        "        zs = torch.empty(seq_length - 1, batch_size, self.z_dim*self.num_classes, device=self.device)\n",
        "        hs = torch.empty(seq_length - 1, batch_size, self.h_dim, device=self.device)\n",
        "\n",
        "        kl_loss = 0\n",
        "        for t in range(seq_length - 1):\n",
        "            h = self.rssm.recurrent(z, actions[t], h)\n",
        "            next_prior, detach_next_prior = self.rssm.prior(h, detach=True)\n",
        "            next_posterior, detach_next_posterior = self.rssm.posterior(h, embs[t+1], detach=True)\n",
        "            z = next_posterior.rsample().flatten(1)\n",
        "            hs[t] = h\n",
        "            zs[t] = z\n",
        "            kl_loss += self.kl_balance_alpha * torch.mean(kl_divergence(detach_next_posterior, next_prior)) + \\\n",
        "                       (1 - self.kl_balance_alpha) * torch.mean(kl_divergence(next_posterior, detach_next_prior))\n",
        "        kl_loss = kl_loss / (seq_length - 1)\n",
        "\n",
        "        flatten_hs = hs.view(-1, self.h_dim)\n",
        "        flatten_zs = zs.view(-1, self.z_dim * self.num_classes)\n",
        "\n",
        "        obs_dist = self.decoder(flatten_zs, flatten_hs)\n",
        "\n",
        "        obs_loss = -torch.mean(obs_dist.log_prob(rearrange(observations[1:], 't b c h w -> (t b) c h w')))\n",
        "\n",
        "        wm_loss = obs_loss + self.kl_loss_scale * kl_loss\n",
        "        return wm_loss, (zs, hs), OrderedDict(wm_loss=wm_loss.item(), obs_loss=obs_loss.item(), kl_loss=kl_loss.item())\n",
        "\n",
        "    def imagine(self, action, z, h):\n",
        "        next_h = self.rssm.recurrent(z, action, h)\n",
        "        next_prior = self.rssm.prior(next_h)\n",
        "        next_z = next_prior.rsample().flatten(1)\n",
        "        return next_h, next_z\n"
      ],
      "metadata": {
        "id": "dygRTxcYn3Nu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#achiever_reward.py\n",
        "\n",
        "from typing import Literal\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange\n",
        "\n",
        "# from .network import AchieverDistanceEstimator, State2Emb\n",
        "\n",
        "\n",
        "class LatentDistanceReward(nn.Module):\n",
        "    def __init__(self,\n",
        "                 z_dim,\n",
        "                 num_classes,\n",
        "                 h_dim,\n",
        "                 emb_dim,\n",
        "                 mlp_hidden_dim,\n",
        "                 device):\n",
        "        super(LatentDistanceReward, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.mlp_hidden_dim = mlp_hidden_dim\n",
        "        self.device = device\n",
        "\n",
        "        self.state2emb = State2Emb(\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            emb_dim = emb_dim,\n",
        "            hidden_dim = mlp_hidden_dim\n",
        "        )\n",
        "\n",
        "        self.distance_estimator = AchieverDistanceEstimator(\n",
        "            emb_dim = emb_dim,\n",
        "            hidden_dim = mlp_hidden_dim\n",
        "        )\n",
        "\n",
        "    def imagine_compute_reward(self, current_z, current_h, goal_z, goal_h):\n",
        "        current_emb = self.state2emb(current_z, current_h)\n",
        "        goal_emb = self.state2emb(goal_z, goal_h)\n",
        "        distance = self.distance_estimator(current_emb, goal_emb)\n",
        "        return -distance\n",
        "\n",
        "    def compute_reward(self, z, h, goal_emb):\n",
        "        current_emb = self.state2emb(z, h)\n",
        "        distance = self.distance_estimator(current_emb, goal_emb)\n",
        "        return -distance\n",
        "\n",
        "    def train_state2emb(self, zs, hs, target_embs):\n",
        "        embs_dist = self.state2emb(zs, hs)\n",
        "        loss = -torch.mean(embs_dist.log_prob(target_embs))\n",
        "        return loss\n",
        "\n",
        "    def train_distance_estimator(self, zs, hs, num_positives, neg_sampling_factor, batch_length):\n",
        "        def get_future_goal_idxs(seq_len, bs):\n",
        "            cur_idx_list = []\n",
        "            goal_idx_list = []\n",
        "            for cur_idx in range(seq_len):\n",
        "                for goal_idx in range(cur_idx, seq_len):\n",
        "                    cur_idx_list.append(np.concatenate([np.ones((bs,1), dtype=np.int32)*cur_idx, np.arange(bs).reshape(-1,1)], axis = -1))\n",
        "                    goal_idx_list.append(np.concatenate([np.ones((bs,1), dtype=np.int32)*goal_idx, np.arange(bs).reshape(-1,1)], axis = -1))\n",
        "\n",
        "            return np.concatenate(cur_idx_list,0), np.concatenate(goal_idx_list,0)\n",
        "\n",
        "        def get_future_goal_idxs_neg_sampling(num_negs, seq_len, bs):\n",
        "            cur_idxs = np.random.randint((0,0), (seq_len, bs), size=(num_negs,2))\n",
        "            goal_idxs = np.random.randint((0,0), (seq_len, bs), size=(num_negs,2))\n",
        "            for i in range(num_negs):\n",
        "                goal_idxs[i,1] = np.random.choice([j for j in range(bs) if j//batch_length != cur_idxs[i,1]//batch_length])\n",
        "            return cur_idxs, goal_idxs\n",
        "\n",
        "        zs, hs = zs.detach(), hs.detach()\n",
        "\n",
        "        current_idxs, goal_idxs = get_future_goal_idxs(zs.shape[0], zs.shape[1])\n",
        "        idx = np.random.choice(np.arange(len(current_idxs)), num_positives, replace=False)\n",
        "        current_idx, goal_idx = current_idxs[idx], goal_idxs[idx]\n",
        "        current_zs, current_hs = zs[current_idx[:,0], current_idx[:,1]], hs[current_idx[:,0], current_idx[:,1]]\n",
        "        goal_zs, goal_hs = zs[goal_idx[:,0], goal_idx[:,1]], hs[goal_idx[:,0], goal_idx[:,1]]\n",
        "        current_embs, goal_embs = self.state2emb(current_zs, current_hs).mean, self.state2emb(goal_zs, goal_hs).mean\n",
        "        target_distance = (goal_idx[:,0] - current_idx[:,0]) / zs.shape[0]\n",
        "        pred_distance = self.distance_estimator(current_embs, goal_embs)\n",
        "        loss = F.mse_loss(pred_distance, target_distance)\n",
        "\n",
        "        num_negatives = num_positives * neg_sampling_factor\n",
        "        current_idx, goal_idx = get_future_goal_idxs_neg_sampling(num_negatives, zs.shape[0], zs.shape[1])\n",
        "        current_zs, current_hs = zs[current_idx[:,0], current_idx[:,1]], hs[current_idx[:,0], current_idx[:,1]]\n",
        "        goal_zs, goal_hs = zs[goal_idx[:,0], goal_idx[:,1]], hs[goal_idx[:,0], goal_idx[:,1]]\n",
        "        current_embs, goal_embs = self.state2emb(current_zs, current_hs).mean, self.state2emb(goal_zs, goal_hs).mean\n",
        "        target_distance = torch.ones(num_negatives, 1, device=self.device) * zs.shape[0]\n",
        "        pred_distance = self.distance_estimator(current_embs, goal_embs)\n",
        "        loss += F.mse_loss(pred_distance, target_distance)\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "w2NJDBCWnL3o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#achiever.py\n",
        "\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.distributions as td\n",
        "from einops import rearrange\n",
        "\n",
        "# from .network import AchieverActor, AchieverCritic\n",
        "# from .worldmodel import WorldModel\n",
        "# from .achiever_reward import LatentDistanceReward\n",
        "# from .utils import compute_lambda_target\n",
        "\n",
        "\n",
        "class Achiever(nn.Module):\n",
        "    def __init__(self,\n",
        "                 world_model: WorldModel,\n",
        "                 instrinsic_reward,\n",
        "                 action_dim,\n",
        "                 z_dim,\n",
        "                 num_classes,\n",
        "                 h_dim,\n",
        "                 emb_dim,\n",
        "                 mlp_hidden_dim,\n",
        "                 min_std,\n",
        "                 discount,\n",
        "                 lambda_,\n",
        "                 actor_entropy_scale,\n",
        "                 device):\n",
        "        super(Achiever, self).__init__()\n",
        "\n",
        "        self.world_model = world_model\n",
        "\n",
        "        self.action_dim = action_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.mlp_hidden_dim = mlp_hidden_dim\n",
        "        self.discount = discount\n",
        "        self.lambda_ = lambda_\n",
        "        self.actor_entropy_scale = actor_entropy_scale\n",
        "        self.device = device\n",
        "\n",
        "        self.actor = AchieverActor(\n",
        "            action_dim = action_dim,\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            emb_dim = emb_dim,\n",
        "            hidden_dim = mlp_hidden_dim,\n",
        "            min_std = min_std\n",
        "        )\n",
        "        self.critic = AchieverCritic(\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            emb_dim = emb_dim,\n",
        "            hidden_dim = mlp_hidden_dim\n",
        "        )\n",
        "        self.target_critic = AchieverCritic(\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            emb_dim = emb_dim,\n",
        "            hidden_dim = mlp_hidden_dim\n",
        "        )\n",
        "        self.target_critic.load_state_dict(self.critic.state_dict())\n",
        "\n",
        "        self.instrinsic_reward = instrinsic_reward\n",
        "\n",
        "    def train(self, init_zs: torch.Tensor, init_hs: torch.Tensor, goal_observations: torch.Tensor, horison_length, num_positives, neg_sampling_factor, batch_seq_length):\n",
        "        goal_observations = rearrange(goal_observations, 'b t c h w -> (t b) c h w')\n",
        "        shuffle_idx = torch.randperm(goal_observations.shape[0])\n",
        "        goal_observations = goal_observations[shuffle_idx]\n",
        "        goal_embs = self.world_model.encoder(goal_observations)\n",
        "\n",
        "        zs = init_zs.detach() # (batch_size * seq_length, z_dim * num_classes)\n",
        "        hs = init_hs.detach() # (batch_size * seq_length, h_dim)\n",
        "\n",
        "        imagined_zs = torch.empty(horison_length, *init_zs.shape, device=self.device)\n",
        "        imagined_hs = torch.empty(horison_length, *init_hs.shape, device=self.device)\n",
        "        imagined_action_log_probs = torch.empty(horison_length, init_zs.shape[0], device=self.device)\n",
        "        imagined_action_entropys = torch.empty(horison_length, init_zs.shape[0], device=self.device)\n",
        "\n",
        "        for t in range(horison_length):\n",
        "            actions, action_log_probs, action_entropys = self.actor(zs.detach(), hs.detach(), goal_embs)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                hs, zs = self.world_model.imagine(actions, zs, hs)\n",
        "\n",
        "            imagined_hs[t] = hs.detach()\n",
        "            imagined_zs[t] = zs.detach()\n",
        "            imagined_action_log_probs[t] = action_log_probs\n",
        "            imagined_action_entropys[t] = action_entropys\n",
        "\n",
        "        flatten_hs = imagined_hs.view(-1, self.h_dim).detach() # (horison_length * batch_size * seq_length, h_dim)\n",
        "        flatten_zs = imagined_zs.view(-1, self.z_dim * self.num_classes).detach() # (horison_length * batch_size * seq_length, z_dim * num_classes)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            rewards = self.instrinsic_reward.compute_reward(flatten_zs, flatten_hs, goal_embs).view(horison_length, -1) # (horison_length, batch_size * seq_length)\n",
        "            target_values = self.target_critic(flatten_zs, flatten_hs, goal_embs).view(horison_length, -1) # (horison_length, batch_size * seq_length)\n",
        "\n",
        "        lambda_target = compute_lambda_target(rewards, self.discount, target_values, self.lambda_)\n",
        "\n",
        "        objective = imagined_action_log_probs * ((lambda_target - target_values).detach())\n",
        "        actor_loss = -torch.sum(torch.mean(objective + self.actor_entropy_scale * imagined_action_entropys, dim=1))\n",
        "\n",
        "        value_mean = self.critic(flatten_zs.detach(), flatten_hs.detach()).view(horison_length, -1)\n",
        "        value_dist = td.Independent(td.Normal(value_mean, 1),  1)\n",
        "        critic_loss = -torch.mean(value_dist.log_prob(lambda_target.detach()).unsqueeze(-1))\n",
        "\n",
        "        distance_estimator_loss = self.instrinsic_reward.train_distance_estimator(imagined_zs, imagined_hs, num_positives, neg_sampling_factor, batch_seq_length)\n",
        "\n",
        "        return actor_loss, critic_loss, distance_estimator_loss, OrderedDict(ach_actor_loss=actor_loss.item(), ach_critic_loss=critic_loss.item(), distance_estimator_loss=distance_estimator_loss.item())\n",
        "\n",
        "    def update_critic(self):\n",
        "        self.target_critic.load_state_dict(self.critic.state_dict())\n"
      ],
      "metadata": {
        "id": "-37bqKebnC1g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#explorer_reward.py\n",
        "from typing import Literal\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange\n",
        "\n",
        "# from .network import ExprolerStatePredictor\n",
        "\n",
        "\n",
        "class EmsembleReward(nn.Module):\n",
        "    def __init__(self,\n",
        "                 z_dim,\n",
        "                 num_classes,\n",
        "                 h_dim,\n",
        "                 min_std,\n",
        "                 mlp_hidden_dim,\n",
        "                 device,\n",
        "                 num_emsembles = 10,\n",
        "                 offset = 1,\n",
        "                 target_mode: Literal['z', 'h', 'zh'] = 'z'):\n",
        "        super(EmsembleReward, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.min_std = min_std\n",
        "        self.num_emsembles = num_emsembles\n",
        "        self.offset = offset\n",
        "        self.target_mode = target_mode\n",
        "        self.mlp_hidden_dim = mlp_hidden_dim\n",
        "        self.device = device\n",
        "\n",
        "        if target_mode == 'z':\n",
        "            self.target_dim = z_dim * num_classes\n",
        "        elif target_mode == 'h':\n",
        "            self.target_dim = h_dim\n",
        "        elif target_mode == 'zh':\n",
        "            self.target_dim = z_dim * num_classes + h_dim\n",
        "\n",
        "        self.emsembles = nn.ModuleList()\n",
        "        for _ in range(num_emsembles):\n",
        "            self.emsembles.append(\n",
        "                ExprolerStatePredictor(\n",
        "                    z_dim = z_dim,\n",
        "                    num_classes = num_classes,\n",
        "                    h_dim = h_dim,\n",
        "                    min_std = min_std,\n",
        "                    hidden_dim = mlp_hidden_dim,\n",
        "                    target_dim = self.target_dim\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def compute_reward(self, z, h):\n",
        "        input_ = torch.concat([z, h], dim=1)\n",
        "        preds = torch.empty(self.num_emsembles, z.shape[0], self.target_dim, device=self.device)\n",
        "        for n in range(self.num_emsembles):\n",
        "            f = self.emsembles[n]\n",
        "            preds[n] = f(input_).mean\n",
        "        var = torch.std(preds, dim=0)\n",
        "        reward = torch.sum(var, dim=1)\n",
        "        return reward\n",
        "\n",
        "    def train(self, zs, hs):\n",
        "        input_ = torch.concat([zs, hs], dim=2)\n",
        "\n",
        "        if self.target_mode == 'z':\n",
        "            target = zs\n",
        "        elif self.target_mode == 'h':\n",
        "            target = hs\n",
        "        elif self.target_mode == 'zh':\n",
        "            target = input_\n",
        "\n",
        "        input_ = rearrange(input_[:-self.offset].detach(), 't b d -> (t b) d')\n",
        "        target = rearrange(input_[self.offset:].detach(), 't b d -> (t b) d')\n",
        "\n",
        "        loss = 0\n",
        "        for f in self.emsembles:\n",
        "            dist = f(input_)\n",
        "            loss += -torch.mean(dist.log_prob(target))\n",
        "        return loss, OrderedDict(emsemble_loss=loss.item())\n",
        "\n"
      ],
      "metadata": {
        "id": "Ijd1tc6_or_q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#explorer.py\n",
        "\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.distributions as td\n",
        "from einops import rearrange\n",
        "\n",
        "# from .network import ExplorerActor, ExplorerCritic\n",
        "# from .worldmodel import WorldModel\n",
        "# from .explorer_reward import EmsembleReward\n",
        "# from .utils import compute_lambda_target\n",
        "\n",
        "\n",
        "class Explorer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 world_model: WorldModel,\n",
        "                 instrinsic_reward,\n",
        "                 action_dim,\n",
        "                 z_dim,\n",
        "                 num_classes,\n",
        "                 h_dim,\n",
        "                 mlp_hidden_dim,\n",
        "                 min_std,\n",
        "                 num_emsembles,\n",
        "                 emsembles_offset,\n",
        "                 emsembles_target_mode,\n",
        "                 discount,\n",
        "                 lambda_,\n",
        "                 actor_entropy_scale,\n",
        "                 device):\n",
        "        super(Explorer, self).__init__()\n",
        "\n",
        "        self.world_model = world_model\n",
        "\n",
        "        self.action_dim = action_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.mlp_hidden_dim = mlp_hidden_dim\n",
        "        self.min_std = min_std\n",
        "        self.num_emsembles = num_emsembles\n",
        "        self.emsembles_offset = emsembles_offset\n",
        "        self.emsembles_target_mode = emsembles_target_mode\n",
        "        self.discount = discount\n",
        "        self.lambda_ = lambda_\n",
        "        self.actor_entropy_scale = actor_entropy_scale\n",
        "        self.device = device\n",
        "\n",
        "        self.actor = ExplorerActor(\n",
        "            action_dim = action_dim,\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            hidden_dim = mlp_hidden_dim,\n",
        "            min_std = min_std\n",
        "        )\n",
        "        self.critic = ExplorerCritic(\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            hidden_dim = mlp_hidden_dim\n",
        "        )\n",
        "        self.target_critic = ExplorerCritic(\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            hidden_dim = mlp_hidden_dim\n",
        "        )\n",
        "        self.target_critic.load_state_dict(self.critic.state_dict())\n",
        "\n",
        "        self.instrinsic_reward = instrinsic_reward\n",
        "\n",
        "    def train(self, init_zs: torch.Tensor, init_hs: torch.Tensor, horison_length):\n",
        "        zs = init_zs.detach() # (batch_size * seq_length, z_dim * num_classes)\n",
        "        hs = init_hs.detach() # (batch_size * seq_length, h_dim)\n",
        "\n",
        "        imagined_zs = torch.empty(horison_length, *init_zs.shape, device=self.device)\n",
        "        imagined_hs = torch.empty(horison_length, *init_hs.shape, device=self.device)\n",
        "        imagined_action_log_probs = torch.empty(horison_length, init_zs.shape[0], device=self.device)\n",
        "        imagined_action_entropys = torch.empty(horison_length, init_zs.shape[0], device=self.device)\n",
        "\n",
        "        for t in range(horison_length):\n",
        "            actions, action_log_probs, action_entropys = self.actor(zs.detach(), hs.detach())\n",
        "\n",
        "            with torch.no_grad():\n",
        "                hs, zs = self.world_model.imagine(actions, zs, hs)\n",
        "\n",
        "            imagined_hs[t] = hs.detach()\n",
        "            imagined_zs[t] = zs.detach()\n",
        "            imagined_action_log_probs[t] = action_log_probs\n",
        "            imagined_action_entropys[t] = action_entropys\n",
        "\n",
        "        flatten_hs = imagined_hs.view(-1, self.h_dim).detach() # (horison_length * batch_size * seq_length, h_dim)\n",
        "        flatten_zs = imagined_zs.view(-1, self.z_dim * self.num_classes).detach() # (horison_length * batch_size * seq_length, z_dim * num_classes)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            rewards = self.instrinsic_reward.compute_reward(flatten_zs, flatten_hs).view(horison_length, -1) # (horison_length, batch_size * seq_length)\n",
        "            target_values = self.target_critic(flatten_zs, flatten_hs).view(horison_length, -1) # (horison_length, batch_size * seq_length)\n",
        "\n",
        "        lambda_target = compute_lambda_target(rewards, self.discount, target_values, self.lambda_)\n",
        "\n",
        "        objective = imagined_action_log_probs * ((lambda_target - target_values).detach())\n",
        "        actor_loss = -torch.sum(torch.mean(objective + self.actor_entropy_scale * imagined_action_entropys, dim=1))\n",
        "\n",
        "        value_mean = self.critic(flatten_zs.detach(), flatten_hs.detach()).view(horison_length, -1)\n",
        "        value_dist = td.Independent(td.Normal(value_mean, 1),  1)\n",
        "        critic_loss = -torch.mean(value_dist.log_prob(lambda_target.detach()).unsqueeze(-1))\n",
        "\n",
        "        return actor_loss, critic_loss, OrderedDict(exp_actor_loss=actor_loss.item(), exp_critic_loss=critic_loss.item())\n",
        "\n",
        "    def update_critic(self):\n",
        "        self.target_critic.load_state_dict(self.critic.state_dict())\n"
      ],
      "metadata": {
        "id": "XY9zGP7yoKFA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#replay_buffer.py\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# class ReplayBuffer:\n",
        "#     def __init__(self,\n",
        "#                  capacity,\n",
        "#                  observation_shape,\n",
        "#                  action_dim):\n",
        "#         self.capacity = capacity\n",
        "#         self.observation_shape = observation_shape\n",
        "#         self.action_dim = action_dim\n",
        "\n",
        "#         self.observations = np.zeros((capacity, *observation_shape), dtype=np.float32)\n",
        "#         self.actions = np.zeros((capacity, action_dim), dtype=np.float32)\n",
        "#         self.done = np.zeros((capacity, 1), dtype=bool)\n",
        "\n",
        "#         self.idx = 0\n",
        "#         self.if_filled = False\n",
        "\n",
        "#     def push(self, observation, action, done):\n",
        "#         self.observations[self.idx] = observation\n",
        "#         self.actions[self.idx] = action\n",
        "#         self.done[self.idx] = done\n",
        "\n",
        "#         if self.idx == self.capacity - 1:\n",
        "#             self.is_filled = True\n",
        "#         self.idx = (self.idx + 1) % self.capacity\n",
        "\n",
        "#     def sample(self, batch_size, seq_length):\n",
        "#         episode_borders = np.where(self.done)[0]\n",
        "#         sampled_indexes = []\n",
        "#         for _ in range(batch_size):\n",
        "#             cross_border = True\n",
        "#             while cross_border:\n",
        "#                 initial_index = np.random.randint(len(self) - seq_length + 1)\n",
        "#                 final_index = initial_index + seq_length - 1\n",
        "#                 cross_border = np.logical_and(initial_index <= episode_borders,\n",
        "#                                               episode_borders < final_index).any()\n",
        "#             sampled_indexes += list(range(initial_index, final_index + 1))\n",
        "\n",
        "#         sampled_observations = self.observations[sampled_indexes].reshape(\n",
        "#             batch_size, seq_length, *self.observations.shape[1:])\n",
        "#         sampled_actions = self.actions[sampled_indexes].reshape(\n",
        "#             batch_size, seq_length, self.actions.shape[1])\n",
        "#         sampled_done = self.done[sampled_indexes].reshape(\n",
        "#             batch_size, seq_length, 1)\n",
        "#         return sampled_observations, sampled_actions, sampled_done\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.capacity if self.is_filled else self.idx\n",
        "\n",
        "#     def save(self, dir):\n",
        "#         dir = Path(dir)\n",
        "#         np.save(dir / \"observations\", self.observations)\n",
        "#         np.save(dir / \"actions\", self.actions)\n",
        "#         np.save(dir / \"done\", self.done)\n",
        "\n",
        "#     def load(self, dir):\n",
        "#         dir = Path(dir)\n",
        "#         self.observations = np.load(dir / \"observations\")\n",
        "#         self.actions = np.load(dir / \"actions\")\n",
        "#         self.done = np.load(dir / \"done\")\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "class ReplayBuffer:\n",
        "    def __init__(self,\n",
        "                 capacity,\n",
        "                 observation_shape,\n",
        "                 action_dim):\n",
        "        self.capacity = capacity\n",
        "        self.observation_shape = observation_shape\n",
        "        self.action_dim = action_dim\n",
        "\n",
        "        self.observations = np.zeros((capacity, *observation_shape), dtype=np.float32)\n",
        "        self.actions = np.zeros((capacity, action_dim), dtype=np.float32)\n",
        "        self.done = np.zeros((capacity, 1), dtype=bool)\n",
        "\n",
        "        self.idx = 0\n",
        "        self.if_filled = False  # 修正: 正しいフィールド名を使用\n",
        "\n",
        "    def push(self, observation, action, done):\n",
        "        self.observations[self.idx] = observation\n",
        "        self.actions[self.idx] = action\n",
        "        self.done[self.idx] = done\n",
        "\n",
        "        # インデックス更新とバッファが満杯になったかのフラグ更新\n",
        "        if self.idx == self.capacity - 1:\n",
        "            self.if_filled = True\n",
        "        self.idx = (self.idx + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size, seq_length):\n",
        "        episode_borders = np.where(self.done)[0]\n",
        "        sampled_indexes = []\n",
        "        for _ in range(batch_size):\n",
        "            cross_border = True\n",
        "            while cross_border:\n",
        "                initial_index = np.random.randint(len(self) - seq_length + 1)\n",
        "                final_index = initial_index + seq_length - 1\n",
        "                cross_border = np.logical_and(initial_index <= episode_borders,\n",
        "                                              episode_borders < final_index).any()\n",
        "            sampled_indexes += list(range(initial_index, final_index + 1))\n",
        "\n",
        "        sampled_observations = self.observations[sampled_indexes].reshape(\n",
        "            batch_size, seq_length, *self.observations.shape[1:])\n",
        "        sampled_actions = self.actions[sampled_indexes].reshape(\n",
        "            batch_size, seq_length, self.actions.shape[1])\n",
        "        sampled_done = self.done[sampled_indexes].reshape(\n",
        "            batch_size, seq_length, 1)\n",
        "        return sampled_observations, sampled_actions, sampled_done\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.capacity if self.if_filled else self.idx  # 修正: 正しいフィールドを使用\n",
        "\n",
        "    def save(self, dir):\n",
        "        dir = Path(dir)\n",
        "        np.save(dir / \"observations\", self.observations)\n",
        "        np.save(dir / \"actions\", self.actions)\n",
        "        np.save(dir / \"done\", self.done)\n",
        "\n",
        "    def load(self, dir):\n",
        "        dir = Path(dir)\n",
        "        self.observations = np.load(dir / \"observations.npy\")\n",
        "        self.actions = np.load(dir / \"actions.npy\")\n",
        "        self.done = np.load(dir / \"done.npy\")\n",
        "\n",
        "    def debug_info(self, n=5):\n",
        "        \"\"\"\n",
        "        リプレイバッファのデバッグ情報を取得します。\n",
        "        :param n: 表示するサンプル数\n",
        "        :return: デバッグ情報の辞書\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'current_size': len(self),\n",
        "            'latest_observations': self.observations[max(0, self.idx - n):self.idx].tolist(),\n",
        "            'latest_actions': self.actions[max(0, self.idx - n):self.idx].tolist(),\n",
        "            'latest_done_flags': self.done[max(0, self.idx - n):self.idx].tolist()\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "rQKNQtrBo5Ho"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lexa.py\n",
        "\n",
        "from typing import Union, Literal\n",
        "import functools\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from gymnasium import Env\n",
        "\n",
        "# from config import Config\n",
        "# from model.worldmodel import WorldModel\n",
        "# from model.explorer import Explorer\n",
        "# from model.explorer_reward import EmsembleReward\n",
        "# from model.achiever import Achiever\n",
        "# from model.achiever_reward import LatentDistanceReward\n",
        "# from replay_buffer import ReplayBuffer\n",
        "\n",
        "\n",
        "class LEXA:\n",
        "    def __init__(self, cfg: Config, env: Env):\n",
        "        self.cfg = cfg\n",
        "        self.env = env\n",
        "        self.device = torch.device(self.cfg.device)\n",
        "\n",
        "        self.world_model = WorldModel(\n",
        "            img_size = cfg.env.img_size,\n",
        "            emb_dim = cfg.model.world_model.emb_dim,\n",
        "            action_dim = self.env.action_space.shape[0],\n",
        "            z_dim = cfg.model.world_model.z_dim,\n",
        "            num_classes = cfg.model.world_model.num_classes,\n",
        "            h_dim = cfg.model.world_model.h_dim,\n",
        "            hidden_dim = cfg.model.world_model.hidden_dim,\n",
        "            num_layers_za2hidden = cfg.model.world_model.num_layers_za2hidden,\n",
        "            num_layers_h2z = cfg.model.world_model.num_layers_h2z,\n",
        "            mlp_hidden_dim = cfg.model.world_model.mlp_hidden_dim,\n",
        "            min_std = cfg.model.world_model.min_std,\n",
        "            kl_balance_alpha = cfg.model.world_model.kl_balance_alpha,\n",
        "            kl_loss_scale = cfg.model.world_model.kl_loss_scale,\n",
        "            device = self.device\n",
        "        ).to(self.device)\n",
        "        self.explorer_reward = EmsembleReward(\n",
        "            z_dim = cfg.model.world_model.z_dim,\n",
        "            num_classes = cfg.model.world_model.num_classes,\n",
        "            h_dim = cfg.model.world_model.h_dim,\n",
        "            min_std = cfg.model.world_model.min_std,\n",
        "            mlp_hidden_dim = cfg.model.explorer.mlp_hidden_dim,\n",
        "            device = self.device,\n",
        "            num_emsembles = cfg.model.explorer.num_emsembles,\n",
        "            offset = cfg.model.explorer.emsembles_offset,\n",
        "            target_mode = cfg.model.explorer.emsembles_target_mode,\n",
        "        ).to(self.device)\n",
        "        self.explorer = Explorer(\n",
        "            world_model = self.world_model,\n",
        "            instrinsic_reward = self.explorer_reward,\n",
        "            action_dim = self.env.action_space.shape[0],\n",
        "            z_dim = cfg.model.world_model.z_dim,\n",
        "            num_classes = cfg.model.world_model.num_classes,\n",
        "            h_dim = cfg.model.world_model.h_dim,\n",
        "            mlp_hidden_dim = cfg.model.explorer.mlp_hidden_dim,\n",
        "            min_std = cfg.model.explorer.min_std,\n",
        "            num_emsembles = cfg.model.explorer.num_emsembles,\n",
        "            emsembles_offset = cfg.model.explorer.emsembles_offset,\n",
        "            emsembles_target_mode = cfg.model.explorer.emsembles_target_mode,\n",
        "            discount = cfg.model.explorer.discount,\n",
        "            lambda_ = cfg.model.explorer.lambda_,\n",
        "            actor_entropy_scale = cfg.model.explorer.actor_entropy_scale,\n",
        "            device = self.device\n",
        "        ).to(self.device)\n",
        "        self.achiever_reward = LatentDistanceReward(\n",
        "            z_dim = cfg.model.world_model.z_dim,\n",
        "            num_classes = cfg.model.world_model.num_classes,\n",
        "            h_dim = cfg.model.world_model.h_dim,\n",
        "            emb_dim = cfg.model.world_model.emb_dim,\n",
        "            mlp_hidden_dim = cfg.model.achiever.mlp_hidden_dim,\n",
        "            device = self.device\n",
        "        ).to(self.device)\n",
        "        self.achiever = Achiever(\n",
        "            world_model = self.world_model,\n",
        "            instrinsic_reward = self.achiever_reward,\n",
        "            action_dim = self.env.action_space.shape[0],\n",
        "            z_dim = cfg.model.world_model.z_dim,\n",
        "            num_classes = cfg.model.world_model.num_classes,\n",
        "            h_dim = cfg.model.world_model.h_dim,\n",
        "            emb_dim = cfg.model.world_model.emb_dim,\n",
        "            mlp_hidden_dim = cfg.model.achiever.mlp_hidden_dim,\n",
        "            min_std = cfg.model.achiever.min_std,\n",
        "            discount = cfg.model.achiever.discount,\n",
        "            lambda_ = cfg.model.achiever.lambda_,\n",
        "            actor_entropy_scale = cfg.model.achiever.actor_entropy_scale,\n",
        "            device = self.device\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.wm_opt = optim.Adam(self.world_model.parameters(),\n",
        "                                 lr = cfg.learning.world_model_lr,\n",
        "                                 eps = cfg.learning.epsilon,\n",
        "                                 weight_decay = cfg.learning.weight_decay)\n",
        "        self.exp_reward_opt = optim.Adam(self.explorer_reward.parameters(),\n",
        "                                         lr = cfg.learning.world_model_lr,\n",
        "                                         eps = cfg.learning.epsilon,\n",
        "                                         weight_decay = cfg.learning.weight_decay)\n",
        "        self.exp_actor_opt = optim.Adam(self.explorer.actor.parameters(),\n",
        "                                        lr = cfg.learning.explorer_actor_lr,\n",
        "                                        eps = cfg.learning.epsilon,\n",
        "                                        weight_decay = cfg.learning.weight_decay)\n",
        "        self.exp_critic_opt = optim.Adam(self.explorer.critic.parameters(),\n",
        "                                         lr = cfg.learning.explorer_critic_lr,\n",
        "                                         eps = cfg.learning.epsilon,\n",
        "                                         weight_decay = cfg.learning.weight_decay)\n",
        "        self.ach_reward_opt = optim.Adam(self.achiever_reward.parameters(),\n",
        "                                        lr = cfg.learning.achiever_critic_lr,\n",
        "                                        eps = cfg.learning.epsilon,\n",
        "                                        weight_decay = cfg.learning.weight_decay)\n",
        "        self.ach_actor_opt = optim.Adam(self.achiever.actor.parameters(),\n",
        "                                        lr = cfg.learning.achiever_actor_lr,\n",
        "                                        eps = cfg.learning.epsilon,\n",
        "                                        weight_decay = cfg.learning.weight_decay)\n",
        "        self.ach_critic_opt = optim.Adam(self.achiever.critic.parameters(),\n",
        "                                         lr = cfg.learning.achiever_critic_lr,\n",
        "                                         eps = cfg.learning.epsilon,\n",
        "                                         weight_decay = cfg.learning.weight_decay)\n",
        "\n",
        "        self.agent = Agent(self.world_model, self.explorer, self.achiever, self.device)\n",
        "\n",
        "    def train(self, observations, actions):\n",
        "        observations = torch.from_numpy(observations).to(self.device)\n",
        "        actions = torch.from_numpy(actions).to(self.device)\n",
        "\n",
        "        wm_loss, (zs, hs), wm_metrics = self.world_model.train(observations, actions)\n",
        "        emsemble_loss, emsemble_metrics = self.explorer_reward.train(zs, hs)\n",
        "        self.wm_opt.zero_grad(True)\n",
        "        wm_loss.backward()\n",
        "        clip_grad_norm_(self.world_model.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.wm_opt.step()\n",
        "        self.exp_reward_opt.zero_grad(True)\n",
        "        emsemble_loss.backward()\n",
        "        clip_grad_norm_(self.explorer_reward.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.exp_reward_opt.step()\n",
        "\n",
        "        zs = zs.view(-1, self.cfg.model.world_model.z_dim * self.cfg.model.world_model.num_classes)\n",
        "        hs = hs.view(-1, self.cfg.model.world_model.h_dim)\n",
        "\n",
        "        exp_actor_loss, axp_critic_loss, exp_metrics = self.explorer.train(zs, hs, self.cfg.data.imagination_horizon)\n",
        "        self.exp_actor_opt.zero_grad(True)\n",
        "        exp_actor_loss.backward()\n",
        "        clip_grad_norm_(self.explorer.actor.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.exp_actor_opt.step()\n",
        "        self.exp_critic_opt.zero_grad(True)\n",
        "        axp_critic_loss.backward()\n",
        "        clip_grad_norm_(self.explorer.critic.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.exp_critic_opt.step()\n",
        "\n",
        "        ach_actor_loss, ach_critic_loss, de_loss, ach_metrics = self.achiever.train(zs, hs, observations,\n",
        "                                                                                    self.cfg.data.imagination_horizon,\n",
        "                                                                                    self.cfg.model.achiever.num_positives,\n",
        "                                                                                    self.cfg.model.achiever.neg_sampling_factor,\n",
        "                                                                                    self.cfg.data.seq_length)\n",
        "        self.ach_actor_opt.zero_grad(True)\n",
        "        ach_actor_loss.backward()\n",
        "        clip_grad_norm_(self.achiever.actor.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.ach_actor_opt.step()\n",
        "        self.ach_critic_opt.zero_grad(True)\n",
        "        ach_critic_loss.backward()\n",
        "        clip_grad_norm_(self.achiever.critic.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.ach_critic_opt.step()\n",
        "        self.ach_reward_opt.zero_grad(True)\n",
        "        de_loss.backward()\n",
        "        clip_grad_norm_(self.achiever_reward.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.ach_reward_opt.step()\n",
        "\n",
        "        return wm_metrics | emsemble_metrics | exp_metrics | ach_metrics\n",
        "\n",
        "    @staticmethod\n",
        "    def load(checkpoint):\n",
        "        cfg = checkpoint['config']\n",
        "        env = checkpoint['env']\n",
        "        output = LEXA(cfg, env)\n",
        "        output.world_model.load_state_dict(checkpoint['world_model'])\n",
        "        output.explorer_reward.load_state_dict(checkpoint['exp_reward'])\n",
        "        output.explorer.load_state_dict(checkpoint['explorer'])\n",
        "        output.achiever_reward.load_state_dict(checkpoint['ach_reward'])\n",
        "        output.achiever.load_state_dict(checkpoint['achiever'])\n",
        "        output.wm_opt.load_state_dict(checkpoint['wm_opt'])\n",
        "        output.exp_reward_opt.load_state_dict(checkpoint['exp_reward_opt'])\n",
        "        output.exp_actor_opt.load_state_dict(checkpoint['exp_actor_opt'])\n",
        "        output.exp_critic_opt.load_state_dict(checkpoint['exp_critic_opt'])\n",
        "        output.ach_reward_opt.load_state_dict(checkpoint['ach_reward_opt'])\n",
        "        output.ach_actor_opt.load_state_dict(checkpoint['ach_actor_opt'])\n",
        "        output.ach_critic_opt.load_state_dict(checkpoint['ach_critic_opt'])\n",
        "        return output\n",
        "\n",
        "    def save(self, path):\n",
        "        path = Path(path)\n",
        "        path.mkdir(parents=True, exist_ok=True)\n",
        "        torch.save(\n",
        "            {\n",
        "                'world_model': self.world_model.state_dict(),\n",
        "                'exp_reward': self.explorer_reward.state_dict(),\n",
        "                'explorer': self.explorer.state_dict(),\n",
        "                'ach_reward': self.achiever_reward.state_dict(),\n",
        "                'achiever': self.achiever.state_dict(),\n",
        "                'wm_opt': self.wm_opt.state_dict(),\n",
        "                'exp_reward_opt': self.exp_reward_opt.state_dict(),\n",
        "                'exp_actor_opt': self.exp_actor_opt.state_dict(),\n",
        "                'exp_critic_opt': self.exp_critic_opt.state_dict(),\n",
        "                'ach_reward_opt': self.ach_reward_opt.state_dict(),\n",
        "                'ach_actor_opt': self.ach_actor_opt.state_dict(),\n",
        "                'ach_critic_opt': self.ach_critic_opt.state_dict(),\n",
        "                'config': self.cfg,\n",
        "                'env': self.env,\n",
        "            },\n",
        "            path\n",
        "        )\n",
        "\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, world_model: WorldModel, explorer: Explorer, achiever: Achiever, device: torch.device):\n",
        "        self.world_model = world_model\n",
        "        self.explorer = explorer\n",
        "        self.achiever = achiever\n",
        "        self.device = device\n",
        "\n",
        "        self.h = torch.zeros(1, self.world_model.h_dim, device=self.device)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def __call__(self, observation, mode: Literal['explorer', 'achiever'], goal=None, train=True):\n",
        "        observation = torch.from_numpy(observation).unsqueeze(0).to(self.device)\n",
        "\n",
        "        if mode == 'explorer':\n",
        "            policy = self.explorer.actor\n",
        "        elif mode == 'achiever':\n",
        "            policy = self.achiever.actor\n",
        "            assert goal is not None, 'goal must be provided in achiever mode'\n",
        "            goal = torch.from_numpy(goal).to(self.device)\n",
        "            goal_emb = self.world_model.encoder(goal)\n",
        "            policy = functools.partial(policy, goal_emb=goal_emb)\n",
        "\n",
        "        obs_emb = self.world_model.encoder(observation)\n",
        "        z_posterior = self.world_model.rssm.posterior(self.h, obs_emb)\n",
        "        z = z_posterior.sample().flatten(1)\n",
        "        action, _, _ = policy(z, self.h, train=train)\n",
        "\n",
        "        self.h = self.world_model.rssm.recurrent(z, action, self.h)\n",
        "\n",
        "        return action.squeeze().cpu().numpy()\n",
        "\n",
        "    def reset(self):\n",
        "        self.h = torch.zeros(1, self.world_model.h_dim, device=self.device)\n"
      ],
      "metadata": {
        "id": "TRtwWmSElWRJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#utils.py\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from einops import rearrange\n",
        "\n",
        "\n",
        "def preprocess_obs(obs):\n",
        "    height, width = obs.shape[0], obs.shape[1]\n",
        "    obs = Image.fromarray(obs)\n",
        "    obs = obs.convert(\"RGB\")\n",
        "    obs = np.array(obs).reshape(height, width, 3)\n",
        "    obs = obs.astype(np.float32)\n",
        "    obs = rearrange(obs, 'h w c -> c h w')\n",
        "    normalized_obs = obs / 255.0 - 0.5\n",
        "    return normalized_obs\n",
        "\n",
        "\n",
        "def fix_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n"
      ],
      "metadata": {
        "id": "2U5AzQqim2uz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xr_nk1HZwPTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install -y xvfb\n",
        "!pip install pyvirtualdisplay\n",
        "# 仮想ディスプレイのセットアップ\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "display = Display(visible=0, size=(1024, 768))\n",
        "display.start()\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "import mujoco\n",
        "import glfw\n",
        "\n"
      ],
      "metadata": {
        "id": "vS45lLZVjdew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c86c799-15ad-4563-8ed6-67187a9b3a7f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 7,815 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.12 [28.7 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.12 [864 kB]\n",
            "Fetched 7,815 kB in 1s (8,886 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 9.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 123634 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.12_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.12_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\n",
            "Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# def preprocess_obs(obs, target_size=(128, 128)):\n",
        "#     \"\"\"\n",
        "#     観測データを指定された形状にリサイズします。\n",
        "#     :param obs: 入力観測データ (H, W, C) または (C, H, W)\n",
        "#     :param target_size: リサイズ先の形状 (W, H)\n",
        "#     :return: リサイズされた観測データ\n",
        "#     \"\"\"\n",
        "#     if obs.shape[0] == 3:  # チャネルが先頭にある場合 (C, H, W)\n",
        "#         obs = np.transpose(obs, (1, 2, 0))  # (H, W, C) に変換\n",
        "\n",
        "#     resized = cv2.resize(obs, target_size, interpolation=cv2.INTER_AREA)\n",
        "#     resized = np.transpose(resized, (2, 0, 1))  # (C, H, W) に戻す\n",
        "#     return resized.astype(np.float32) / 255.0 - 0.5\n"
      ],
      "metadata": {
        "id": "nk1_dB2491os"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#envs.franka_kitchen\n",
        "from itertools import combinations\n",
        "import numpy as np\n",
        "from gymnasium import Env\n",
        "from gymnasium.spaces import Box\n",
        "from gymnasium.wrappers import AddRenderObservation, TimeLimit\n",
        "from gymnasium_robotics.envs.franka_kitchen.kitchen_env import KitchenEnv\n",
        "\n",
        "\n",
        "class FrankaKichenEnv(Env):\n",
        "    def __init__(self,\n",
        "                 img_size,\n",
        "                 action_repeat,\n",
        "                 time_limit,\n",
        "                 seed):\n",
        "        self._seed = seed\n",
        "        self._action_repeat = action_repeat\n",
        "        self._base_env = KitchenEnv(render_mode='rgb_array',\n",
        "                                    width=img_size,\n",
        "                                    height=img_size,\n",
        "                                    default_camera_config=dict(distance=1.86, lookat=[-0.3, .5, 2.], azimuth=90, elevation=-60))\n",
        "        self._env = TimeLimit(self._base_env, time_limit)\n",
        "\n",
        "        self.observation_space = Box(0, 255, (img_size, img_size, 3), dtype=np.uint8)\n",
        "        self.action_space = self._env.action_space\n",
        "\n",
        "        self.action_space.seed(seed)\n",
        "        self.observation_space.seed(seed)\n",
        "\n",
        "        self.obs_element_goals, self.obs_element_indices, self.goal_configs = get_kitchen_benchmark_goals()\n",
        "        self.goals = list(range(len(self.obs_element_goals)))\n",
        "        self.goal_idx = -1\n",
        "\n",
        "        self._env.reset(seed=self._seed)\n",
        "        self.init_qpos = self._base_env.data.qpos.copy()\n",
        "        self.init_qvel = self._base_env.data.qvel.copy()\n",
        "        self.goal_rendered = False\n",
        "\n",
        "    def reset(self):\n",
        "        self._env.reset(seed=self._seed)\n",
        "        self.goal_rendered = False\n",
        "        return self._env.render()\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0\n",
        "        for step in range(self._action_repeat):\n",
        "            state, reward, terminated, truncated, info = self._env.step(action)\n",
        "            terminated = self.compute_success()\n",
        "            done = truncated or terminated\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        obs = self._env.render()\n",
        "        return obs, total_reward, done, info\n",
        "\n",
        "    def render(self):\n",
        "        return self._env.render()\n",
        "\n",
        "    def close(self):\n",
        "        return self._env.close()\n",
        "\n",
        "    def set_goal_idx(self, idx):\n",
        "        assert idx in self.goals\n",
        "        self.goal_idx = idx\n",
        "\n",
        "    def get_goal_obs(self):\n",
        "        if self.goal_idx == -1:\n",
        "            return None\n",
        "\n",
        "        if self.goal_rendered:\n",
        "            return self.rendered_goal_obs\n",
        "\n",
        "        element_indices = self.obs_element_indices[self.goal_idx]\n",
        "        element_values = self.obs_element_goals[self.goal_idx]\n",
        "\n",
        "        backup_qpos = self._base_env.data.qpos.copy()\n",
        "        backup_qvel = self._base_env.data.qvel.copy()\n",
        "\n",
        "        qpos = self.init_qpos.copy()\n",
        "        qpos[element_indices] = element_values\n",
        "        self._base_env.robot_env.set_state(qpos, np.zeros_like(self.init_qvel))\n",
        "\n",
        "        goal_obs = self._env.render()\n",
        "\n",
        "        self._base_env.robot_env.set_state(backup_qpos, backup_qvel)\n",
        "\n",
        "        self.goal_rendered = True\n",
        "        self.rendered_goal_obs = goal_obs\n",
        "        return goal_obs\n",
        "\n",
        "    def compute_success(self):\n",
        "        if self.goal_idx == -1:\n",
        "            return False\n",
        "\n",
        "        qpos = self._base_env.data.qpos.copy()\n",
        "\n",
        "        element_indices = self.obs_element_indices[self.goal_idx]\n",
        "        element_values = self.obs_element_goals[self.goal_idx]\n",
        "        goal_qpos = self.init_qpos.copy()\n",
        "        goal_qpos[element_indices] = element_values\n",
        "\n",
        "        per_obj_success = {\n",
        "            'bottom_burner' : ((qpos[9]<-0.38) and (goal_qpos[9]<-0.38)) or ((qpos[9]>-0.38) and (goal_qpos[9]>-0.38)),\n",
        "            'top_burner':    ((qpos[13]<-0.38) and (goal_qpos[13]<-0.38)) or ((qpos[13]>-0.38) and (goal_qpos[13]>-0.38)),\n",
        "            'light_switch':  ((qpos[17]<-0.25) and (goal_qpos[17]<-0.25)) or ((qpos[17]>-0.25) and (goal_qpos[17]>-0.25)),\n",
        "            'slide_cabinet' :  abs(qpos[19] - goal_qpos[19])<0.1,\n",
        "            'hinge_cabinet' :  abs(qpos[21] - goal_qpos[21])<0.2,\n",
        "            'microwave' :      abs(qpos[22] - goal_qpos[22])<0.2,\n",
        "            'kettle' : np.linalg.norm(qpos[23:25] - goal_qpos[23:25]) < 0.2\n",
        "        }\n",
        "        task_objects = self.goal_configs[self.goal_idx]\n",
        "\n",
        "        success = 1\n",
        "        for _obj in task_objects:\n",
        "            success *= per_obj_success[_obj]\n",
        "\n",
        "        return bool(success)\n",
        "\n",
        "    def get_kitchen_benchmark_goals():\n",
        "\n",
        "        object_goal_vals = {'bottom_burner' :  [-0.88, -0.01],\n",
        "                            'light_switch' :  [ -0.69, -0.05],\n",
        "                            'slide_cabinet':  [0.37],\n",
        "                            'hinge_cabinet':   [0., 0.5],\n",
        "                            'microwave'    :   [-0.5],\n",
        "                            'kettle'       :   [-0.23, 0.75, 1.62, 0.99, 0., 0., -0.06]}\n",
        "\n",
        "        object_goal_idxs = {'bottom_burner' :  [9, 10],\n",
        "                            'light_switch' :  [17, 18],\n",
        "                            'slide_cabinet':  [19],\n",
        "                            'hinge_cabinet':  [20, 21],\n",
        "                            'microwave'    :  [22],\n",
        "                            'kettle'       :  [23, 24, 25, 26, 27, 28, 29]}\n",
        "\n",
        "        base_task_names = [ 'bottom_burner', 'light_switch', 'slide_cabinet', 'hinge_cabinet', 'microwave', 'kettle' ]\n",
        "\n",
        "\n",
        "        goal_configs = []\n",
        "        #single task\n",
        "        for i in range(6):\n",
        "          goal_configs.append( [base_task_names[i]])\n",
        "\n",
        "        #two tasks\n",
        "        for i,j  in combinations([1,2,3,5], 2) :\n",
        "          goal_configs.append( [base_task_names[i], base_task_names[j]] )\n",
        "\n",
        "        obs_element_goals = [] ; obs_element_indices = []\n",
        "        for objects in goal_configs:\n",
        "            _goal = np.concatenate([object_goal_vals[obj] for obj in objects])\n",
        "            _goal_idxs = np.concatenate([object_goal_idxs[obj] for obj in objects])\n",
        "\n",
        "            obs_element_goals.append(_goal)\n",
        "            obs_element_indices.append(_goal_idxs)\n",
        "\n",
        "        return obs_element_goals, obs_element_indices, goal_configs\n",
        "\n",
        "\n",
        "    def debug_environment(self):\n",
        "        \"\"\"\n",
        "        環境の属性とプロパティをデバッグ出力します。\n",
        "        \"\"\"\n",
        "        print(\"Attributes of _base_env:\")\n",
        "        print(dir(self._base_env))\n",
        "\n",
        "        if hasattr(self._base_env, 'unwrapped'):\n",
        "            print(\"\\nAttributes of _base_env.unwrapped:\")\n",
        "            print(dir(self._base_env.unwrapped))\n",
        "\n",
        "        if hasattr(self._base_env.unwrapped, 'model'):\n",
        "            model = self._base_env.unwrapped.model\n",
        "            print(\"\\nModel properties:\")\n",
        "            print(dir(model))\n",
        "\n",
        "        if hasattr(self._base_env.unwrapped, 'data'):\n",
        "            data = self._base_env.unwrapped.data\n",
        "            print(\"\\nData properties:\")\n",
        "            print(dir(data))\n"
      ],
      "metadata": {
        "id": "Ii__-AWlrQXa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j7sstYf13kuk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gymnasium_robotics.envs.maze.maps\n",
        "\n",
        "\"\"\"A collection of maze map structures for the Gymnasium-Robotics PointMaze environments.\n",
        "\n",
        "The code is inspired by the D4RL repository hosted on GitHub (https://github.com/Farama-Foundation/D4RL), published in the paper\n",
        "'D4RL: Datasets for Deep Data-Driven Reinforcement Learning' by Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, Sergey Levine.\n",
        "\n",
        "Original Author of the code: Justin Fu\n",
        "\n",
        "The modifications made involve organizing the code into different files: `maps.py`, `maze_env.py`, `point_env.py`, and `point_maze_env.py`.\n",
        "As well as adding support for the Gymnasium API.\n",
        "\n",
        "This project is covered by the Apache 2.0 License.\n",
        "\"\"\"\n",
        "\n",
        "RESET = R = \"r\"  # Initial Reset position of the agent\n",
        "GOAL = G = \"g\"\n",
        "COMBINED = C = \"c\"  # These cells can be selected as goal or reset locations\n",
        "\n",
        "\n",
        "EMPTY_MAZE = [\n",
        "    [1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "OPEN = [\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "OPEN_DIVERSE_G = [\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, R, G, G, G, G, 1],\n",
        "    [1, G, G, G, G, G, 1],\n",
        "    [1, G, G, G, G, G, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "OPEN_DIVERSE_GR = [\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, C, C, C, C, C, 1],\n",
        "    [1, C, C, C, C, C, 1],\n",
        "    [1, C, C, C, C, C, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "# Maze specifications for dataset generation\n",
        "U_MAZE = [\n",
        "    [1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "MEDIUM_MAZE = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 1, 1, 0, 0, 1],\n",
        "    [1, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 1, 0, 0, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 0, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 1, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "MEDIUM_MAZE_DIVERSE_G = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, R, 0, 1, 1, 0, 0, 1],\n",
        "    [1, 0, 0, 1, 0, 0, G, 1],\n",
        "    [1, 1, 0, 0, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, G, 1, 0, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 1, G, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "MEDIUM_MAZE_DIVERSE_GR = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, C, 0, 1, 1, 0, 0, 1],\n",
        "    [1, 0, 0, 1, 0, 0, C, 1],\n",
        "    [1, 1, 0, 0, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, C, 1, 0, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 1, C, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "LARGE_MAZE = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1],\n",
        "    [1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "LARGE_MAZE_DIVERSE_G = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, R, 0, 0, 0, 1, G, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 0, G, 0, 1, 0, 0, G, 1],\n",
        "    [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1],\n",
        "    [1, 0, G, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, G, 0, G, 1, 0, G, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "LARGE_MAZE_DIVERSE_GR = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, C, 0, 0, 0, 1, C, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 0, C, 0, 1, 0, 0, C, 1],\n",
        "    [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1],\n",
        "    [1, 0, C, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, C, 0, C, 1, 0, C, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n"
      ],
      "metadata": {
        "id": "Z4Jfh6SEyVrn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#core.py\n",
        "\n",
        "from abc import abstractmethod\n",
        "from typing import Optional\n",
        "\n",
        "import gymnasium as gym\n",
        "from gymnasium import error\n",
        "\n",
        "\n",
        "class GoalEnv(gym.Env):\n",
        "    r\"\"\"A goal-based environment.\n",
        "\n",
        "    It functions just as any regular Gymnasium environment but it imposes a required structure on the observation_space. More concretely,\n",
        "    the observation space is required to contain at least three elements, namely `observation`, `desired_goal`, and `achieved_goal`.\n",
        "    Here, `desired_goal` specifies the goal that the agent should attempt to achieve. `achieved_goal` is the goal that it currently achieved instead.\n",
        "    `observation` contains the actual observations of the environment as per usual.\n",
        "\n",
        "    - :meth:`compute_reward` - Externalizes the reward function by taking the achieved and desired goal, as well as extra information. Returns reward.\n",
        "    - :meth:`compute_terminated` - Returns boolean termination depending on the achieved and desired goal, as well as extra information.\n",
        "    - :meth:`compute_truncated` - Returns boolean truncation depending on the achieved and desired goal, as well as extra information.\n",
        "    \"\"\"\n",
        "\n",
        "    def reset(\n",
        "        self,\n",
        "        *,\n",
        "        seed: Optional[int] = None,\n",
        "        options: Optional[dict] = None,\n",
        "    ):\n",
        "        \"\"\"Reset the environment.\n",
        "\n",
        "        In addition, check if the observation space is correct by inspecting the `observation`, `achieved_goal`, and `desired_goal` keys.\n",
        "        \"\"\"\n",
        "        super().reset(seed=seed)\n",
        "        # Enforce that each GoalEnv uses a Goal-compatible observation space.\n",
        "        if not isinstance(self.observation_space, gym.spaces.Dict):\n",
        "            raise error.Error(\n",
        "                \"GoalEnv requires an observation space of type gym.spaces.Dict\"\n",
        "            )\n",
        "        for key in [\"observation\", \"achieved_goal\", \"desired_goal\"]:\n",
        "            if key not in self.observation_space.spaces:\n",
        "                raise error.Error(\n",
        "                    'GoalEnv requires the \"{}\" key to be part of the observation dictionary.'.format(\n",
        "                        key\n",
        "                    )\n",
        "                )\n",
        "\n",
        "    @abstractmethod\n",
        "    def compute_reward(self, achieved_goal, desired_goal, info):\n",
        "        \"\"\"Compute the step reward. This externalizes the reward function and makes it dependent on a desired goal and the one that was achieved.\n",
        "\n",
        "        If you wish to include additional rewards that are independent of the goal, you can include the necessary values\n",
        "        to derive it in 'info' and compute it accordingly.\n",
        "\n",
        "        Args:\n",
        "            achieved_goal (object): the goal that was achieved during execution\n",
        "            desired_goal (object): the desired goal that we asked the agent to attempt to achieve\n",
        "            info (dict): an info dictionary with additional information\n",
        "\n",
        "        Returns:\n",
        "            float: The reward that corresponds to the provided achieved goal w.r.t. to the desired\n",
        "            goal. Note that the following should always hold true:\n",
        "\n",
        "                ob, reward, terminated, truncated, info = env.step()\n",
        "                assert reward == env.compute_reward(ob['achieved_goal'], ob['desired_goal'], info)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def compute_terminated(self, achieved_goal, desired_goal, info):\n",
        "        \"\"\"Compute the step termination. Allows to customize the termination states depending on the desired and the achieved goal.\n",
        "\n",
        "        If you wish to determine termination states independent of the goal, you can include necessary values to derive it in 'info'\n",
        "        and compute it accordingly. The envirtonment reaches a termination state when this state leads to an episode ending in an episodic\n",
        "        task thus breaking .\n",
        "\n",
        "        More information can be found in: https://farama.org/New-Step-API#theory\n",
        "\n",
        "        Termination states are\n",
        "\n",
        "        Args:\n",
        "            achieved_goal (object): the goal that was achieved during execution\n",
        "            desired_goal (object): the desired goal that we asked the agent to attempt to achieve\n",
        "            info (dict): an info dictionary with additional information\n",
        "\n",
        "        Returns:\n",
        "            bool: The termination state that corresponds to the provided achieved goal w.r.t. to the desired\n",
        "            goal. Note that the following should always hold true:\n",
        "\n",
        "                ob, reward, terminated, truncated, info = env.step()\n",
        "                assert terminated == env.compute_terminated(ob['achieved_goal'], ob['desired_goal'], info)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def compute_truncated(self, achieved_goal, desired_goal, info):\n",
        "        \"\"\"Compute the step truncation. Allows to customize the truncated states depending on the desired and the achieved goal.\n",
        "\n",
        "        If you wish to determine truncated states independent of the goal, you can include necessary values to derive it in 'info'\n",
        "        and compute it accordingly. Truncated states are those that are out of the scope of the Markov Decision Process (MDP) such\n",
        "        as time constraints in a continuing task.\n",
        "\n",
        "        More information can be found in: https://farama.org/New-Step-API#theory\n",
        "\n",
        "        Args:\n",
        "            achieved_goal (object): the goal that was achieved during execution\n",
        "            desired_goal (object): the desired goal that we asked the agent to attempt to achieve\n",
        "            info (dict): an info dictionary with additional information\n",
        "\n",
        "        Returns:\n",
        "            bool: The truncated state that corresponds to the provided achieved goal w.r.t. to the desired\n",
        "            goal. Note that the following should always hold true:\n",
        "\n",
        "                ob, reward, terminated, truncated, info = env.step()\n",
        "                assert truncated == env.compute_truncated(ob['achieved_goal'], ob['desired_goal'], info)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n"
      ],
      "metadata": {
        "id": "J8NiXhdUzmuM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gymnasium_robotics.envs.maze.maze_v4.py\n",
        "\n",
        "\n",
        "\"\"\"A maze environment with Gymnasium API for the Gymnasium-Robotics PointMaze environments.\n",
        "\n",
        "The code is inspired by the D4RL repository hosted on GitHub (https://github.com/Farama-Foundation/D4RL), published in the paper\n",
        "'D4RL: Datasets for Deep Data-Driven Reinforcement Learning' by Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, Sergey Levine.\n",
        "\n",
        "Original Author of the code: Justin Fu\n",
        "\n",
        "The modifications made involve organizing the code into different files: `maps.py`, `maze_env.py`, `point_env.py`, and `point_maze_env.py`.\n",
        "As well as adding support for the Gymnasium API.\n",
        "\n",
        "This project is covered by the Apache 2.0 License.\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "import tempfile\n",
        "import time\n",
        "import xml.etree.ElementTree as ET\n",
        "from os import path\n",
        "from typing import Dict, List, Optional, Union\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# from gymnasium_robotics.core import GoalEnv\n",
        "# from gymnasium_robotics.envs.maze.maps import COMBINED, GOAL, RESET, U_MAZE\n",
        "\n",
        "\n",
        "class Maze:\n",
        "    r\"\"\"This class creates and holds information about the maze in the MuJoCo simulation.\n",
        "\n",
        "    The accessible attributes are the following:\n",
        "    - :attr:`maze_map` - The maze discrete data structure.\n",
        "    - :attr:`maze_size_scaling` - The maze scaling for the continuous coordinates in the MuJoCo simulation.\n",
        "    - :attr:`maze_height` - The height of the walls in the MuJoCo simulation.\n",
        "    - :attr:`unique_goal_locations` - All the `(i,j)` possible cell indices for goal locations.\n",
        "    - :attr:`unique_reset_locations` - All the `(i,j)` possible cell indices for agent initialization locations.\n",
        "    - :attr:`combined_locations` - All the `(i,j)` possible cell indices for goal and agent initialization locations.\n",
        "    - :attr:`map_length` - Maximum value of j cell index\n",
        "    - :attr:`map_width` - Mazimum value of i cell index\n",
        "    - :attr:`x_map_center` - The x coordinate of the map's center\n",
        "    - :attr:`y_map_center` - The y coordinate of the map's center\n",
        "\n",
        "    The Maze class also presents a method to convert from cell indices to `(x,y)` coordinates in the MuJoCo simulation:\n",
        "    - :meth:`cell_rowcol_to_xy` - Convert from `(i,j)` to `(x,y)`\n",
        "\n",
        "    ### Version History\n",
        "    * v4: Refactor compute_terminated into a pure function compute_terminated and a new function update_goal which resets the goal position. Bug fix: missing maze_size_scaling factor added in generate_reset_pos() -- only affects AntMaze.\n",
        "    * v3: refactor version of the D4RL environment, also create dependency on newest [mujoco python bindings](https://mujoco.readthedocs.io/en/latest/python.html) maintained by the MuJoCo team in Deepmind.\n",
        "    * v2 & v1: legacy versions in the [D4RL](https://github.com/Farama-Foundation/D4RL).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        maze_map: List[List[Union[str, int]]],\n",
        "        maze_size_scaling: float,\n",
        "        maze_height: float,\n",
        "    ):\n",
        "\n",
        "        self._maze_map = maze_map\n",
        "        self._maze_size_scaling = maze_size_scaling\n",
        "        self._maze_height = maze_height\n",
        "\n",
        "        self._unique_goal_locations = []\n",
        "        self._unique_reset_locations = []\n",
        "        self._combined_locations = []\n",
        "\n",
        "        # Get the center cell Cartesian position of the maze. This will be the origin\n",
        "        self._map_length = len(maze_map)\n",
        "        self._map_width = len(maze_map[0])\n",
        "        self._x_map_center = self.map_width / 2 * maze_size_scaling\n",
        "        self._y_map_center = self.map_length / 2 * maze_size_scaling\n",
        "\n",
        "    @property\n",
        "    def maze_map(self) -> List[List[Union[str, int]]]:\n",
        "        \"\"\"Returns the list[list] data structure of the maze.\"\"\"\n",
        "        return self._maze_map\n",
        "\n",
        "    @property\n",
        "    def maze_size_scaling(self) -> float:\n",
        "        \"\"\"Returns the scaling value used to integrate the maze\n",
        "        encoding in the MuJoCo simulation.\n",
        "        \"\"\"\n",
        "        return self._maze_size_scaling\n",
        "\n",
        "    @property\n",
        "    def maze_height(self) -> float:\n",
        "        \"\"\"Returns the un-scaled height of the walls in the MuJoCo\n",
        "        simulation.\n",
        "        \"\"\"\n",
        "        return self._maze_height\n",
        "\n",
        "    @property\n",
        "    def unique_goal_locations(self) -> List[np.ndarray]:\n",
        "        \"\"\"Returns all the possible goal locations in discrete cell\n",
        "        coordinates (i,j)\n",
        "        \"\"\"\n",
        "        return self._unique_goal_locations\n",
        "\n",
        "    @property\n",
        "    def unique_reset_locations(self) -> List[np.ndarray]:\n",
        "        \"\"\"Returns all the possible reset locations for the agent in\n",
        "        discrete cell coordinates (i,j)\n",
        "        \"\"\"\n",
        "        return self._unique_reset_locations\n",
        "\n",
        "    @property\n",
        "    def combined_locations(self) -> List[np.ndarray]:\n",
        "        \"\"\"Returns all the possible goal/reset locations in discrete cell\n",
        "        coordinates (i,j)\n",
        "        \"\"\"\n",
        "        return self._combined_locations\n",
        "\n",
        "    @property\n",
        "    def map_length(self) -> int:\n",
        "        \"\"\"Returns the length of the maze in number of discrete vertical cells\n",
        "        or number of rows i.\n",
        "        \"\"\"\n",
        "        return self._map_length\n",
        "\n",
        "    @property\n",
        "    def map_width(self) -> int:\n",
        "        \"\"\"Returns the width of the maze in number of discrete horizontal cells\n",
        "        or number of columns j.\n",
        "        \"\"\"\n",
        "        return self._map_width\n",
        "\n",
        "    @property\n",
        "    def x_map_center(self) -> float:\n",
        "        \"\"\"Returns the x coordinate of the center of the maze in the MuJoCo simulation\"\"\"\n",
        "        return self._x_map_center\n",
        "\n",
        "    @property\n",
        "    def y_map_center(self) -> float:\n",
        "        \"\"\"Returns the x coordinate of the center of the maze in the MuJoCo simulation\"\"\"\n",
        "        return self._y_map_center\n",
        "\n",
        "    def cell_rowcol_to_xy(self, rowcol_pos: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Converts a cell index `(i,j)` to x and y coordinates in the MuJoCo simulation\"\"\"\n",
        "        x = (rowcol_pos[1] + 0.5) * self.maze_size_scaling - self.x_map_center\n",
        "        y = self.y_map_center - (rowcol_pos[0] + 0.5) * self.maze_size_scaling\n",
        "\n",
        "        return np.array([x, y])\n",
        "\n",
        "    def cell_xy_to_rowcol(self, xy_pos: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Converts a cell x and y coordinates to `(i,j)`\"\"\"\n",
        "        i = math.floor((self.y_map_center - xy_pos[1]) / self.maze_size_scaling)\n",
        "        j = math.floor((xy_pos[0] + self.x_map_center) / self.maze_size_scaling)\n",
        "        return np.array([i, j])\n",
        "\n",
        "    @classmethod\n",
        "    def make_maze(\n",
        "        cls,\n",
        "        agent_xml_path: str,\n",
        "        maze_map: list,\n",
        "        maze_size_scaling: float,\n",
        "        maze_height: float,\n",
        "    ):\n",
        "        \"\"\"Class method that returns an instance of Maze with a decoded maze information and the temporal\n",
        "           path to the new MJCF (xml) file for the MuJoCo simulation.\n",
        "\n",
        "        Args:\n",
        "            agent_xml_path (str): the goal that was achieved during execution\n",
        "            maze_map (list[list[str,int]]): the desired goal that we asked the agent to attempt to achieve\n",
        "            maze_size_scaling (float): an info dictionary with additional information\n",
        "            maze_height (float): an info dictionary with additional information\n",
        "\n",
        "        Returns:\n",
        "            Maze: The reward that corresponds to the provided achieved goal w.r.t. to the desired\n",
        "            goal. Note that the following should always hold true:\n",
        "            str: The xml temporal file to the new mjcf model with the included maze.\n",
        "        \"\"\"\n",
        "        tree = ET.parse(agent_xml_path)\n",
        "        worldbody = tree.find(\".//worldbody\")\n",
        "\n",
        "        maze = cls(maze_map, maze_size_scaling, maze_height)\n",
        "        empty_locations = []\n",
        "        for i in range(maze.map_length):\n",
        "            for j in range(maze.map_width):\n",
        "                struct = maze_map[i][j]\n",
        "                # Store cell locations in simulation global Cartesian coordinates\n",
        "                x = (j + 0.5) * maze_size_scaling - maze.x_map_center\n",
        "                y = maze.y_map_center - (i + 0.5) * maze_size_scaling\n",
        "                if struct == 1:  # Unmovable block.\n",
        "                    # Offset all coordinates so that maze is centered.\n",
        "                    ET.SubElement(\n",
        "                        worldbody,\n",
        "                        \"geom\",\n",
        "                        name=f\"block_{i}_{j}\",\n",
        "                        pos=f\"{x} {y} {maze_height / 2 * maze_size_scaling}\",\n",
        "                        size=f\"{0.5 * maze_size_scaling} {0.5 * maze_size_scaling} {maze_height / 2 * maze_size_scaling}\",\n",
        "                        type=\"box\",\n",
        "                        material=\"\",\n",
        "                        contype=\"1\",\n",
        "                        conaffinity=\"1\",\n",
        "                        rgba=\"0.7 0.5 0.3 1.0\",\n",
        "                    )\n",
        "\n",
        "                elif struct == RESET:\n",
        "                    maze._unique_reset_locations.append(np.array([x, y]))\n",
        "                elif struct == GOAL:\n",
        "                    maze._unique_goal_locations.append(np.array([x, y]))\n",
        "                elif struct == COMBINED:\n",
        "                    maze._combined_locations.append(np.array([x, y]))\n",
        "                elif struct == 0:\n",
        "                    empty_locations.append(np.array([x, y]))\n",
        "\n",
        "        # Add target site for visualization\n",
        "        ET.SubElement(\n",
        "            worldbody,\n",
        "            \"site\",\n",
        "            name=\"target\",\n",
        "            pos=f\"0 0 {maze_height / 2 * maze_size_scaling}\",\n",
        "            size=f\"{0.2 * maze_size_scaling}\",\n",
        "            rgba=\"1 0 0 0\",\n",
        "            type=\"sphere\",\n",
        "        )\n",
        "\n",
        "        # Add the combined cell locations (goal/reset) to goal and reset\n",
        "        if (\n",
        "            not maze._unique_goal_locations\n",
        "            and not maze._unique_reset_locations\n",
        "            and not maze._combined_locations\n",
        "        ):\n",
        "            # If there are no given \"r\", \"g\" or \"c\" cells in the maze data structure,\n",
        "            # any empty cell can be a reset or goal location at initialization.\n",
        "            maze._combined_locations = empty_locations\n",
        "        elif not maze._unique_reset_locations and not maze._combined_locations:\n",
        "            # If there are no given \"r\" or \"c\" cells in the maze data structure,\n",
        "            # any empty cell can be a reset location at initialization.\n",
        "            maze._unique_reset_locations = empty_locations\n",
        "        elif not maze._unique_goal_locations and not maze._combined_locations:\n",
        "            # If there are no given \"g\" or \"c\" cells in the maze data structure,\n",
        "            # any empty cell can be a gaol location at initialization.\n",
        "            maze._unique_goal_locations = empty_locations\n",
        "\n",
        "        maze._unique_goal_locations += maze._combined_locations\n",
        "        maze._unique_reset_locations += maze._combined_locations\n",
        "\n",
        "        # Save new xml with maze to a temporary file\n",
        "        with tempfile.TemporaryDirectory() as tmp_dir:\n",
        "            temp_xml_name = f\"ant_maze{str(time.time())}.xml\"\n",
        "            temp_xml_path = path.join(path.dirname(tmp_dir), temp_xml_name)\n",
        "            tree.write(temp_xml_path)\n",
        "\n",
        "        return maze, temp_xml_path\n",
        "\n",
        "\n",
        "class MazeEnv(GoalEnv):\n",
        "    def __init__(\n",
        "        self,\n",
        "        agent_xml_path: str,\n",
        "        reward_type: str = \"dense\",\n",
        "        continuing_task: bool = True,\n",
        "        reset_target: bool = True,\n",
        "        maze_map: List[List[Union[int, str]]] = U_MAZE,\n",
        "        maze_size_scaling: float = 1.0,\n",
        "        maze_height: float = 0.5,\n",
        "        position_noise_range: float = 0.25,\n",
        "        **kwargs,\n",
        "    ):\n",
        "\n",
        "        self.reward_type = reward_type\n",
        "        self.continuing_task = continuing_task\n",
        "        self.reset_target = reset_target\n",
        "        self.maze, self.tmp_xml_file_path = Maze.make_maze(\n",
        "            agent_xml_path, maze_map, maze_size_scaling, maze_height\n",
        "        )\n",
        "\n",
        "        self.position_noise_range = position_noise_range\n",
        "\n",
        "    def generate_target_goal(self) -> np.ndarray:\n",
        "        assert len(self.maze.unique_goal_locations) > 0\n",
        "        goal_index = self.np_random.integers(\n",
        "            low=0, high=len(self.maze.unique_goal_locations)\n",
        "        )\n",
        "        goal = self.maze.unique_goal_locations[goal_index].copy()\n",
        "        return goal\n",
        "\n",
        "    def generate_reset_pos(self) -> np.ndarray:\n",
        "        assert len(self.maze.unique_reset_locations) > 0\n",
        "\n",
        "        # While reset position is close to goal position\n",
        "        reset_pos = self.goal.copy()\n",
        "        while (\n",
        "            np.linalg.norm(reset_pos - self.goal) <= 0.5 * self.maze.maze_size_scaling\n",
        "        ):\n",
        "            reset_index = self.np_random.integers(\n",
        "                low=0, high=len(self.maze.unique_reset_locations)\n",
        "            )\n",
        "            reset_pos = self.maze.unique_reset_locations[reset_index].copy()\n",
        "\n",
        "        return reset_pos\n",
        "\n",
        "    def reset(\n",
        "        self,\n",
        "        *,\n",
        "        seed: Optional[int] = None,\n",
        "        options: Optional[Dict[str, Optional[np.ndarray]]] = None,\n",
        "    ):\n",
        "        \"\"\"Reset the maze simulation.\n",
        "\n",
        "        Args:\n",
        "            options (dict[str, np.ndarray]): the options dictionary can contain two items, \"goal_cell\" and \"reset_cell\" that will set the initial goal and reset location (i,j) in the self.maze.map list of list maze structure.\n",
        "\n",
        "        \"\"\"\n",
        "        super().reset(seed=seed)\n",
        "\n",
        "        if options is None:\n",
        "            goal = self.generate_target_goal()\n",
        "            # Add noise to goal position\n",
        "            self.goal = self.add_xy_position_noise(goal)\n",
        "            reset_pos = self.generate_reset_pos()\n",
        "        else:\n",
        "            if \"goal_cell\" in options and options[\"goal_cell\"] is not None:\n",
        "                # assert that goal cell is valid\n",
        "                assert self.maze.map_length > options[\"goal_cell\"][0]\n",
        "                assert self.maze.map_width > options[\"goal_cell\"][1]\n",
        "                assert (\n",
        "                    self.maze.maze_map[options[\"goal_cell\"][0]][options[\"goal_cell\"][1]]\n",
        "                    != 1\n",
        "                ), f\"Goal can't be placed in a wall cell, {options['goal_cell']}\"\n",
        "\n",
        "                goal = self.maze.cell_rowcol_to_xy(options[\"goal_cell\"])\n",
        "\n",
        "            else:\n",
        "                goal = self.generate_target_goal()\n",
        "\n",
        "            # Add noise to goal position\n",
        "            self.goal = self.add_xy_position_noise(goal)\n",
        "\n",
        "            if \"reset_cell\" in options and options[\"reset_cell\"] is not None:\n",
        "                # assert that goal cell is valid\n",
        "                assert self.maze.map_length > options[\"reset_cell\"][0]\n",
        "                assert self.maze.map_width > options[\"reset_cell\"][1]\n",
        "                assert (\n",
        "                    self.maze.maze_map[options[\"reset_cell\"][0]][\n",
        "                        options[\"reset_cell\"][1]\n",
        "                    ]\n",
        "                    != 1\n",
        "                ), f\"Reset can't be placed in a wall cell, {options['reset_cell']}\"\n",
        "\n",
        "                reset_pos = self.maze.cell_rowcol_to_xy(options[\"reset_cell\"])\n",
        "\n",
        "            else:\n",
        "                reset_pos = self.generate_reset_pos()\n",
        "\n",
        "        # Update the position of the target site for visualization\n",
        "        self.update_target_site_pos()\n",
        "        # Add noise to reset position\n",
        "        self.reset_pos = self.add_xy_position_noise(reset_pos)\n",
        "\n",
        "        # Update the position of the target site for visualization\n",
        "        self.update_target_site_pos()\n",
        "\n",
        "    def add_xy_position_noise(self, xy_pos: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Pass an x,y coordinate and it will return the same coordinate with a noise addition\n",
        "        sampled from a uniform distribution\n",
        "        \"\"\"\n",
        "        noise_x = (\n",
        "            self.np_random.uniform(\n",
        "                low=-self.position_noise_range, high=self.position_noise_range\n",
        "            )\n",
        "            * self.maze.maze_size_scaling\n",
        "        )\n",
        "        noise_y = (\n",
        "            self.np_random.uniform(\n",
        "                low=-self.position_noise_range, high=self.position_noise_range\n",
        "            )\n",
        "            * self.maze.maze_size_scaling\n",
        "        )\n",
        "        xy_pos[0] += noise_x\n",
        "        xy_pos[1] += noise_y\n",
        "\n",
        "        return xy_pos\n",
        "\n",
        "    def compute_reward(\n",
        "        self, achieved_goal: np.ndarray, desired_goal: np.ndarray, info\n",
        "    ) -> float:\n",
        "        distance = np.linalg.norm(achieved_goal - desired_goal, axis=-1)\n",
        "        if self.reward_type == \"dense\":\n",
        "            return np.exp(-distance)\n",
        "        elif self.reward_type == \"sparse\":\n",
        "            return (distance <= 0.45).astype(np.float64)\n",
        "\n",
        "    def compute_terminated(\n",
        "        self, achieved_goal: np.ndarray, desired_goal: np.ndarray, info\n",
        "    ) -> bool:\n",
        "        if not self.continuing_task:\n",
        "            # If task is episodic terminate the episode when the goal is reached\n",
        "            return bool(np.linalg.norm(achieved_goal - desired_goal) <= 0.45)\n",
        "        else:\n",
        "            # Continuing tasks don't terminate, episode will be truncated when time limit is reached (`max_episode_steps`)\n",
        "            return False\n",
        "\n",
        "    def update_goal(self, achieved_goal: np.ndarray) -> None:\n",
        "        \"\"\"Update goal position if continuing task and within goal radius.\"\"\"\n",
        "\n",
        "        if (\n",
        "            self.continuing_task\n",
        "            and self.reset_target\n",
        "            and bool(np.linalg.norm(achieved_goal - self.goal) <= 0.45)\n",
        "            and len(self.maze.unique_goal_locations) > 1\n",
        "        ):\n",
        "            # Generate a goal while within 0.45 of achieved_goal. The distance check above\n",
        "            # is not redundant, it avoids calling update_target_site_pos() unless necessary\n",
        "            while np.linalg.norm(achieved_goal - self.goal) <= 0.45:\n",
        "                # Generate another goal\n",
        "                goal = self.generate_target_goal()\n",
        "                # Add noise to goal position\n",
        "                self.goal = self.add_xy_position_noise(goal)\n",
        "\n",
        "            # Update the position of the target site for visualization\n",
        "            self.update_target_site_pos()\n",
        "\n",
        "    def compute_truncated(\n",
        "        self, achieved_goal: np.ndarray, desired_goal: np.ndarray, info\n",
        "    ) -> bool:\n",
        "        return False\n",
        "\n",
        "    def update_target_site_pos(self, pos):\n",
        "        \"\"\"Override this method to update the site qpos in the MuJoCo simulation\n",
        "        after a new goal is selected. This is mainly for visualization purposes.\"\"\"\n",
        "        raise NotImplementedError\n"
      ],
      "metadata": {
        "id": "BTwO5-Hc3k7A"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gymnasium_robotics.envs.utils.mujoco_utils.py\n",
        "\n",
        "from typing import Dict, Tuple, Union\n",
        "\n",
        "import numpy as np\n",
        "from gymnasium import error\n",
        "\n",
        "try:\n",
        "    import mujoco\n",
        "    from mujoco import MjData, MjModel, mjtObj\n",
        "except ImportError as e:\n",
        "    raise error.DependencyNotInstalled(f\"{e}. (HINT: you need to install mujoco\")\n",
        "\n",
        "MJ_OBJ_TYPES = [\n",
        "    \"mjOBJ_BODY\",\n",
        "    \"mjOBJ_JOINT\",\n",
        "    \"mjOBJ_GEOM\",\n",
        "    \"mjOBJ_SITE\",\n",
        "    \"mjOBJ_CAMERA\",\n",
        "    \"mjOBJ_ACTUATOR\",\n",
        "    \"mjOBJ_SENSOR\",\n",
        "]\n",
        "\n",
        "\n",
        "def robot_get_obs(model, data, joint_names):\n",
        "    \"\"\"Returns all joint positions and velocities associated with a robot.\"\"\"\n",
        "    if data.qpos is not None and joint_names:\n",
        "        names = [n for n in joint_names if n.startswith(\"robot\")]\n",
        "        return (\n",
        "            np.squeeze(np.array([get_joint_qpos(model, data, name) for name in names])),\n",
        "            np.squeeze(np.array([get_joint_qvel(model, data, name) for name in names])),\n",
        "        )\n",
        "    return np.zeros(0), np.zeros(0)\n",
        "\n",
        "\n",
        "def ctrl_set_action(model, data, action):\n",
        "    \"\"\"For torque actuators it copies the action into mujoco ctrl field.\n",
        "\n",
        "    For position actuators it sets the target relative to the current qpos.\n",
        "    \"\"\"\n",
        "    if model.nmocap > 0:\n",
        "        _, action = np.split(action, (model.nmocap * 7,))\n",
        "\n",
        "    if len(data.ctrl) > 0:\n",
        "        for i in range(action.shape[0]):\n",
        "            if model.actuator_biastype[i] == 0:\n",
        "                data.ctrl[i] = action[i]\n",
        "            else:\n",
        "                idx = model.jnt_qposadr[model.actuator_trnid[i, 0]]\n",
        "                data.ctrl[i] = data.qpos[idx] + action[i]\n",
        "\n",
        "\n",
        "def mocap_set_action(model, data, action):\n",
        "    \"\"\"Update the position of the mocap body with the desired action.\n",
        "\n",
        "    The action controls the robot using mocaps. Specifically, bodies\n",
        "    on the robot (for example the gripper wrist) is controlled with\n",
        "    mocap bodies. In this case the action is the desired difference\n",
        "    in position and orientation (quaternion), in world coordinates,\n",
        "    of the target body. The mocap is positioned relative to\n",
        "    the target body according to the delta, and the MuJoCo equality\n",
        "    constraint optimizer tries to center the welded body on the mocap.\n",
        "    \"\"\"\n",
        "    if model.nmocap > 0:\n",
        "        action, _ = np.split(action, (model.nmocap * 7,))\n",
        "        action = action.reshape(model.nmocap, 7)\n",
        "\n",
        "        pos_delta = action[:, :3]\n",
        "        quat_delta = action[:, 3:]\n",
        "\n",
        "        reset_mocap2body_xpos(model, data)\n",
        "        data.mocap_pos[:] = data.mocap_pos + pos_delta\n",
        "        data.mocap_quat[:] = data.mocap_quat + quat_delta\n",
        "\n",
        "\n",
        "def reset_mocap_welds(model, data):\n",
        "    \"\"\"Resets the mocap welds that we use for actuation.\"\"\"\n",
        "    if model.nmocap > 0 and model.eq_data is not None:\n",
        "        for i in range(model.eq_data.shape[0]):\n",
        "            if model.eq_type[i] == mujoco.mjtEq.mjEQ_WELD:\n",
        "                model.eq_data[i, :7] = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
        "    mujoco.mj_forward(model, data)\n",
        "\n",
        "\n",
        "def reset_mocap2body_xpos(model, data):\n",
        "    \"\"\"Resets the position and orientation of the mocap bodies to the same\n",
        "    values as the bodies they're welded to.\n",
        "    \"\"\"\n",
        "\n",
        "    if model.eq_type is None or model.eq_obj1id is None or model.eq_obj2id is None:\n",
        "        return\n",
        "    for eq_type, obj1_id, obj2_id in zip(\n",
        "        model.eq_type, model.eq_obj1id, model.eq_obj2id\n",
        "    ):\n",
        "        if eq_type != mujoco.mjtEq.mjEQ_WELD:\n",
        "            continue\n",
        "\n",
        "        mocap_id = model.body_mocapid[obj1_id]\n",
        "        if mocap_id != -1:\n",
        "            # obj1 is the mocap, obj2 is the welded body\n",
        "            body_idx = obj2_id\n",
        "        else:\n",
        "            # obj2 is the mocap, obj1 is the welded body\n",
        "            mocap_id = model.body_mocapid[obj2_id]\n",
        "            body_idx = obj1_id\n",
        "\n",
        "        assert mocap_id != -1\n",
        "        data.mocap_pos[mocap_id][:] = data.xpos[body_idx]\n",
        "        data.mocap_quat[mocap_id][:] = data.xquat[body_idx]\n",
        "\n",
        "\n",
        "def get_site_jacp(model, data, site_id):\n",
        "    \"\"\"Return the Jacobian' translational component of the end-effector of\n",
        "    the corresponding site id.\n",
        "    \"\"\"\n",
        "    jacp = np.zeros((3, model.nv))\n",
        "    mujoco.mj_jacSite(model, data, jacp, None, site_id)\n",
        "\n",
        "    return jacp\n",
        "\n",
        "\n",
        "def get_site_jacr(model, data, site_id):\n",
        "    \"\"\"Return the Jacobian' rotational component of the end-effector of\n",
        "    the corresponding site id.\n",
        "    \"\"\"\n",
        "    jacr = np.zeros((3, model.nv))\n",
        "    mujoco.mj_jacSite(model, data, None, jacr, site_id)\n",
        "\n",
        "    return jacr\n",
        "\n",
        "\n",
        "def set_joint_qpos(model, data, name, value):\n",
        "    \"\"\"Set the joint positions (qpos) of the model.\"\"\"\n",
        "    joint_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_JOINT, name)\n",
        "    assert joint_id != -1, f\"Joint with name '{name}' is not part of the model!\"\n",
        "    joint_type = model.jnt_type[joint_id]\n",
        "    joint_addr = model.jnt_qposadr[joint_id]\n",
        "\n",
        "    if joint_type == mujoco.mjtJoint.mjJNT_FREE:\n",
        "        ndim = 7\n",
        "    elif joint_type == mujoco.mjtJoint.mjJNT_BALL:\n",
        "        ndim = 4\n",
        "    else:\n",
        "        assert joint_type in (mujoco.mjtJoint.mjJNT_HINGE, mujoco.mjtJoint.mjJNT_SLIDE)\n",
        "        ndim = 1\n",
        "\n",
        "    start_idx = joint_addr\n",
        "    end_idx = joint_addr + ndim\n",
        "    value = np.array(value)\n",
        "    if ndim > 1:\n",
        "        assert value.shape == (\n",
        "            end_idx - start_idx\n",
        "        ), f\"Value has incorrect shape {name}: {value}\"\n",
        "    data.qpos[start_idx:end_idx] = value\n",
        "\n",
        "\n",
        "def set_joint_qvel(model, data, name, value):\n",
        "    \"\"\"Set the joints linear and angular (qvel) of the model.\"\"\"\n",
        "    joint_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_JOINT, name)\n",
        "    assert joint_id != -1, f\"Joint with name '{name}' is not part of the model!\"\n",
        "    joint_type = model.jnt_type[joint_id]\n",
        "    joint_addr = model.jnt_dofadr[joint_id]\n",
        "\n",
        "    if joint_type == mujoco.mjtJoint.mjJNT_FREE:\n",
        "        ndim = 6\n",
        "    elif joint_type == mujoco.mjtJoint.mjJNT_BALL:\n",
        "        ndim = 3\n",
        "    else:\n",
        "        assert joint_type in (mujoco.mjtJoint.mjJNT_HINGE, mujoco.mjtJoint.mjJNT_SLIDE)\n",
        "        ndim = 1\n",
        "\n",
        "    start_idx = joint_addr\n",
        "    end_idx = joint_addr + ndim\n",
        "    value = np.array(value)\n",
        "    if ndim > 1:\n",
        "        assert value.shape == (\n",
        "            end_idx - start_idx\n",
        "        ), f\"Value has incorrect shape {name}: {value}\"\n",
        "    data.qvel[start_idx:end_idx] = value\n",
        "\n",
        "\n",
        "def get_joint_qpos(model, data, name):\n",
        "    \"\"\"Return the joints position and orientation (qpos) of the model.\"\"\"\n",
        "    joint_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_JOINT, name)\n",
        "    assert joint_id != -1, f\"Joint with name '{name}' is not part of the model!\"\n",
        "    joint_type = model.jnt_type[joint_id]\n",
        "    joint_addr = model.jnt_qposadr[joint_id]\n",
        "\n",
        "    if joint_type == mujoco.mjtJoint.mjJNT_FREE:\n",
        "        ndim = 7\n",
        "    elif joint_type == mujoco.mjtJoint.mjJNT_BALL:\n",
        "        ndim = 4\n",
        "    else:\n",
        "        assert joint_type in (mujoco.mjtJoint.mjJNT_HINGE, mujoco.mjtJoint.mjJNT_SLIDE)\n",
        "        ndim = 1\n",
        "\n",
        "    start_idx = joint_addr\n",
        "    end_idx = joint_addr + ndim\n",
        "\n",
        "    return data.qpos[start_idx:end_idx].copy()\n",
        "\n",
        "\n",
        "def get_joint_qvel(model, data, name):\n",
        "    \"\"\"Return the joints linear and angular velocities (qvel) of the model.\"\"\"\n",
        "    joint_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_JOINT, name)\n",
        "    assert joint_id != -1, f\"Joint with name '{name}' is not part of the model!\"\n",
        "    joint_type = model.jnt_type[joint_id]\n",
        "    joint_addr = model.jnt_dofadr[joint_id]\n",
        "\n",
        "    if joint_type == mujoco.mjtJoint.mjJNT_FREE:\n",
        "        ndim = 6\n",
        "    elif joint_type == mujoco.mjtJoint.mjJNT_BALL:\n",
        "        ndim = 4\n",
        "    else:\n",
        "        assert joint_type in (mujoco.mjtJoint.mjJNT_HINGE, mujoco.mjtJoint.mjJNT_SLIDE)\n",
        "        ndim = 1\n",
        "\n",
        "    start_idx = joint_addr\n",
        "    end_idx = joint_addr + ndim\n",
        "\n",
        "    return data.qvel[start_idx:end_idx].copy()\n",
        "\n",
        "\n",
        "def get_site_xpos(model, data, name):\n",
        "    site_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_SITE, name)\n",
        "    assert site_id != -1, f\"Site with name '{name}' is not part of the model!\"\n",
        "    return data.site_xpos[site_id]\n",
        "\n",
        "\n",
        "def get_site_xvelp(model, data, name):\n",
        "    site_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_SITE, name)\n",
        "    assert site_id != -1, f\"Site with name '{name}' is not part of the model!\"\n",
        "    jacp = get_site_jacp(model, data, site_id)\n",
        "    xvelp = jacp @ data.qvel\n",
        "    return xvelp\n",
        "\n",
        "\n",
        "def get_site_xvelr(model, data, name):\n",
        "    site_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_SITE, name)\n",
        "    assert site_id != -1, f\"Site with name '{name}' is not part of the model!\"\n",
        "    jacp = get_site_jacr(model, data, site_id)\n",
        "    xvelp = jacp @ data.qvel\n",
        "    return xvelp\n",
        "\n",
        "\n",
        "def set_mocap_pos(model, data, name, value):\n",
        "    body_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_BODY, name)\n",
        "    assert body_id != -1, f\"Body with name '{name}' is not part of the model!\"\n",
        "    mocap_id = model.body_mocapid[body_id]\n",
        "    data.mocap_pos[mocap_id] = value\n",
        "\n",
        "\n",
        "def set_mocap_quat(model: MjModel, data: MjData, name: str, value):\n",
        "    body_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_BODY, name)\n",
        "    assert body_id != -1, f\"Body with name '{name}' is not part of the model!\"\n",
        "    mocap_id = model.body_mocapid[body_id]\n",
        "    data.mocap_quat[mocap_id] = value\n",
        "\n",
        "\n",
        "def get_site_xmat(model: MjModel, data: MjData, name: str):\n",
        "    site_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_SITE, name)\n",
        "    assert site_id != -1, f\"Site with name '{name}' is not part of the model!\"\n",
        "    return data.site_xmat[site_id].reshape(3, 3)\n",
        "\n",
        "\n",
        "def extract_mj_names(\n",
        "    model: MjModel, obj_type: mjtObj\n",
        ") -> Tuple[Union[Tuple[str, ...], Tuple[()]], Dict[str, int], Dict[int, str]]:\n",
        "\n",
        "    if obj_type == mujoco.mjtObj.mjOBJ_BODY:\n",
        "        name_addr = model.name_bodyadr\n",
        "        n_obj = model.nbody\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_JOINT:\n",
        "        name_addr = model.name_jntadr\n",
        "        n_obj = model.njnt\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_GEOM:\n",
        "        name_addr = model.name_geomadr\n",
        "        n_obj = model.ngeom\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_SITE:\n",
        "        name_addr = model.name_siteadr\n",
        "        n_obj = model.nsite\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_LIGHT:\n",
        "        name_addr = model.name_lightadr\n",
        "        n_obj = model.nlight\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_CAMERA:\n",
        "        name_addr = model.name_camadr\n",
        "        n_obj = model.ncam\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_ACTUATOR:\n",
        "        name_addr = model.name_actuatoradr\n",
        "        n_obj = model.nu\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_SENSOR:\n",
        "        name_addr = model.name_sensoradr\n",
        "        n_obj = model.nsensor\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_TENDON:\n",
        "        name_addr = model.name_tendonadr\n",
        "        n_obj = model.ntendon\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_MESH:\n",
        "        name_addr = model.name_meshadr\n",
        "        n_obj = model.nmesh\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"`{}` was passed as the MuJoCo model object type. The MuJoCo model object type can only be of the following mjtObj enum types: {}.\".format(\n",
        "                obj_type, MJ_OBJ_TYPES\n",
        "            )\n",
        "        )\n",
        "\n",
        "    id2name = {i: None for i in range(n_obj)}\n",
        "    name2id = {}\n",
        "    for addr in name_addr:\n",
        "        name = model.names[addr:].split(b\"\\x00\")[0].decode()\n",
        "        if name:\n",
        "            obj_id = mujoco.mj_name2id(model, obj_type, name)\n",
        "            assert 0 <= obj_id < n_obj and id2name[obj_id] is None\n",
        "            name2id[name] = obj_id\n",
        "            id2name[obj_id] = name\n",
        "\n",
        "    return tuple(id2name[id] for id in sorted(name2id.values())), name2id, id2name\n",
        "\n",
        "\n",
        "class MujocoModelNames:\n",
        "    \"\"\"Access mjtObj object names and ids of the current MuJoCo model.\n",
        "\n",
        "    This class supports access to the names and ids of the following mjObj types:\n",
        "        mjOBJ_BODY\n",
        "        mjOBJ_JOINT\n",
        "        mjOBJ_GEOM\n",
        "        mjOBJ_SITE\n",
        "        mjOBJ_CAMERA\n",
        "        mjOBJ_ACTUATOR\n",
        "        mjOBJ_SENSOR\n",
        "\n",
        "    The properties provided for each ``mjObj`` are:\n",
        "        ``mjObj``_names: list of the mjObj names in the model of type mjOBJ_FOO.\n",
        "        ``mjObj``_name2id: dictionary with name of the mjObj as keys and id of the mjObj as values.\n",
        "        ``mjObj``_id2name: dictionary with id of the mjObj as keys and name of the mjObj as values.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model: MjModel):\n",
        "        \"\"\"Access mjtObj object names and ids of the current MuJoCo model.\n",
        "\n",
        "        Args:\n",
        "            model: mjModel of the MuJoCo environment.\n",
        "        \"\"\"\n",
        "        (\n",
        "            self._body_names,\n",
        "            self._body_name2id,\n",
        "            self._body_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_BODY)\n",
        "        (\n",
        "            self._joint_names,\n",
        "            self._joint_name2id,\n",
        "            self._joint_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_JOINT)\n",
        "        (\n",
        "            self._geom_names,\n",
        "            self._geom_name2id,\n",
        "            self._geom_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_GEOM)\n",
        "        (\n",
        "            self._site_names,\n",
        "            self._site_name2id,\n",
        "            self._site_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_SITE)\n",
        "        (\n",
        "            self._camera_names,\n",
        "            self._camera_name2id,\n",
        "            self._camera_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_CAMERA)\n",
        "        (\n",
        "            self._actuator_names,\n",
        "            self._actuator_name2id,\n",
        "            self._actuator_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_ACTUATOR)\n",
        "        (\n",
        "            self._sensor_names,\n",
        "            self._sensor_name2id,\n",
        "            self._sensor_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_SENSOR)\n",
        "\n",
        "    @property\n",
        "    def body_names(self):\n",
        "        return self._body_names\n",
        "\n",
        "    @property\n",
        "    def body_name2id(self):\n",
        "        return self._body_name2id\n",
        "\n",
        "    @property\n",
        "    def body_id2name(self):\n",
        "        return self._body_id2name\n",
        "\n",
        "    @property\n",
        "    def joint_names(self):\n",
        "        return self._joint_names\n",
        "\n",
        "    @property\n",
        "    def joint_name2id(self):\n",
        "        return self._joint_name2id\n",
        "\n",
        "    @property\n",
        "    def joint_id2name(self):\n",
        "        return self._joint_id2name\n",
        "\n",
        "    @property\n",
        "    def geom_names(self):\n",
        "        return self._geom_names\n",
        "\n",
        "    @property\n",
        "    def geom_name2id(self):\n",
        "        return self._geom_name2id\n",
        "\n",
        "    @property\n",
        "    def geom_id2name(self):\n",
        "        return self._geom_id2name\n",
        "\n",
        "    @property\n",
        "    def site_names(self):\n",
        "        return self._site_names\n",
        "\n",
        "    @property\n",
        "    def site_name2id(self):\n",
        "        return self._site_name2id\n",
        "\n",
        "    @property\n",
        "    def site_id2name(self):\n",
        "        return self._site_id2name\n",
        "\n",
        "    @property\n",
        "    def camera_names(self):\n",
        "        return self._camera_names\n",
        "\n",
        "    @property\n",
        "    def camera_name2id(self):\n",
        "        return self._camera_name2id\n",
        "\n",
        "    @property\n",
        "    def camera_id2name(self):\n",
        "        return self._camera_id2name\n",
        "\n",
        "    @property\n",
        "    def actuator_names(self):\n",
        "        return self._actuator_names\n",
        "\n",
        "    @property\n",
        "    def actuator_name2id(self):\n",
        "        return self._actuator_name2id\n",
        "\n",
        "    @property\n",
        "    def actuator_id2name(self):\n",
        "        return self._actuator_id2name\n",
        "\n",
        "    @property\n",
        "    def sensor_names(self):\n",
        "        return self._sensor_names\n",
        "\n",
        "    @property\n",
        "    def sensor_name2id(self):\n",
        "        return self._sensor_name2id\n",
        "\n",
        "    @property\n",
        "    def sensor_id2name(self):\n",
        "        return self._sensor_id2name\n"
      ],
      "metadata": {
        "id": "nJrY82ddynPi"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ant_maze_v5.py\n",
        "\n",
        "import sys\n",
        "from os import path\n",
        "from typing import Dict, List, Optional, Union\n",
        "\n",
        "import numpy as np\n",
        "from gymnasium import spaces\n",
        "from gymnasium.envs.mujoco.ant_v5 import AntEnv\n",
        "from gymnasium.utils.ezpickle import EzPickle\n",
        "\n",
        "# from gymnasium_robotics.envs.maze.maps import U_MAZE\n",
        "# from gymnasium_robotics.envs.maze.maze_v4 import MazeEnv\n",
        "# from gymnasium_robotics.utils.mujoco_utils import MujocoModelNames\n",
        "\n",
        "\n",
        "class AntMazeEnv(MazeEnv, EzPickle):\n",
        "\n",
        "    metadata = {\n",
        "        \"render_modes\": [\n",
        "            \"human\",\n",
        "            \"rgb_array\",\n",
        "            \"depth_array\",\n",
        "        ],\n",
        "        \"render_fps\": 50,\n",
        "    }\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        render_mode: Optional[str] = None,\n",
        "        maze_map: List[List[Union[str, int]]] = U_MAZE,\n",
        "        reward_type: str = \"sparse\",\n",
        "        continuing_task: bool = True,\n",
        "        reset_target: bool = False,\n",
        "        xml_file: Union[str, None] = None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        if xml_file is None:\n",
        "            # Get the ant.xml path from the Gymnasium package\n",
        "            ant_xml_file_path = path.join(\n",
        "                path.dirname(sys.modules[AntEnv.__module__].__file__), \"assets/ant.xml\"\n",
        "            )\n",
        "        else:\n",
        "            ant_xml_file_path = xml_file\n",
        "        super().__init__(\n",
        "            agent_xml_path=ant_xml_file_path,\n",
        "            maze_map=maze_map,\n",
        "            maze_size_scaling=4,\n",
        "            maze_height=0.5,\n",
        "            reward_type=reward_type,\n",
        "            continuing_task=continuing_task,\n",
        "            reset_target=reset_target,\n",
        "            **kwargs,\n",
        "        )\n",
        "        # Create the MuJoCo environment, include position observation of the Ant for GoalEnv\n",
        "        self.ant_env = AntEnv(\n",
        "            xml_file=self.tmp_xml_file_path,\n",
        "            exclude_current_positions_from_observation=False,\n",
        "            render_mode=render_mode,\n",
        "            reset_noise_scale=0.0,\n",
        "            **kwargs,\n",
        "        )\n",
        "        self._model_names = MujocoModelNames(self.ant_env.model)\n",
        "        self.target_site_id = self._model_names.site_name2id[\"target\"]\n",
        "\n",
        "        self.action_space = self.ant_env.action_space\n",
        "        obs_shape: tuple = self.ant_env.observation_space.shape\n",
        "        self.observation_space = spaces.Dict(\n",
        "            dict(\n",
        "                observation=spaces.Box(\n",
        "                    -np.inf, np.inf, shape=(obs_shape[0] - 2,), dtype=\"float64\"\n",
        "                ),\n",
        "                achieved_goal=spaces.Box(-np.inf, np.inf, shape=(2,), dtype=\"float64\"),\n",
        "                desired_goal=spaces.Box(-np.inf, np.inf, shape=(2,), dtype=\"float64\"),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.render_mode = render_mode\n",
        "        EzPickle.__init__(\n",
        "            self,\n",
        "            render_mode,\n",
        "            maze_map,\n",
        "            reward_type,\n",
        "            continuing_task,\n",
        "            reset_target,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    def reset(self, *, seed: Optional[int] = None, **kwargs):\n",
        "        super().reset(seed=seed, **kwargs)\n",
        "\n",
        "        self.ant_env.init_qpos[:2] = self.reset_pos\n",
        "\n",
        "        obs, info = self.ant_env.reset(seed=seed)\n",
        "        obs_dict = self._get_obs(obs)\n",
        "        info[\"success\"] = bool(\n",
        "            np.linalg.norm(obs_dict[\"achieved_goal\"] - self.goal) <= 0.45\n",
        "        )\n",
        "\n",
        "        return obs_dict, info\n",
        "\n",
        "    def step(self, action):\n",
        "        ant_obs, _, _, _, info = self.ant_env.step(action)\n",
        "        obs = self._get_obs(ant_obs)\n",
        "\n",
        "        reward = self.compute_reward(obs[\"achieved_goal\"], self.goal, info)\n",
        "        terminated = self.compute_terminated(obs[\"achieved_goal\"], self.goal, info)\n",
        "        truncated = self.compute_truncated(obs[\"achieved_goal\"], self.goal, info)\n",
        "        info[\"success\"] = bool(np.linalg.norm(obs[\"achieved_goal\"] - self.goal) <= 0.45)\n",
        "\n",
        "        if self.render_mode == \"human\":\n",
        "            self.render()\n",
        "\n",
        "        # Update the goal position if necessary\n",
        "        self.update_goal(obs[\"achieved_goal\"])\n",
        "\n",
        "        return obs, reward, terminated, truncated, info\n",
        "\n",
        "    def _get_obs(self, ant_obs: np.ndarray) -> Dict[str, np.ndarray]:\n",
        "        achieved_goal = ant_obs[:2]\n",
        "        observation = ant_obs[2:]\n",
        "\n",
        "        return {\n",
        "            \"observation\": observation.copy(),\n",
        "            \"achieved_goal\": achieved_goal.copy(),\n",
        "            \"desired_goal\": self.goal.copy(),\n",
        "        }\n",
        "\n",
        "    def update_target_site_pos(self):\n",
        "        self.ant_env.model.site_pos[self.target_site_id] = np.append(\n",
        "            self.goal, self.maze.maze_height / 2 * self.maze.maze_size_scaling\n",
        "        )\n",
        "\n",
        "    def render(self):\n",
        "        return self.ant_env.render()\n",
        "\n",
        "    def close(self):\n",
        "        super().close()\n",
        "        self.ant_env.close()\n",
        "\n",
        "    @property\n",
        "    def model(self):\n",
        "        return self.ant_env.model\n",
        "\n",
        "    @property\n",
        "    def data(self):\n",
        "        return self.ant_env.data\n"
      ],
      "metadata": {
        "id": "by4KHCH_3wdS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xSc_wfjI5DJE"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AU26AZroN07L"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AntMazeEnv(MazeEnv, EzPickle):\n",
        "    metadata = {\n",
        "        \"render_modes\": [\n",
        "            \"human\",\n",
        "            \"rgb_array\",\n",
        "            \"depth_array\",\n",
        "        ],\n",
        "        \"render_fps\": 50,\n",
        "    }\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        render_mode: Optional[str] = None,\n",
        "        maze_map: List[List[Union[str, int]]] = None,\n",
        "        reward_type: str = \"sparse\",\n",
        "        continuing_task: bool = True,\n",
        "        reset_target: bool = False,\n",
        "        xml_file: Union[str, None] = None,\n",
        "        max_episode_steps: int = 1000,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        if xml_file is None:\n",
        "            ant_xml_file_path = path.join(\n",
        "                path.dirname(sys.modules[AntEnv.__module__].__file__), \"assets/ant.xml\"\n",
        "            )\n",
        "        else:\n",
        "            ant_xml_file_path = xml_file\n",
        "\n",
        "        super().__init__(\n",
        "            agent_xml_path=ant_xml_file_path,\n",
        "            maze_map=maze_map,\n",
        "            maze_size_scaling=4,\n",
        "            maze_height=0.5,\n",
        "            reward_type=reward_type,\n",
        "            continuing_task=continuing_task,\n",
        "            reset_target=reset_target,\n",
        "            **kwargs,\n",
        "        )\n",
        "        self.ant_env = AntEnv(\n",
        "            xml_file=self.tmp_xml_file_path,\n",
        "            exclude_current_positions_from_observation=False,\n",
        "            render_mode=\"rgb_array\",\n",
        "            reset_noise_scale=0.0,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        # ゴール位置のサイト ID を取得\n",
        "        self._model_names = MujocoModelNames(self.ant_env.model)\n",
        "        self.target_site_id = self._model_names.site_name2id[\"target\"]\n",
        "\n",
        "        self.action_space = self.ant_env.action_space\n",
        "\n",
        "        self.observation_space = spaces.Dict(\n",
        "            dict(\n",
        "                observation=spaces.Box(low=0, high=255, shape=(256, 256, 3), dtype=np.uint8),\n",
        "                achieved_goal=spaces.Box(low=-np.inf, high=np.inf, shape=(2,), dtype=np.float32),\n",
        "                desired_goal=spaces.Box(low=-np.inf, high=np.inf, shape=(2,), dtype=np.float32),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.render_mode = render_mode\n",
        "        EzPickle.__init__(\n",
        "            self,\n",
        "            render_mode,\n",
        "            maze_map,\n",
        "            reward_type,\n",
        "            continuing_task,\n",
        "            reset_target,\n",
        "            max_episode_steps,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    def reset(self, *, seed: Optional[int] = None, **kwargs):\n",
        "        \"\"\"\n",
        "        環境をリセットし、初期状態を返す\n",
        "        \"\"\"\n",
        "        # MazeEnv のリセットを呼び出して初期化\n",
        "        super().reset(seed=seed, **kwargs)\n",
        "\n",
        "        # ゴールと初期位置を反映\n",
        "        self.ant_env.init_qpos[:2] = self.reset_pos\n",
        "        self.ant_env.reset(seed=seed)\n",
        "\n",
        "        self.update_target_site_pos()\n",
        "\n",
        "        return self._get_obs()\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        1ステップ実行\n",
        "        \"\"\"\n",
        "        _, _, _, _, info = self.ant_env.step(action)\n",
        "        obs = self._get_obs()\n",
        "        achieved_goal = self.ant_env.data.qpos[:2]\n",
        "        reward = self.compute_reward(achieved_goal, self.goal, {})\n",
        "        terminated = self.compute_terminated(achieved_goal, self.goal, {})\n",
        "        truncated = False\n",
        "        info = {\"success\": terminated}\n",
        "        return obs, reward, terminated, truncated, info\n",
        "\n",
        "    def _get_obs(self) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"\n",
        "        現在の観測を取得\n",
        "        \"\"\"\n",
        "        import mujoco\n",
        "        from mujoco.glfw import glfw\n",
        "\n",
        "        width, height = 256, 256\n",
        "        rgb_array = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "        depth_array = np.zeros((height, width), dtype=np.float32)\n",
        "\n",
        "        # GLFW の初期化\n",
        "        if not glfw.init():\n",
        "            raise RuntimeError(\"Failed to initialize GLFW\")\n",
        "\n",
        "        # GLFW ウィンドウの作成（オフスクリーン用）\n",
        "        glfw.window_hint(glfw.VISIBLE, glfw.FALSE)  # ウィンドウを非表示にする\n",
        "        window = glfw.create_window(width, height, \"MuJoCo Offscreen\", None, None)\n",
        "        if not window:\n",
        "            glfw.terminate()\n",
        "            raise RuntimeError(\"Failed to create GLFW window\")\n",
        "\n",
        "        # OpenGL コンテキストを現在のスレッドに設定\n",
        "        glfw.make_context_current(window)\n",
        "\n",
        "        # MuJoCo 描画コンテキストの作成\n",
        "        context = mujoco.MjrContext(self.ant_env.model, mujoco.mjtFontScale.mjFONTSCALE_150)\n",
        "\n",
        "        # カメラ設定\n",
        "        camera = mujoco.MjvCamera()\n",
        "        mujoco.mjv_defaultCamera(camera)\n",
        "        camera.lookat[:] = [0, 0, 0]\n",
        "        camera.distance = 16.0  # 必要に応じて調整\n",
        "        camera.azimuth = 90\n",
        "        camera.elevation = -90\n",
        "\n",
        "        # シーン設定\n",
        "        scene = mujoco.MjvScene(self.ant_env.model, maxgeom=1000)\n",
        "        mujoco.mjv_updateScene(\n",
        "            self.ant_env.model,\n",
        "            self.ant_env.data,\n",
        "            mujoco.MjvOption(),\n",
        "            None,\n",
        "            camera,\n",
        "            mujoco.mjtCatBit.mjCAT_ALL,\n",
        "            scene,\n",
        "        )\n",
        "\n",
        "        # 描画\n",
        "        mujoco.mjr_render(\n",
        "            mujoco.MjrRect(0, 0, width, height),\n",
        "            scene,\n",
        "            context,\n",
        "        )\n",
        "\n",
        "        # ピクセルデータを取得\n",
        "        mujoco.mjr_readPixels(rgb_array, depth_array, mujoco.MjrRect(0, 0, width, height), context)\n",
        "\n",
        "        # GLFW を終了\n",
        "        glfw.terminate()\n",
        "\n",
        "        # ゴールと観測データを取得\n",
        "        achieved_goal = self.ant_env.data.qpos[:2]\n",
        "\n",
        "        return {\n",
        "            \"observation\": rgb_array,\n",
        "            \"achieved_goal\": achieved_goal,\n",
        "            \"desired_goal\": self.goal,\n",
        "        }\n",
        "\n",
        "\n",
        "    def update_target_site_pos(self):\n",
        "        \"\"\"\n",
        "        ゴール位置を MuJoCo シミュレーションに反映\n",
        "        \"\"\"\n",
        "        pos = self.goal  # ゴール位置を設定\n",
        "        self.ant_env.model.site_pos[self.target_site_id] = np.append(\n",
        "            pos, self.maze.maze_height / 2 * self.maze.maze_size_scaling\n",
        "        )\n",
        "\n",
        "    def render(self):\n",
        "        \"\"\"\n",
        "        人間向けレンダリング\n",
        "        \"\"\"\n",
        "        return self.ant_env.render(mode=\"human\")\n",
        "\n",
        "    def close(self):\n",
        "        super().close()\n",
        "        self.ant_env.close()\n"
      ],
      "metadata": {
        "id": "50V4qSC8xtyA"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# カスタム迷路を指定\n",
        "custom_map = [\n",
        "    [1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1],\n",
        "]\n",
        "# 環境を作成\n",
        "env = AntMazeEnv(maze_map=custom_map, max_episode_steps=1000)\n",
        "\n",
        "# 環境をリセット\n",
        "obs = env.reset()\n",
        "\n",
        "# 1ステップ実行\n",
        "action = env.action_space.sample()\n",
        "obs, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "# エピソード終了フラグ\n",
        "done = terminated or truncated\n",
        "\n",
        "# 観測画像を表示\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(obs[\"observation\"])\n",
        "plt.title(f\"Reward: {reward}, Done: {done}\")\n",
        "plt.show()\n",
        "\n",
        "# 環境を閉じる\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "MQXYNegWBbqg",
        "outputId": "73577824-7011-4cd6-ed14-0c778b88dcb1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa4AAAGzCAYAAAB3vfPfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACiFUlEQVR4nOydeZwcZZ3/31XV15w99z2Z3HdIQoAcEBIIEBBQFESRFXARlUNFRBF3RcH9Leq6K+qiuK6CFx6wIoqCcieBJJCEQO47mWQy991z9FXP74/JdLp7+qyquTLPm9eQ7qrn+T7feurp51PPt56qRxFCCCQSiUQiGSeoo+2ARCKRSCTpIIVLIpFIJOMKKVwSiUQiGVdI4ZJIJBLJuEIKl0QikUjGFVK4JBKJRDKukMIlkUgkknGFFC6JRCKRjCukcEkkEolkXCGFSzJhUBSFb3zjG6PthmQEueWWW5g8efJouyGxGClcEp544gkURQn92Ww2KisrueWWW6irqxtt98YMXq+X++67j4qKCjIyMli6dCkvvvhiyvnr6uq4/vrrycvLIzc3lw984AMcPnzYsD/f+MY3Is5bZmYmkyZN4uqrr+bxxx/H6/Uatj3arF69OuLYwv/27t072u5JRhnbaDsgGTs89NBDTJkyhf7+fjZt2sQTTzzBhg0b2LlzJy6Xa7TdG3VuueUWnn76ae6++25mzJjBE088wfve9z5effVVLrjggoR5PR4PF110EZ2dnXz1q1/Fbrfzve99j1WrVrF9+3YKCwsN+/XjH/+Y7OxsvF4vdXV1/P3vf+ef//mfeeSRR3juueeorq42bHs0qaqq4uGHHx6yvaKiYhS8kYwphGTC8/jjjwtAvP322xHb77vvPgGI3//+96PkWXp4PJ6E+wHx9a9/3ZDtzZs3C0D8x3/8R2hbX1+fmDZtmli+fHnS/N/+9rcFIN56663Qtj179ghN08T9999vyKevf/3rAhDNzc1D9v36178WqqqKpUuXGrI92qxatUrMmzfPtJ2bb75Z1NTUmHdIMqaQoUJJXFauXAnAoUOHIrbv3buX6667joKCAlwuF+eccw5//vOfQ/s7OjrQNI0f/OAHoW0tLS2oqkphYSEibEGC22+/nbKystD39evX8+EPf5hJkybhdDqprq7mC1/4An19fRE+3HLLLWRnZ3Po0CHe9773kZOTw4033ggMhPS+8IUvUFxcTE5ODu9///s5ceJEzGPcu3cvtbW1Sevi6aefRtM0PvWpT4W2uVwubr31VjZu3Mjx48eT5j/33HM599xzQ9tmz57NmjVr+MMf/pC0/HS58cYb+eQnP8nmzZuHhDOfeuoplixZQkZGBkVFRfzTP/3TkJDwYP3W1dVxzTXXkJ2dTXFxMffeey/BYDAira7rPPLII8ybNw+Xy0VpaSmf/vSnaW9vj0jX2dnJ3r176ezsNH18zz77LFdeeSUVFRU4nU6mTZvGN7/5zSG+xeJ3v/sdS5YsIScnh9zcXBYsWMD3v//9iDQdHR3cfffdVFdX43Q6mT59Ot/+9rfRdd207xLzSOGSxOXo0aMA5Ofnh7bt2rWLZcuWsWfPHr7yla/wn//5n2RlZXHNNdfwzDPPAJCXl8f8+fNZt25dKN+GDRtQFIW2tjZ2794d2r5+/fqQQMJAp9rb28vtt9/OD3/4Q9auXcsPf/hDbrrppiH+BQIB1q5dS0lJCd/97ne59tprAfjkJz/JI488wmWXXca3vvUt7HY7V155ZcxjnDNnTkzb0bzzzjvMnDmT3NzciO3nnXceANu3b4+bV9d13nvvPc4555wh+8477zwOHTpEd3d3Uh/S5eMf/zgA//jHP0LbnnjiCa6//no0TePhhx/mtttu449//CMXXHABHR0dEfmDwSBr166lsLCQ7373u6xatYr//M//5H/+538i0n3605/mS1/6Eueffz7f//73+cQnPsFvfvMb1q5di9/vD6V75plnmDNnTqidJCMYDNLS0hLx5/F4QseRnZ3NPffcw/e//32WLFnCAw88wFe+8pWENl988UVuuOEG8vPz+fa3v823vvUtVq9ezRtvvBFK09vby6pVq/j1r3/NTTfdxA9+8APOP/987r//fu65556UfJcMM6M95JOMPoOhwpdeekk0NzeL48ePi6effloUFxcLp9Mpjh8/Hkq7Zs0asWDBAtHf3x/apuu6WLFihZgxY0Zo25133ilKS0tD3++55x5x4YUXipKSEvHjH/9YCCFEa2urUBRFfP/73w+l6+3tHeLfww8/LBRFEceOHQttu/nmmwUgvvKVr0Sk3b59uwDEHXfcEbH9Yx/7WMxQISBWrVqVtI7mzZsnLr744iHbd+3aJQDx2GOPxc3b3NwsAPHQQw8N2ffoo48KQOzduzepD9EkChUKIUR7e7sAxAc/+EEhhBA+n0+UlJSI+fPni76+vlC65557TgDigQceCG0brN9onxcvXiyWLFkS+r5+/XoBiN/85jcR6V544YUh2wfb2eOPP5702FatWiWAIX8333yzECJ2O/n0pz8tMjMzI9pmdKjw85//vMjNzRWBQCBu2d/85jdFVlaW2L9/f8T2r3zlK0LTNFFbW5vUf8nwIkdckhCXXHIJxcXFVFdXc91115GVlcWf//xnqqqqAGhra+OVV17h+uuvp7u7O3QV3Nraytq1azlw4EAo5LRy5UoaGxvZt28fMDCyuvDCC1m5ciXr168HBkZhQoiIEVdGRkboc09PDy0tLaxYsQIhBO+8884Qn2+//faI73/7298A+NznPhex/e677455zEIIXnvttaR109fXh9PpHLJ9cNJKdCgzOi9gOL9RsrOzAUKjuS1bttDU1MQdd9wRMdnmyiuvZPbs2fz1r38dYuMzn/lMxPeVK1dGzIR86qmncLvdXHrppREjoyVLlpCdnc2rr74aSnvLLbcghOCWW25Jyf/Jkyfz4osvRvx9+ctfBiLbyWBbXLlyJb29vQlnHebl5dHT05NwNuhTTz3FypUryc/PjzimSy65hGAwGBFJkIwOclahJMSjjz7KzJkz6ezs5Oc//znr1q2L6GwPHjyIEIKvfe1rfO1rX4tpo6mpicrKypAYrV+/nqqqKt555x3+7d/+jeLiYr773e+G9uXm5rJw4cJQ/traWh544AH+/Oc/x7xHEo7NZguJ6iDHjh1DVVWmTZsWsX3WrFlp1kYkGRkZMaeX9/f3h/YnygsYzm+UwbBaTk4OMFA3ELsuZs+ezYYNGyK2uVwuiouLI7bl5+dHnJcDBw7Q2dlJSUlJTB+ampoM+5+VlcUll1wSc9+uXbv413/9V1555RW6uroi9iW6h3bHHXfwhz/8gSuuuILKykouu+wyrr/+ei6//PJQmgMHDvDee+8NOfZBzByTxBqkcElCnHfeeaH7MNdccw0XXHABH/vYx9i3bx/Z2dmhG9P33nsva9eujWlj+vTpwMCU5SlTprBu3TomT56MEILly5dTXFzM5z//eY4dO8b69etZsWIFqjow8A8Gg1x66aW0tbVx3333MXv2bLKysqirq+OWW24ZcmPc6XSG8g435eXlMZ9pq6+vBxJP0S4oKMDpdIbSppvfKDt37gROn5N00TQtaRpd1ykpKeE3v/lNzP3xOn8zdHR0sGrVKnJzc3nooYeYNm0aLpeLbdu2cd999yWcQFFSUsL27dv5+9//zvPPP8/zzz/P448/zk033cQvfvGL0DFdeumlodFdNDNnzrT8mCTpIYVLEpPBm/cXXXQR//3f/81XvvIVpk6dCoDdbo97JRzOypUrWbduHVOmTGHRokXk5OSwcOFC3G43L7zwAtu2bePBBx8Mpd+xYwf79+/nF7/4RcSEiXQe8q2pqUHXdQ4dOhQxshgMWRpl0aJFvPrqq3R1dUVM0Ni8eXNofzxUVWXBggVs2bJlyL7NmzczderU0KjISn71q18BhC4yampqgIG6uPjiiyPS7tu3L7Q/HaZNm8ZLL73E+eefPyyjxli89tprtLa28sc//pELL7wwtP3IkSMp5Xc4HFx99dVcffXV6LrOHXfcwU9+8hO+9rWvMX36dKZNm4bH40mpjUtGB3mPSxKX1atXc9555/HII4/Q399PSUkJq1ev5ic/+UnM0UNzc3PE95UrV3L06FF+//vfh0KHqqqyYsUK/uu//gu/3x9xf2vwCl+ETZcXQgyZqpyIK664AiBiKj7AI488EjN9qtPhr7vuOoLBYMSMOq/Xy+OPP87SpUsjHvKtra0dcp/luuuu4+23344Qr3379vHKK6/w4Q9/OGn56fLkk0/yv//7vyxfvpw1a9YAcM4551BSUsJjjz0WEbZ8/vnn2bNnT9yZl4m4/vrrCQaDfPOb3xyyLxAIRMxUtGo6fKx24vP5+NGPfpQ0b2tra8R3VVU566yzgNOh3Ouvv56NGzfy97//fUj+jo4OAoGAYd8l1iBHXJKEfOlLX+LDH/4wTzzxBJ/5zGd49NFHueCCC1iwYAG33XYbU6dOpbGxkY0bN3LixAnefffdUN5BUdq3bx///u//Htp+4YUX8vzzz+N0Ooc81zRt2jTuvfde6urqyM3N5f/+7/+G3OtKxKJFi7jhhhv40Y9+RGdnJytWrODll1/m4MGDMdPPmTOHVatWJZ2gsXTpUj784Q9z//3309TUxPTp0/nFL37B0aNH+dnPfhaR9qabbuL111+P6FjvuOMOfvrTn3LllVdy7733Yrfb+a//+i9KS0v54he/GJF/9erVQ/In4umnnyY7Oxufzxd6c8Ybb7zBwoULeeqpp0Lp7HY73/72t/nEJz7BqlWruOGGG2hsbOT73/8+kydP5gtf+EJK5YWzatUqPv3pT/Pwww+zfft2LrvsMux2OwcOHOCpp57i+9//Ptdddx0wMB3+E5/4BI8//njKEzRisWLFCvLz87n55pv53Oc+h6Io/OpXv0qpvj75yU/S1tbGxRdfTFVVFceOHeOHP/whixYtYs6cOcBAm//zn//MVVddxS233MKSJUvo6elhx44dPP300xw9epSioiLD/kssYHQmM0rGEvHenCGEEMFgUEybNk1MmzYtNIX40KFD4qabbhJlZWXCbreLyspKcdVVV4mnn356SP6SkhIBiMbGxtC2DRs2CECsXLlySPrdu3eLSy65RGRnZ4uioiJx2223iXfffXfINOqbb75ZZGVlxTyevr4+8bnPfU4UFhaKrKwscfXVV4vjx4+bmg4/aPfee+8VZWVlwul0inPPPVe88MILQ9INTuWO5vjx4+K6664Tubm5Ijs7W1x11VXiwIEDQ9ItWbJElJWVJfVncDr84J/L5RJVVVXiqquuEj//+c8jpoWH8/vf/14sXrxYOJ1OUVBQIG688UZx4sSJiDTx6newzGj+53/+RyxZskRkZGSInJwcsWDBAvHlL39ZnDx5MpQm3enwid6c8cYbb4hly5aJjIwMUVFRIb785S+Lv//97wIQr776asRxhE+Hf/rpp8Vll10mSkpKhMPhEJMmTRKf/vSnRX19fYT97u5ucf/994vp06cLh8MhioqKxIoVK8R3v/td4fP5kvovGV4UIVK8rJNIJMNOd3c3BQUFPPLII9x5552j7Y5EMiaR97gkkjHEunXrqKys5LbbbhttVySSMYsccUkkEolkXCFHXBKJRCIZV0jhkkgkEsm4YtSE69FHH2Xy5Mm4XC6WLl3KW2+9NVquSCQSiWQcMSrC9fvf/5577rmHr3/962zbto2FCxeydu1a+Q4wiUQikSRlVCZnLF26lHPPPZf//u//BgbeDVZdXc1nP/vZmOvpeL3eiCf9dV2nra2NwsJCFEUZMb8lEolEYg1CCLq7u6moqEj7naMj/uYMn8/H1q1buf/++0PbVFXlkksuYePGjTHzPPzwwxHvtJNIJBLJmcHx48eHrPKQjBEXrpaWFoLBIKWlpRHbS0tL466jE73yaGdnJ5MmTSIvyyFHXBKJRDIOEULQ0eMz9ILpcfGuQqfTGXMRPkVRpHBJJBLJOMZIHz7ikzOKiorQNI3GxsaI7Y2NjZSVlY20OxKJRCIZZ4y4cDkcDpYsWcLLL78c2qbrOi+//DLLly8faXckEolEMs4YlVDhPffcw80338w555wTWu+pp6eHT3ziE6PhjkQikUjGEaMiXB/5yEdobm7mgQceoKGhgUWLFvHCCy8MmbAhkUgkEkk04/Ilu11dXbjdbvKznXJyhkQikYxDhBC0e7x0dnaSm5ubVl75rkKJRCKRjCukcEkkEolkXCGFSyKRSCTjCilcEolEIhlXSOGSSCQSybhCCpdEIpFIxhVSuCQSiUQyrpDCJZFIJJJxxbh4O/xwcedn7+ac884zZSNIAK/o5blnnqP26HEaTzbET5zkWensnBzKykq57dbPoGqaKb9auhs5cvQIr/79Vdpb2ggEg4bsaKrK8lXLmTd7AdOnzjTlU7+3j90Hd7Du5fU0nKwnGNQN25qzYA6Xf+ByynIqUFVzdbVj97vs2bebLZveJt7j+Kk+5v65z32BqqpqU/4IdHy+Pv74pz9Se6yW1uZWw7by8vOomTyFG2/4uCmfANr7Wti1YyebNmyipakFXTd2/pwuF+evWsGi+WdTVlphyqcuTyeHjh/ghT8/T2dHJ7qJNrX8whWcf+EKSnLKweSLDd7atpEDB/bz7tZ3Tdmx2Wzc/5V/JSfNB3SHotPV1cGzzz3L0cNH6e7qNmwpv7CAXo+HE0drTfpknAktXOecdx7v/8AHTdkI4KdP97Dzvd10dnXT1Nhs2FZGVibFZWVcefUHsNvtpvw63n6Erdu2sHXzNro6u9ENvh9Fs9mYPnsmKy5cybIlK0z51N3TRdaWTHa8u4vmphaECMRPnKTfqKiuZM0VlzClYAY2zVxdZbgz6Nf72fb2O8R7kYySonRduOoi5s9fYMofnSB9fR62vLuN9vZO2ts6DdvKzMmmetIkrn7/NabeMiOEoKHnBJrTxu5de2lr6wCDIuFwOpk9fy6r16xh5rTZhn0CaG5rZMuuAta/ugGPpxcwdoEGMG3WdNa87zJqCqahKuaCUQHNT3/Ay47tu0zZsdkdXLr2CkpKSkzZEQRpbm5ky45tNDY209PTZ9hWdm5O3N/JSDGhhcsKbNjJwo2nu4fmhmZqjxi/CvH2e8nLzbPEL7vdjggKGk42UHukFp/PZ8iOzWajv6+fYMB4hxBNY30jRw8fNWWzvbUdl8tlySu/AoEAPT09HDt0zPQP0uc1Vs/hqGgowk5HRwcn605y9NBRw7aCepBJ1TWmfQJwOO34vD7q6+o5euio4dFNjjuH3r5eggajANEIIairrePEsROmbHZ3deNwOlIeXSfC7w/Q3dlt6tzBwGoa1tSTiq4rdLR3UFdbR31dvSlrejDBRecIIO9xSSSS8YtC6nHcCUyqEYPxghSuM5kzq61KDGJ1p6Wc+k8iGS2kcJ2pyH5Fwpl3pS2RgBQuSQqM1evrsemVZMSRzWDCIYVLIpGkyFhUiLF6WSUZTqRwScYvsr8acc54kTjDD+9MQQqXRCKRSMYVUrjOcM74K2SJxCJk0HH8IIVLkhgF+ayMZAIhG/p4QAqXRDJGkc9LSazmTGlPUrjOUM6UBiqRjCTyVzM+kMJlEWOxwUvxSh1ZVykiq0kyBpDCZRnyF50SVlWTvO828sj6TpmB5ikrbLiQwiUZUeSPWSKRmGVCL2uiEyCAHxvG13MK6AH6/b1kZGVQUFRAeWW5YVtFJUXkFeQbzh/hlz+AoioUFhfS29OLz298WROny2l6YcsBBkSrsKiQ8spyU8s15Lpz8Xl9iAzj3ggEAh3NppGRmUFFVYXpZU1sDg2BjmLimjAoAvjxkpWdTVFJET2eHsO2ikuLcee5DecPx+/zY7PbKCouoruq2/D5y87JtrBNDVwMFZcWEwwGTS0kmZmVid/nR2QaH1wKBKBjs9vIys6iosrcQpkOhwNVw3SbCgg/AcVPdk42JWUlppYDKi4tptfjobk+waK5w8yEFi6v6KNf7yET46uL9vt7aew5SXFZEXMWzKGwuDBOyuRjjazsLMrLywe6U4Oryw7S09ODqmnMXzyfyppKQ2tfKSiomkZ+QT4Oh920T0IM5J+zYA4FhQXowri9ydOm0NHeQWV2ANVm7ActEATow5lhp6SshAsuuiC+cKX4O8/MdhLU/agmLob69V669Q4qqysQ6EyaPMmwrdy8XKZNnYYQwpQoCyHo7uwmMzOTBYsXUFldaWIFZCd5+fnYbDZr2pQCZ593Nl0dXaaOsay8jO6ubvRc3bByDVwM+XBlOqmormDlxSsN+wMDF46qXZhuU726hz7FQ1VNFQCebs+QNAOimxx3npvjR2s5vO+AYX/MoojRXsrSAF1dXbjdbvKznaauHK744FVMnjYVT3d6V7RK2P8zsjIoLivi3JXLKcotIs+ZFzdXMk/7lX5aPa38/IePE9TNLR43bdZUaqbWsPics8kKZqIavFoTQrCvfh/vbdvBnvf2JM8Q5yAVRSE7O5vzLjyP+VPmkZeTDyn+UGJxorGOd3ZvY+e2Xfh9fkM2VFUlvzCPOQvnMnXaVCYX1MQ/gBR56tk/cKKuju6ubsNhUXe+m9KKElZdtpo8hxuXYnxYGVD91NXX8cvHf2XYBgycv9lnzWbGjOnMmTUHR9CB0boK6gGOth7ljVff5NjhY6Z8KiotYtHShSyatogMR4aJFgUHju1nz6E97Niy07CgapqGOz+Xc1ecS3VVNeW55kZcejDIr/7wK1paWunt6TVsp7CkgPKqMi65/CIyRQ6aMC6Cqqrz/F+f4wuf/ZxhGzDQt7R7vHR2dpKbm97gYUKPuGqPHqezq5vmhmbDNgqKCpizYA5X5BZRUVJJjjMnYfpEnZkXL7oQbHpzE36/31Qf6spyUVFRSXlhORlkGBYuXdep722gsbGRNze8mVqmGH6rqkpxSTHnrjyXvLx8SgtLDfkzSGtHG+1tHby16S36eo0tQ66qKlU1VUyeOYX8gnxKiktNL29/9Mgx3nvvPZobjbepyupK5vjnUJJXQn5mPi7NZdiWHz9Njc28sf4NwzZgQCTyS/KZPnU6JYWlOHAYFmZ/0E9bsJ0jh4+wcf1Gwz5pmsb0WdNZeN5CCgoKyclM/NtLxuHjh2lpbuXNDW8aDoPaHXbKK8s5e/kS8gryKS0w1879fj/79u3nyOEjtLe2G7YzbeY0FEWhJK+MTC0bm2JMuAZDoTk51oSfjTKhhavxZANNjc3UHqk1bKO8spzC4kLynHnkOHNMTT5w4sThd/DetvcGhMsEZy0+C3+/nyyyTNlBGYj9t7W08e7Wdw2b0TSN6snV5nwJw+/3093VzY53dsQMe6TqU39/P/39/WRmZVri1/Fjx9m7ay/Hjx43bKO3p5ei4iLcNrcp0QKwY8fn8bF9y3ZTdhRF4fyLzifQH8CJ07StrJwsThw/Ycovm82GZtF9MgCfz0dnRyfvbn2XQMDY0vROp5MeTw+60HFlmDt3MHAxdOzwMfbs2EPDSeP3lBRFoaK8gmzVjaoYv1c20L9ppu63WYGcVSiRSCQWI996MrxI4ZJILER2VhLJ8COFSyKRSCTjCilcEolEIhlXSOGSjE9kRE5yChmenXhI4bIE+eK8UUFWuUS2gQnJxBYuixq9lK3xjZwBNs6Rp27CMbGFy2Jk5yeRpIaZB72HC3kBM36QwiWRSCSScYUULolEMq6Ro6SJhxQuiUQikYwrpHBJJBIJyFlW4wgpXBKJRCIZV0jhOkORM6TSYCxeaY81fySSMcSEXtYkOycbV2Ym3n6vYRtFJUVkZWfRr/TjxWt6yQdVVSmrKMPn95myk5GVgWazYMkHAf6An4ysDMoqygybUTU1werQBuypKg6Hg9LyUrJzsuMnTCAAmqZRUFSAzWYj4A+A8fUaQ+Tm5VJcUmxqWZrC4kKys7MJKAGCBNEwdx4dDgdllcbPHYCqqLhcLkvalEDg9/tx57lN+WXTbOQX5Jv2ZxBN03C5XJRVlBEIGlvWxOFwUFhUiKIqhm1Ek5+fT0lpiamLmYLCAjKzMtDxo2Af9WVJzDKhhauktJSSslLy3cYbf15BPuXl5bR6WtGFwOF3GLalqiqdXZ3MnTfX8HpAgxSXFKPZNRobG03Z0oVOd3c3eXl5zJ8/37AdRVMoKCoABVpaWwj0mzs+j8dDrjuX2XNn4+2Lc+GR5IeuqioVlRU47A462jrQujXTC0mWlJQwY9YMCguMi3RZZRmlpaW0dLbQ1dmFEjDuk6Zp9Hv7WbBggWEbACgDi6YKIUy3qaAI0uXvorSs1JRfqqYyafIkAJoam+hydBm2BeD1ecnLz2PegnnoQWMrINvsNkrLSkFAe1s7dJpyiUAgQFV1FYqiUFpqfFHKmqk1FBUV0dbRQtAHZhZYt9k0OrtMHphJFCGEmdWuR4Wuri7cbjf52U5THc3PnvgVV179AdP+CAT33HcPm97cxHvb3jNsp6yijLnz5vLHp/6I3W58aW2Auu46Nm7ayLf+9VscPnAYr9fYqNJut/P5r3yeyy6+jPPPO9+UT9293by65VX+4xv/wXvb3hsY5Rjk/R9+Pw//8GGqsqqwqeauv55/5XleeuUlfvL9nyB04z8HRVFYv349ixcvNuUPQH9/P3ffdzebNmziwN4Dhu1MmjKJ5cuX8/Of/tyUPwJBk6+JvzzzF37yyE/Yt3sfwYCx3i/Xncvn7/88H7j8A8yZMceUX83tzby16y2+fPuXOVF7wpSg3vWlu7jr3ruoyqoy/YD075/9Pa+88gq//t9fm7LjdDrZvXs3ZWXmRswo0NzUxAMPfZUNr26gvq7esKnJ0yYT8PtoOFFnyiUhBO0eL52dneTm5qaVd0KPuFRNMy0QMLC8fVAP4vf7TYWIfH4fgUAAu91u2q/BkI7f78fn8xn2SyDQdR1VVU37ZNNsKCgEAgF8Pp/hjg8gGAyiqAp2u920cCkoA+fP58fsdZwV9QQD5y0YNN+mBu3YbDbTo0k1qIbCfH6f3/Dy9j6/D13X0VTzv7/BFZAH27lRn4BQO7fZbaZWCYaB+ho8f2ZQFAXNon5K1VTL2pRuop6tYHwHOscaY+2GulX+jLXjOoWcfCKRTEykcEkkktSQ1wmSMYIULolEkhJn/CMWY/GxCElMpHBJJBKJxZzRAj8GkMIlSY68EpVIJGMIKVwSCfIKWSIZT0jhkkgkEsm4QgqXRCKRSMYVUrjOUM74GWCSEWcitKeJcIxnAlK4JBJJyph9FZLlyIlDExIpXJLxi+ywJIPItjChkMIlkUgkknGFFC6JRDKukfelJh6WC9c3vvENFEWJ+Js9e3Zof39/P3feeSeFhQOL5V177bU0NjZa7YZEIhnDnPFic4Yf3mgzLCOuefPmUV9fH/rbsGFDaN8XvvAF/vKXv/DUU0/x+uuvc/LkST70oQ8NhxsSiWQMcsaLlmTYGZb1uGw2W8yFzzo7O/nZz37Gk08+ycUXXwzA448/zpw5c9i0aRPLli0bDnfi0tLdyPH2I5Fr3ST5TUX/6AL+AD09PUybNRVXlouzFp9lyBcFhYysDIpLiqnrrktpifREHUBDSwM2u41Lr7yU8y44D103tqKrpmpUVlcStAep88RfOC5pZ6RAX38fABetvYj5i+YnX7QxgckZs2fQUNeAo9qBTTPejP1eP6pLZeqMqdz86Zth0CWDfWsgI0Bdd13y9ZMS2Pd6vXR3dTP3rLnkF+bT0dFhzBkgOyebmsk1NPuaDduAgfWlGpsacee7WXv1WpZdsAxdGGtTTqeT8qpyfHYfTd4mU351+jtRFIX3f/j9dHd1m1pPbcbsGTQ2NuJyuAzPnhS6wOfz4cp1Mfesudxy+y2n25QBNJtGW6ANvVvHZovTzpPYFwj6+/rp6Gpn/uL5FBYX0uvpDe1Llxx3DscOHuGlvzakndcqLF8B+Rvf+Ab/8R//gdvtxuVysXz5ch5++GEmTZrEK6+8wpo1a2hvbycvLy+Up6amhrvvvpsvfOELMW16vd6IFXy7urqorq42vQLyHV/+HEuWn4MInqqCFE2Fd9KKqqBqGv1eP/7+AP5+Ywu0KShoNg3NriFsqfmTSCxsdhvoEOgN4Pf7EzbQZKKTkZeBQJheHXjwz+vxEvSnsBBdArfsTjvOLCfBYDDi2NK6mlcGFrcUukAP6vR39adUdiIy3ZkompLahUKcMlRVRVM1dJ+Ot99LwGt8VV/NrqHZNFSX+eCK3W5H9+n4+nz4fX7DHbKiKWQXZBMMBg2LH5x6VlFRUFWV3o5e9IBxWwCOTAf2TLupxSgVFFRNReiCoD+Itzv1lcfj/UYz8zMT//5SEC5N09BUFbtQ6e/tJxD6/aV/Em12O1s2b+axR/477bwRfo2lFZCXLl3KE088waxZs6ivr+fBBx9k5cqV7Ny5k4aGBhwOR4RoAZSWltLQEF+9H374YR588EGrXeXVv7/K1s3baDiZ+MohUWdYWFzI/MXzuePez1NeWE4WWaZ8amxs5LIrLjO9cuqlV17K8mXL+eg1HzVlR9d1dp/cze9+9Tv++Ns/Gu7QNVWjpKyEO754B2tWrqG0sNSUX7v37+avL/+VP/zqD/T29BrzSdOomVLDhz72IS5cfSFTC6aaXiX4i1/5Itvf3U5jvfH7ttU11SxYtIB/+eq/kO3KxmbyZ/rezve44Z9uMGVDURSuuf4aVp2/ig+s+YApW/6gn0Oth/jew99jw6sbkmeIg6ZqzJo7i5s+dRNXXXoV2ZnZpvzauHUjr77xKr/75e8Mr87tcDionFTJpz//ac5Zcg5VuVWmfPL7/dx2x20cOnSIttY2w3ZmzJ7BwkVn8bX77kdTHSgkj+gkQvHCY5gTLjNYLlxXXHFF6PNZZ53F0qVLqamp4Q9/+AMZGRmGbN5///3cc889oe+DIy6ztLe00dXZTe2RWsM2ent6qaypJCuYSQbGji+cQCDA4QOH8fl8puycd8F5psUPAAUcTgedHZ0c2n/IsBlN0wZGzRbd3ggEA/T29HL4wGE83R7DPmmaNhDacbks8aupoYnaI7UcP3bcsA1VUameVI1DONBMdjAA3j4vB/ceNGVDURQ83R5L2pSiKGRkZNDS2GLKL5vNRq47vSv1RAQCAfo8fRzae4hAwNgo1+lyIhgYwdsdScLFKSCEoKG+gdojtTTUGw/NZWdnM3nyZFQcnAmTyYflHlc4eXl5zJw5k4MHD3LppZfi8/no6OiIGHU1NjbGvCc2iNPpxOl0Wu5bIBhEF5gSCZ/fRzAQRD31nxV4vV7THYSu64bi17FQFAU9qOPzGq8nTdOsEdJBBOhiwCejfmmaht/nR+gCRbVGUQOBAD6fcZ9g4Co7GAxa9touXTd37uB0G7DqzoKiKgN1ZcIvPagT8BsPow5BnK4ro8KloAy0KYRlbxmxqk3pQR0salOjzbBLr8fj4dChQ5SXl7NkyRLsdjsvv/xyaP++ffuora1l+fLlw+2KRCKRSM4ALB9x3XvvvVx99dXU1NRw8uRJvv71r6NpGjfccANut5tbb72Ve+65h4KCAnJzc/nsZz/L8uXLR3xGoWR0GItXe/KFxBLJ+MJy4Tpx4gQ33HADra2tFBcXc8EFF7Bp0yaKi4sB+N73voeqqlx77bV4vV7Wrl3Lj370I6vdkEgkkvSR1y/jAsuF63e/+13C/S6Xi0cffZRHH33U6qIlEolEMgEY/9NLJBLJ+EOObCQmkMIlSY7sZCQSyRhCCtcZjKUTDqR4SSSSMYIULolEIpGMK6RwSSQSiWRcIYVLIpFhUIlkXCGFSyIBKV4pIB/UlowVpHBJkiI7K4nVyIlDEjNI4bIA2bFLJBLJyDHsb4cfy2iqimazxV9ZNJw42mSz2dA0DSHEwOKBZjTs1BvP7Xa76Te7a+rAchhmfRJCIIRAVdWBxSmN+qNpoXoWCFMLCA7aUBQFu91u2C+bZhtYaVoZqHeBMP3288HjNFVXNg1VVdGFbrqegIEFM034AwNLrajqwHWuFedO6AOLG5rxy26zh1YK17GgrhROt3ODvxmb/XR/IoQF7VwIS9qUzWZDUZUBf8TQw0u31Vu8/nDaTGjhWr5qOdNnz6S/rz9ie8wRVJyG7HQ5KSgqYF/9Pup7G8jMyjTsjz/gp7u7m89/5fOxBSeNH1NldSUZeRnsPrkbh9MRf4mFuJsHdgghOHH8BAsWLeCLX/ti6g5EoaoqGZkD65XVd9XjwTPUJyX8oxLz8yD9aj9Tpk/hzi/fmXBpi0TnUlEUcnJyKCgooPZoLb4KX8x0Se2FsfqK1cxdPJe+3r6ktuKRnZNNflE+e+r2kOPOwZVhfK0wn9dHIDPAfd+4z7ANGKiryVMno2VpHGg6MOCTwc49GAhSd6KONZevYe6CuYZ9UlWVvPw8FBTqPfU4A+ZWRCcDps+azr0P3Jveat9hSVVVJSMrA1VVOXbiGH0lfQmyJV/RWA/qvO9D7+P8i8+nv78/ZpqEtk7hznNTWFzInuPvkevOxeFwRJka+v94Jn1eP00e42uDWYEiRls6DdDV1YXb7SY/21xD/ZcHv8GKC1cOWe00psU4xWiaht3p4I23NtLY2Ehbi/FVSjOyMsjLy2Pl0pWhq9tUfIhF0B6kpa2Fd7e8S2dH56m1eOKQwK6qqixYtICSwhIKcgtSdyC6CEUhqAdp72vn3S3v0traGrtzSFEsaqbWcN7556H0KcaXkFcUbDYbDS0N1DfVs2fHnpRGuonE64rLriA/L3/oek5pnDu73Y6qqWzeupnGhkY6OztTzxxFdk42RUVFnLf4PMM2BlGzVI7XHmf3jt10tHcYvup22B0sWLyA0sJSsjOMr1qsoODX/XT7utm0fhMej8fUSGDeWfOYO38uSn8aJyuqOEVR0GwaxxuP09DYwIE9BxJkTe6rpmpcc/U1OBwOgkFjqzID2B12AsEAO3Zuo/FkI729p1cNT0VAw8lx53Bo7wGee/pZw/7AwEVxu8dLZ2cnublpLggqxiGdnZ0CEPnZTlGQ4zL89+yf/miJP8FgUNz++dvFwiULxanTbeivrKJMXHLZJcLn85n26UT3CfH7F34v5iyYIxxOh2GfbHabuO+h+8TrG1837VOnp1P88eU/iiXLlgjNppmqqw9+9IPicOdh4Q/6Tfv157//Wdx5751CURRTPgHi7bffNu2PEEL09PSIWz59i5g5Z6YpfyZNmSRu+PgNQtd1U/7oui4avY3isd88JuYunCs0zfj5y3Xnige/+6DYuXen6XpqbG0Uz772rJg8bbIpnwBx9/13i2Ndx0RQD5r261dP/Urc9OmbTLcnh8Mh6urqTPsjhBD1DSfFLZ+8UUydUi0yHDbDf3PmTBezZk421fcW5LhEfrZTAKKzszPtY5GTM8505LyRpMhp3hLJ+EIKl0QyVpFaKpHERAqXZGSRnbFEIjGJFC7JyCKFSyKRmEQKl0QikUjGFVK4JBLJiCMnw0jMIIXrDGWsdgxj1S+JRDJ+kMIlGb9IDRxZZH1LxghSuKxC/qhHHDl6k0gmJlK4rET2oxKJRDLsSOGSSEBedEgk4wgpXBKJZOSRFwrjlzFw7qRwSSQSiWRcIYVLIpFIJOOKCb2QpJWoqoqmamiaZtyGpqJo1ozDB9fYGfTJqF+aNrAar6kF+mLY1DQt7no/qaCqqqn84SiKgqIqoZWszdqyClVVUTXVVJsaPH9WIIQA5dT5s5nzyWpU1Vw9AadXCLYARVFQFfM+2Ww2C9uUEqqnpH4lWqNPUxH66MYLJ7Rw9Xv76O7pMmlFQQid7JxsikuLqZ5cbdhSYXEhBUUFdPd2Y9PMnZre3l4URaGkrASv14vf7zdkx2azkZGZQVAP0mWyrnr6egAoLilm0uRJSRfGSzTdPb8gn/6+fjyqB00x2REqAwsu1kypMS1cAT1Ad0+3OX+Afm8/uXm5lFeW4/P6kmeIQ1llGe58N54+j2mf+vx92O12SstL6evpG1il2wBZ2Vm4Mlz4g366e83VVZ+3D0VRKK8sR1XVxAumpuBXf18/Hs1j+lELTdNwu93UTKkxZcfusNPn60u5TSVanLLP14c73015dTk2R5L+JcHhl1WU4ensoqmuPiWfhoMJvQLyZ79yN+eev9RYZiWyY+3zBUx3eiG7ijXrQ4X8CTNl1O6QelaM241XT0qkwaR2DZ17JYZNkfgHn45dK0dcpn0Kwyq/rOwuLKsrYZ1fiqJE1rtBs9H+mLGZqJ5i2Y3XbhQFnIlGykN+FiGDkf8Cm9Zt5L+/9Uh8WykgTKyAPKFHXOteWsd77+ykqbHJsI3CokLmLJjDJ266jby8fNM+tbS2cOuttw5d+j1NLr78YhYvWszFF1xsyo5AUN9Vz7NPPctzzzxn2I6maRSXFHPrZ29l3tR5uHPcQ9KkI35Hao/wxltv8Ozvn6Wvr8+QT6qqUlVTxdXXXc2yFcvItxs8f2Ei+63/+BZ79+ylubHZmC2gclIlc+bP4Y7b7sDpcBq2M8i+/fu45557TNlQFIWrr72asxefzbkLzzVlKyiCtHpb+ckjP2HThk2G7aiayvRZ0/nozR9l4YyFZDgzTPm1c+9Otr67lf/7zf8ljQbEw263U1ZZxk2fuok5c+aQZ88z5VMgEOCBBx+g9lgtHW0dQ/anKohTZ05l7ry53HHb7WlcMIi4X5uPtKRoY3iY0MJVf7KBpqYWjh05ZthGeWU5BYUF5OXkU1pYatqnQH+A97a9h89nPDwEsGDxAoL+oGmfdKHjwUNrayvbt2w3bEfTNCZNngSAO8dNaYE5vxoaGuju6ua97e/h6TIWBtM0jb7ePnxeH263m2JnsalRgBCC+hP17Nm5h+NHjxu20+PpobCwkMLcQjIyzHXGAEeUI7zz1jumbCiKwopVK1B0heL8YlO2AnoAf5+fE7UnTPml2U7fvyvILSA7M9uUX3bVTmd7J9u3bDd84eh0Oun2dCMQ5LnzKHGVmPLJ5/NRe6SW3bt203iy0ZStspIyCt1FltzzzM1Kb4RkNRNauHRdh0CQYMDY1RVAMBg8dUPXuhBKwB8w5ROAHtStDZ/owpxPAsNXsYkIBAKGOxkhBMFgECEEimpN2ErXdQJB4z5BeJuyBiGE6RG8oijoujVtanAyjB7UTftl5p5WNEKIgfNnok1pmna6nVsUCdV1nWAgaLpNjcO7QnGR0+ElEsnIE3WPVCJJBylcEolEIhlXSOGSSCQSybhCCpckORaGdBSsmeovGXnkeZOMFaRwSVJD9lkjihQJiSQ+UrgkEolEMq6QwiUvbJNi6dX/WKtvObtNIhl3TOjnuM5oxmCHnLYABo+CHv2EvgIKVJW0cfWaCiYX/DN+nz+0KyJdzK+ntyuqQl5+HvMW5pKrHgYR691rcXyOs/lTn1zGNVdPwdPdEztBCrjz8ygrK8Vu38Ppn6jxZ3CmTOnmpz+9K36CuKbDdyjMWzibqoog6AkeGhZRrwmKgYJOvtLLnbcu46qLypP4E23v9HdVVSgqKeKsSf04xbvQb49dcIr2ZpS1kLG6jGn/dTO6LmKkT2T71EutNZVcdy6Lyz3k9G6H/ozIfNHlxrN1qjxN17nnprNpb5tCX29vjPSx6jv6jReCwuIiysqKUVpeTlBuivaARRUtPPIvH4hdLym1J+jr8/Ppb/4pXuKESOGSjChpiZfeMiBeAxkJ/1CQCwXzCjh73oVEqEgs8Rrcpgx5wWIYp17RJOLYSAFFgYtXTwOmp5wnjqVT/w4KqbkHR0tKBJ/85GWxd6bSyUSk0YHaGNtFDNGKbUNFkKXApatnwKoZUTZi+BC+TegxRCcA4jgEUsgfJgoDX0+nKXMLynLdnDPnwhj5E9kOsxVK0w/eWmLXgUhQRyLMjkAD3rdyMojJKdiKYVtE/du9K4bf8fLHSjPwYXKeYPL7l8Q5hiS2Tn3s8vQbFi4ZKpQkZdRnApopOsZISzJcRF0oDFcZlthXov5NI4uhckYm2wgYGxNI4ZKMbaJHPxGDprAvsbaHj7SUKGPxRlWJbCtElROd1kh8NqnxOGnSKSdBvrhmwzYkrStOpxt812OovhOcn1jbE53HcLvR5zPV/DC0vHARi1u1cUQ54jhj+RorU1iWuOc7XmFxbMWzrUR9TyV/LGK2+RQMDJNmSuGSjBPS6EDDtykRv9z0O9CkImVWqJKls8JWsnwJxGxwQ8wOMJ5QRHfySc7VkLRxxCaiM44nNinkH7IjxuZktuLVW1xRTeRDtN14+1LZYaQdpLZ5yM5Emhs3rzXIe1ySMUysH0kanWDCe1oJtsdLlxZGBC3Wd4Womzxplpnq/bHovCKqeOX0diU8yeD5Cb9/caoOT62YnFJ+xNBDDe2Ks0MRQ31INb8Sdu8mJBjiVNo4tkSE4ymUk2RfPLux/IlrN873uAnDyx3qToKTEDtZXDsJC0kijsmRIy7J2MVIw44lcGMeC66SxyRhI7BhcTlsdDfWGHNuDdc5SK1oq5nQI645C2ZTXlVJe2u7YRu5eblMmTaFusY6WjvbCPiNLz2gqirdnm6uvu5qAsEAZiZEzJg9A5vDxu79uweWNDAxM61X6WXSlElcc/01iRMmcFdVVfIL8gE4evwojY3J1xaqLG6nIGLZnySjp4iRVozt6dgwPWJKN22i/KnYjnd+44ykkhJvJBT2JeH28I7y1MhBEZEjj1j5Ux5lMXCeRZR/6eQP9zX0XaRgK8G+wdGSEKf9iybR6C1m2mT+JBrNRZUZfQ6GHE+KvsR3LsW85pjQwnX5B65gzRWX4HK5IraHBCOFvsTn9dHR3sG2Ldtob+ugu6s7YfpEOBwOct25fOu/v4WipjGTL0ayhroGGusb+cuLf6G/r9/w+k6KojB56mTOO/88rrvxuqR+xPVZQH9fP/v37mfD5g3x6ymMq9dUUDCv4LTxsH+GfIkQrSTiFGt7vHRxGU6hMmozHKuELFpQwm2kGvY71WHGCn8NyZ9MbAZtERaqitchpyJWUaITbtNM2E8hUrRSEqvw44i2kYI4DXU0WUIDtqN8DZ3TJMWntjNlJrRwleVUMKVghrlVbzOgMjvAL//nt7y16S12vLPDsK3S8lJmz53NbR+7DbvdbtgOgKPaQX1dPU//+mkOHzyMz2tsRWW73c6dX76TaVXTqM6uNuWTR/Wwn/08+/tneW/7e0kXxptc8M+nntNKguFR0nAzmv6El23hpa5plKFCMqbsWjw0sIIx6NJoM6GFS1U1bJo5gQBQbSp+n5++3j483caWkQfIzsnG2+fFptqwqeZOjU2zIRD09vbi6fYYFi6b3TYQ/hSY9klTNAD6+vrwdHmSCtfAGzGSjJ4iRlrESZ+ijaFfEmyLR3Rao+KV7pVpvHIEiUUsVr5YaVIJD0ZtjzUaGxxRxA0bJhglRbsWPtqKWU6s/GZGUumG/ZSw40pQZoT/MQuIsz08Uwr1ppzaIE59SVhuqn4MV77ETGjhkowjEonQsIQHUxUcJc7ndImXN93QXqp2E9mKJXTh9RiWL5WwXzphw2RiE1MoonxL5Z5QqNOO2jfYuSeb0ZfKDMMIcU5QZlxSDOHFNWckBDiYgPh5Y+2KuPAY/vtcclahZOySqM8d9fBglFiOS0bb/+iLB+vMjilM+zNM9WQZI++cFK4zmDNiTacIfYgRHlTCNxD1GwpLH2HDyGhLifqLty1VjOaNzmcmfyp+JKqL8I9hNoZsizYffg7C/Yi2F74rln9R5zGWvWifk14MKbHTxvUhjs/RPqR8ipTIYmLVW7wyEiVLvCO+uYRZktTpMHY/Urgk44QYopWsYwxPP/gl7Y7ACqEyIzRGyzCaJ8XOMXp7dD1HmEohXUx7CcQqWlSU8H1KZP5EnXi8ciL0L12xUiLzJ5r8laqfsYQ0bvrUNw/xISFpil7EjrQUMSlSuCRjmDidyXBeyiUqf0IxwsdueXEJRgLp2EjwdUyRlm/hgj0+kcI11hi/bWmYiL6CjfGji3UVH/Ex1hVtsivAWKOsNH22ZGQ2kqO8eKOvRDbCtkckSTB6GlKEEjtduIF4F+3JRjxD3EwiaNHpot/6kU6ZMQ0rCY4zRpZYn9MaVcUoJxVbyfYN2ZXsHFqLFK6xxBgVrVG/VxYuWgk7yjjb46UbUkB0mlSP2ypxGc6y0s0bS8TC/42VPvpjkroO7+RivZg3oVhF9+qxhCNcJOIRXk46nXgKYhVLsFMi3vmJI8iGhDRNkp3TQZGPm89apHBJxjZDRCtqe/SX6O0Jry7j9YzJeqORFKp0bRr1J1m66H+T1F2s85DwIiOWeIUXm6DDjFlOnM5UiU4Xh2hRjfieIFM8EUylSaVkO/ocxPI7GYmOI8G5imMmLSxq+lK4JGMXZciHkSpQEpfhrqN0RyepmxwDRqxhDLkyWsgHkCVjm2F7YW7My/oE29PFSL5keYy+RSPVh10T5VHCtivEeMo3Km30A8mRu2J8Gfg++HBy6CW1MQxEvykjlTdAxLQVdWzh7wmMdzyx3guY8hsoBg2E54lp1KDtJAnjncIUs8c+/tEh7RHXunXruPrqq6moqEBRFP70pz9F7BdC8MADD1BeXk5GRgaXXHIJBw4ciEjT1tbGjTfeSG5uLnl5edx66614PMZflSQZR6TVn0eFpFIVrSGhjlg2E5QTN12qvqaaL908Rsow61us7cTYl+B7eJhtiOnosNXg96hzEe+0xfM7vMx44cKUQnPReRL4k8CdtEaScW3H2ZHIZnT5cROlvjn2zlROkNGLwKGkLVw9PT0sXLiQRx99NOb+73znO/zgBz/gscceY/PmzWRlZbF27Vr6+/tDaW688UZ27drFiy++yHPPPce6dev41Kc+ZfwoJMOLde2NUZ/oMYSx5s94YrjrbgyemzHhUiLBTd+UtVjoWwLSDhVeccUVXHHFFTH3CSF45JFH+Nd//Vc+8IEPAPDLX/6S0tJS/vSnP/HRj36UPXv28MILL/D2229zzjnnAPDDH/6Q973vfXz3u9+loqLCxOFIzlhijaBijcDijcoSfjdyZWjk12n1LzranpFQYrI8seJD8WJO0fGmsO+hj2HpI0wrDFm+JN77C+O9qzDh2+EH7cc6nqg0xEqSKF8M32KVFRr5RPuZIE+s4kPlxIr5peNzCseUbtp0TJrA0skZR44coaGhgUsuuSS0ze12s3TpUjZu3AjAxo0bycvLC4kWwCWXXIKqqmzevDmmXa/XS1dXV8TfWEGc+k9VVVRVRdM0U3+qauEpUTDtj02zoSiKqaVfokm1nhQ1OiSTQLRihZ+I9z18WyqipcT4SxWzedLJP1x5ktVVsnIShJUSnSoFhszoi/iY6OpeGZouvA0P2RfPbyWxP9G+pUyU7WTphmxLUGRK7iRKkMBAOj+ZZHlMdCmWTs5oaGgAoLS0NGJ7aWlpaF9DQwMlJSWRTthsFBQUhNJE8/DDD/Pggw9a6aplCHQC9JFfmEdVTVVESDRdCooKqKi0ZsTp7feiKRo1U2rQNO3UEiHpo9k0cnJysNmsaypVNVX09fYRDAbjJ1IgLz/PsjKHGJdYzHBeag+OlqwxZd6OWSMjNCxJCQvrdgQZF7MK77//fu65557Q966uLqqrzS1qCLBj97tkuDOSrguVCM2m4cywM2fhXCbPnJJQuBLe31EGBNxhd/D8K88nTpsCiktBIPjQxz6Ez+dD6CK5D6f8iP5eUFBAQ0sDf/nHXwz7pQxeqdrh6uuuxuf1IWItax5W7ryFuUMdix5pxduW9Huq6dJhuPNEp7VitmCyPHHXr4hKGx62itUxD56rGOHA0MdY3wfzKJgL9YUnUyBu24vlZ9S+uDMMk9lLM3+iqk45Uzxf4tgzVGY6PliDpcJVVlYGQGNjI+Xl5aHtjY2NLFq0KJSmqakpIl8gEKCtrS2UPxqn04nT6bTSVQD27NtNv95PT09PWvnCO++MzAxKykpYesEF5Bfkk5mVmVK+GDsJ+AN0tHXws8d+RlCPPRpJVTimzphKzeQaLlx9IS6XayDslmr+sCS60Kk9Wsv2rdvZ9e6u1IUrKpmiKmTnZLPsgmUsW7EMt9sd8ikeuephoDmOzegwS7J4xeD3VNOlwnAKVSo9RiKBSbV8s/e4otMlEq9Y2aNtRXXucFq0iBIcJXxfrOJiiIZCbBuhdHEcjl7nK4k2nBbaOGkSlpOCoiin/jd4LMmaS1ItSbW9JVO1kRlNWipcU6ZMoaysjJdffjkkVF1dXWzevJnbb78dgOXLl9PR0cHWrVtZsmQJAK+88gq6rrN06VIr3UnKlk1vs+3tdzh26JhhGxVVFVxw0QV85P03UlJcmjxDIjJA69b4yfd/Yji0N8jNn76Z0oJSphZMNWVHIPBV+NjzxB5+9J8/MmxH0wbClssuWEa+PZ9iZ3EKhdcbLm8o4yE8mExUx0s8Zxg7r7EUZTOLFcdyJtVHGqQtXB6Ph4MHD4a+HzlyhO3bt1NQUMCkSZO4++67+bd/+zdmzJjBlClT+NrXvkZFRQXXXHMNAHPmzOHyyy/ntttu47HHHsPv93PXXXfx0Y9+dMRnFAoxMBMyYcgqqY3B/NZMYFAUBaGb82nAsdP2TJk55YfAqnpK06/oC/FhDQ/G25bKPqN5UvFhSCUwtLcyEhJMZjM8TTohxvA4VLTd6HBg2PZ4YcToMkK74g1nSDB6SsVGmD9xk4SNLNNe2The/jjJErkZYSvevmQGEtS15cpqKPY4hLSFa8uWLVx00UWh74P3nm6++WaeeOIJvvzlL9PT08OnPvUpOjo6uOCCC3jhhRdwuVyhPL/5zW+46667WLNmDaqqcu211/KDH/zA1IFIzlBGPTyYjlgZCTGmkidZmkQ9XrJ08fKkEx6MZSfFGyfRYcPot2JAVKhPxDCdYqgPYofwhoQkExzWYLq07nPF8CHlCwETgpQse7r33FIlOow5DKQtXKtXr0545a0oCg899BAPPfRQ3DQFBQU8+eST6RYtSYd4/fW4JZloxRMno6MsKwTFrP1UbUb3Osk6u2TpwtPGEjAjV9BJhC+Z1sUyZ3aiRio2gPSeyYqyHc+HuJ17qn7H2Rfud6oGUjmlaVyLpJzHBPIlu5LkjEsBHJdOn2EM1zmwwu6Z0j6iL+gmBlK4JGMYJewveluyfOH/Rm9PpVyzaRL5Phw9jZFyhnNUGe8cxMqXwvkNbU5kT0l+2KnYMCoGIdvpZk61zBi202niKbk2PlRQCpdkfJDw92T0x2aik0maZiTKSSVPusJhtJx08qa7K0ZnHfMtGMnKjc4TJRaG++zhFKuw5Jb7kG4ZY4cJLVwDp9qCszWOTviZjzwZYw95TiTWMqGFS3KmMkwjAkOjF8MxJ4vyD343EzYcyRFtutlTsD8soxUTYd9R0XGj5z+VUK4VEYb0kMIlScrYWYpklDrQUQ8PjuWwoVX5DdysGYnwmaFy42Qd8bBsqtmH+/cdry0aL1cKlyQlxo54SSRWMtrt2qAQRtuYYEjhkoxdkkZjYoUx0jFuVTqrw4Nm0sTKE15PRssxGwZNFm5KvitmkUPSDtNozHAkNUk5piO0Y1m0rBDl2EjhkpxhWBVOTDU8mG6eZDasTh+dN1UbwxH2szgMGf3asFQ7+lT1N1SkEeEZvk47VK7ZEOBw34oaRttSuCRnCGP5ylMiSQfZlpMhhUsy8hj6XVp19W8VIxUeTJTXbJlW1I2Vl+0JwodmfYiXJGEY2gCWVUeaRoajmSdr4sM9YkuAFC7JyGJZQ7cqJGhF/pEWrWg7ZsKTRkKVRoh1w3I4w5XRdtJImnaRg2FBC0K4Ru5rGRKUYVKcERKycbEC8njB9FIkp2xYsTxKuL2xhHLqv1T9Sr0qzIpRKrbGkmDFspvuuQ7PEy+/Ebtm8qWTfbAu4yRMsntoeWn4HLJt8jgHD9SsmWh76SZRwnYMZ5eRzjlJZEaMtZ4tBbq6unC73eRnO0118t98+NtcuOoifF6fYRs2h0ZmtpMXXnqJo0eOcfzYcWCgg06X3LxcSkpKeP8V70dVzQ2G/S4/JxtO8saLb9DU0EQgEDBkR9M0Vl+xmqqSKordKSz+GAdFUQjoAZr7m3n1+VepP1GPrusJ83zqk8u4ePW0QQvRFqM+mxGbM0G4wFhvkMpb5aO3x0qXzrZEZYoYH0Wcz3BqUb3Y6SI+isjPQ+yJ2Oni5Yk4HBE/f6rHMMSPJHmGlBPDv3jHk2hfRH0Sx2YCW9FpYvl16mOXpx/30q/T2dlJbm4u6TChR1xVVdXMn7/AlA2BTlD3c6Kujvfee4+9u/YatlVcUsyMWTNYvHgxdrvdlF8nuk/Q0NzA9ne3U3ukFp/PmDjbbDbmLp7LgpkLOGfJOaZ86u7p5vVtr7N3z1727NxDIJhYTK+5egow3USJw3nvZbhFy8ilqdnLWTP50xkyJEqbgg/RSWKaS9UfsyNVIygkXbokXrHp5jlDmdDCZQUKKip2uru6aW5s5vjR44Zt+f1+CgsKLfHLYXcgdEFjfSPHjx03PKq02W309fYZHrHFYrCektn0dPfE2GplSNBInpEYZUWPJoezY43VGybLb6XApWgrXmjOoLn0DyGB2AyG2RIGrwyKVUQhKdhPaNtM5VgWy7QEOTnDIuSbJUYLWe8SZDOYYEjhkpwBWDnDMJGtkQgPxgtLmpk5mGp6I/uM+mDlTEYl6l+z9swlH5J32EV1NFQ71amMw+ObFC7JOCZRp2j2BxNuY7SFI500ZvKM9DFbYS4dsVISXBcoQ7eZOZ5Q/lRdi5PWqiodlRHp8BUqhUuSnBG5apRIxjnyNzJiSOGSTADSDQkaSWc0j5GR2VgY/aWTzoitFGxb7abZUVbIiFX1YmEdnGFI4ZKMI4bzV2p1eDHV9GbKGs480cdipn7i3Q+x6N7ZYKhtiLkRCBVYInZGC041vJxOuuH+jVmDFC7JOGV8/MDGP7IuRhzD1yRx7uFZyRhpDlK4JOMYMyFAI7aTpU/XvlmGe9RllGEsY1iimGNgIsqgyVifjeS3Cit+YsPglxSuMxU5oeIU8cJUw1lGsrRW3xsayRM9nPWZyI7VobFYRSYbsSgppDHLaN3bM0Gy0zYMSOGSjBNGKjSYTsc3kve0rLQ9nMeYDslspyoUad6fiXdfahQ64PTukcmr0UGkcEnGIfLHKxmLjMA9JgkghUsy7lCi/g3fPpohs2RpR+IeylgeASbyzYQfaWdNM4wYGhFZaHrYZyKaHMFZEToc5p+iFC7JGUy6d5WHI1xj9i77cN+lT6eTS5RnNIYaRkRoGGynbM5Ejz5S1Rt9z2+MIoVLIpGcOYzdvnZiY/F5meDLmugIgihohi0ERYB+vRd3vpvK6kp6e3oN2yosLqSsssxw/nC8Xi+qqlJdU42qqPj9fkN2NJtGVnYWNpt1TaVyUiU9nh6CwWDCdO78PEZ+QoNVd+itHCkNbh/OxZuUBGkT7TNLtJ8p+B0vSVw30/FfIfnyIKmbGliGhdTLH86qNl3OSDmXnAktXD5fP319PSCMV4MfL916B6UVJczxz6GouMiYIQWys7MpLS2lv7/fsNAM0t3VjaZqLFi0gOpJ1UlFIh6qqpJfmI+qqfT2GhdlgH5vPwBz5s+hsLAQXQxdATl8eZiystIhe9MXm1SxckrZcIX3jHQcaXbakCC9FR1XPBup2k7Dh7T13sqO2YAtRYmxpleqBxHefsaGuAwnihAJVz8bk3R1deF2u8nPdqLEe6tyClx61eVUT6mhq7MrpfSx1tzKys6msrqCNe+/nJK8Etw2t2F/AkqAls4W/t+D/8+w0Awy96y5zJo1i1UXrMIhHDF9TwVd6Ow9uZeNGzayddPWgY0GTKmKSo47hzXvW8PimYspzE2+YKbdvgebrT5sS7rClew+TKx7SVYI43DelzLyc003T6z0Isa+6HTJviezH892smXrw9OJ09sjkifKE25ahG1LJU+88tPJE50/1oKTqeQnMn+iPBH2kxxDdNrQP9F1HGtb9PGc/tzl6ce99Ot0dnaSm5tLOkzoEVftseO0d3RSX1efPDGxhauopAiBTp7DTX5mPi7NZdifIEG6OrvYtGGT6RFXfmE+k2smk+3KRkMzJVw5uTk0NjTy5ro3DfujaiplFWWsed8anA4nGRkZKeSKbp6C2B18vO3pkMhGdBjLjC0zeYZbtJKlteIaN564pWo7DR/SdtfKa3gD4caYY4h062U4xyEmbFvs1oQWrraWVjraOzl66KhhGz2eHiZNnoRLyTAlWsCAwAQUDuw9YFq4Ojo6CHgD2Cw4xc4MJ50dnezfs9+wDU3T8Hl9BnJGi0a6ImKkvEQClu7IKB0/4+UZrVFWvH2j3DnGurpPmDUdETEgOMnshf5J59hS3G6U4TyFI4CcVSgZw4zzX5dk5JFNZkIwoUdckolG9Igp1mgu1XDdSIUNRzs8mGq6kRyVmSkmjeO1JNQXz4XhPK8m0kXfVzPCCJx6KVyScUai+1wwVJhGI6QYKy1p+jLa4UGrSXT/xmx8LM3jiCccVoQaDZ0CI/4Pgy9G86UTZbYIGSqUSCSjiMUTIszml6FG6xmGOpUjLsk4ZDgnaKRjeyTChqkyHOHBwbQi6vtwEcd2WkUO0+glPLHhUJ+VvsTKa1B4h6vpWJs5AilcknGCVZ3+SIcUUynfCnvDld6IveEQNxHxz9BdsWYYDndMLd1yUjY4CunGF1K4JGc4IyFKZidgmCl3uNIPZ2dsQUgvjc0j1neHi9gwHeLwpbNitGtp5oTIe1wSyRDOzKtUY4xCaHCiM6rVMj4eGJMjLsk4JfwHYUXYL9bU+GjbyfKP5KhrpEdPw92bGrA/UuFAw5id7DGWjy2akfVBCpdkHGFl2C9VWyM17X243lU4nHfrrQ4BGrWVRtqkU7cNhPpSEtAE+y25T5ZK/rE0g9McMlQokUjGP2Nh0DHaTKA6kCMuyQTA7EhorIQNhzs8aPW096TDmxSzpzECTClpqjMQLZpoEafYYcszAZDCJRnHxOvszUw5TyQgoxU2HO3woJUhQYN5054xmKSctN0QBoQ0FVtp5LEqnSH3LVJQi8zIUKFEIhlh5DBCYo4JPeLKy88jMyeboH560cZ0160qLi0mNy+XgOrHjx87dlM+aZrGpCmTTC9rkpObg81hzen1eX1k52QzacokwzY0TaOssswCb2KNSqyaSRgvTaIX86ZSxki9ZNeqkdZIxrQMjCZTHQAaCRum4Yap/EbKH7FJhiYMjNA1yYQWrprJU6ieNIlJ1TVA+qIF4M5zM23qNOrq62hqbMbnMbLm1AAOh4N+bz/Lly83vQJyzeQaNJvGezvfw9vnRdd1Y4YUCGQGKCoq4vwLzjfsj6qquPPdAOzbv48jyhGSLb49ZUo3JSXJhCLd8N1wCZzV+UcjPDgWZp0Nh1CnMOPP7LR1UzMD0y0/1j06A2WaZRQHzhNauG684eNc/f5rTNsRQvC5ez/HG+vfYPuW7YbtlFWWsWDBAv76579is5k7Nc2+Zja8sYEb/ukGDu49aHARR7DZbdz3jfu4/JLL+cKnvmDKJ0+fh9e3vc4999zDO2+9QyAQSJj+pz+9i09+8jJTZUrGGlb3djLsCEy4apjQwgWgKOafC0o2cjCCFX5ZzVj0KTFmRljxJn2ks3aXVf4ks2lFnlTjbSMUEjQzAjFsb7RHIaOoPoMjRpMTQUeKCS9ckvFKvPtAVs8kjJV2sBwrZw4aYSyEB4dzhmGS6eiGDiVJmM2yztni2ZOG0lk9szJNhtG+nFUoGSdY9SsQFtkScT6PlB9jQbRSLceKfLHqK9YIIYV6TakaRGqnaNhGKCM2E2MYTZu9dxgfKVwSiWSEGEOxpjHNSEzMGd/IUKHkDGEw3Bcd9hvOmYTRYcORmLE4UiMtK0dnFnaslofyUqwLwyMrE+E6qwMDYwpzEQcpXJKxTcJ+PXpnuveqUnk+KxWb4aI5yGi/8ileHiOiZTZddNoE+ayaRDEsHXaSe24pZI25Y9TFxWoH0pn8YwwZKpSMXUb9By2RSMxj/Q9Zjrgk44iRCscZyZ/qCM5IOVZd4puZaWC0TKN5rRhVDeeVTzqhxqg8abll5aQkK8oZ/tFUKkjhkpyBmBGqROKYTDhjlWtEbMPzjIXw4HDMErQq+1gXOIvKHLXow9gMe6QdKly3bh1XX301FRUVKIrCn/70p4j9t9xyC4qiRPxdfvnlEWna2tq48cYbyc3NJS8vj1tvvRWPx2PqQCSSAcbmD21iI8/JuGAcnaa0haunp4eFCxfy6KOPxk1z+eWXU19fH/r77W9/G7H/xhtvZNeuXbz44os899xzrFu3jk996lPpey+ZOJiZuZUwn5Gpx+mGXYarnFTypOLrSPgWnjfdXWLo1/C31aTkTlSiQRspzhlJy3a6WS3B3Cy98UbaocIrrriCK664ImEap9NJWVnsN4Hv2bOHF154gbfffptzzjkHgB/+8Ie8733v47vf/S4VFRXpuiQ5o4k1czD8e7w8ZqbGpzOTMNH+Qcy8JioZZu45DOcMw1TvAaUotCLJ/sF9KRWXQljUcITWRGjXSEgznesUq0KvY4BhmVX42muvUVJSwqxZs7j99ttpbW0N7du4cSN5eXkh0QK45JJLUFWVzZs3x7Tn9Xrp6uqK+JNMBKy82S8ZeYbrHFhh90xpHymI9RmI5cJ1+eWX88tf/pKXX36Zb3/727z++utcccUVoWU6GhoaKCkpichjs9koKCigoaEhps2HH34Yt9sd+quurrbabcl4QMT9QuqhklTDaamGBEUKacPT6CnmSUZ4fiN+GA0hplLv6WwL/xjre3SYUETuTxReFAy1G/5VRKeLYSNURpS9WKHGIWUk8SHmy7kT+RNlO2HhKdRNhL2h2YeWmWKeeHVjocBaPqvwox/9aOjzggULOOuss5g2bRqvvfYaa9asMWTz/vvv55577gl97+rqkuI1URhs7IoAlLDvETujMqQSHoyVLtpW+PZY++I5G068shORynT4VIQnXdKNM8XrmdLo9UTUh7jFxMoTK2+cY0ilnLRGL1GCFt9oEh/SEJjkho3vMyQq6bQJUwUNYdinw0+dOpWioiIOHjzImjVrKCsro6mpKSJNIBCgra0t7n0xp9OJ0+kcFv+sWJJECBExi9IoqqKe6puFab8G85v1S1XUUF6rlm9J3aew/YLT4hX6HrGTyMThNuKJUiziCV0su6kQXWepCGPCy3gD+8zmSaXziSVaSTq2hIIUZ1QQniepUMVIFz1aiWsjSpCSHdaQfSK+7URlJjI8xId0/UrkixERSljYsDLswnXixAlaW1spLy8HYPny5XR0dLB161aWLFkCwCuvvIKu6yxdunS43Ymgva+Fhp4TOJz2GHuTdEyndvt9fro7u5l91mzyS/I5/yLjqwS7XC4Kigpo8jWhBtVQOfFWZk60YnNjUyN2u51rrr8GT7cHPZj6CsjhdlVVZfLUyahZKs3+5mQZ4yKEoM/fB8DV117NilUrhqzKHH088xbOTtnnBCUndmxMkY6IjUWG21cr7KczqhpHGL5uGZ/1kbZweTweDh48GPp+5MgRtm/fTkFBAQUFBTz44INce+21lJWVcejQIb785S8zffp01q5dC8CcOXO4/PLLue2223jsscfw+/3cddddfPSjHx3xGYW7duxEc9rirg4cVxjCNtvsNjIzM5kxYzrTp04n0J94Vd9EaDYNIQR/eeYviLDWlEig4o1a8vLzyHBlsOr8Vfj9/rRGS9HlaVkax2uPs+PdHSnbiGEUu91OcWkxZy8+G0VXkvpUVRFk4J7QKQNAxOgp6UBqULSi/w3fH8tAKmKXbCSVSr5UZyUa2T9ceeJ9TyNEFCu0ljDcliS0FnNkJGKkEfFtxCs6ZgJB5L22FIgY8YTlT5gumR9x9qWUPVH5aXxPZVu8/SYEUxFpxn9ee+01LrrooiHbb775Zn784x9zzTXX8M4779DR0UFFRQWXXXYZ3/zmNyktLQ2lbWtr46677uIvf/kLqqpy7bXX8oMf/IDs7OyUfOjq6sLtdpOf7TQVmpu3+Cxy8/Oor6sHEgtEPIqKi1iweAGfu+ceSgpLcWIupNnY2MjaK9fi9/tN2bn8/ZezfNlyrrvyOlN2dKFzoOkAT/7iSZ5+8mnDdjRNo7S8lM/d9zmWzV9GcX5xCoW/A9SGbVCi+nolxsdY51CJsS86XaJzb6SNWZlnpEQqUd5Uw4NJvicLD8ZKF1d0YoTj4omYIEws4ghcrDLD90Xkj5FuyOeo76E8Ika6GMeT8NhipY1z3NEGQvWYyO84+RPZi7Adx7ewj12eftzLvkFnZye5ubmkQ9ojrtWrVye8Uv773/+e1EZBQQFPPvlkukVbTktTC21tHRw9dBQwJlzdVd1UVlfiCDpw4DDtUyAQYN/uffh95oRr2QXL4o4k08WV4aKjvYN9O/cZtqHZNPp6+izxxziC8RM2HC+YEcg0yjBdjFV+mvVlJOorDSx3x4pzlZwJ/a5CXdchqKd1/yeaYDB46l6NYkj4YtoMBEOPDxhFF7p1DUgBIYR5n3QD9Tx4DDGfP47eObjN6MPJg6Qyq8+qGYbJ8qTDcI3M4o2g0h1pxdsW9mVIiCnJKGSIiXh2wr7EdTNVu6nWc4yRXcysifbFcC2m/8l8EoltxC0sYaGjxoQWLsk4QpB4VqE49SWmoMX6nmi2YSojs0RCl0qedPKlam848lglWkkEK972VIQq7iGF+TokShRHLOKJWNxjEHE+x/E1WbqU1CvVcpLYSUmw0/huxIZB5HpckgnKGAvZjCtGqu4sKmesnGqr/LDEzjBVygjVtRxxScY4YaOi0Kgr7Pupj6evIpXIkVhKDyfHGmHFG40l8nGQ4RqBjcQIK16+VEdaYdtSDQ/GShs9QkplVBNz9JNk5DTUqTg+xRq1JSK6/IRDpATlRm+PspfKAC0VzApOSiM965DCJRnbiFOiEh4mHNhB7LAhMQQt0RT4VMKG4YykkKWLmfwphqgS5rEgPBieL+mU8zjiFF5+wv1x8iRLG+FjQgdTKDR8cxoiFp3IUOgxlfRpXKiklcYcMlQoGbuETz8e3oKG2f6ZwAiHB00Xl6gzH01bZhgTTsTBqqFfasgRl2RsExoQiVP/xpmEEfoYayQWazQV/mNK9JByLIfC86V6ENFYMQPVqjBgsrRpXlEbHm0lEq0URjhJ98XaH0eUhoyqUiDWSCzi3zguxPQzhTLSMRBRfoKRaLzNVg28InYaFzQpXJKxS/iAK1y8gOT3suD0fbF46aK3h/87SDpvt0hHjIzkHQmhis6TRugoWhxSFSyIIVpiqL2YLooYeaI65pQ7VBHja1g9xPQtGfHSpirSsV0zJn5pCFU6jMJAUAqXZIwz+CNWTovX4Bs0IgZSUelCeeNM4kj5Wa10RlhmRlZW/vqtErhkwwQrRllhG1MSmwSCFi008XwN/56onFj7h5BA0OLVQSwbqeyLJ3LpClXKmLhoGQ53wpD3uCTjhxG/shuFS8kxw0gde6oCkb7JMWTIAiz0xfLDGvl6kiMuyTghbPQUPVswOhw45D5YnHQJw4bh3weNWRHes/qVU2Y6jSSjqLjbklxpJ9wW9iVWeDBWOdGjuSFJYoXz4mSJaStZaC7WyDAZiWymciwJbKazb0j5qY5I00uWtl8mkcIlGdsMCfOdEhAxOEX+1M5Y4cCQgIV3oInesBFeaCrT4kXU91SI90MeiZBiqkKVaP9whAcTfI/pTlTapCG5GOG0pOG1RCG4aB/iJRTx96WqQSmLbzK7KbabdJpXosO2pID4yFChZPyR9Mp0xJwYxyToVEekbKuLTyY04xmrjm04Kmh06l2OuCTjg4gQIadGTqc2JlsZOdFoDCJHZEPebxi+LZZT8Ug3JBhrRJesjHTsmb2UNhIKjLUtwcgqrsuJOsc4Ihj34iZGwljhtCEjuxTqL8KOiL8vUfmxMqU6OkteWOo+Jd02ulcJE1q4nC4nDqeLHHeOYRvZOdk4XU6CegB/0G9qfTAhBEERJNedi89vfEkSBQWn04miKeZ9QhAMBHHYHeS601szJxxN08jKzgIgKIIE9EBSvxR01HDViRalwXBh0rBhkntc8bYTvm2od/HTxLofFi9fPFLtGNLu1cylGY7wYKxtKXX0UXZTDZ8lE7WkIbAUxCamnRSObcjXsGNLS2jibDYjdAnzJbFhsc5NaOFaceEKZs2fQ39/v2EbTpeTvPx8jrYepS3YTlZOVsL0iTprn89Hl7eLz9//eWNLgEBoaZXyqnKyC7I51HqIjIwMFDVGuQn60EE7QhfUnahjweIFfPFrX0yYNpl9V4YLgFZvK/4+/4BPCXzIV3rJSmUG+pDXQY02qYzWRqr8sUIKowczdseaPavcGounMl2G4RgmtHAtWrCE1WvWoJtYZ0rVNGw2G3/8yzMcOXyEE8dPGLaV686lrLyMm264CU3VDNsB8Nl9HKs9xvce/h4tjS0EAgFDdjRNY83la5g2eRrnzDvHlE/+oJ8TbSf4ySM/4UTtiYF10BL063feuoxLV8849S1Z2O/U/mRvzoiVP9EoLS7Rv0Yj4cRE+VItN5UyjKYNS580tJdo9GTAxpCyE/gd88I/ka1keU99iWsrXjqifDUwGk4pf4ztyU5rwnqOkz9RXaVUbpJzZkLQJrRwlZdWMGvabNN2dF3n2OFjbFy/ke1bthu2U1ZZxoIFC5jzwBzsdrspn5q8TRw5doQNr27g4N6DhldDttltzF0wl4VzFjJv1jxTPnX3dnOi7QSbNmzinbfeSSqmV11UDqtOCVcqU+AHw4aDv4jBV0SlEx6MJXYpYZWQRecdaaGKkS9aOJIK1qkv4flSFa1kYpHIZtyONlkPnEI4Lpl4xrSbyIdU7aYRBkyYMJbApmLYbPnDw4QWLskZxmAnEOr3x1L4MB5mBXIsE0dQrLRvpW1LbI2n82OSUTxUKVyS8UG6Yb/B10MNjroGSfbsV8z3G4ZjRmBSfe9huAOp9g5me5EURwQpj7bSHGklLCtOOC7maCXFEcIQ21HhuaSDoCRhsHS2R++POL5kec2MkIy0mah6SsukdUonhUsyxkkkKEmmwIeLV7gNiP1Qcmi7Evkbi9CbdAUpUd5UhczIfhN5E4bwor7ETGuVaMXyM1E4LnpbnB1xRTCO4VQjeUPEO0GmZEJkRmhiHZ/R/CkVbUDETSKFSzK2iRCadCZXwNAX8yYRu9DHKNVKqlVWjspi5R+m0VTCXUZGWWEb446e4m1P0GGnM9pKudON44MpQUkigInsRny1QGgS7UhxkDZsqmMB8s0ZkrGLFb+bWFf9kmEihRGKFWVYaj8NY4YGwbLdDQdyxCUZs7y+fjfBOFPmp8yYyvmrVpChZaKGX3/FG+wkeH6utu44x+tOsHP7ThLECJOXAXzoQx+iuLg4foKkDBgPBAJs2LiBhvpGOts7MNoBZufkUFZWypqLLzblkhDQp/dx9PARdr67k462DoQeI04W/cYIhiaxO+wsPPssptRMpSAvP0FYLzJf6EvYxUivt4/G1kY2vv4mnu4ehNDjj+5Cm6JHOQPf5y+az4JFC8hx5MQZUMcLUw4dZe4/tJ8TdSc4sOdAkvQx7Ib5p6kqN3zsY2RlZcawE8tWfHu9vb1sfnsjDXUN9PT0xj+mJCPXHHc2QtfpD9mIV3Ri3/r6/TEKSQ0pXJIxy69/u45f/3ZdzH3Xfuxa5l54Iy6tHBRzz7zt2FvHP17eyw+/82NEoo43BZYs+QTFxWeZsgHg8/Xyyyd/yBuvv8H+PfsN25k0ZRLnX3A+F190d+yH31OeeCno1ptYt2U7P/zOn9i3cx9Bg88/5rhz+OK/fpHrrlpBQZHJRyw8jWw/2sq/fPNPHD923LBPAJ+773OUL/og2ZmTURRzwahNBw7z4osH+PX//tqUHYfDwfv+6TtkFVSYsgPQ1VjPE3//LetfWU9DXYNhOzXTatADAVrqG035Y+a3JkOFEokkdQRjL/plkT/i1H+SJIyBNiCFSyKRpIbs0yVjBClcEskYRV79SySxkcIlmfDIENH4xtJzJ5vBuEAKl0QikUjGFVK4JBKJRDKukMIlGb/IsI5Ekh5nyG9GPsdlEYqioJ1am8soNs2GqllzLSHEwEOEmjrgkx40tjCl3WZHVdX4i0UaQNVUNJu5Z69UVR14ADbi1U3GUBQFVVWx2Wymn+Mys9p0NKqimm5Tmqahqta1KYXT7dzosdptdkvbE4S1KRNmVUU1ff4HURTFknZusxuv51goioJNtaFpp/wyYNqm2QgYXOjWKia0cHV5OmluO/UQ3ZATmPoZFUKnqLSI6bOmn24QBszlF+QzafIkmtub49tJ0W6HrwNVUZk1dxa57lwCfoMLSdo08vLz8Ot+mtqaDNkYpM/bB8D0WdNRVdWwmAJUTqqkq6sLu9ce+eYMI2hQVFzEkqVLTN/o9wa9pusJwOvzUlpRyuz5s8l15xq2U1xaTEVVBc3tzYC5iQwdvg6cLiez5s4iOzs7tEp3ujYzMzPJcefQ6+ulsdXcQ6zt3e0oisKcBXMoLis21aYKigro7uqmUTSaEwsBml2jtKyUs88724QZgd1mp93TjtJiXrzauzsoryhnzllzKKssG9howGxJaQltzS00naw37ZNRFGHVJcYI0tXVhdvtJj/baaqBfe6r93De+UsHrrLCzSgJlqOPYrB8byAY9203IVtKjG0x0NO5moljc9Avw/UTZVcIYcloRFEU0yOkQazyKfxfswz6Y8avkE8WjkoiRMaga4qiDPgU5ZZRm8nOX7TdWAIZalOplhnr5brhmwy2qXC7g+fNijYlEKHoidk2pSgKGY7TY5Uh5y0Ndzev38Sj3/6+YX9g4HjaPV46OzvJzU3v4mxCj7ie/9PfWPfKek4eP2nYRklZCWefdzZ3f/ZeCgoKTfvU1NjEFVdcgd+fxnu8YjS4az58DcuWLePKS6805Y+OTr2nnl/+9Jc8+fiThu2oqkp5ZTn3PXgfC2cspCC3wJRf+w/v5+V1L/OLn/yCnp4eQzY0TWPy9Mn80z//ExddchGFdvPn70v3f4nt27ebeqXO5GmTWXTOIv7l3n/B5XSZ9mnHjh187MaPmbKhKAo33HID5y8/nwuXXRixL90RV1AP0tDTwLe//m1ee/E1wz6pmsqcBXP45Gc/yfIFy8nMyEyeKZwot7e8u4X1m9bzi5/8gmDA2Kuj7A471TXV3HHvHSw8ayGlmaWG7Azi9/v5zJ2f4dDBQ7S0tBi2M2feHBafvZivful+SwS1u85j2oYZJrRwdXZ24enp5cSxE4Zt6EGdrs4uMhwZ5GTmmPapy9HFidoT+Hw+c3a6uggGg2RnZpuyowsdZ8CJx+Ph+NHjhu2E32vJcGaY9suu2env76fueB3dXd3GfLJpZGZnEggEyMjIIMueZepHLYSgs72ThroGU3WVkZlBd2c3Wa4sMjIyDNsZRFM0U/4AKKpCj6cHdEyfu4AewKW7aG9v5/gxE23KplFcNvBC48yMTNO/P1VR6evto662znBo3eFy4HK5QJzyKcucTz6fj/bWdhpONtBo4t2AxcXF9Hh6yMrItuSepxUXVGaY0MIldB09qJt6MWcwGEQP6pZO1gkEAqZ8ggHBscopRRkIFZr2ycT9h3gEg0FTfg2cO2FZ+FLXdYK6eZ/SChcnwYpzp+gKuq5b97CvcqquzPilWN+mhC4IBoyfv2AgSFA3V9fRDNaTqX5KDw70CWcIcjq8RCKRSMYVUrgk45dxN61IIpFYgRQuiUQikYwrpHBJJJLUkaNcyRhACpdEIpGc6YyBxR+tRAqXRCIZceQyMhIzSOGSSM6wq9FxgaxviQmkcEnGLfKqXQKyHUxEpHBJJBKJZFwhhUsikUgk4wopXBKJZHwj71FOOKRwSSQSiWRcIYVLIhmLyBFE6si6mnBI4ZJIJCkhZ++liKymYWdCr4D8/o98iGmzpiddzynRSrSZWZmUlpcyb85CNNWWdB2tIbbCvmqahtfn5bm/PRe5rIWBQ5wxewalxaVUllQSCASM/5gUIAN279zN3p17DRoZWM8pKzuL81acR7Y9G7tqN7Wiq6ffQ1N7E7ve3YXfl8aim1E+ufPdzJk3h8qqSnSP+WUftry7hda2Vnq6jS1uCeDOc1NSWsI5i84hGAgaXhsKBtasau9o58VXXkw/c9TquHPmz6G0uJTSgtLIhU5FdLYk51UFJUPhrTffSrpOWCJbqqJSUFTAgsULyHPloSrmrsPbu9tpahtoU0IXScuPhaZp5LpzOevssyjIL0D1mfNJ13XefPtNOjs76evti50oBRcLiwopKS1h2ZLz8Hl9aS6UGVmApmlseH0d33rom2nYiGHVxArIE1q4vv3od1nzvstwOB2xEyjh/4T//zQ+r5+uri42bXqbluZWOjs6E5aZSLhcLhd5+Xlc/aGrIxd7i3OIiQS1sbGR+pP17Hp3F32ePsNCqKoq02dNZ+r0qdRMqUk9YxS60Onv6+fg/oPs3bWXzvZOU2tOVVRXsPDshVRUVWDTjC0rJ4Sgv6+fI4ePcKL2BEcPHTUlpgBXXnMlxaXFOJ1Owzb6evvo7uxmy5YttLe04+lOY7XZKPczsjIoLS/lsvddliBLnGMWkWkaTjZw/NhxDu0/RHd39+m6ipE9UYdvt9uZPns6c+bMobikOGFeEelEZDoh6O7q5sjhI+x8dyd9vX0hwTHC1JlTmTF7BlVVVaF+JZW6ifbJ5/Wxd/deTtadpO54XeoORNsUA7+/91//fnJzc7HZY7TzFA+3t6eXrs5O9ry3g7aWNrz93tR8YGgdZGRksH/PXv78+2dSKzwOZoRrQi8kWZJTTk3BNFNrCIpM0N06P/3vx3lzw5u8u/Vdw7bKKsqYt2Aet3/89tiNNA1cDhcnjp/gd7/8HYf2HsLnNbaiss1u494H7mVa1TSqsqtM+eTRPBzgAP/3m/9j+5btAyNBg3zwox/k6muvpiKjwtyVdg4cfO8gO97ZwY//68emheuDaz/ItMJppmyQDb3Zvfz4kR+zcf1GDuw9YNhU9eRqVpy/gls/cqs5nwCHw8H2rdv57S9+y/5d+w0vbJjjzuHzX/k8S2YvoSbP+MUQQKNo5LA4zC9+8gvqauvSHElEcse9d3DRJRcxtWCq6eXtt725jS2btvDbn//WlB2H08Fdn7yL8vJyU3YogoamBp549H9547U3aDjZYNhUzZQaAgFzK7SbZUILF4piOrygnPrf4CqlZjrjQDCAHtRRrPDr1A8vGBjwybBfCqGrWPN1dcqnoEmfTtlQFMWSuhJCIHRBIBAwLVxgvp4GbVjRpgZX6FZQTHXGQoiBlbARoTZlVLgCgUBoNV5L27nf3MrhQheWtild102dOxgYcSmY9wcFVBSCepBA0Nxvb7CfGk3k5AyJRCKRjCukcElGFgvvqMpZbhIrEaf+k4x9pHBJRgVVUXDaNUzeSrAM2WGlgHxDhWSMIIVLMnIooKnKwJ+moKoDf2NFvCQSyfhACpdkxFAUBafDhtNhw27TBr7bBz5LJBJJqqQlXA8//DDnnnsuOTk5lJSUcM0117Bv376INP39/dx5550UFhaSnZ3NtddeS2NjY0Sa2tparrzySjIzMykpKeFLX/qS6dk3kkgcdg2HXQqCRCI580hLuF5//XXuvPNONm3axIsvvojf7+eyyy6jp+f0WwK+8IUv8Je//IWnnnqK119/nZMnT/KhD30otD8YDHLllVfi8/l48803+cUvfsETTzzBAw88YN1RnaEIIahrqOPoiaOhv87u2A88K8rAfSSbpmLTVNRRjse1dbRyou4Yh/Yforend2AKuhAEgjpBEw8iSySSiUdaz3G98MILEd+feOIJSkpK2Lp1KxdeeCGdnZ387Gc/48knn+Tiiy8G4PHHH2fOnDls2rSJZcuW8Y9//IPdu3fz0ksvUVpayqJFi/jmN7/Jfffdxze+8Q0cjjhvsZAAsHP/Tjy9ntAzUXOmzyE7M3vgeY8ocVJVJTTyCvhUfCYezjSKEAJd6Jyor2XPvl1sen0Tba3t6KeeDfMHgoy/d7dIzlhkWxwXmLrH1dk5cLVfUFAAwNatW/H7/VxyySWhNLNnz2bSpEls3LgRgI0bN7JgwQJKS0tDadauXUtXVxe7du2KWY7X66WrqyviTzLA/iP7eW3Ta0kfnNU0hQynjQynDZs2crc2/X4fG956jfqmutDMPZ8/QL/XT583YE605Cw3iWRCYvjNGbquc/fdd3P++eczf/58ABoaGnA4HOTl5UWkLS0tpaGhIZQmXLQG9w/ui8XDDz/Mgw8+aNTVM5pgMEhPbw97Du1BVVScDidTqqcMSRc+GtNUBeXUk/iBoJ6aeBgQiLaOVpqb6+g5tAW/34/P0396hCWnEkokEoMYFq4777yTnTt3smHDBiv9icn999/PPffcE/re1dVFdXX1sJc72gg9iO7rBSCoC3z+ADabDadj4AWug2+iDwQD7Ds0MEkmJzuHitIKdNuAIMUSJU1TGZy2IcSAeCV2JHWfg8GBV8oANDef5Nihnaj1u1H9fpR+ge4PoIDpd8FJJJKJiyHhuuuuu3juuedYt24dVVWnX7xaVlaGz+ejo6MjYtTV2NhIWVlZKM1bb70VYW9w1uFgmmicTqept22PV3ydDdS/9D1UFE40d/HS1iN85ps/pbC0ikAwwD/W/yNyeQmg29PNC6+/wMyzZtLn9dPv8ycMI9ptKpqm4PVZc/+rsbmeXQfeG7DdtI/89gMsWjYN1W6nsaOH9/a/hlPEeTO1RGIA+fD4xCOtmx1CCO666y6eeeYZXnnlFaZMiQxJLVmyBLvdzssvvxzatm/fPmpra1m+fDkAy5cvZ8eOHTQ1NYXSvPjii+Tm5jJ37lwzx3LGYbOrFJbmUFCcTXVlHsvnlLP5r79i56aXsdvsLJyzkNLi0iH5dF3nrfVvsXXjVoQAX0DH6w/g8weHiNjAC0UVHDaNDKcdp8P4EiEHjuzjeEMtejBAbssuKuxdTKkuwJbhxO8PIHSNmasvJ7OgyFAZEolEAmmOuO68806efPJJnn32WXJyckL3pNxuNxkZGbjdbm699VbuueceCgoKyM3N5bOf/SzLly9n2bJlAFx22WXMnTuXj3/843znO9+hoaGBf/3Xf+XOO+8cl6OqwfebaZqG3WE3dQwOhyNyORNFQbHbyHDYsDls2HTB85u2oGoqlVNnU1VWic/nw9PjobMrclr8oX2HwtaXUlBU7ZSPWmhGYvQUeZtNQ9cFiuYdCDGKgWVNYs1YDMcf8NPT4+HAvh0E/L24M+wUBJopzHKSX5CDXxcEcKFkuCibXUN23vM4nU40zfhzZjabDaFb8245RVFQNRWn02n67fCKaj4EOqxtygS6PrBygcPhwOl0Gn4Tu9PpTNqm0sXusONwOUwta6JpmiWrA8BAm9JULf5afynidJpbc3AQHR1d0dE0DYfDYcovh8OBsaVbrSOtFv3jH/8YgNWrV0dsf/zxx7nlllsA+N73voeqqlx77bV4vV7Wrl3Lj370o1BaTdN47rnnuP3221m+fDlZWVncfPPNPPTQQ+aOZNTQEfhw5+dSXllOj8f4yreFRYWUlp0eQfV4+nnrzX0sOXcqeXlZlGUUcaUKuw7v4+f/djt3ffu3TKuZRnlJOU/+8cmIhRm9Xi8BfwC/10+uOxeH00GOOye0X1EGZhnGo98XQNcFNpuNjKwMtARvt2hpaeKldX9n8zO/YVaxkw+tmkvZ5CJUTUUPBKk73EjhuR8lp2wubH2dssoyuru7CerGO5nCkkL6+voQmeY7GrvDTk5uDtNmTzPdcblcLtP+BAniU3zkFeRROanSlE9l5WWUlJaY9gnA2+/F6XRSNamKYDBoWLiysrPIzMw0deESQgwsl1NdU43L5TLepgTkunMNr1sXjd1uJ9edy7QZ5tZmczgc2GzmLzz66KNH6yWvMJ/qydVkZWXFTZvsYrCssozOtg4a69JYJNNiJvQKyLd/4bOcfe45+A0sjT5Yqs1uw5XpJKgqBIWOLvSEKxMntKkqIMDT6kEIQdDXT2f9QeZm9zCp0MHMmeX4+vy0tXRxoq6d2v48fLll+DILaGhsQCDo6+1j3659IRFTVRVd6KiqitPl5H0feh9O18AVvKYq2GwaWoxRgq6fbr6qquLt8eLtGXpv6tC+Q3g7mskJtLC4wkVVWS7Vk4txqgrt7T00tvbwZmsmNnc5jpwCsvIHfjACYapDVhQFBQVPq8fwSsqKomC323FkObA5bZa8vcXf4yfoN7eGlt1px+lyYnPZ0HU9tHbVEFKoPlVVCQaCeNrSWEU5BgoKrlwXml1DUzUCeiBlHwaSRS3/rmj0efrwe+Ncu6dgVyAGfn85roEfpMD8iElAb0evYTuDbcqeZUfRlIQjwKTRglO7da9uvk257NhddrIyHOhBPeL4Uo5anEqmaApvbdjMj//jh4b9AbkCsmEOHNiPN+Cju6vbsI2s7CwqqipYs3YteQX5uDIGrriNiFcgEKCtrY3vPf29iKvZlmAzM8szyS/IpiAvi/yCbDTg0FuHaGltoU3N4WhDZ0i49u7aS1FJEUVFRUyaPAmXy4WiKmiaxoyZM3C6BkI1BXkFOOwaqhr/VqcQghN1tWx+YzNbN20dst/b1kye5md6hZPZU6ooKMjG4bDR3trFrkP1vHegma19eQjqyHXnsuaKNcyZMwe32512/YRz4vgJtm7Zytsb3zZ8layoCnn5eSy9YClzZ86lrCT25KB0eOJ/n6D2aC2ebuNCkVeQR0VlBVd/4GpycnMSh3WS9Dl+v5/aY7U89tRjxpwZ7KxQOGvJWcyePZv5Z83H7rCfvmhM2v9GJggEAhyvO85Lz7/EwX0HE5abEAVKy0tZvnI5CxcuJCMjw9RzfXv37mXXzl1s2bgl6cVQvM5e0zTcbjerLlvF5CmTKS0aeg86mY1wgoEg//Pj/6GlqYXent6k6eNRVFJEVXUV7//AlWRlZWKz2SM8SYlTyXx+H03HGxOnHWYmtHC9u/VddmzfxdFDRw3bqKiqYOXFK/mnD3+C0oL4jTRluuDXP/31kNmCZ88oJ9OmcdnF88nOcVGc6WSNLti27yRv7trOr369jmDwdANcePZCSkpLmDZjGvkF+aFww9H9RwFwOV3MvHBm0nsNAh1fST8H9hzgFz/5xZD9d1+3jNXzJrNq0WRsRbkoQqB7+nnnvVoef/4dfvPSDmDgB10zpYY1V6zBbXNT4jQXvmr0NVJ/op7fPfE7wxcemqYxe95s5syfQ0lpCcX2YtOrBG97cxtvvvkmx48eN2xn5pyZLL9wOXf9811kZmQatgOAC070nOCXP/mlKTOKonCn+05mTZnFpLxJpmwF9AC+Ch9vv/k2z/3fc4btaDaNs887m+Url1OSUUJOVk7yTAnY79vPidoTPPnzJw2PbhxOB9NmTOOCiy+gtKiUqtyq5JkS4PP52PT6Jnbv3E1jvXGxWHjOQs5feT7Ty2YlvFBNlaJsa8LPRpnQwjWe2H2smXt+9He+3ufj3AWTmD+3ivyKfM62a5QVZBMI6Dz7xl52HW0GYM6COaxatYrrrr6Ot959i77+vgh7Xp+XVza+wvyZ8ykvKU/bn7KCbO674QJWLZpMZVketsJclB4vtfVtvLX7OA898TrHm2K/R9EK5KJ/EsnERQrXOKHfF6C2sZN/bD5AjzeAarMxa3oJue5MFBRWLJhEU0cPqqqw43ATrgwXubm5FOQVUF1eTUt7C20dbSF7Qgi6Pd3UN9UjhKC8pDzl0cb8KSWcPbOc5QtqqKwoICvLSdAfYM/Bet7dX8/L2w5zsK6Nft/Qq1arxUaKl0Qy8ZDCNc74/au7OFzfTl+fl8qy88nOdlHgsrN8XjWqMjAS2nusBaELgsEgiqIwf9Z8jp44SkdXx5DY/dETR2nraBuIxcfQrYE3uAcRQg+9bf4D58/mgxfOYfaMCnA5CPgCeJra+cuGPby2/Sgvbjk8QrUhkUgmIlK4xiHbDzSwt7aF//rDRr5668V89oYLyKssYLlDY1p5PpNK3Dz56pu82u/n49d/HICq8iqKC4p5deOr+PyRkxm6ewbetuF02FCjZhjqQZ23Nm+m+fBhLlkylQduupDq6iLy8rPB5aC7qZN1Ww/zye/8iZ5+/6i8gV4ikUwspHCNQ/xBHX+vj+5eH39ZtwddF9z1sfPJqlpAaYmN5Y43aOv14lW8/PFXP+HS919Pjjsf1aUyY8oMAsEAwUCQQ8cOhaale31eEAG0qDfH68EAtB5nUaWLslkLmbpkJpk2FSUYpL25kz++9B6vbTtMY3uKz6+N1cjeWPXrTEXWt8QEUrjGOS9tPsCOg/V8+NIFFC6YittdjttZj8thY9e+Ov78u/9h8XkrcDqdOFyZzJo6C4B+bz8nGk7g8/tC4UPBQGgwdK9LD4LfS6HoYMnMYs45azLMqEJv76K3qZ3Dhxr45fPv8Nbe0XsQUSKRTDykcJ0BNLZ6mPGB/+Bn/36SGz50Psyaz9SKcirmNXP2tFJeeuIbTFp0EWs+clcoj9Ph5LILL2Pbzm2cqD8BgM8fRFOV0+8rbK3Fdnwb/3TVIlw1ZVBaAHUNtB1uZPu7R/nIg0/R3ePFn+zt8mMcOcFDYjWyTQ0vUrjOEPq8fn7yu/XsO9LE1z//IdQcG053FkXnns0KoeITzbz715/yt837WbH6MlasXM2O/Tto72wP/chsmoqmKgghyOs8SI6zh7wF1bimlKEpCoG6JvZvO8xzr+7kjXeO0u8LoKoKNtTkS6NIJBKJRUjhOoN4/e1DNDR2cv3y6VTOqyazpJiMigpmzZlGw4lG9hzczNuvvkGeO5fKqkp27dgaevWLLgSaquBy2ChyZ5Iv2ijIsVEyqQyyM+lpaKX9aCOb3z7IC2/uY/OegfCgpqmg6AT12Gt/SSQSidVI4TrD2Ffbwvx/+gG//uq1rF4+k4q5PTBrOaU1XRRP30N+loN/vLWeez7xG8oLc7BrKgjo6fdR3+ZhZnUh//LxCyk8qwYtNxsynLDvGJvf3MffNuzlp3/dNmR0pSoDgtfvC0jxOoORD31LxgpSuM5AhIBtXRnk+2qoKL0cGt5GsevoJRVsO/QiTpvKRYtqyMvJQFEGXqjb0+enqb2H6klF5M2dhJbpQu/uxXuont9tauWVdUd5Y+Nuevp9CDEgVnbbwOuiFGUgvOiwawSDQoYNJeMXqcvjAilcZyitfhttejZkTAJ20e3poLmtBa8vQEFuJoW5GWRnOBBAUNfp6fOT5bKT686kubOXQsDfE6StDfY2eNlX383RhtOvcBKKQNMVVJWQeGmKAkJH1xX0cTb0kiMJiWT8IIXrTEdRYNL7OLT+r/zjN09wzqxyCnMzyc104rRrEcKVl+2irbuPZ371Glctn0FPThW7mYpfNA65EhUCvP4gTrsWEi8YuOelqgp9XvNLhEgkEkkspHBNEApyMlgwtYRplQXkZrnIynCg2DUQA2/H6O/14nLYyHTZQQief+sgu09sZeOBds654Py4dn2BIJqq4rBHLgroctgIBPXxETY8tdqzRHJGcwa1cSlcZzhCCHZt3UD/yf2U5mfhzskgM8uJw+WATBfoAj0QRFEVsk8JTW6Wk0P17XR0dtHSeDLh2kRCDIzYAkEFTVVCYUNFAVUoaEIhqJ9BvxiJJVgVmrU8xGuVOdnkh5UJLVw2mw2b3YHDkWChviQMLq2tB4P4/X7TK7AGAgGcTnMrO8PAWkUAfr+Pv/z6vylz9nPpOdPIyc1Ay3RChgvy3aALVJ8fh6KQFQgSDATJzXSSl+UiN9NJdoYT9dQilLGWEA9f28fhsEX47WDg99vvDaBpGnaHPXSMPp+5JdJ1/dSqzg4nPocxWzabbcAnBYKnzp9ZNE3D4bCmTQWtaFPKQF2Z8QcGzrOmDYzQzfoUEAH0oI7NZjPll81uw26zIxD4/X7L2pTD6TC8ZpXT6QwdkxXt3Of3YbfZzbcpuwNN0wgEAiiKuUdXFAUCwdF9J6kiTK91PfJ0dXXhdrvJzzbXwf/g0ce4dO0VEasNp4uqgWoXPP7LX7Fv336OHT5m2FZ+fj5V1VXc89l7BjoJE7QF2jhw8ADP/vZZZmjNnDUpj5ULJ5FbkYealQnZWVA6DdDA2w/H96K3dODp7OF4UxfbDzawec8JXtp2jI999k4cDidB/9B6umz1ZZSXDqznFe9cDL5Gqs/Xx86jO/nzH/5M7ZHapKvMJuLspWfzkU98hFJHKSrGOhlFUbDZbLy9422279jOq8+/avoK/v899P+YPHlywiXbk2IHr+7ll7/4JQf2HqDhZINhU4XFhcycMZPbP3m7cX9O0exr5p0t7/Dq31/lZF3ikXiiaszIyODSD1zKsoXLqC6rNuyPoii0e9rZfWw3f3j8D7S3tptqUxddcRFrrljDpNxJhlYwH/TJZrPx0psvsWPHDjat22TYHwC7zc4Pv/9D3LluU/2Uz+GjzdPKn598hv2799PR1mHYVlFpIU31Dbz9prljE0LQ7vHS2dlJbm5uWnkn9IgrJzeXkhJzK3kKdIK6n5aWVo4cPsKeHXsM2yopLUFRFMrKyrDb7ckzJEDv1lEUOH7sKK19LWRqQS5cVAOqCqpyagkTLwgFhBeEHgrzAQR1QZ83QFt3H0E9yOSayVSWVg68mDfsWidw6r9JFclXxe3u6YajUHuslt27dpvq3KsmV5Gbm0tZXhk21WQzFtDW2saunbtMj5hdThelJeZWwg4SxNPnoamxiUMHD5leoTvfnU95eerrrcVCCIGvy4fX7+XwocMcPng4eUcapyqzc7JZtnoZ2dnZVFRUGPYJQGlR4CgcOniIhpMNpjr3s1ecTW5uLuXl5aiKuVWCg/4gzU3N7N6525Qdh8OBO9dNaam5NuXFC7qgsaGBg/sP0NzYbNhWRXcFfT0pvlR7mJjQwmUFCioqdnp7emlvbTd1dYyC6QY6iN1uAyHobG9n2/6jlLmdA52yGOy8dAh0QVCAzwd6ECEGxhu6Dj5/gJ5+Hx2efnxeH+Ul5Zyz8Bw6PB34/D6C+kAHcbzhOP2+fkqLSrHb7Sn94DvaOmg82Wh4eXSArs4u0+I+SDAYpL+vn4aTDaaFy5JwIxp2YafH00Nrc6upNuVwOujq7DLtE4DdbifgD9DaOuCTbnDiTW9PLz6fD2HRvU8hBC0tLTTWN5oSrr7ePmx2a7rEQCBAX08fjfWNpuw4HA5TxzSIEycu3UWPp4eW5hYaG4z75cp0ETTx27UCc5cVkjGLw24DodPS1EIwGMTrD9LR3Y/o90GfF3r6oKEZGpuhpRX6fPT3+/D0euns6eNYYyd93gA1JbmheL/D4WDtqrVUllVGlNXc1szfXvsbnh7PaBzqmctYC+KPNX/GOPLZwOFDjrjOULZu3MK7b23FqQT54vXLWHr2NApmVtLT1oUzqOMM6mDTQNcRgSABTz8dnb00tnuobexkzeoFnLWgmz17jrN905vMmzITZelKbJqNyVWTycrIYs/B02HRYCDI7v27KSspY3LV5Jg+KQo47Bom551IJJIJjhSuM4ygHqSvv4/97+2k8fAhZpTncv2lC6mZVUlGRQEtJ1vRA0F0fwDNYQddRw8E6evup7G1m+auXoLA4iWz8Pf2U52XwdtPvErTscMcP3aUqupJlBSWkOHK4Hj9cfr6+kJhwxMNJxBCUJhXCAyM0JwOZ5h3CrZTDyhL8ZJIJEaRwnWG0dPrYcNbr9G89y0W5PTyyL99BPvcKWDXwDswNfdkYycdPf2UurMICoHXH6CpvYe399ZRWJTDJz+6AmaeBb5e8ouy+IYCz7z+Kv98wzM89+pmnE4X2ZnZrL1wLevfWk9Ta1Oo/LrGOuoaB94cP3fGXObOmDvER6fdhsNuw++Xb9eQSCTpI4XrDOLwsQOcOHaAkxv/xtqFpVRUurHNnQJ6kP6GTlprm/nsd/5Ea0cv/qA+8MonMbCkidcfoNPjxeHQeGb9Xh57GCZNq0atmML0c/xc5XAyueI4/3L3bVz/8ds4b8WFAMyfNZ/GlkZ27d81xJ/aulq6Pd2cs/AcNFXj9PvFBaqi4LRr+PxBeSdAMnaQjXFcIIVrnNPT20NvXy+qqtBcd4jOk/vIp5tpU2dRXFWEyHDSc6KR2gP1bNtyiJe3Hqa7N/FDkTsPN/Haa1tZ6g8w65yFuCtLme4P4lRh02/Xc3DnVtzuPGbOXUBBXgEAjS2NtHe2R8yA8vR68Pq8tLS2kJsT+ZyGooA6OC1fdhaSsYBsh+MGKVzjlMFp24ePH2b/oX24nDaCBzeR421i9eULUWrKEaoCjS0c3naY3/3jXR7+zYaU7d/8td9z6zWH+enXbTBvMUWzXbiLc/lCMMBvXvwjr7z0D376+78hhKAgr4BVS1fx4voX6fJETr32B/ysf3s9SxYsobiwaFjqQCKRJOZMm+EohWucous6699eT7enGwJetMPrmFWTQ2nFLJhcAZ3dtDW08962w3z9f19mX21L2mU88+oudh5s4G//cwcFU6qwlZUybeVCPpKZwdGDTXznizfxkc98hckz5wGw7OxlnKg/we4DQx+63LV/F3a7DWXwPVCScYdcSHJ8Y9n5GwNNQArXOMTT46GxpZHXX3qJ8oIMppRkUZKtU5jnJCcnA7w+jh6q59ChJja8d5I9R1to6Uz/Sfe2zl629/nYebSb2VndlNhsuApzqa4uwu71cbLpMM0Ht9LVepJjjZ2svvhSiguKqSqv4mTUy3l7+3oJdPvp7GzH4+klENQHXr47Bn4EEolkfCGFaxzS2NLIxi1v8IcnnuDa86dxwSULmD2rDCUnAyF0qG9l08aDbNxTz0u7m+nqN/42h6CA5w/pKI52igM9MGcK+YU5ZPuLyHZovLv9ed452MBTr+/m6edeZvrMORTkFfDC6y/Q198XcYXX4+nl1X+so7GxBZ8/SMDM+/wk4xu5lIzEBFK4xiHNh/aw67lf8b9fvIJJlQWUFOei2DW6GzoJ2vLIW3E7y6tPom/cxEsPfMeaQsvPQ58xj8aXHyXP7SQj00XFlFLy87KYP6WUxTPKefoHX2X2uRfzoU98notXXMz+I/vZf2Q/EBlj13Xd1MtQJRLJxEYK1zhCCMG+zf/A17CbpdMKmT6lhJxsJ6oCLc1d2Atn4iyYBvZsnNlunJnZ1hWuOVFcBWTVnI8ty46i+bE1biczx0WxXWO+XcPnP4Gr9wTvvvp/vHOgntJJNUyvmc6h2kMRphQU08u2SCSSiYsUrnGCHgwQ8Pay941nKXL0c+m508gsyiUYCOLt99Pa7qd89gIypywZNh9UuxP3gisGvvQ2Q/0uFIdGpsPO5EwnGTaNE40dvPvib/j5X7fykZs+zbLzlnOi4QTBQHDgTRpOJ5pNk8I1QsgJFZIzESlc44TW2t1s/9P3uWh2CVm5ZWhZTuj1cuhYCyc6gqy69TtoDlco/bB3WBlFcO7naFn/vyieWooqCiiZVERhcS6zqouYXJbHrmOb+d5XNvPVH/wWu91Jd283WflZ7Nm9h/q6+uHzTSKRnNFMcOHSEQQB1fDCcQHhp1f3UFhSwLSZ00yNJAoKC6iZWkO0K007XsLbfIBZNflk5mWiKAr9XX2s23KIgimLmHnheWiODJSwVVv7+/rRNI0Zs2eQnZ1teLkNm82GO88dWr04hKKA5iB7xioUfzdKlhPl+HrQ/GTkZzF7WilZmQ7qW3rZ+tcneOdQI809fhZfdB7TZg3Uk5nlGiqrK+np7kFkGRdngcCHD7vTTn5hPovPXWz62TB7lh0/fuwYX3KlP9hPR6CD4rJiZs6ZSXaO8ZBvcWkx1TXGF2sMp8fTg8vlYubsmWRmZBq+T5mRmUFObo5lS4goisLsubMpKi6K7VOKp7SwqJDenl4oYshvMFV0dProw+6yU1xazMJzFhozdAqH3YHP4cOLFyfOuOmSXaR2ebvo8HVQUlbC7PmzKa0wvnxScWkxHa1ttDaaW7LFDBNauLq6OmhqbkDoxld3CSh++hQP5VVlKIpCRbnxhfEyszIoKiqiuakJVTvtU/eRbbh8jVRXFRBUVTw9XpqbPWze38TZVdlUl0ynsTmyEXV0taOpKgsXncXkyZMNr52kqApFxYUEggEaGmOMkmwFYCugMwh0BHDiJzvHRUlJLpkuO8XuHt7e9TpvvL6HEz1w9sXnMXfeXMpKykyJRM2UGjrbO2lSG0+9Tiqm92H/H4pQwK/5UO0K5ZXlnL/yfMP+DOIXPppbm7Dp9shyhzihxN3VRx+dvk4mT56My+Fi6tSpafsx2JHl5ORQXVVNc0tTdIJYH2MnOPW1o72D7KwsFi5ayKTqSYbPn91hp6Awn96+nthtKg3auztQFIXFZy+ix9MbuwNP0c2S0hK6OjppyGhANahcuqLTo/Vid9mpqq403qZO+axpGm2eVtAFLt2VJEv8A+3wddDS1UJ1TTUuRwb9vX3hxaRFVm4mh/cfZNc77xnIbQ2KGIevH+jq6sLtdpOf7TQ1wll9+SVUTaqms7MzpfSxRmXZOdlU1VRx7Y3XUpJXRrbqNuyPjp+2jha++tWvRoxG7r24nFkV2WhZTppPtvHm4W6e3dl1qqHGnugwf/F85s6Zx6WrLkHFgdFLSF3o7Duxk/WvrWfzhs2JEwvBogoX18x3UzWlBNWmgi7ob/Pw0tuHONQeZPY1/8SSuUspdJt7i8bh2oNsePs1Nq3bjM8b4xVWyunzpSiD/zu17VRVqKpKUXEhK1atYP5ZZ1GdN8WUTwBP/OanHD12lO6u7tB5CV9ZOtlnBYWCwgIqq6v40JUfxmYzv1hm7fFjfO+H/zGwUOipn3vEZ04/Tzew2Ojpz+H7Fi9bzKL5izhv4VLMXPP6gz52H3+P5599nv27953yIX0UFMorylm5ZiUrl1xEVoa5yUjv7NzCW+9s4q0Nb4VWPEgXTdPIK8znksvXMHPGLKaVzTLlUyAQ4N+/+xCNDQ30eBI/i5lIuErKSqiuqeb917+f0qwKMmxZhn3qpYs/P/MnPvuJ2w3bgIH21e7x0tnZSW5ubvIMYUzoEVftkWM0N7VQV1tn2EZJWQkAmSKHTC3b1JLfCnaCPtjw6oaI0F7duy6yXRqKpuHt99HeG6ChO/Gb1QuLC5laMw1NdWAmFIqAnNwcGuoaWPfyuqTJt7s0Xvi7jYxMJx9ZM5/rL56PI8PBtsONbDrUyexrBjppVTW3hmnA76ejrYON6zbG/EHHE6vBzwoKmqYxdeYUFp2zmJzs7AghMYIQgoP7D/Heu+9SX1cfKUyDFxhK8s9Tpk0eeIWjwHQ9AXi6Pax/eX2EEEV8DilVlIhxWtwUFKqmVNE/1Yuq2hioUGN1paGRl5/HkQOHWf/K+tD2dMXLptqYc9YcVq5ZaUmb8nl9tLe288ZrbxAIGlu5wOFwUD25mosvvYjMrCzTPikK7N+9n4P7D9DSnP7bbwaZPX82LkcGpVkVuGwZhv0SCFxk4VQyDPtiBRNauLq7uunp6TM1UUBRFDzdHjRhx6aYuzpWUNGDUF9XHyFc9QZ0tdfTS8AfRCFeGC1VnwZCO729vSnVUz2w79Tn4hwXVQXZYNPYeaSJY039pnwJJ6jreL1eGk424OmOvfLyoHgpp1Ur4rNNs5GX7ybgDwy9h2eQzo5OmhubQ3WlhJUfc4SlDDgTLl45uTl4PD2WTa7x+3zU151ECIaOuqJFa2AHIky8EAP+9vf2EwgO3BM2g4KCw+mgq7OLhrqGweLTRtM0yirLTPkSTjCo4+0faFMBg0vTO5wOsrKyEEJgs5nvXoWAjrYOmhubaWwwfk+ptKKU/t4+MmzmxFRBwYYdzWS/YpYJLVyS4eVXf3+XX/39XWCgk6meYs0kgQESXPErQz7ETqIkTmMJIlERAhH2enwFJWzhl+Fy5gziVBOQ0/0nHubjEJIxiZDv1Bld4lb96ftKQ5KIOJ8tcMUKc5YKhJXNUzbzlDiTqkkKlyQpA33MmdTsh5EY4nO67kRkXYZ33uH/imhDVromz+NIIC8chxcpXJKEnEmdXSgyONwhQjH0y5ARlgj7ED4ZYlhDhYkQIdE8M8625ExGCpcFyNFIGsg3PcUghlSNv6dURg/ZpiYccnKGJCnjqgtVIudmKNEbRozBkVbUgwiDlRmaVBD2kHTCiRyWuDN0BD2uTu4IIOtjXCBHXJIUGG+/ZuPPGFlD1B0OEfYXkSJs2+B9rVEK1432GT6TBk0yAjP8SOGSSCwlWbeV7JVEIlr2JBJJFFK4JMmxoh+NeOZm7HXKw+bREFGKHm1FTt6IPYHDepdG/QyMugOS8YwULsmEx8rQTiJLsUQp5vR4MUxzMxI+OCaRjB+kcElGFtlXJmWsjkqtZGwubzk2vZIMRQqX5MzgVCgyNItQSe2Gv+Ud1eA7/8IeJI54Mitqe3i+4RWrqMkgEsk4RgqXZGQ58wcT8Webi9OjqZBORQjZ8M1Ii2X1TD8No8pEaOejiBQuC5FhhrGDEjbsUlCin6YaykieuhhLpwy5/zWM/hhe4kZyRnAm9FMT+gHk/MICsnNzTNkoKS0hvyAfVdUBHUy+7t9m05g8bXLEsiZGyHHnYLNbs1SHz+snx53D5GmT08sY1j9qNo3yynJL/AGwaRoZGRnUTK2ht2dwPa6h624N/Xw6naYN+ORwOvD5fWDH9ANFhcWFVE6qxGbTTi+pMiSEqUT6FJEOyqvKcee7Ta0NFo7T6Tx97k4tWTLYeUUsHEmcxSURKIpCZlamRUt1CPr6+igoyqdmWk3kviGJ49ux2WyUlhtfgj4abbBNTakxtR5XWWUZiqbgM/kbhoG2UVxWTJenEldm4hWQE9VVcWkxWbmZ9NBJBtnYsKZvGC0mtHD1ejwIIdANNlKAHk83x48c4/m//ZWc7FwUk4PYzq5OAn4fetDYCqyDHDt4BLtiQ/GaMoMQgiZPA4f2HjBVTwid7o5ONq3bSPORFnKz0lvxNJqTjSfZs3sX3v4+gtFrJynRowolXNNC6KpKW0srWzdtoberhxx7numxyNFDh+lobcPb38fpEpXTg6wI38L8Ctve1NDAvt12/vzsM9gtEIq6uhN4+/sjpiqeXkSSIdPyIzedftXHwT37Uf0qHQ3tpvwJ6kEau09y8ngdetS5S0e4gkLQ2tTC5vWb6K7z4HIm6diTcODwfvbv20sg4EMP6oZs+IHOtg7e2rCZpuONFGWXmPIpEAzSVF9Pr6dnaDtPg47WNg7vP8hfnvkTTiUDzWTX//ZbSVZDH2YUIcbfS9G6urpwu93kZzstuyqVSCQSycghhKDd46Wzs5Pc3PQuZOU9LolEIpGMK6RwSSQSiWRcIYVLIpFIJOMKKVwSiUQiGVekJVwPP/ww5557Ljk5OZSUlHDNNdewb9++iDSrV68emN4b9veZz3wmIk1tbS1XXnklmZmZlJSU8KUvfYmAiRkzEolEIpk4pDUn8vXXX+fOO+/k3HPPJRAI8NWvfpXLLruM3bt3k5WVFUp322238dBDD4W+Z2Zmhj4Hg0GuvPJKysrKePPNN6mvr+emm27Cbrfz7//+7xYckkQikUjOZExNh29ubqakpITXX3+dCy+8EBgYcS1atIhHHnkkZp7nn3+eq666ipMnT1JaOvDw4GOPPcZ9991Hc3MzDocjablyOrxEIpGMb0ZtOnzn/2/vXmOaOv84gH+pgw4vpcMKbVWwMKdhLWRzs2nM2BIaLjOL073wwhZcFomsJPMyY1iczL3BsGQvtpjtneyFus1ERkbcEiYUw1ZREYLg1tiGids4kmFKK4hc+vu/WDj5n1Fbrj079PdJTtKe5zmnz/PNOf5se8oZHAQAJCcnS9afOXMGOp0OZrMZFRUVGB4eFttcLhcsFotYtACgoKAAfr8f3d3dIV/n0aNH8Pv9koUxxlhsmvXPp4PBIA4cOIAtW7bAbDaL6/fs2YP09HQYjUZ0dnbi6NGjcLvduHDhAgBAEARJ0QIgPhcEIeRrVVVV4cSJE7MdKmOMsUVk1oXL4XCgq6sLLS0tkvWlpaXiY4vFAoPBgLy8PHi9XmRmZs7qtSoqKnDo0CHxud/vx9q1a2c3cMYYY4o2q48Ky8vLUV9fj6amJqxZsyZsX6vVCgDweDwAAL1ej3v37kn6TD7X6/Uh96FWq6HRaCQLY4yx2DSjwkVEKC8vR21tLRobG2EymSJu09HRAQAwGP75y+A2mw03b95Ef3+/2KehoQEajQZZWVkzGQ5jjLEYNKOPCh0OB86ePYu6ujqsWLFC/E4qKSkJiYmJ8Hq9OHv2LF599VWsXLkSnZ2dOHjwIHJzc5GdnQ0AyM/PR1ZWFt566y1UV1dDEAQcO3YMDocDarV6/mfIGGNsUZnR5fCPu/T89OnT2Lt3L+7evYs333wTXV1dGBoawtq1a7F9+3YcO3ZM8vHenTt3UFZWBqfTiWXLlqGkpAQnT56c9r1++HJ4xhhTtrlcDs+3NWGMMRZ1cylciryRpHiXVuXVXMYYY5jbv+OKLFyBQAAA4BsalXkkjDHG5iIQCCApKWlG2yjyo8JgMAi3242srCzcvXuXL48PYfK3bpxPaJxPeJxPZJxReJHyISIEAgEYjUaoVDP7ZZYi33GpVCqsXr0aAPh3XRFwPuFxPuFxPpFxRuGFy2em77Qm8f24GGOMKQoXLsYYY4qi2MKlVqtRWVnJP1p+DM4nPM4nPM4nMs4ovIXMR5EXZzDGGItdin3HxRhjLDZx4WKMMaYoXLgYY4wpChcuxhhjisKFizHGmKIosnCdOnUK69atw5NPPgmr1YqrV6/KPSRZfPTRR4iLi5MsGzduFNtHRkbgcDiwcuVKLF++HG+88caUu08vNpcvX8Zrr70Go9GIuLg4fPfdd5J2IsLx48dhMBiQmJgIu92O27dvS/rcv38fxcXF0Gg00Gq1eOedd/DgwYMozmLhRMpn7969U46pwsJCSZ/Fmk9VVRVefPFFrFixAikpKXj99dfhdrslfaZzTvX29mLr1q1YunQpUlJScOTIEYyPj0dzKgtmOhm98sorU46h/fv3S/rMNSPFFa5vvvkGhw4dQmVlJW7cuIGcnBwUFBRI7qgcS5599ln09fWJS0tLi9h28OBBfP/99zh//jyam5vx119/YceOHTKOduENDQ0hJycHp06dCtleXV2Nzz77DF9++SVaW1uxbNkyFBQUYGRkROxTXFyM7u5uNDQ0oL6+HpcvX0ZpaWm0prCgIuUDAIWFhZJj6ty5c5L2xZpPc3MzHA4Hrly5goaGBoyNjSE/Px9DQ0Nin0jn1MTEBLZu3YrR0VH88ssv+Oqrr1BTU4Pjx4/LMaV5N52MAGDfvn2SY6i6ulpsm5eMSGE2b95MDodDfD4xMUFGo5GqqqpkHJU8KisrKScnJ2Sbz+ej+Ph4On/+vLju119/JQDkcrmiNEJ5AaDa2lrxeTAYJL1eT5988om4zufzkVqtpnPnzhER0a1btwgAXbt2Tezzww8/UFxcHP35559RG3s0/DsfIqKSkhLatm3bY7eJpXz6+/sJADU3NxPR9M6pixcvkkqlIkEQxD5ffPEFaTQaevToUXQnEAX/zoiI6OWXX6b33nvvsdvMR0aKesc1OjqKtrY22O12cZ1KpYLdbofL5ZJxZPK5ffs2jEYjMjIyUFxcjN7eXgBAW1sbxsbGJFlt3LgRaWlpMZtVT08PBEGQZJKUlASr1Spm4nK5oNVq8cILL4h97HY7VCoVWltboz5mOTidTqSkpGDDhg0oKyvDwMCA2BZL+QwODgIAkpOTAUzvnHK5XLBYLEhNTRX7FBQUwO/3o7u7O4qjj45/ZzTpzJkz0Ol0MJvNqKiowPDwsNg2Hxkp6q/D//3335iYmJBMGABSU1Px22+/yTQq+VitVtTU1GDDhg3o6+vDiRMn8NJLL6GrqwuCICAhIQFarVayTWpqKgRBkGfAMpucd6jjZ7JNEASkpKRI2p944gkkJyfHRG6FhYXYsWMHTCYTvF4vPvjgAxQVFcHlcmHJkiUxk08wGMSBAwewZcsWmM1mAJjWOSUIQsjja7JtMQmVEQDs2bMH6enpMBqN6OzsxNGjR+F2u3HhwgUA85ORogoXkyoqKhIfZ2dnw2q1Ij09Hd9++y0SExNlHBlTql27domPLRYLsrOzkZmZCafTiby8PBlHFl0OhwNdXV2S74yZ1OMy+v/vOy0WCwwGA/Ly8uD1epGZmTkvr62ojwp1Oh2WLFky5Sqee/fuQa/XyzSq/w6tVotnnnkGHo8Her0eo6Oj8Pl8kj6xnNXkvMMdP3q9fsqFPuPj47h//35M5paRkQGdTgePxwMgNvIpLy9HfX09mpqasGbNGnH9dM4pvV4f8viabFssHpdRKFarFQAkx9BcM1JU4UpISMCmTZtw6dIlcV0wGMSlS5dgs9lkHNl/w4MHD+D1emEwGLBp0ybEx8dLsnK73ejt7Y3ZrEwmE/R6vSQTv9+P1tZWMRObzQafz4e2tjaxT2NjI4LBoHgCxpI//vgDAwMDMBgMABZ3PkSE8vJy1NbWorGxESaTSdI+nXPKZrPh5s2bkuLe0NAAjUaDrKys6ExkAUXKKJSOjg4AkBxDc85olheTyObrr78mtVpNNTU1dOvWLSotLSWtViu5QiVWHD58mJxOJ/X09NDPP/9MdruddDod9ff3ExHR/v37KS0tjRobG+n69etks9nIZrPJPOqFFQgEqL29ndrb2wkAffrpp9Te3k537twhIqKTJ0+SVquluro66uzspG3btpHJZKKHDx+K+ygsLKTnnnuOWltbqaWlhdavX0+7d++Wa0rzKlw+gUCA3n//fXK5XNTT00M//fQTPf/887R+/XoaGRkR97FY8ykrK6OkpCRyOp3U19cnLsPDw2KfSOfU+Pg4mc1mys/Pp46ODvrxxx9p1apVVFFRIceU5l2kjDweD3388cd0/fp16unpobq6OsrIyKDc3FxxH/ORkeIKFxHR559/TmlpaZSQkECbN2+mK1euyD0kWezcuZMMBgMlJCTQ6tWraefOneTxeMT2hw8f0rvvvktPPfUULV26lLZv3059fX0yjnjhNTU1EYApS0lJCRH9c0n8hx9+SKmpqaRWqykvL4/cbrdkHwMDA7R7925avnw5aTQaevvttykQCMgwm/kXLp/h4WHKz8+nVatWUXx8PKWnp9O+ffum/KdwseYTKhcAdPr0abHPdM6p33//nYqKiigxMZF0Oh0dPnyYxsbGojybhREpo97eXsrNzaXk5GRSq9X09NNP05EjR2hwcFCyn7lmxPfjYowxpiiK+o6LMcYY48LFGGNMUbhwMcYYUxQuXIwxxhSFCxdjjDFF4cLFGGNMUbhwMcYYUxQuXIwxxhSFCxdjjDFF4cLFGGNMUbhwMcYYU5T/AZjPFTsRkZkoAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F15HhMQcpbzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dJcaBEY1pb1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tFqYlKfMpb4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KU7-DWH0pb6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# カスタム迷路を指定\n",
        "custom_map = [\n",
        "    [1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "# custom_map = [\n",
        "#     [1, 1, 1, 1, 1, 1, 1],\n",
        "#     [1, 0, 0, 1, 0, 0, 1],\n",
        "#     [1, 1, 0, 1, 1, 0, 1],\n",
        "#     [1, 0, 0, 0, 1, 0, 1],\n",
        "#     [1, 0, 1, 0, 0, 0, 1],\n",
        "#     [1, 0, 1, 1, 1, 0, 1],\n",
        "#     [1, 1, 1, 1, 1, 1, 1],\n",
        "# ]\n",
        "\n",
        "env = AntMazeEnv(maze_type='UMaze', maze_map=custom_map, max_episode_steps=1000, seed=40)\n",
        "\n",
        "\n",
        "obs = env.reset()\n",
        "\n",
        "\n",
        "action = env.action_space.sample()\n",
        "obs, reward, done, info = env.step(action)\n",
        "\n",
        "# 画像を確認\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(obs)\n",
        "plt.show()\n",
        "\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "TBDYebIw2blV",
        "outputId": "d10d02ae-7372-4496-cc47-a90ee2dcf09f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oaHb_V-lIv7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TrpPzb85IwEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NgcNlVwskVTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "from omegaconf import OmegaConf\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "import logging\n",
        "\n",
        "# ログの設定\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    handlers=[\n",
        "        logging.StreamHandler(sys.stdout)\n",
        "    ]\n",
        ")\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# from config import Config\n",
        "# from lexa import LEXA\n",
        "# from envs.franka_kitchen import FrankaKichenEnv\n",
        "# from replay_buffer import ReplayBuffer\n",
        "# from utils import fix_seed, preprocess_obs\n",
        "\n",
        "base_path = \"/output\"\n",
        "\n",
        "config_dict = {\n",
        "    'model': {\n",
        "        'world_model': {\n",
        "            'emb_dim': 1024,\n",
        "            'z_dim': 32,\n",
        "            'num_classes': 32,\n",
        "            'h_dim': 600,\n",
        "            'hidden_dim': 600,\n",
        "            'num_layers_za2hidden': 1,\n",
        "            'num_layers_h2z': 1,\n",
        "            'mlp_hidden_dim': 400,\n",
        "            'min_std': 0.1,\n",
        "            'kl_balance_alpha': 0.8,\n",
        "            'kl_loss_scale': 0.1,\n",
        "        },\n",
        "        'explorer': {\n",
        "            'num_emsembles': 10,\n",
        "            'emsembles_offset': 1,\n",
        "            'emsembles_target_mode': 'z',\n",
        "            'mlp_hidden_dim': 400,\n",
        "            'min_std': 0.1,\n",
        "            'discount': 0.99,\n",
        "            'lambda_': 0.95,\n",
        "            'actor_entropy_scale': 0.0001,\n",
        "            'slow_critic_update': 100,\n",
        "        },\n",
        "        'achiever': {\n",
        "            'num_positives': 256,\n",
        "            'neg_sampling_factor': 0.1,\n",
        "            'mlp_hidden_dim': 400,\n",
        "            'min_std': 0.1,\n",
        "            'discount': 0.99,\n",
        "            'lambda_': 0.95,\n",
        "            'actor_entropy_scale': 0.0001,\n",
        "            'slow_critic_update': 100,\n",
        "        }\n",
        "    },\n",
        "    'env': {\n",
        "        'task': 'FrankaKitchen-v1',\n",
        "        'img_size': 128,\n",
        "        'action_repeat': 2,\n",
        "        'time_limit': 1000,\n",
        "    },\n",
        "    'data': {\n",
        "        'buffer_size': 200,\n",
        "        'batch_size': 50,\n",
        "        'seq_length': 50,\n",
        "        'imagination_horizon': 15,\n",
        "    },\n",
        "    'learning': {\n",
        "        'seed_steps': 5000,\n",
        "        'num_steps': 200,\n",
        "        'expl_episode_freq': 2,\n",
        "        'world_model_lr': 0.0002,\n",
        "        'explorer_actor_lr': 0.00004,\n",
        "        'explorer_critic_lr': 0.0001,\n",
        "        'achiever_actor_lr': 0.00004,\n",
        "        'achiever_critic_lr': 0.0001,\n",
        "        'epsilon': 0.00001,\n",
        "        'weight_decay': 0.000001,\n",
        "        'grad_clip': 100,\n",
        "        'update_freq': 4,\n",
        "        'eval_episode_freq': 5,\n",
        "    },\n",
        "    'wandb': {\n",
        "        'logging': False,\n",
        "        'name': 'lexa',\n",
        "        'group': '',\n",
        "        'project': 'LEXA',\n",
        "    },\n",
        "    'device': 'cuda',\n",
        "    'seed': 0,\n",
        "}\n",
        "\n",
        "def main(cfg):\n",
        "    logger.info(\"Initializing configuration and environment...\")\n",
        "    cfg = Config(**cfg)\n",
        "    fix_seed(cfg.seed)\n",
        "\n",
        "    # env = FrankaKichenEnv(cfg.env.img_size, cfg.env.action_repeat, cfg.env.time_limit, cfg.seed)\n",
        "    # eval_env = FrankaKichenEnv(cfg.env.img_size, cfg.env.action_repeat, cfg.env.time_limit, cfg.seed)\n",
        "\n",
        "\n",
        "    env = AntMazeEnv(maze_type='UMaze', maze_map=custom_map, max_episode_steps=1000, seed=42)\n",
        "    eval_env = AntMazeEnv(maze_type='UMaze', maze_map=custom_map, max_episode_steps=1000, seed=42)\n",
        "\n",
        "    logger.info(\"Environment initialized. Setting up LEXA and replay buffer...\")\n",
        "    lexa = LEXA(cfg, env)\n",
        "    replay_buffer = ReplayBuffer(cfg.data.buffer_size,\n",
        "                                 (3, cfg.env.img_size, cfg.env.img_size),\n",
        "                                 env.action_space.shape[0])\n",
        "\n",
        "    obs = env.reset()\n",
        "    logger.info(\"Starting seed steps...\")\n",
        "\n",
        "    # seed steps\n",
        "    for step in range(cfg.learning.seed_steps):\n",
        "        action = env.action_space.sample()\n",
        "        next_obs, reward, done, info = env.step(action)\n",
        "        print(\"Original obs shape:\", obs.shape, \"dtype:\", obs.dtype, \"min:\", obs.min(), \"max:\", obs.max())\n",
        "\n",
        "\n",
        "        # 画像を表示 (必要に応じて一定間隔で表示)\n",
        "\n",
        "        if step % 1000 == 0:\n",
        "            plt.figure(figsize=(6, 6))\n",
        "            plt.imshow(obs)\n",
        "            plt.title(\"Original Observation\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "\n",
        "        replay_buffer.push(preprocess_obs(obs), action, done)\n",
        "        obs = next_obs\n",
        "        if done:\n",
        "            obs = env.reset()\n",
        "        if step % 1000 == 0:\n",
        "            logger.info(f\"Completed {step} seed steps.\")\n",
        "\n",
        "    logger.info(\"Seed steps completed. Starting learning steps...\")\n",
        "\n",
        "    # learning steps\n",
        "    obs = env.reset()\n",
        "    goal = None\n",
        "    episodes = 0\n",
        "    best_score = -1\n",
        "    for step in tqdm(range(cfg.learning.num_steps)):\n",
        "        with torch.no_grad():\n",
        "            if episodes % cfg.learning.expl_episode_freq == 0:\n",
        "                mode = 'explorer'\n",
        "            else:\n",
        "                mode = 'achiever'\n",
        "\n",
        "            action = lexa.agent(preprocess_obs(obs), mode, goal)\n",
        "            next_obs, reward, done, info = env.step(action)\n",
        "            replay_buffer.push(preprocess_obs(obs), action, done)\n",
        "            obs = next_obs\n",
        "\n",
        "        if (step + 1) % cfg.learning.update_freq:\n",
        "            logger.debug(\"Updating model...\")\n",
        "            observations, actions, done_flags = replay_buffer.sample(cfg.data.batch_size, cfg.data.seq_length)\n",
        "            metrics = lexa.train(observations, actions)\n",
        "\n",
        "        if (step + 1) % cfg.model.explorer.slow_critic_update:\n",
        "            lexa.explorer.update_critic()\n",
        "        if (step + 1) % cfg.model.achiever.slow_critic_update:\n",
        "            lexa.achiever.update_critic()\n",
        "\n",
        "        if done:\n",
        "            logger.info(f\"Steps: {step + 1}, Episode: {episodes}, Metrics: {metrics}\")\n",
        "            lexa.save(base_path / cfg.wandb.name / f'{step + 1}')\n",
        "            episodes += 1\n",
        "            obs = env.reset()\n",
        "            lexa.agent.reset()\n",
        "            goal, _, _ = replay_buffer.sample(1, 1)\n",
        "            goal = goal.squeeze(1)\n",
        "            if episodes % cfg.learning.eval_episode_freq:\n",
        "                logger.info(\"Evaluating agent...\")\n",
        "                with torch.no_grad():\n",
        "                    success = 0\n",
        "                    for goal_idx in eval_env.goals:\n",
        "                        eval_obs = eval_env.reset()\n",
        "                        eval_env.set_goal_idx(goal_idx)\n",
        "                        goal_obs = eval_env.get_goal_obs()\n",
        "                        eval_done = False\n",
        "                        while not eval_done:\n",
        "                            eval_action = lexa.agent(preprocess_obs(eval_obs), 'achiever', preprocess_obs(goal_obs), train=False)\n",
        "                            eval_obs, eval_reward, eval_done, eval_info = eval_env.step(eval_action)\n",
        "                        if eval_env.compute_success():\n",
        "                            success += 1\n",
        "                    score = success / len(eval_env.goals)\n",
        "                logger.info(f\"Steps: {step + 1}, Episode: {episodes}, Eval Score: {score}\")\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    lexa.save(base_path / cfg.wandb.name / 'best')\n",
        "                lexa.agent.reset()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    logger.info(\"Starting training script...\")\n",
        "    cfg = OmegaConf.create(config_dict)\n",
        "    main(cfg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "7pjEkP8Y1WD2",
        "outputId": "eb46d9d7-707c-4fa2-cd67-91fd35541da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9c4e53c9231c>\u001b[0m in \u001b[0;36m<cell line: 205>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training script...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOmegaConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-9c4e53c9231c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Environment initialized. Setting up LEXA and replay buffer...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mlexa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLEXA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     replay_buffer = ReplayBuffer(cfg.data.buffer_size,\n\u001b[1;32m    118\u001b[0m                                  \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-4788a61f9974>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, env)\u001b[0m\n\u001b[1;32m     93\u001b[0m         ).to(self.device)\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         self.wm_opt = optim.Adam(self.world_model.parameters(),\n\u001b[0m\u001b[1;32m     96\u001b[0m                                  \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld_model_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                                  \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mfused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         )\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;31m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__dynamo_disable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdisable_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlobalStateGuard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompileTimeInstructionCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inductor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minductor_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mShapeGuard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_dispatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_traceable_wrapper_subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m from torch.utils._sympy.functions import (\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mApplication\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloorDiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPythonMod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIsNonOverlappingAndDenseIndicator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCleanDiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloorToInt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCeilToInt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_sympy/functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msympify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m         assuming, Q, ask, register_handler, remove_handler, refine)\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_degree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpquo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mpexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_gcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/polys/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m         GroebnerBasis, poly)\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m from .polyfuncs import (symmetrize, horner, interpolate,\n\u001b[0m\u001b[1;32m     80\u001b[0m         rational_interpolate, viete)\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/polys/polyfuncs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyoptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mallowed_flags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolytools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpoly_from_expr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPoly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m from sympy.polys.specialpolys import (\n\u001b[0m\u001b[1;32m     11\u001b[0m     symmetric_poly, interpolating_poly)\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/polys/specialpolys.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;31m# A few useful polynomials from Wang's paper ('78).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_f_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/polys/rings.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m from sympy.polys.polyutils import (expr_from_dict, _dict_reorder,\n\u001b[1;32m     29\u001b[0m                                    _parallel_dict_from_expr)\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDefaultPrinting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpublic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/printing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpython\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpycode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcodeprinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_ccode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_fcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/printing/pycode.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprecedence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecedence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcodeprinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCodePrinter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m _kw = {\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/printing/codeprinter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefault_sort_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbol\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melementary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplexes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStrPrinter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecedence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecedence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPRECEDENCE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/functions/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mconjugate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolar_lift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiodic_argument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munbranched_argument\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         principal_branch, transpose, adjoint, polarify, unpolarify)\n\u001b[0;32m---> 19\u001b[0;31m from sympy.functions.elementary.trigonometric import (sin, cos, tan,\n\u001b[0m\u001b[1;32m     20\u001b[0m         sec, csc, cot, sinc, asin, acos, atan, asec, acsc, acot, atan2)\n\u001b[1;32m     21\u001b[0m from sympy.functions.elementary.exponential import (exp_polar, exp, log,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g7UVWpXG5fnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "nJbv8u18xmXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "R6K--s3DAoue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "1qvZKvDvDYXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M_CQDERZkihC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}