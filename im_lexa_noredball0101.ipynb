{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLyThA97hKdQ",
        "outputId": "b3493958-422d-414e-d018-2ffdec8f2260"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Google Driveのマウント\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive') # , force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install omegaconf\n",
        "# !pip install gymnasium\n",
        "!pip install gymnasium-robotics\n",
        "# !pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaRyWHkMi1j5",
        "outputId": "156b1d1f-f44f-4d89-aba4-ced3a86ea277"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0.2)\n",
            "Collecting gymnasium-robotics\n",
            "  Using cached gymnasium_robotics-1.3.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting mujoco<3.2.0,>=2.2.0 (from gymnasium-robotics)\n",
            "  Using cached mujoco-3.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium-robotics) (1.26.4)\n",
            "Collecting gymnasium>=1.0.0 (from gymnasium-robotics)\n",
            "  Using cached gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting PettingZoo>=1.23.0 (from gymnasium-robotics)\n",
            "  Using cached pettingzoo-1.24.3-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: Jinja2>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium-robotics) (3.1.4)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from gymnasium-robotics) (2.36.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0->gymnasium-robotics) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0->gymnasium-robotics) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium>=1.0.0->gymnasium-robotics)\n",
            "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0.3->gymnasium-robotics) (3.0.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.10/dist-packages (from mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (1.11.0)\n",
            "Collecting glfw (from mujoco<3.2.0,>=2.2.0->gymnasium-robotics)\n",
            "  Using cached glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (3.1.7)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio->gymnasium-robotics) (11.0.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (6.4.5)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco<3.2.0,>=2.2.0->gymnasium-robotics) (3.21.0)\n",
            "Downloading gymnasium_robotics-1.3.1-py3-none-any.whl (26.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.1/26.1 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mujoco-3.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pettingzoo-1.24.3-py3-none-any.whl (847 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m847.8/847.8 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: glfw, farama-notifications, gymnasium, PettingZoo, mujoco, gymnasium-robotics\n",
            "Successfully installed PettingZoo-1.24.3 farama-notifications-0.0.4 glfw-2.8.0 gymnasium-1.0.0 gymnasium-robotics-1.3.1 mujoco-3.1.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#config.py\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class WorldModelConfig:\n",
        "    emb_dim: int = 1024\n",
        "    z_dim: int = 32\n",
        "    num_classes: int = 32\n",
        "    h_dim: int = 600\n",
        "    hidden_dim: int = 600\n",
        "    num_layers_za2hidden: int = 1\n",
        "    num_layers_h2z: int = 1\n",
        "    mlp_hidden_dim: int = 400\n",
        "    min_std: float = 0.1\n",
        "    kl_balance_alpha: float = 0.8\n",
        "    kl_loss_scale: float = 0.1\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ExplorerConfig:\n",
        "    num_emsembles: int = 10\n",
        "    emsembles_offset: int = 1\n",
        "    emsembles_target_mode: str = 'z'\n",
        "    mlp_hidden_dim: int = 400\n",
        "    min_std: float = 0.1\n",
        "    discount: float = 0.99\n",
        "    lambda_: float = 0.95\n",
        "    actor_entropy_scale: float = 1e-4\n",
        "    slow_critic_update: int = 100\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class AchieverConfig:\n",
        "    num_positives: int = 256\n",
        "    neg_sampling_factor: int = 0.1\n",
        "    mlp_hidden_dim: int = 400\n",
        "    min_std: float = 0.1\n",
        "    discount: float = 0.99\n",
        "    lambda_: float = 0.95\n",
        "    actor_entropy_scale: float = 1e-4\n",
        "    slow_critic_update: int = 100\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LEXAModelConfig:\n",
        "    world_model: WorldModelConfig = WorldModelConfig()\n",
        "    explorer: ExplorerConfig = ExplorerConfig()\n",
        "    achiever: AchieverConfig = AchieverConfig()\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataConfig:\n",
        "    buffer_size: int = 2e6\n",
        "    batch_size: int = 50\n",
        "    seq_length: int = 50\n",
        "    imagination_horizon: int = 15\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LearningConfig:\n",
        "    seed_steps: int = 5000\n",
        "    num_steps: int = 1e7\n",
        "    expl_episode_freq: int = 2\n",
        "    world_model_lr: float = 2e-4\n",
        "    explorer_actor_lr: float = 4e-5\n",
        "    explorer_critic_lr: float = 1e-4\n",
        "    achiever_actor_lr: float = 4e-5\n",
        "    achiever_critic_lr: float = 1e-4\n",
        "    epsilon: float = 1e-5\n",
        "    weight_decay: float = 1e-6\n",
        "    grad_clip: float = 100\n",
        "    update_freq: int = 4\n",
        "    eval_episode_freq: int = 5\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class EnvConfig:\n",
        "    task: str = 'FrankaKitchen-v1'\n",
        "    img_size: int = 128\n",
        "    action_repeat: int = 2\n",
        "    time_limit: int = 1000\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class WandbConfig:\n",
        "    logging: bool = False\n",
        "    name: str = 'lexa'\n",
        "    group: str = ''\n",
        "    project: str = 'LEXA'\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    model: LEXAModelConfig = LEXAModelConfig()\n",
        "    env: EnvConfig = EnvConfig()\n",
        "    data: DataConfig = DataConfig()\n",
        "    learning: LearningConfig = LearningConfig()\n",
        "    wandb: WandbConfig = WandbConfig()\n",
        "    device: str = 'cuda'\n",
        "    seed: int = 0\n"
      ],
      "metadata": {
        "id": "Qjs3Dlf0lRVc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tCemWxTHrtJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model"
      ],
      "metadata": {
        "id": "dtaG_0HVnFcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model.utils.py\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.distributions as td\n",
        "from torch.distributions.utils import _standard_normal\n",
        "from einops import rearrange\n",
        "\n",
        "\n",
        "class TruncatedNormal(td.Normal):\n",
        "    def __init__(self, loc: torch.Tensor, scale: torch.Tensor, low: float = -1.0, high: float = 1.0, eps: float = 1e-6) -> None:\n",
        "        super().__init__(loc, scale, validate_args=False)\n",
        "        self.low = low\n",
        "        self.high = high\n",
        "        self.eps = eps\n",
        "\n",
        "    def _clamp(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        clamped_x = torch.clamp(x, self.low + self.eps, self.high - self.eps)\n",
        "        x = x - x.detach() + clamped_x.detach()\n",
        "        return x\n",
        "\n",
        "    def sample(self, clip: float | None = None, sample_shape: torch.Size = torch.Size()) -> torch.Tensor:\n",
        "        shape = self._extended_shape(sample_shape)\n",
        "        eps = _standard_normal(shape, dtype=self.loc.dtype, device=self.loc.device)\n",
        "\n",
        "        eps *= self.scale\n",
        "        if clip is not None:\n",
        "            eps = torch.clamp(eps, -clip, clip)\n",
        "        x = self.loc + eps\n",
        "        return self._clamp(x)\n",
        "\n",
        "\n",
        "def compute_lambda_target(rewards: torch.Tensor, discount: float, values: torch.Tensor, lambda_: float):\n",
        "    V_lambda = torch.zeros_like(rewards)\n",
        "\n",
        "    for t in reversed(range(rewards.shape[0])):\n",
        "        if t == rewards.shape[0] - 1:\n",
        "            V_lambda[t] = rewards[t] + discount * values[t]\n",
        "        else:\n",
        "            V_lambda[t] = rewards[t] + discount * ((1-lambda_) * values[t+1] + lambda_ * V_lambda[t+1])\n",
        "\n",
        "    return V_lambda\n"
      ],
      "metadata": {
        "id": "enlGlMzrnZkb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#network.py\n",
        "\n",
        "from typing import Literal\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Normal, OneHotCategoricalStraightThrough, Independent, Bernoulli\n",
        "\n",
        "# from .utils import TruncatedNormal\n",
        "\n",
        "\n",
        "class RSSM(nn.Module):\n",
        "    def __init__(self,\n",
        "                 z_dim=30,\n",
        "                 num_classes=20,\n",
        "                 h_dim=200,\n",
        "                 hidden_dim=200,\n",
        "                 emb_dim=32,\n",
        "                 action_dim=9,\n",
        "                 num_layers_za2hidden=1,\n",
        "                 num_layers_h2z=1,\n",
        "                 min_std=0.1):\n",
        "        super(RSSM, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.h_dim = h_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.num_layers_za2hidden = num_layers_za2hidden\n",
        "        self.num_layers_h2z = num_layers_h2z\n",
        "        self.num_classes = num_classes\n",
        "        self.min_std = min_std\n",
        "\n",
        "        self.za2hidden = nn.Sequential(\n",
        "            *([nn.Sequential(nn.Linear(self.z_dim + self.action_dim, self.hidden_dim), nn.ELU())] + \\\n",
        "            [nn.Sequential(nn.Linear(self.hidden_dim, self.hidden_dim), nn.ELU()) for _ in range(self.num_layers_za2hidden - 1)])\n",
        "        )\n",
        "        self.transition = nn.GRUCell(self.hidden_dim, self.h_dim)\n",
        "\n",
        "        self.prior_hidden = nn.Sequential(\n",
        "            *([nn.Sequential(nn.Linear(self.h_dim, self.hidden_dim), nn.ELU())] + \\\n",
        "            [nn.Sequential(nn.Linear(self.hidden_dim, self.hidden_dim), nn.ELU()) for _ in range(self.num_layers_h2z - 1)])\n",
        "        )\n",
        "        self.prior_logits = nn.Linear(self.hidden_dim, self.z_dim * self.num_classes)\n",
        "\n",
        "        self.posterior_hidden = nn.Sequential(\n",
        "            *([nn.Sequential(nn.Linear(self.h_dim + self.emb_dim, self.hidden_dim), nn.ELU())] + \\\n",
        "            [nn.Sequential(nn.Linear(self.hidden_dim, self.hidden_dim), nn.ELU()) for _ in range(self.num_layers_h2z - 1)])\n",
        "        )\n",
        "        self.posterior_logits = nn.Linear(self.hidden_dim, self.z_dim * self.num_classes)\n",
        "\n",
        "    def recurrent(self, z, action, h):\n",
        "        hidden = self.za2hidden(torch.concat([z, action], dim=1))\n",
        "        next_h = self.transition(hidden, h)\n",
        "        return next_h\n",
        "\n",
        "    def prior(self, h, detach=False):\n",
        "        hidden = self.prior_hidden(h)\n",
        "        logits = self.prior_logits(hidden)\n",
        "        logits = logits.reshape(logits.shape[0], self.z_dim, self.num_classes)\n",
        "        prior = Independent(OneHotCategoricalStraightThrough(logits=logits), 1)\n",
        "        if detach:\n",
        "            detach_prior = Independent(OneHotCategoricalStraightThrough(logits=logits.detach()), 1)\n",
        "            return prior, detach_prior\n",
        "        return prior\n",
        "\n",
        "    def posterior(self, h, emb, detach=False):\n",
        "        hidden = self.posterior_hidden(torch.concat([h, emb], dim=1))\n",
        "        logits = self.posterior_logits(hidden)\n",
        "        logits = logits.reshape(logits.shape[0], self.z_dim, self.num_classes)\n",
        "        posterior = Independent(OneHotCategoricalStraightThrough(logits=logits), 1)\n",
        "        if detach:\n",
        "            detach_posterior = Independent(OneHotCategoricalStraightThrough(logits=logits.detach()), 1)\n",
        "            return posterior, detach_posterior\n",
        "        return posterior\n",
        "\n",
        "\n",
        "class ConvEncoder(nn.Module):\n",
        "    def __init__(self, input_size, emb_dim):\n",
        "        super(ConvEncoder, self).__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LayerNorm([32, input_size // 2, input_size // 2]),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LayerNorm([64, input_size // 4, input_size // 4]),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LayerNorm([128, input_size // 8, input_size // 8]),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LayerNorm([256, input_size // 16, input_size // 16]),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear((input_size // 16) ** 2 * 256 , emb_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvDecoder(nn.Module):\n",
        "    def __init__(self, img_size, z_dim, num_classes, h_dim):\n",
        "        super(ConvDecoder, self).__init__()\n",
        "\n",
        "        self.img_size = img_size\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(z_dim * num_classes + h_dim, (img_size // 16) ** 2 * 256),\n",
        "            nn.LayerNorm([(img_size // 16) ** 2 * 256,]),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.LayerNorm([128, img_size // 8, img_size // 8]),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.LayerNorm([64, img_size // 4, img_size // 4]),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.LayerNorm([32, img_size // 2, img_size // 2]),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, z, h):\n",
        "        x = torch.concat([z, h], dim=1)\n",
        "        out = self.fc(x)\n",
        "        out = out.reshape(out.shape[0], 256, self.img_size // 16, self.img_size // 16)\n",
        "        out = self.net(out)\n",
        "        dist = Independent(Normal(out, 1), 3)\n",
        "        return dist\n",
        "\n",
        "\n",
        "class Discount(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, h_dim, hidden_dim=256):\n",
        "        super(Discount, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(z_dim * num_classes + h_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, z, h):\n",
        "        logits = self.net(torch.concat([z, h], dim=1))\n",
        "        dist = Independent(Bernoulli(logits=logits), 1)\n",
        "        return dist\n",
        "\n",
        "\n",
        "class ExprolerStatePredictor(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, h_dim, target_dim, min_std, hidden_dim=256):\n",
        "        super(ExprolerStatePredictor, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.min_std = min_std\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.target_dim = target_dim\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(z_dim * num_classes + h_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.mean_fc = nn.Linear(hidden_dim, target_dim)\n",
        "        self.std_fc = nn.Linear(hidden_dim, target_dim)\n",
        "\n",
        "    def forward(self, z, h):\n",
        "        h = self.net(torch.concat([z, h], dim=1))\n",
        "        mean = self.mean_fc(h)\n",
        "        std = self.std_fc(h) + self.min_std\n",
        "        return Independent(Normal(mean, std), 1)\n",
        "\n",
        "\n",
        "class ExplorerActor(nn.Module):\n",
        "    def __init__(self, action_dim, z_dim, num_classes, h_dim, hidden_dim=256, min_std=0.1):\n",
        "        super(ExplorerActor, self).__init__()\n",
        "\n",
        "        self.action_dim = action_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.min_std = min_std\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(z_dim * num_classes + h_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.mean_fc = nn.Linear(hidden_dim, action_dim)\n",
        "        self.std_fc = nn.Linear(hidden_dim, action_dim)\n",
        "\n",
        "    def forward(self, z, h, train=True):\n",
        "        h = self.net(torch.concat([z, h], dim=1))\n",
        "        mean = F.tanh(self.mean_fc(h))\n",
        "        std = 2 * F.sigmoid(self.std_fc(h) / 2) + self.min_std\n",
        "        dist = Independent(TruncatedNormal(mean, std, -1, 1), 1)\n",
        "        if train:\n",
        "            action = dist.rsample()\n",
        "            log_prob = dist.log_prob(action.detach())\n",
        "            entropy = dist.entropy()\n",
        "            return action, log_prob, entropy\n",
        "        else:\n",
        "            action = dist.mean\n",
        "            return action, None, None\n",
        "\n",
        "\n",
        "class ExplorerCritic(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, h_dim, hidden_dim=256):\n",
        "        super(ExplorerCritic, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(z_dim * num_classes + h_dim, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, z, h):\n",
        "        return self.net(torch.concat([z, h]), dim=1)\n",
        "\n",
        "\n",
        "class State2Emb(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, h_dim, emb_dim, hidden_dim=256):\n",
        "        super(State2Emb, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(z_dim * num_classes + h_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.mean_fc = nn.Linear(hidden_dim, emb_dim)\n",
        "        self.std_fc = nn.Linear(hidden_dim, emb_dim)\n",
        "\n",
        "    def forward(self, z, h):\n",
        "        h = self.net(torch.concat([z, h], dim=1))\n",
        "        mean = self.mean_fc(h)\n",
        "        std = self.std_fc(h)\n",
        "        return Independent(Normal(mean, std), 1)\n",
        "\n",
        "\n",
        "class AchieverDistanceEstimator(nn.Module):\n",
        "    def __init__(self, emb_dim, hidden_dim=256):\n",
        "        super(AchieverDistanceEstimator, self).__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.state2emb = nn\n",
        "\n",
        "        self.current_fc = nn.Sequential(nn.Linear(emb_dim, hidden_dim),\n",
        "                                        nn.GELU())\n",
        "        self.goal_fc = nn.Sequential(nn.Linear(emb_dim, hidden_dim),\n",
        "                                     nn.GELU())\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, current_emb, goal_emb):\n",
        "        cur_h = self.current_fc(current_emb)\n",
        "        goal_h = self.goal_fc(goal_emb)\n",
        "        return self.net(torch.concat([cur_h, goal_h]), dim=1)\n",
        "\n",
        "\n",
        "class AchieverCritic(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, h_dim, emb_dim, hidden_dim=256):\n",
        "        super(AchieverCritic, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.state_fc = nn.Sequential(nn.Linear(z_dim * num_classes + h_dim, hidden_dim),\n",
        "                                      nn.GELU())\n",
        "        self.goal_fc = nn.Sequential(nn.Linear(emb_dim, hidden_dim),\n",
        "                                     nn.GELU())\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, z, h, goal_emb):\n",
        "        state_h = self.state_fc(torch.concat([z, h]), dim=1)\n",
        "        goal_h = self.goal_fc(goal_emb)\n",
        "        return self.net(torch.concat([state_h, goal_h]), dim=1)\n",
        "\n",
        "\n",
        "class AchieverActor(nn.Module):\n",
        "    def __init__(self, action_dim, z_dim, num_classes, h_dim, emb_dim, hidden_dim=256, min_std=0.1):\n",
        "        super(AchieverActor, self).__init__()\n",
        "\n",
        "        self.action_dim = action_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.min_std = min_std\n",
        "\n",
        "        self.state_fc = nn.Sequential(nn.Linear(z_dim * num_classes + h_dim, hidden_dim),\n",
        "                                      nn.GELU())\n",
        "        self.goal_fc = nn.Sequential(nn.Linear(emb_dim, hidden_dim),\n",
        "                                     nn.GELU())\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "        self.mean_fc = nn.Linear(hidden_dim, action_dim)\n",
        "        self.std_fc = nn.Linear(hidden_dim, action_dim)\n",
        "\n",
        "    def forward(self, z, h, goal_emb, train=True):\n",
        "        state_h = self.state_fc(torch.concat([z, h], dim=1))\n",
        "        goal_h = self.goal_fc(goal_emb)\n",
        "        h = self.net(torch.concat([state_h, goal_h], dim=1))\n",
        "        mean = F.tanh(self.mean_fc(h))\n",
        "        std = 2 * F.sigmoid(self.std_fc(h) / 2) + self.min_std\n",
        "        dist = Independent(TruncatedNormal(mean, std, -1, 1), 1)\n",
        "        if train:\n",
        "            action = dist.rsample()\n",
        "            log_prob = dist.log_prob(action.detach())\n",
        "            entropy = dist.entropy()\n",
        "            return action, log_prob, entropy\n",
        "        else:\n",
        "            action = dist.mean\n",
        "        return action, None, None\n"
      ],
      "metadata": {
        "id": "zZkXKZ49nTUH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#worldmodel.py\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import kl_divergence\n",
        "from einops import rearrange\n",
        "\n",
        "# from .network import RSSM, ConvEncoder, ConvDecoder, Discount\n",
        "\n",
        "\n",
        "class WorldModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 img_size,\n",
        "                 emb_dim,\n",
        "                 action_dim,\n",
        "                 z_dim,\n",
        "                 num_classes,\n",
        "                 h_dim,\n",
        "                 hidden_dim,\n",
        "                 num_layers_za2hidden,\n",
        "                 num_layers_h2z,\n",
        "                 mlp_hidden_dim,\n",
        "                 min_std,\n",
        "                 kl_balance_alpha,\n",
        "                 kl_loss_scale,\n",
        "                 device):\n",
        "        super(WorldModel, self).__init__()\n",
        "\n",
        "        self.img_size = img_size\n",
        "        self.action_dim = action_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_layers_za2hidden = num_layers_za2hidden\n",
        "        self.num_layers_h2z = num_layers_h2z\n",
        "        self.mlp_hidden_dim = mlp_hidden_dim\n",
        "        self.min_std = min_std\n",
        "        self.kl_balance_alpha = kl_balance_alpha\n",
        "        self.kl_loss_scale = kl_loss_scale\n",
        "        self.device = device\n",
        "\n",
        "        self.rssm = RSSM(\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            hidden_dim = hidden_dim,\n",
        "            emb_dim = emb_dim,\n",
        "            action_dim = action_dim,\n",
        "            num_layers_za2hidden = num_layers_za2hidden,\n",
        "            num_layers_h2z = num_layers_h2z,\n",
        "            min_std = min_std\n",
        "        )\n",
        "        self.encoder = ConvEncoder(\n",
        "            input_size = img_size,\n",
        "            emb_dim = emb_dim\n",
        "        )\n",
        "        self.decoder = ConvDecoder(\n",
        "            img_size = img_size,\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim\n",
        "        )\n",
        "\n",
        "    def train(self, observations, actions):\n",
        "        batch_size, seq_length, *_ = observations.shape\n",
        "        observations = rearrange(observations, 'b t c h w -> t b c h w')\n",
        "        actions = rearrange(actions, 'b t d -> t b d')\n",
        "\n",
        "        embs = self.encoder(rearrange(observations, 't b c h w -> (t b) c h w'))\n",
        "        embs = rearrange(embs, '(t b) d -> t b d')\n",
        "\n",
        "        z = torch.zeros(batch_size, self.z_dim*self.num_classes, device=self.device)\n",
        "        h = torch.zeros(batch_size, self.h_dim, device=self.device)\n",
        "\n",
        "        zs = torch.empty(seq_length - 1, batch_size, self.z_dim*self.num_classes, device=self.device)\n",
        "        hs = torch.empty(seq_length - 1, batch_size, self.h_dim, device=self.device)\n",
        "\n",
        "        kl_loss = 0\n",
        "        for t in range(seq_length - 1):\n",
        "            h = self.rssm.recurrent(z, actions[t], h)\n",
        "            next_prior, detach_next_prior = self.rssm.prior(h, detach=True)\n",
        "            next_posterior, detach_next_posterior = self.rssm.posterior(h, embs[t+1], detach=True)\n",
        "            z = next_posterior.rsample().flatten(1)\n",
        "            hs[t] = h\n",
        "            zs[t] = z\n",
        "            kl_loss += self.kl_balance_alpha * torch.mean(kl_divergence(detach_next_posterior, next_prior)) + \\\n",
        "                       (1 - self.kl_balance_alpha) * torch.mean(kl_divergence(next_posterior, detach_next_prior))\n",
        "        kl_loss = kl_loss / (seq_length - 1)\n",
        "\n",
        "        flatten_hs = hs.view(-1, self.h_dim)\n",
        "        flatten_zs = zs.view(-1, self.z_dim * self.num_classes)\n",
        "\n",
        "        obs_dist = self.decoder(flatten_zs, flatten_hs)\n",
        "\n",
        "        obs_loss = -torch.mean(obs_dist.log_prob(rearrange(observations[1:], 't b c h w -> (t b) c h w')))\n",
        "\n",
        "        wm_loss = obs_loss + self.kl_loss_scale * kl_loss\n",
        "        return wm_loss, (zs, hs), OrderedDict(wm_loss=wm_loss.item(), obs_loss=obs_loss.item(), kl_loss=kl_loss.item())\n",
        "\n",
        "    def imagine(self, action, z, h):\n",
        "        next_h = self.rssm.recurrent(z, action, h)\n",
        "        next_prior = self.rssm.prior(next_h)\n",
        "        next_z = next_prior.rsample().flatten(1)\n",
        "        return next_h, next_z\n"
      ],
      "metadata": {
        "id": "dygRTxcYn3Nu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#achiever_reward.py\n",
        "\n",
        "from typing import Literal\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange\n",
        "\n",
        "# from .network import AchieverDistanceEstimator, State2Emb\n",
        "\n",
        "\n",
        "class LatentDistanceReward(nn.Module):\n",
        "    def __init__(self,\n",
        "                 z_dim,\n",
        "                 num_classes,\n",
        "                 h_dim,\n",
        "                 emb_dim,\n",
        "                 mlp_hidden_dim,\n",
        "                 device):\n",
        "        super(LatentDistanceReward, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.mlp_hidden_dim = mlp_hidden_dim\n",
        "        self.device = device\n",
        "\n",
        "        self.state2emb = State2Emb(\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            emb_dim = emb_dim,\n",
        "            hidden_dim = mlp_hidden_dim\n",
        "        )\n",
        "\n",
        "        self.distance_estimator = AchieverDistanceEstimator(\n",
        "            emb_dim = emb_dim,\n",
        "            hidden_dim = mlp_hidden_dim\n",
        "        )\n",
        "\n",
        "    def imagine_compute_reward(self, current_z, current_h, goal_z, goal_h):\n",
        "        current_emb = self.state2emb(current_z, current_h)\n",
        "        goal_emb = self.state2emb(goal_z, goal_h)\n",
        "        distance = self.distance_estimator(current_emb, goal_emb)\n",
        "        return -distance\n",
        "\n",
        "    def compute_reward(self, z, h, goal_emb):\n",
        "        current_emb = self.state2emb(z, h)\n",
        "        distance = self.distance_estimator(current_emb, goal_emb)\n",
        "        return -distance\n",
        "\n",
        "    def train_state2emb(self, zs, hs, target_embs):\n",
        "        embs_dist = self.state2emb(zs, hs)\n",
        "        loss = -torch.mean(embs_dist.log_prob(target_embs))\n",
        "        return loss\n",
        "\n",
        "    def train_distance_estimator(self, zs, hs, num_positives, neg_sampling_factor, batch_length):\n",
        "        def get_future_goal_idxs(seq_len, bs):\n",
        "            cur_idx_list = []\n",
        "            goal_idx_list = []\n",
        "            for cur_idx in range(seq_len):\n",
        "                for goal_idx in range(cur_idx, seq_len):\n",
        "                    cur_idx_list.append(np.concatenate([np.ones((bs,1), dtype=np.int32)*cur_idx, np.arange(bs).reshape(-1,1)], axis = -1))\n",
        "                    goal_idx_list.append(np.concatenate([np.ones((bs,1), dtype=np.int32)*goal_idx, np.arange(bs).reshape(-1,1)], axis = -1))\n",
        "\n",
        "            return np.concatenate(cur_idx_list,0), np.concatenate(goal_idx_list,0)\n",
        "\n",
        "        def get_future_goal_idxs_neg_sampling(num_negs, seq_len, bs):\n",
        "            cur_idxs = np.random.randint((0,0), (seq_len, bs), size=(num_negs,2))\n",
        "            goal_idxs = np.random.randint((0,0), (seq_len, bs), size=(num_negs,2))\n",
        "            for i in range(num_negs):\n",
        "                goal_idxs[i,1] = np.random.choice([j for j in range(bs) if j//batch_length != cur_idxs[i,1]//batch_length])\n",
        "            return cur_idxs, goal_idxs\n",
        "\n",
        "        zs, hs = zs.detach(), hs.detach()\n",
        "\n",
        "        current_idxs, goal_idxs = get_future_goal_idxs(zs.shape[0], zs.shape[1])\n",
        "        idx = np.random.choice(np.arange(len(current_idxs)), num_positives, replace=False)\n",
        "        current_idx, goal_idx = current_idxs[idx], goal_idxs[idx]\n",
        "        current_zs, current_hs = zs[current_idx[:,0], current_idx[:,1]], hs[current_idx[:,0], current_idx[:,1]]\n",
        "        goal_zs, goal_hs = zs[goal_idx[:,0], goal_idx[:,1]], hs[goal_idx[:,0], goal_idx[:,1]]\n",
        "        current_embs, goal_embs = self.state2emb(current_zs, current_hs).mean, self.state2emb(goal_zs, goal_hs).mean\n",
        "        target_distance = (goal_idx[:,0] - current_idx[:,0]) / zs.shape[0]\n",
        "        pred_distance = self.distance_estimator(current_embs, goal_embs)\n",
        "        loss = F.mse_loss(pred_distance, target_distance)\n",
        "\n",
        "        num_negatives = num_positives * neg_sampling_factor\n",
        "        current_idx, goal_idx = get_future_goal_idxs_neg_sampling(num_negatives, zs.shape[0], zs.shape[1])\n",
        "        current_zs, current_hs = zs[current_idx[:,0], current_idx[:,1]], hs[current_idx[:,0], current_idx[:,1]]\n",
        "        goal_zs, goal_hs = zs[goal_idx[:,0], goal_idx[:,1]], hs[goal_idx[:,0], goal_idx[:,1]]\n",
        "        current_embs, goal_embs = self.state2emb(current_zs, current_hs).mean, self.state2emb(goal_zs, goal_hs).mean\n",
        "        target_distance = torch.ones(num_negatives, 1, device=self.device) * zs.shape[0]\n",
        "        pred_distance = self.distance_estimator(current_embs, goal_embs)\n",
        "        loss += F.mse_loss(pred_distance, target_distance)\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "w2NJDBCWnL3o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#achiever.py\n",
        "\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.distributions as td\n",
        "from einops import rearrange\n",
        "\n",
        "# from .network import AchieverActor, AchieverCritic\n",
        "# from .worldmodel import WorldModel\n",
        "# from .achiever_reward import LatentDistanceReward\n",
        "# from .utils import compute_lambda_target\n",
        "\n",
        "\n",
        "class Achiever(nn.Module):\n",
        "    def __init__(self,\n",
        "                 world_model: WorldModel,\n",
        "                 instrinsic_reward,\n",
        "                 action_dim,\n",
        "                 z_dim,\n",
        "                 num_classes,\n",
        "                 h_dim,\n",
        "                 emb_dim,\n",
        "                 mlp_hidden_dim,\n",
        "                 min_std,\n",
        "                 discount,\n",
        "                 lambda_,\n",
        "                 actor_entropy_scale,\n",
        "                 device):\n",
        "        super(Achiever, self).__init__()\n",
        "\n",
        "        self.world_model = world_model\n",
        "\n",
        "        self.action_dim = action_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.mlp_hidden_dim = mlp_hidden_dim\n",
        "        self.discount = discount\n",
        "        self.lambda_ = lambda_\n",
        "        self.actor_entropy_scale = actor_entropy_scale\n",
        "        self.device = device\n",
        "\n",
        "        self.actor = AchieverActor(\n",
        "            action_dim = action_dim,\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            emb_dim = emb_dim,\n",
        "            hidden_dim = mlp_hidden_dim,\n",
        "            min_std = min_std\n",
        "        )\n",
        "        self.critic = AchieverCritic(\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            emb_dim = emb_dim,\n",
        "            hidden_dim = mlp_hidden_dim\n",
        "        )\n",
        "        self.target_critic = AchieverCritic(\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            emb_dim = emb_dim,\n",
        "            hidden_dim = mlp_hidden_dim\n",
        "        )\n",
        "        self.target_critic.load_state_dict(self.critic.state_dict())\n",
        "\n",
        "        self.instrinsic_reward = instrinsic_reward\n",
        "\n",
        "    def train(self, init_zs: torch.Tensor, init_hs: torch.Tensor, goal_observations: torch.Tensor, horison_length, num_positives, neg_sampling_factor, batch_seq_length):\n",
        "        goal_observations = rearrange(goal_observations, 'b t c h w -> (t b) c h w')\n",
        "        shuffle_idx = torch.randperm(goal_observations.shape[0])\n",
        "        goal_observations = goal_observations[shuffle_idx]\n",
        "        goal_embs = self.world_model.encoder(goal_observations)\n",
        "\n",
        "        zs = init_zs.detach() # (batch_size * seq_length, z_dim * num_classes)\n",
        "        hs = init_hs.detach() # (batch_size * seq_length, h_dim)\n",
        "\n",
        "        imagined_zs = torch.empty(horison_length, *init_zs.shape, device=self.device)\n",
        "        imagined_hs = torch.empty(horison_length, *init_hs.shape, device=self.device)\n",
        "        imagined_action_log_probs = torch.empty(horison_length, init_zs.shape[0], device=self.device)\n",
        "        imagined_action_entropys = torch.empty(horison_length, init_zs.shape[0], device=self.device)\n",
        "\n",
        "        for t in range(horison_length):\n",
        "            actions, action_log_probs, action_entropys = self.actor(zs.detach(), hs.detach(), goal_embs)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                hs, zs = self.world_model.imagine(actions, zs, hs)\n",
        "\n",
        "            imagined_hs[t] = hs.detach()\n",
        "            imagined_zs[t] = zs.detach()\n",
        "            imagined_action_log_probs[t] = action_log_probs\n",
        "            imagined_action_entropys[t] = action_entropys\n",
        "\n",
        "        flatten_hs = imagined_hs.view(-1, self.h_dim).detach() # (horison_length * batch_size * seq_length, h_dim)\n",
        "        flatten_zs = imagined_zs.view(-1, self.z_dim * self.num_classes).detach() # (horison_length * batch_size * seq_length, z_dim * num_classes)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            rewards = self.instrinsic_reward.compute_reward(flatten_zs, flatten_hs, goal_embs).view(horison_length, -1) # (horison_length, batch_size * seq_length)\n",
        "            target_values = self.target_critic(flatten_zs, flatten_hs, goal_embs).view(horison_length, -1) # (horison_length, batch_size * seq_length)\n",
        "\n",
        "        lambda_target = compute_lambda_target(rewards, self.discount, target_values, self.lambda_)\n",
        "\n",
        "        objective = imagined_action_log_probs * ((lambda_target - target_values).detach())\n",
        "        actor_loss = -torch.sum(torch.mean(objective + self.actor_entropy_scale * imagined_action_entropys, dim=1))\n",
        "\n",
        "        value_mean = self.critic(flatten_zs.detach(), flatten_hs.detach()).view(horison_length, -1)\n",
        "        value_dist = td.Independent(td.Normal(value_mean, 1),  1)\n",
        "        critic_loss = -torch.mean(value_dist.log_prob(lambda_target.detach()).unsqueeze(-1))\n",
        "\n",
        "        distance_estimator_loss = self.instrinsic_reward.train_distance_estimator(imagined_zs, imagined_hs, num_positives, neg_sampling_factor, batch_seq_length)\n",
        "\n",
        "        return actor_loss, critic_loss, distance_estimator_loss, OrderedDict(ach_actor_loss=actor_loss.item(), ach_critic_loss=critic_loss.item(), distance_estimator_loss=distance_estimator_loss.item())\n",
        "\n",
        "    def update_critic(self):\n",
        "        self.target_critic.load_state_dict(self.critic.state_dict())\n"
      ],
      "metadata": {
        "id": "-37bqKebnC1g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#explorer_reward.py\n",
        "from typing import Literal\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange\n",
        "\n",
        "# from .network import ExprolerStatePredictor\n",
        "\n",
        "\n",
        "class EmsembleReward(nn.Module):\n",
        "    def __init__(self,\n",
        "                 z_dim,\n",
        "                 num_classes,\n",
        "                 h_dim,\n",
        "                 min_std,\n",
        "                 mlp_hidden_dim,\n",
        "                 device,\n",
        "                 num_emsembles = 10,\n",
        "                 offset = 1,\n",
        "                 target_mode: Literal['z', 'h', 'zh'] = 'z'):\n",
        "        super(EmsembleReward, self).__init__()\n",
        "\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.min_std = min_std\n",
        "        self.num_emsembles = num_emsembles\n",
        "        self.offset = offset\n",
        "        self.target_mode = target_mode\n",
        "        self.mlp_hidden_dim = mlp_hidden_dim\n",
        "        self.device = device\n",
        "\n",
        "        if target_mode == 'z':\n",
        "            self.target_dim = z_dim * num_classes\n",
        "        elif target_mode == 'h':\n",
        "            self.target_dim = h_dim\n",
        "        elif target_mode == 'zh':\n",
        "            self.target_dim = z_dim * num_classes + h_dim\n",
        "\n",
        "        self.emsembles = nn.ModuleList()\n",
        "        for _ in range(num_emsembles):\n",
        "            self.emsembles.append(\n",
        "                ExprolerStatePredictor(\n",
        "                    z_dim = z_dim,\n",
        "                    num_classes = num_classes,\n",
        "                    h_dim = h_dim,\n",
        "                    min_std = min_std,\n",
        "                    hidden_dim = mlp_hidden_dim,\n",
        "                    target_dim = self.target_dim\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def compute_reward(self, z, h):\n",
        "        input_ = torch.concat([z, h], dim=1)\n",
        "        preds = torch.empty(self.num_emsembles, z.shape[0], self.target_dim, device=self.device)\n",
        "        for n in range(self.num_emsembles):\n",
        "            f = self.emsembles[n]\n",
        "            preds[n] = f(input_).mean\n",
        "        var = torch.std(preds, dim=0)\n",
        "        reward = torch.sum(var, dim=1)\n",
        "        return reward\n",
        "\n",
        "    def train(self, zs, hs):\n",
        "        input_ = torch.concat([zs, hs], dim=2)\n",
        "\n",
        "        if self.target_mode == 'z':\n",
        "            target = zs\n",
        "        elif self.target_mode == 'h':\n",
        "            target = hs\n",
        "        elif self.target_mode == 'zh':\n",
        "            target = input_\n",
        "\n",
        "        input_ = rearrange(input_[:-self.offset].detach(), 't b d -> (t b) d')\n",
        "        target = rearrange(input_[self.offset:].detach(), 't b d -> (t b) d')\n",
        "\n",
        "        loss = 0\n",
        "        for f in self.emsembles:\n",
        "            dist = f(input_)\n",
        "            loss += -torch.mean(dist.log_prob(target))\n",
        "        return loss, OrderedDict(emsemble_loss=loss.item())\n",
        "\n"
      ],
      "metadata": {
        "id": "Ijd1tc6_or_q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#explorer.py\n",
        "\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.distributions as td\n",
        "from einops import rearrange\n",
        "\n",
        "# from .network import ExplorerActor, ExplorerCritic\n",
        "# from .worldmodel import WorldModel\n",
        "# from .explorer_reward import EmsembleReward\n",
        "# from .utils import compute_lambda_target\n",
        "\n",
        "\n",
        "class Explorer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 world_model: WorldModel,\n",
        "                 instrinsic_reward,\n",
        "                 action_dim,\n",
        "                 z_dim,\n",
        "                 num_classes,\n",
        "                 h_dim,\n",
        "                 mlp_hidden_dim,\n",
        "                 min_std,\n",
        "                 num_emsembles,\n",
        "                 emsembles_offset,\n",
        "                 emsembles_target_mode,\n",
        "                 discount,\n",
        "                 lambda_,\n",
        "                 actor_entropy_scale,\n",
        "                 device):\n",
        "        super(Explorer, self).__init__()\n",
        "\n",
        "        self.world_model = world_model\n",
        "\n",
        "        self.action_dim = action_dim\n",
        "        self.z_dim = z_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.h_dim = h_dim\n",
        "        self.mlp_hidden_dim = mlp_hidden_dim\n",
        "        self.min_std = min_std\n",
        "        self.num_emsembles = num_emsembles\n",
        "        self.emsembles_offset = emsembles_offset\n",
        "        self.emsembles_target_mode = emsembles_target_mode\n",
        "        self.discount = discount\n",
        "        self.lambda_ = lambda_\n",
        "        self.actor_entropy_scale = actor_entropy_scale\n",
        "        self.device = device\n",
        "\n",
        "        self.actor = ExplorerActor(\n",
        "            action_dim = action_dim,\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            hidden_dim = mlp_hidden_dim,\n",
        "            min_std = min_std\n",
        "        )\n",
        "        self.critic = ExplorerCritic(\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            hidden_dim = mlp_hidden_dim\n",
        "        )\n",
        "        self.target_critic = ExplorerCritic(\n",
        "            z_dim = z_dim,\n",
        "            num_classes = num_classes,\n",
        "            h_dim = h_dim,\n",
        "            hidden_dim = mlp_hidden_dim\n",
        "        )\n",
        "        self.target_critic.load_state_dict(self.critic.state_dict())\n",
        "\n",
        "        self.instrinsic_reward = instrinsic_reward\n",
        "\n",
        "    def train(self, init_zs: torch.Tensor, init_hs: torch.Tensor, horison_length):\n",
        "        zs = init_zs.detach() # (batch_size * seq_length, z_dim * num_classes)\n",
        "        hs = init_hs.detach() # (batch_size * seq_length, h_dim)\n",
        "\n",
        "        imagined_zs = torch.empty(horison_length, *init_zs.shape, device=self.device)\n",
        "        imagined_hs = torch.empty(horison_length, *init_hs.shape, device=self.device)\n",
        "        imagined_action_log_probs = torch.empty(horison_length, init_zs.shape[0], device=self.device)\n",
        "        imagined_action_entropys = torch.empty(horison_length, init_zs.shape[0], device=self.device)\n",
        "\n",
        "        for t in range(horison_length):\n",
        "            actions, action_log_probs, action_entropys = self.actor(zs.detach(), hs.detach())\n",
        "\n",
        "            with torch.no_grad():\n",
        "                hs, zs = self.world_model.imagine(actions, zs, hs)\n",
        "\n",
        "            imagined_hs[t] = hs.detach()\n",
        "            imagined_zs[t] = zs.detach()\n",
        "            imagined_action_log_probs[t] = action_log_probs\n",
        "            imagined_action_entropys[t] = action_entropys\n",
        "\n",
        "        flatten_hs = imagined_hs.view(-1, self.h_dim).detach() # (horison_length * batch_size * seq_length, h_dim)\n",
        "        flatten_zs = imagined_zs.view(-1, self.z_dim * self.num_classes).detach() # (horison_length * batch_size * seq_length, z_dim * num_classes)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            rewards = self.instrinsic_reward.compute_reward(flatten_zs, flatten_hs).view(horison_length, -1) # (horison_length, batch_size * seq_length)\n",
        "            target_values = self.target_critic(flatten_zs, flatten_hs).view(horison_length, -1) # (horison_length, batch_size * seq_length)\n",
        "\n",
        "        lambda_target = compute_lambda_target(rewards, self.discount, target_values, self.lambda_)\n",
        "\n",
        "        objective = imagined_action_log_probs * ((lambda_target - target_values).detach())\n",
        "        actor_loss = -torch.sum(torch.mean(objective + self.actor_entropy_scale * imagined_action_entropys, dim=1))\n",
        "\n",
        "        value_mean = self.critic(flatten_zs.detach(), flatten_hs.detach()).view(horison_length, -1)\n",
        "        value_dist = td.Independent(td.Normal(value_mean, 1),  1)\n",
        "        critic_loss = -torch.mean(value_dist.log_prob(lambda_target.detach()).unsqueeze(-1))\n",
        "\n",
        "        return actor_loss, critic_loss, OrderedDict(exp_actor_loss=actor_loss.item(), exp_critic_loss=critic_loss.item())\n",
        "\n",
        "    def update_critic(self):\n",
        "        self.target_critic.load_state_dict(self.critic.state_dict())\n"
      ],
      "metadata": {
        "id": "XY9zGP7yoKFA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#replay_buffer.py\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# class ReplayBuffer:\n",
        "#     def __init__(self,\n",
        "#                  capacity,\n",
        "#                  observation_shape,\n",
        "#                  action_dim):\n",
        "#         self.capacity = capacity\n",
        "#         self.observation_shape = observation_shape\n",
        "#         self.action_dim = action_dim\n",
        "\n",
        "#         self.observations = np.zeros((capacity, *observation_shape), dtype=np.float32)\n",
        "#         self.actions = np.zeros((capacity, action_dim), dtype=np.float32)\n",
        "#         self.done = np.zeros((capacity, 1), dtype=bool)\n",
        "\n",
        "#         self.idx = 0\n",
        "#         self.if_filled = False\n",
        "\n",
        "#     def push(self, observation, action, done):\n",
        "#         self.observations[self.idx] = observation\n",
        "#         self.actions[self.idx] = action\n",
        "#         self.done[self.idx] = done\n",
        "\n",
        "#         if self.idx == self.capacity - 1:\n",
        "#             self.is_filled = True\n",
        "#         self.idx = (self.idx + 1) % self.capacity\n",
        "\n",
        "#     def sample(self, batch_size, seq_length):\n",
        "#         episode_borders = np.where(self.done)[0]\n",
        "#         sampled_indexes = []\n",
        "#         for _ in range(batch_size):\n",
        "#             cross_border = True\n",
        "#             while cross_border:\n",
        "#                 initial_index = np.random.randint(len(self) - seq_length + 1)\n",
        "#                 final_index = initial_index + seq_length - 1\n",
        "#                 cross_border = np.logical_and(initial_index <= episode_borders,\n",
        "#                                               episode_borders < final_index).any()\n",
        "#             sampled_indexes += list(range(initial_index, final_index + 1))\n",
        "\n",
        "#         sampled_observations = self.observations[sampled_indexes].reshape(\n",
        "#             batch_size, seq_length, *self.observations.shape[1:])\n",
        "#         sampled_actions = self.actions[sampled_indexes].reshape(\n",
        "#             batch_size, seq_length, self.actions.shape[1])\n",
        "#         sampled_done = self.done[sampled_indexes].reshape(\n",
        "#             batch_size, seq_length, 1)\n",
        "#         return sampled_observations, sampled_actions, sampled_done\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.capacity if self.is_filled else self.idx\n",
        "\n",
        "#     def save(self, dir):\n",
        "#         dir = Path(dir)\n",
        "#         np.save(dir / \"observations\", self.observations)\n",
        "#         np.save(dir / \"actions\", self.actions)\n",
        "#         np.save(dir / \"done\", self.done)\n",
        "\n",
        "#     def load(self, dir):\n",
        "#         dir = Path(dir)\n",
        "#         self.observations = np.load(dir / \"observations\")\n",
        "#         self.actions = np.load(dir / \"actions\")\n",
        "#         self.done = np.load(dir / \"done\")\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "class ReplayBuffer:\n",
        "    def __init__(self,\n",
        "                 capacity,\n",
        "                 observation_shape,\n",
        "                 action_dim):\n",
        "        self.capacity = capacity\n",
        "        self.observation_shape = observation_shape\n",
        "        self.action_dim = action_dim\n",
        "\n",
        "        self.observations = np.zeros((capacity, *observation_shape), dtype=np.float32)\n",
        "        self.actions = np.zeros((capacity, action_dim), dtype=np.float32)\n",
        "        self.done = np.zeros((capacity, 1), dtype=bool)\n",
        "\n",
        "        self.idx = 0\n",
        "        self.if_filled = False  # 修正: 正しいフィールド名を使用\n",
        "\n",
        "    def push(self, observation, action, done):\n",
        "        self.observations[self.idx] = observation\n",
        "        self.actions[self.idx] = action\n",
        "        self.done[self.idx] = done\n",
        "\n",
        "        # インデックス更新とバッファが満杯になったかのフラグ更新\n",
        "        if self.idx == self.capacity - 1:\n",
        "            self.if_filled = True\n",
        "        self.idx = (self.idx + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size, seq_length):\n",
        "        episode_borders = np.where(self.done)[0]\n",
        "        sampled_indexes = []\n",
        "        for _ in range(batch_size):\n",
        "            cross_border = True\n",
        "            while cross_border:\n",
        "                initial_index = np.random.randint(len(self) - seq_length + 1)\n",
        "                final_index = initial_index + seq_length - 1\n",
        "                cross_border = np.logical_and(initial_index <= episode_borders,\n",
        "                                              episode_borders < final_index).any()\n",
        "            sampled_indexes += list(range(initial_index, final_index + 1))\n",
        "\n",
        "        sampled_observations = self.observations[sampled_indexes].reshape(\n",
        "            batch_size, seq_length, *self.observations.shape[1:])\n",
        "        sampled_actions = self.actions[sampled_indexes].reshape(\n",
        "            batch_size, seq_length, self.actions.shape[1])\n",
        "        sampled_done = self.done[sampled_indexes].reshape(\n",
        "            batch_size, seq_length, 1)\n",
        "        return sampled_observations, sampled_actions, sampled_done\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.capacity if self.if_filled else self.idx  # 修正: 正しいフィールドを使用\n",
        "\n",
        "    def save(self, dir):\n",
        "        dir = Path(dir)\n",
        "        np.save(dir / \"observations\", self.observations)\n",
        "        np.save(dir / \"actions\", self.actions)\n",
        "        np.save(dir / \"done\", self.done)\n",
        "\n",
        "    def load(self, dir):\n",
        "        dir = Path(dir)\n",
        "        self.observations = np.load(dir / \"observations.npy\")\n",
        "        self.actions = np.load(dir / \"actions.npy\")\n",
        "        self.done = np.load(dir / \"done.npy\")\n",
        "\n",
        "    def debug_info(self, n=5):\n",
        "        \"\"\"\n",
        "        リプレイバッファのデバッグ情報を取得します。\n",
        "        :param n: 表示するサンプル数\n",
        "        :return: デバッグ情報の辞書\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'current_size': len(self),\n",
        "            'latest_observations': self.observations[max(0, self.idx - n):self.idx].tolist(),\n",
        "            'latest_actions': self.actions[max(0, self.idx - n):self.idx].tolist(),\n",
        "            'latest_done_flags': self.done[max(0, self.idx - n):self.idx].tolist()\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "rQKNQtrBo5Ho"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lexa.py\n",
        "\n",
        "from typing import Union, Literal\n",
        "import functools\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from gymnasium import Env\n",
        "\n",
        "# from config import Config\n",
        "# from model.worldmodel import WorldModel\n",
        "# from model.explorer import Explorer\n",
        "# from model.explorer_reward import EmsembleReward\n",
        "# from model.achiever import Achiever\n",
        "# from model.achiever_reward import LatentDistanceReward\n",
        "# from replay_buffer import ReplayBuffer\n",
        "\n",
        "\n",
        "class LEXA:\n",
        "    def __init__(self, cfg: Config, env: Env):\n",
        "        self.cfg = cfg\n",
        "        self.env = env\n",
        "        self.device = torch.device(self.cfg.device)\n",
        "\n",
        "        self.world_model = WorldModel(\n",
        "            img_size = cfg.env.img_size,\n",
        "            emb_dim = cfg.model.world_model.emb_dim,\n",
        "            action_dim = self.env.action_space.shape[0],\n",
        "            z_dim = cfg.model.world_model.z_dim,\n",
        "            num_classes = cfg.model.world_model.num_classes,\n",
        "            h_dim = cfg.model.world_model.h_dim,\n",
        "            hidden_dim = cfg.model.world_model.hidden_dim,\n",
        "            num_layers_za2hidden = cfg.model.world_model.num_layers_za2hidden,\n",
        "            num_layers_h2z = cfg.model.world_model.num_layers_h2z,\n",
        "            mlp_hidden_dim = cfg.model.world_model.mlp_hidden_dim,\n",
        "            min_std = cfg.model.world_model.min_std,\n",
        "            kl_balance_alpha = cfg.model.world_model.kl_balance_alpha,\n",
        "            kl_loss_scale = cfg.model.world_model.kl_loss_scale,\n",
        "            device = self.device\n",
        "        ).to(self.device)\n",
        "        self.explorer_reward = EmsembleReward(\n",
        "            z_dim = cfg.model.world_model.z_dim,\n",
        "            num_classes = cfg.model.world_model.num_classes,\n",
        "            h_dim = cfg.model.world_model.h_dim,\n",
        "            min_std = cfg.model.world_model.min_std,\n",
        "            mlp_hidden_dim = cfg.model.explorer.mlp_hidden_dim,\n",
        "            device = self.device,\n",
        "            num_emsembles = cfg.model.explorer.num_emsembles,\n",
        "            offset = cfg.model.explorer.emsembles_offset,\n",
        "            target_mode = cfg.model.explorer.emsembles_target_mode,\n",
        "        ).to(self.device)\n",
        "        self.explorer = Explorer(\n",
        "            world_model = self.world_model,\n",
        "            instrinsic_reward = self.explorer_reward,\n",
        "            action_dim = self.env.action_space.shape[0],\n",
        "            z_dim = cfg.model.world_model.z_dim,\n",
        "            num_classes = cfg.model.world_model.num_classes,\n",
        "            h_dim = cfg.model.world_model.h_dim,\n",
        "            mlp_hidden_dim = cfg.model.explorer.mlp_hidden_dim,\n",
        "            min_std = cfg.model.explorer.min_std,\n",
        "            num_emsembles = cfg.model.explorer.num_emsembles,\n",
        "            emsembles_offset = cfg.model.explorer.emsembles_offset,\n",
        "            emsembles_target_mode = cfg.model.explorer.emsembles_target_mode,\n",
        "            discount = cfg.model.explorer.discount,\n",
        "            lambda_ = cfg.model.explorer.lambda_,\n",
        "            actor_entropy_scale = cfg.model.explorer.actor_entropy_scale,\n",
        "            device = self.device\n",
        "        ).to(self.device)\n",
        "        self.achiever_reward = LatentDistanceReward(\n",
        "            z_dim = cfg.model.world_model.z_dim,\n",
        "            num_classes = cfg.model.world_model.num_classes,\n",
        "            h_dim = cfg.model.world_model.h_dim,\n",
        "            emb_dim = cfg.model.world_model.emb_dim,\n",
        "            mlp_hidden_dim = cfg.model.achiever.mlp_hidden_dim,\n",
        "            device = self.device\n",
        "        ).to(self.device)\n",
        "        self.achiever = Achiever(\n",
        "            world_model = self.world_model,\n",
        "            instrinsic_reward = self.achiever_reward,\n",
        "            action_dim = self.env.action_space.shape[0],\n",
        "            z_dim = cfg.model.world_model.z_dim,\n",
        "            num_classes = cfg.model.world_model.num_classes,\n",
        "            h_dim = cfg.model.world_model.h_dim,\n",
        "            emb_dim = cfg.model.world_model.emb_dim,\n",
        "            mlp_hidden_dim = cfg.model.achiever.mlp_hidden_dim,\n",
        "            min_std = cfg.model.achiever.min_std,\n",
        "            discount = cfg.model.achiever.discount,\n",
        "            lambda_ = cfg.model.achiever.lambda_,\n",
        "            actor_entropy_scale = cfg.model.achiever.actor_entropy_scale,\n",
        "            device = self.device\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.wm_opt = optim.Adam(self.world_model.parameters(),\n",
        "                                 lr = cfg.learning.world_model_lr,\n",
        "                                 eps = cfg.learning.epsilon,\n",
        "                                 weight_decay = cfg.learning.weight_decay)\n",
        "        self.exp_reward_opt = optim.Adam(self.explorer_reward.parameters(),\n",
        "                                         lr = cfg.learning.world_model_lr,\n",
        "                                         eps = cfg.learning.epsilon,\n",
        "                                         weight_decay = cfg.learning.weight_decay)\n",
        "        self.exp_actor_opt = optim.Adam(self.explorer.actor.parameters(),\n",
        "                                        lr = cfg.learning.explorer_actor_lr,\n",
        "                                        eps = cfg.learning.epsilon,\n",
        "                                        weight_decay = cfg.learning.weight_decay)\n",
        "        self.exp_critic_opt = optim.Adam(self.explorer.critic.parameters(),\n",
        "                                         lr = cfg.learning.explorer_critic_lr,\n",
        "                                         eps = cfg.learning.epsilon,\n",
        "                                         weight_decay = cfg.learning.weight_decay)\n",
        "        self.ach_reward_opt = optim.Adam(self.achiever_reward.parameters(),\n",
        "                                        lr = cfg.learning.achiever_critic_lr,\n",
        "                                        eps = cfg.learning.epsilon,\n",
        "                                        weight_decay = cfg.learning.weight_decay)\n",
        "        self.ach_actor_opt = optim.Adam(self.achiever.actor.parameters(),\n",
        "                                        lr = cfg.learning.achiever_actor_lr,\n",
        "                                        eps = cfg.learning.epsilon,\n",
        "                                        weight_decay = cfg.learning.weight_decay)\n",
        "        self.ach_critic_opt = optim.Adam(self.achiever.critic.parameters(),\n",
        "                                         lr = cfg.learning.achiever_critic_lr,\n",
        "                                         eps = cfg.learning.epsilon,\n",
        "                                         weight_decay = cfg.learning.weight_decay)\n",
        "\n",
        "        self.agent = Agent(self.world_model, self.explorer, self.achiever, self.device)\n",
        "\n",
        "    def train(self, observations, actions):\n",
        "        observations = torch.from_numpy(observations).to(self.device)\n",
        "        actions = torch.from_numpy(actions).to(self.device)\n",
        "\n",
        "        wm_loss, (zs, hs), wm_metrics = self.world_model.train(observations, actions)\n",
        "        emsemble_loss, emsemble_metrics = self.explorer_reward.train(zs, hs)\n",
        "        self.wm_opt.zero_grad(True)\n",
        "        wm_loss.backward()\n",
        "        clip_grad_norm_(self.world_model.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.wm_opt.step()\n",
        "        self.exp_reward_opt.zero_grad(True)\n",
        "        emsemble_loss.backward()\n",
        "        clip_grad_norm_(self.explorer_reward.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.exp_reward_opt.step()\n",
        "\n",
        "        zs = zs.view(-1, self.cfg.model.world_model.z_dim * self.cfg.model.world_model.num_classes)\n",
        "        hs = hs.view(-1, self.cfg.model.world_model.h_dim)\n",
        "\n",
        "        exp_actor_loss, axp_critic_loss, exp_metrics = self.explorer.train(zs, hs, self.cfg.data.imagination_horizon)\n",
        "        self.exp_actor_opt.zero_grad(True)\n",
        "        exp_actor_loss.backward()\n",
        "        clip_grad_norm_(self.explorer.actor.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.exp_actor_opt.step()\n",
        "        self.exp_critic_opt.zero_grad(True)\n",
        "        axp_critic_loss.backward()\n",
        "        clip_grad_norm_(self.explorer.critic.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.exp_critic_opt.step()\n",
        "\n",
        "        ach_actor_loss, ach_critic_loss, de_loss, ach_metrics = self.achiever.train(zs, hs, observations,\n",
        "                                                                                    self.cfg.data.imagination_horizon,\n",
        "                                                                                    self.cfg.model.achiever.num_positives,\n",
        "                                                                                    self.cfg.model.achiever.neg_sampling_factor,\n",
        "                                                                                    self.cfg.data.seq_length)\n",
        "        self.ach_actor_opt.zero_grad(True)\n",
        "        ach_actor_loss.backward()\n",
        "        clip_grad_norm_(self.achiever.actor.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.ach_actor_opt.step()\n",
        "        self.ach_critic_opt.zero_grad(True)\n",
        "        ach_critic_loss.backward()\n",
        "        clip_grad_norm_(self.achiever.critic.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.ach_critic_opt.step()\n",
        "        self.ach_reward_opt.zero_grad(True)\n",
        "        de_loss.backward()\n",
        "        clip_grad_norm_(self.achiever_reward.parameters(), self.cfg.learning.grad_clip)\n",
        "        self.ach_reward_opt.step()\n",
        "\n",
        "        return wm_metrics | emsemble_metrics | exp_metrics | ach_metrics\n",
        "\n",
        "    @staticmethod\n",
        "    def load(checkpoint):\n",
        "        cfg = checkpoint['config']\n",
        "        env = checkpoint['env']\n",
        "        output = LEXA(cfg, env)\n",
        "        output.world_model.load_state_dict(checkpoint['world_model'])\n",
        "        output.explorer_reward.load_state_dict(checkpoint['exp_reward'])\n",
        "        output.explorer.load_state_dict(checkpoint['explorer'])\n",
        "        output.achiever_reward.load_state_dict(checkpoint['ach_reward'])\n",
        "        output.achiever.load_state_dict(checkpoint['achiever'])\n",
        "        output.wm_opt.load_state_dict(checkpoint['wm_opt'])\n",
        "        output.exp_reward_opt.load_state_dict(checkpoint['exp_reward_opt'])\n",
        "        output.exp_actor_opt.load_state_dict(checkpoint['exp_actor_opt'])\n",
        "        output.exp_critic_opt.load_state_dict(checkpoint['exp_critic_opt'])\n",
        "        output.ach_reward_opt.load_state_dict(checkpoint['ach_reward_opt'])\n",
        "        output.ach_actor_opt.load_state_dict(checkpoint['ach_actor_opt'])\n",
        "        output.ach_critic_opt.load_state_dict(checkpoint['ach_critic_opt'])\n",
        "        return output\n",
        "\n",
        "    def save(self, path):\n",
        "        path = Path(path)\n",
        "        path.mkdir(parents=True, exist_ok=True)\n",
        "        torch.save(\n",
        "            {\n",
        "                'world_model': self.world_model.state_dict(),\n",
        "                'exp_reward': self.explorer_reward.state_dict(),\n",
        "                'explorer': self.explorer.state_dict(),\n",
        "                'ach_reward': self.achiever_reward.state_dict(),\n",
        "                'achiever': self.achiever.state_dict(),\n",
        "                'wm_opt': self.wm_opt.state_dict(),\n",
        "                'exp_reward_opt': self.exp_reward_opt.state_dict(),\n",
        "                'exp_actor_opt': self.exp_actor_opt.state_dict(),\n",
        "                'exp_critic_opt': self.exp_critic_opt.state_dict(),\n",
        "                'ach_reward_opt': self.ach_reward_opt.state_dict(),\n",
        "                'ach_actor_opt': self.ach_actor_opt.state_dict(),\n",
        "                'ach_critic_opt': self.ach_critic_opt.state_dict(),\n",
        "                'config': self.cfg,\n",
        "                'env': self.env,\n",
        "            },\n",
        "            path\n",
        "        )\n",
        "\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, world_model: WorldModel, explorer: Explorer, achiever: Achiever, device: torch.device):\n",
        "        self.world_model = world_model\n",
        "        self.explorer = explorer\n",
        "        self.achiever = achiever\n",
        "        self.device = device\n",
        "\n",
        "        self.h = torch.zeros(1, self.world_model.h_dim, device=self.device)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def __call__(self, observation, mode: Literal['explorer', 'achiever'], goal=None, train=True):\n",
        "        observation = torch.from_numpy(observation).unsqueeze(0).to(self.device)\n",
        "\n",
        "        if mode == 'explorer':\n",
        "            policy = self.explorer.actor\n",
        "        elif mode == 'achiever':\n",
        "            policy = self.achiever.actor\n",
        "            assert goal is not None, 'goal must be provided in achiever mode'\n",
        "            goal = torch.from_numpy(goal).to(self.device)\n",
        "            goal_emb = self.world_model.encoder(goal)\n",
        "            policy = functools.partial(policy, goal_emb=goal_emb)\n",
        "\n",
        "        obs_emb = self.world_model.encoder(observation)\n",
        "        z_posterior = self.world_model.rssm.posterior(self.h, obs_emb)\n",
        "        z = z_posterior.sample().flatten(1)\n",
        "        action, _, _ = policy(z, self.h, train=train)\n",
        "\n",
        "        self.h = self.world_model.rssm.recurrent(z, action, self.h)\n",
        "\n",
        "        return action.squeeze().cpu().numpy()\n",
        "\n",
        "    def reset(self):\n",
        "        self.h = torch.zeros(1, self.world_model.h_dim, device=self.device)\n"
      ],
      "metadata": {
        "id": "TRtwWmSElWRJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#utils.py\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from einops import rearrange\n",
        "\n",
        "\n",
        "def preprocess_obs(obs):\n",
        "    height, width = obs.shape[0], obs.shape[1]\n",
        "    obs = Image.fromarray(obs)\n",
        "    obs = obs.convert(\"RGB\")\n",
        "    obs = np.array(obs).reshape(height, width, 3)\n",
        "    obs = obs.astype(np.float32)\n",
        "    obs = rearrange(obs, 'h w c -> c h w')\n",
        "    normalized_obs = obs / 255.0 - 0.5\n",
        "    return normalized_obs\n",
        "\n",
        "\n",
        "def fix_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n"
      ],
      "metadata": {
        "id": "2U5AzQqim2uz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xr_nk1HZwPTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install -y xvfb\n",
        "!pip install pyvirtualdisplay\n",
        "# 仮想ディスプレイのセットアップ\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "display = Display(visible=0, size=(1024, 768))\n",
        "display.start()\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "import mujoco\n",
        "import glfw\n",
        "\n"
      ],
      "metadata": {
        "id": "vS45lLZVjdew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62d2b02a-bd80-48c6-e695-7b534eccd472"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 7,815 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.12 [28.7 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.12 [864 kB]\n",
            "Fetched 7,815 kB in 2s (4,564 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 9.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 123634 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.12_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.12_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.12) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\n",
            "Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# def preprocess_obs(obs, target_size=(128, 128)):\n",
        "#     \"\"\"\n",
        "#     観測データを指定された形状にリサイズします。\n",
        "#     :param obs: 入力観測データ (H, W, C) または (C, H, W)\n",
        "#     :param target_size: リサイズ先の形状 (W, H)\n",
        "#     :return: リサイズされた観測データ\n",
        "#     \"\"\"\n",
        "#     if obs.shape[0] == 3:  # チャネルが先頭にある場合 (C, H, W)\n",
        "#         obs = np.transpose(obs, (1, 2, 0))  # (H, W, C) に変換\n",
        "\n",
        "#     resized = cv2.resize(obs, target_size, interpolation=cv2.INTER_AREA)\n",
        "#     resized = np.transpose(resized, (2, 0, 1))  # (C, H, W) に戻す\n",
        "#     return resized.astype(np.float32) / 255.0 - 0.5\n"
      ],
      "metadata": {
        "id": "nk1_dB2491os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#envs.franka_kitchen\n",
        "from itertools import combinations\n",
        "import numpy as np\n",
        "from gymnasium import Env\n",
        "from gymnasium.spaces import Box\n",
        "from gymnasium.wrappers import AddRenderObservation, TimeLimit\n",
        "from gymnasium_robotics.envs.franka_kitchen.kitchen_env import KitchenEnv\n",
        "\n",
        "\n",
        "class FrankaKichenEnv(Env):\n",
        "    def __init__(self,\n",
        "                 img_size,\n",
        "                 action_repeat,\n",
        "                 time_limit,\n",
        "                 seed):\n",
        "        self._seed = seed\n",
        "        self._action_repeat = action_repeat\n",
        "        self._base_env = KitchenEnv(render_mode='rgb_array',\n",
        "                                    width=img_size,\n",
        "                                    height=img_size,\n",
        "                                    default_camera_config=dict(distance=1.86, lookat=[-0.3, .5, 2.], azimuth=90, elevation=-60))\n",
        "        self._env = TimeLimit(self._base_env, time_limit)\n",
        "\n",
        "        self.observation_space = Box(0, 255, (img_size, img_size, 3), dtype=np.uint8)\n",
        "        self.action_space = self._env.action_space\n",
        "\n",
        "        self.action_space.seed(seed)\n",
        "        self.observation_space.seed(seed)\n",
        "\n",
        "        self.obs_element_goals, self.obs_element_indices, self.goal_configs = get_kitchen_benchmark_goals()\n",
        "        self.goals = list(range(len(self.obs_element_goals)))\n",
        "        self.goal_idx = -1\n",
        "\n",
        "        self._env.reset(seed=self._seed)\n",
        "        self.init_qpos = self._base_env.data.qpos.copy()\n",
        "        self.init_qvel = self._base_env.data.qvel.copy()\n",
        "        self.goal_rendered = False\n",
        "\n",
        "    def reset(self):\n",
        "        self._env.reset(seed=self._seed)\n",
        "        self.goal_rendered = False\n",
        "        return self._env.render()\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0\n",
        "        for step in range(self._action_repeat):\n",
        "            state, reward, terminated, truncated, info = self._env.step(action)\n",
        "            terminated = self.compute_success()\n",
        "            done = truncated or terminated\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        obs = self._env.render()\n",
        "        return obs, total_reward, done, info\n",
        "\n",
        "    def render(self):\n",
        "        return self._env.render()\n",
        "\n",
        "    def close(self):\n",
        "        return self._env.close()\n",
        "\n",
        "    def set_goal_idx(self, idx):\n",
        "        assert idx in self.goals\n",
        "        self.goal_idx = idx\n",
        "\n",
        "    def get_goal_obs(self):\n",
        "        if self.goal_idx == -1:\n",
        "            return None\n",
        "\n",
        "        if self.goal_rendered:\n",
        "            return self.rendered_goal_obs\n",
        "\n",
        "        element_indices = self.obs_element_indices[self.goal_idx]\n",
        "        element_values = self.obs_element_goals[self.goal_idx]\n",
        "\n",
        "        backup_qpos = self._base_env.data.qpos.copy()\n",
        "        backup_qvel = self._base_env.data.qvel.copy()\n",
        "\n",
        "        qpos = self.init_qpos.copy()\n",
        "        qpos[element_indices] = element_values\n",
        "        self._base_env.robot_env.set_state(qpos, np.zeros_like(self.init_qvel))\n",
        "\n",
        "        goal_obs = self._env.render()\n",
        "\n",
        "        self._base_env.robot_env.set_state(backup_qpos, backup_qvel)\n",
        "\n",
        "        self.goal_rendered = True\n",
        "        self.rendered_goal_obs = goal_obs\n",
        "        return goal_obs\n",
        "\n",
        "    def compute_success(self):\n",
        "        if self.goal_idx == -1:\n",
        "            return False\n",
        "\n",
        "        qpos = self._base_env.data.qpos.copy()\n",
        "\n",
        "        element_indices = self.obs_element_indices[self.goal_idx]\n",
        "        element_values = self.obs_element_goals[self.goal_idx]\n",
        "        goal_qpos = self.init_qpos.copy()\n",
        "        goal_qpos[element_indices] = element_values\n",
        "\n",
        "        per_obj_success = {\n",
        "            'bottom_burner' : ((qpos[9]<-0.38) and (goal_qpos[9]<-0.38)) or ((qpos[9]>-0.38) and (goal_qpos[9]>-0.38)),\n",
        "            'top_burner':    ((qpos[13]<-0.38) and (goal_qpos[13]<-0.38)) or ((qpos[13]>-0.38) and (goal_qpos[13]>-0.38)),\n",
        "            'light_switch':  ((qpos[17]<-0.25) and (goal_qpos[17]<-0.25)) or ((qpos[17]>-0.25) and (goal_qpos[17]>-0.25)),\n",
        "            'slide_cabinet' :  abs(qpos[19] - goal_qpos[19])<0.1,\n",
        "            'hinge_cabinet' :  abs(qpos[21] - goal_qpos[21])<0.2,\n",
        "            'microwave' :      abs(qpos[22] - goal_qpos[22])<0.2,\n",
        "            'kettle' : np.linalg.norm(qpos[23:25] - goal_qpos[23:25]) < 0.2\n",
        "        }\n",
        "        task_objects = self.goal_configs[self.goal_idx]\n",
        "\n",
        "        success = 1\n",
        "        for _obj in task_objects:\n",
        "            success *= per_obj_success[_obj]\n",
        "\n",
        "        return bool(success)\n",
        "\n",
        "    def get_kitchen_benchmark_goals():\n",
        "\n",
        "        object_goal_vals = {'bottom_burner' :  [-0.88, -0.01],\n",
        "                            'light_switch' :  [ -0.69, -0.05],\n",
        "                            'slide_cabinet':  [0.37],\n",
        "                            'hinge_cabinet':   [0., 0.5],\n",
        "                            'microwave'    :   [-0.5],\n",
        "                            'kettle'       :   [-0.23, 0.75, 1.62, 0.99, 0., 0., -0.06]}\n",
        "\n",
        "        object_goal_idxs = {'bottom_burner' :  [9, 10],\n",
        "                            'light_switch' :  [17, 18],\n",
        "                            'slide_cabinet':  [19],\n",
        "                            'hinge_cabinet':  [20, 21],\n",
        "                            'microwave'    :  [22],\n",
        "                            'kettle'       :  [23, 24, 25, 26, 27, 28, 29]}\n",
        "\n",
        "        base_task_names = [ 'bottom_burner', 'light_switch', 'slide_cabinet', 'hinge_cabinet', 'microwave', 'kettle' ]\n",
        "\n",
        "\n",
        "        goal_configs = []\n",
        "        #single task\n",
        "        for i in range(6):\n",
        "          goal_configs.append( [base_task_names[i]])\n",
        "\n",
        "        #two tasks\n",
        "        for i,j  in combinations([1,2,3,5], 2) :\n",
        "          goal_configs.append( [base_task_names[i], base_task_names[j]] )\n",
        "\n",
        "        obs_element_goals = [] ; obs_element_indices = []\n",
        "        for objects in goal_configs:\n",
        "            _goal = np.concatenate([object_goal_vals[obj] for obj in objects])\n",
        "            _goal_idxs = np.concatenate([object_goal_idxs[obj] for obj in objects])\n",
        "\n",
        "            obs_element_goals.append(_goal)\n",
        "            obs_element_indices.append(_goal_idxs)\n",
        "\n",
        "        return obs_element_goals, obs_element_indices, goal_configs\n",
        "\n",
        "\n",
        "    def debug_environment(self):\n",
        "        \"\"\"\n",
        "        環境の属性とプロパティをデバッグ出力します。\n",
        "        \"\"\"\n",
        "        print(\"Attributes of _base_env:\")\n",
        "        print(dir(self._base_env))\n",
        "\n",
        "        if hasattr(self._base_env, 'unwrapped'):\n",
        "            print(\"\\nAttributes of _base_env.unwrapped:\")\n",
        "            print(dir(self._base_env.unwrapped))\n",
        "\n",
        "        if hasattr(self._base_env.unwrapped, 'model'):\n",
        "            model = self._base_env.unwrapped.model\n",
        "            print(\"\\nModel properties:\")\n",
        "            print(dir(model))\n",
        "\n",
        "        if hasattr(self._base_env.unwrapped, 'data'):\n",
        "            data = self._base_env.unwrapped.data\n",
        "            print(\"\\nData properties:\")\n",
        "            print(dir(data))\n"
      ],
      "metadata": {
        "id": "Ii__-AWlrQXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j7sstYf13kuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gymnasium_robotics.envs.maze.maps\n",
        "\n",
        "\"\"\"A collection of maze map structures for the Gymnasium-Robotics PointMaze environments.\n",
        "\n",
        "The code is inspired by the D4RL repository hosted on GitHub (https://github.com/Farama-Foundation/D4RL), published in the paper\n",
        "'D4RL: Datasets for Deep Data-Driven Reinforcement Learning' by Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, Sergey Levine.\n",
        "\n",
        "Original Author of the code: Justin Fu\n",
        "\n",
        "The modifications made involve organizing the code into different files: `maps.py`, `maze_env.py`, `point_env.py`, and `point_maze_env.py`.\n",
        "As well as adding support for the Gymnasium API.\n",
        "\n",
        "This project is covered by the Apache 2.0 License.\n",
        "\"\"\"\n",
        "\n",
        "RESET = R = \"r\"  # Initial Reset position of the agent\n",
        "GOAL = G = \"g\"\n",
        "COMBINED = C = \"c\"  # These cells can be selected as goal or reset locations\n",
        "\n",
        "\n",
        "EMPTY_MAZE = [\n",
        "    [1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "OPEN = [\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "OPEN_DIVERSE_G = [\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, R, G, G, G, G, 1],\n",
        "    [1, G, G, G, G, G, 1],\n",
        "    [1, G, G, G, G, G, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "OPEN_DIVERSE_GR = [\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, C, C, C, C, C, 1],\n",
        "    [1, C, C, C, C, C, 1],\n",
        "    [1, C, C, C, C, C, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "# Maze specifications for dataset generation\n",
        "U_MAZE = [\n",
        "    [1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "MEDIUM_MAZE = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 1, 1, 0, 0, 1],\n",
        "    [1, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 1, 0, 0, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 0, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 1, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "MEDIUM_MAZE_DIVERSE_G = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, R, 0, 1, 1, 0, 0, 1],\n",
        "    [1, 0, 0, 1, 0, 0, G, 1],\n",
        "    [1, 1, 0, 0, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, G, 1, 0, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 1, G, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "MEDIUM_MAZE_DIVERSE_GR = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, C, 0, 1, 1, 0, 0, 1],\n",
        "    [1, 0, 0, 1, 0, 0, C, 1],\n",
        "    [1, 1, 0, 0, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, C, 1, 0, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 1, C, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "LARGE_MAZE = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1],\n",
        "    [1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "LARGE_MAZE_DIVERSE_G = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, R, 0, 0, 0, 1, G, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 0, G, 0, 1, 0, 0, G, 1],\n",
        "    [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1],\n",
        "    [1, 0, G, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, G, 0, G, 1, 0, G, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "LARGE_MAZE_DIVERSE_GR = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, C, 0, 0, 0, 1, C, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 0, C, 0, 1, 0, 0, C, 1],\n",
        "    [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1],\n",
        "    [1, 0, C, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, C, 0, C, 1, 0, C, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n"
      ],
      "metadata": {
        "id": "Z4Jfh6SEyVrn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#core.py\n",
        "\n",
        "from abc import abstractmethod\n",
        "from typing import Optional\n",
        "\n",
        "import gymnasium as gym\n",
        "from gymnasium import error\n",
        "\n",
        "\n",
        "class GoalEnv(gym.Env):\n",
        "    r\"\"\"A goal-based environment.\n",
        "\n",
        "    It functions just as any regular Gymnasium environment but it imposes a required structure on the observation_space. More concretely,\n",
        "    the observation space is required to contain at least three elements, namely `observation`, `desired_goal`, and `achieved_goal`.\n",
        "    Here, `desired_goal` specifies the goal that the agent should attempt to achieve. `achieved_goal` is the goal that it currently achieved instead.\n",
        "    `observation` contains the actual observations of the environment as per usual.\n",
        "\n",
        "    - :meth:`compute_reward` - Externalizes the reward function by taking the achieved and desired goal, as well as extra information. Returns reward.\n",
        "    - :meth:`compute_terminated` - Returns boolean termination depending on the achieved and desired goal, as well as extra information.\n",
        "    - :meth:`compute_truncated` - Returns boolean truncation depending on the achieved and desired goal, as well as extra information.\n",
        "    \"\"\"\n",
        "\n",
        "    def reset(\n",
        "        self,\n",
        "        *,\n",
        "        seed: Optional[int] = None,\n",
        "        options: Optional[dict] = None,\n",
        "    ):\n",
        "        \"\"\"Reset the environment.\n",
        "\n",
        "        In addition, check if the observation space is correct by inspecting the `observation`, `achieved_goal`, and `desired_goal` keys.\n",
        "        \"\"\"\n",
        "        super().reset(seed=seed)\n",
        "        # Enforce that each GoalEnv uses a Goal-compatible observation space.\n",
        "        if not isinstance(self.observation_space, gym.spaces.Dict):\n",
        "            raise error.Error(\n",
        "                \"GoalEnv requires an observation space of type gym.spaces.Dict\"\n",
        "            )\n",
        "        for key in [\"observation\", \"achieved_goal\", \"desired_goal\"]:\n",
        "            if key not in self.observation_space.spaces:\n",
        "                raise error.Error(\n",
        "                    'GoalEnv requires the \"{}\" key to be part of the observation dictionary.'.format(\n",
        "                        key\n",
        "                    )\n",
        "                )\n",
        "\n",
        "    @abstractmethod\n",
        "    def compute_reward(self, achieved_goal, desired_goal, info):\n",
        "        \"\"\"Compute the step reward. This externalizes the reward function and makes it dependent on a desired goal and the one that was achieved.\n",
        "\n",
        "        If you wish to include additional rewards that are independent of the goal, you can include the necessary values\n",
        "        to derive it in 'info' and compute it accordingly.\n",
        "\n",
        "        Args:\n",
        "            achieved_goal (object): the goal that was achieved during execution\n",
        "            desired_goal (object): the desired goal that we asked the agent to attempt to achieve\n",
        "            info (dict): an info dictionary with additional information\n",
        "\n",
        "        Returns:\n",
        "            float: The reward that corresponds to the provided achieved goal w.r.t. to the desired\n",
        "            goal. Note that the following should always hold true:\n",
        "\n",
        "                ob, reward, terminated, truncated, info = env.step()\n",
        "                assert reward == env.compute_reward(ob['achieved_goal'], ob['desired_goal'], info)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def compute_terminated(self, achieved_goal, desired_goal, info):\n",
        "        \"\"\"Compute the step termination. Allows to customize the termination states depending on the desired and the achieved goal.\n",
        "\n",
        "        If you wish to determine termination states independent of the goal, you can include necessary values to derive it in 'info'\n",
        "        and compute it accordingly. The envirtonment reaches a termination state when this state leads to an episode ending in an episodic\n",
        "        task thus breaking .\n",
        "\n",
        "        More information can be found in: https://farama.org/New-Step-API#theory\n",
        "\n",
        "        Termination states are\n",
        "\n",
        "        Args:\n",
        "            achieved_goal (object): the goal that was achieved during execution\n",
        "            desired_goal (object): the desired goal that we asked the agent to attempt to achieve\n",
        "            info (dict): an info dictionary with additional information\n",
        "\n",
        "        Returns:\n",
        "            bool: The termination state that corresponds to the provided achieved goal w.r.t. to the desired\n",
        "            goal. Note that the following should always hold true:\n",
        "\n",
        "                ob, reward, terminated, truncated, info = env.step()\n",
        "                assert terminated == env.compute_terminated(ob['achieved_goal'], ob['desired_goal'], info)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def compute_truncated(self, achieved_goal, desired_goal, info):\n",
        "        \"\"\"Compute the step truncation. Allows to customize the truncated states depending on the desired and the achieved goal.\n",
        "\n",
        "        If you wish to determine truncated states independent of the goal, you can include necessary values to derive it in 'info'\n",
        "        and compute it accordingly. Truncated states are those that are out of the scope of the Markov Decision Process (MDP) such\n",
        "        as time constraints in a continuing task.\n",
        "\n",
        "        More information can be found in: https://farama.org/New-Step-API#theory\n",
        "\n",
        "        Args:\n",
        "            achieved_goal (object): the goal that was achieved during execution\n",
        "            desired_goal (object): the desired goal that we asked the agent to attempt to achieve\n",
        "            info (dict): an info dictionary with additional information\n",
        "\n",
        "        Returns:\n",
        "            bool: The truncated state that corresponds to the provided achieved goal w.r.t. to the desired\n",
        "            goal. Note that the following should always hold true:\n",
        "\n",
        "                ob, reward, terminated, truncated, info = env.step()\n",
        "                assert truncated == env.compute_truncated(ob['achieved_goal'], ob['desired_goal'], info)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n"
      ],
      "metadata": {
        "id": "J8NiXhdUzmuM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gymnasium_robotics.envs.maze.maze_v4.py\n",
        "\n",
        "\n",
        "\"\"\"A maze environment with Gymnasium API for the Gymnasium-Robotics PointMaze environments.\n",
        "\n",
        "The code is inspired by the D4RL repository hosted on GitHub (https://github.com/Farama-Foundation/D4RL), published in the paper\n",
        "'D4RL: Datasets for Deep Data-Driven Reinforcement Learning' by Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, Sergey Levine.\n",
        "\n",
        "Original Author of the code: Justin Fu\n",
        "\n",
        "The modifications made involve organizing the code into different files: `maps.py`, `maze_env.py`, `point_env.py`, and `point_maze_env.py`.\n",
        "As well as adding support for the Gymnasium API.\n",
        "\n",
        "This project is covered by the Apache 2.0 License.\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "import tempfile\n",
        "import time\n",
        "import xml.etree.ElementTree as ET\n",
        "from os import path\n",
        "from typing import Dict, List, Optional, Union\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# from gymnasium_robotics.core import GoalEnv\n",
        "# from gymnasium_robotics.envs.maze.maps import COMBINED, GOAL, RESET, U_MAZE\n",
        "\n",
        "\n",
        "class Maze:\n",
        "    r\"\"\"This class creates and holds information about the maze in the MuJoCo simulation.\n",
        "\n",
        "    The accessible attributes are the following:\n",
        "    - :attr:`maze_map` - The maze discrete data structure.\n",
        "    - :attr:`maze_size_scaling` - The maze scaling for the continuous coordinates in the MuJoCo simulation.\n",
        "    - :attr:`maze_height` - The height of the walls in the MuJoCo simulation.\n",
        "    - :attr:`unique_goal_locations` - All the `(i,j)` possible cell indices for goal locations.\n",
        "    - :attr:`unique_reset_locations` - All the `(i,j)` possible cell indices for agent initialization locations.\n",
        "    - :attr:`combined_locations` - All the `(i,j)` possible cell indices for goal and agent initialization locations.\n",
        "    - :attr:`map_length` - Maximum value of j cell index\n",
        "    - :attr:`map_width` - Mazimum value of i cell index\n",
        "    - :attr:`x_map_center` - The x coordinate of the map's center\n",
        "    - :attr:`y_map_center` - The y coordinate of the map's center\n",
        "\n",
        "    The Maze class also presents a method to convert from cell indices to `(x,y)` coordinates in the MuJoCo simulation:\n",
        "    - :meth:`cell_rowcol_to_xy` - Convert from `(i,j)` to `(x,y)`\n",
        "\n",
        "    ### Version History\n",
        "    * v4: Refactor compute_terminated into a pure function compute_terminated and a new function update_goal which resets the goal position. Bug fix: missing maze_size_scaling factor added in generate_reset_pos() -- only affects AntMaze.\n",
        "    * v3: refactor version of the D4RL environment, also create dependency on newest [mujoco python bindings](https://mujoco.readthedocs.io/en/latest/python.html) maintained by the MuJoCo team in Deepmind.\n",
        "    * v2 & v1: legacy versions in the [D4RL](https://github.com/Farama-Foundation/D4RL).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        maze_map: List[List[Union[str, int]]],\n",
        "        maze_size_scaling: float,\n",
        "        maze_height: float,\n",
        "    ):\n",
        "\n",
        "        self._maze_map = maze_map\n",
        "        self._maze_size_scaling = maze_size_scaling\n",
        "        self._maze_height = maze_height\n",
        "\n",
        "        self._unique_goal_locations = []\n",
        "        self._unique_reset_locations = []\n",
        "        self._combined_locations = []\n",
        "\n",
        "        # Get the center cell Cartesian position of the maze. This will be the origin\n",
        "        self._map_length = len(maze_map)\n",
        "        self._map_width = len(maze_map[0])\n",
        "        self._x_map_center = self.map_width / 2 * maze_size_scaling\n",
        "        self._y_map_center = self.map_length / 2 * maze_size_scaling\n",
        "\n",
        "    @property\n",
        "    def maze_map(self) -> List[List[Union[str, int]]]:\n",
        "        \"\"\"Returns the list[list] data structure of the maze.\"\"\"\n",
        "        return self._maze_map\n",
        "\n",
        "    @property\n",
        "    def maze_size_scaling(self) -> float:\n",
        "        \"\"\"Returns the scaling value used to integrate the maze\n",
        "        encoding in the MuJoCo simulation.\n",
        "        \"\"\"\n",
        "        return self._maze_size_scaling\n",
        "\n",
        "    @property\n",
        "    def maze_height(self) -> float:\n",
        "        \"\"\"Returns the un-scaled height of the walls in the MuJoCo\n",
        "        simulation.\n",
        "        \"\"\"\n",
        "        return self._maze_height\n",
        "\n",
        "    @property\n",
        "    def unique_goal_locations(self) -> List[np.ndarray]:\n",
        "        \"\"\"Returns all the possible goal locations in discrete cell\n",
        "        coordinates (i,j)\n",
        "        \"\"\"\n",
        "        return self._unique_goal_locations\n",
        "\n",
        "    @property\n",
        "    def unique_reset_locations(self) -> List[np.ndarray]:\n",
        "        \"\"\"Returns all the possible reset locations for the agent in\n",
        "        discrete cell coordinates (i,j)\n",
        "        \"\"\"\n",
        "        return self._unique_reset_locations\n",
        "\n",
        "    @property\n",
        "    def combined_locations(self) -> List[np.ndarray]:\n",
        "        \"\"\"Returns all the possible goal/reset locations in discrete cell\n",
        "        coordinates (i,j)\n",
        "        \"\"\"\n",
        "        return self._combined_locations\n",
        "\n",
        "    @property\n",
        "    def map_length(self) -> int:\n",
        "        \"\"\"Returns the length of the maze in number of discrete vertical cells\n",
        "        or number of rows i.\n",
        "        \"\"\"\n",
        "        return self._map_length\n",
        "\n",
        "    @property\n",
        "    def map_width(self) -> int:\n",
        "        \"\"\"Returns the width of the maze in number of discrete horizontal cells\n",
        "        or number of columns j.\n",
        "        \"\"\"\n",
        "        return self._map_width\n",
        "\n",
        "    @property\n",
        "    def x_map_center(self) -> float:\n",
        "        \"\"\"Returns the x coordinate of the center of the maze in the MuJoCo simulation\"\"\"\n",
        "        return self._x_map_center\n",
        "\n",
        "    @property\n",
        "    def y_map_center(self) -> float:\n",
        "        \"\"\"Returns the x coordinate of the center of the maze in the MuJoCo simulation\"\"\"\n",
        "        return self._y_map_center\n",
        "\n",
        "    def cell_rowcol_to_xy(self, rowcol_pos: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Converts a cell index `(i,j)` to x and y coordinates in the MuJoCo simulation\"\"\"\n",
        "        x = (rowcol_pos[1] + 0.5) * self.maze_size_scaling - self.x_map_center\n",
        "        y = self.y_map_center - (rowcol_pos[0] + 0.5) * self.maze_size_scaling\n",
        "\n",
        "        return np.array([x, y])\n",
        "\n",
        "    def cell_xy_to_rowcol(self, xy_pos: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Converts a cell x and y coordinates to `(i,j)`\"\"\"\n",
        "        i = math.floor((self.y_map_center - xy_pos[1]) / self.maze_size_scaling)\n",
        "        j = math.floor((xy_pos[0] + self.x_map_center) / self.maze_size_scaling)\n",
        "        return np.array([i, j])\n",
        "\n",
        "    @classmethod\n",
        "    def make_maze(\n",
        "        cls,\n",
        "        agent_xml_path: str,\n",
        "        maze_map: list,\n",
        "        maze_size_scaling: float,\n",
        "        maze_height: float,\n",
        "    ):\n",
        "        \"\"\"Class method that returns an instance of Maze with a decoded maze information and the temporal\n",
        "           path to the new MJCF (xml) file for the MuJoCo simulation.\n",
        "\n",
        "        Args:\n",
        "            agent_xml_path (str): the goal that was achieved during execution\n",
        "            maze_map (list[list[str,int]]): the desired goal that we asked the agent to attempt to achieve\n",
        "            maze_size_scaling (float): an info dictionary with additional information\n",
        "            maze_height (float): an info dictionary with additional information\n",
        "\n",
        "        Returns:\n",
        "            Maze: The reward that corresponds to the provided achieved goal w.r.t. to the desired\n",
        "            goal. Note that the following should always hold true:\n",
        "            str: The xml temporal file to the new mjcf model with the included maze.\n",
        "        \"\"\"\n",
        "        tree = ET.parse(agent_xml_path)\n",
        "        worldbody = tree.find(\".//worldbody\")\n",
        "\n",
        "        maze = cls(maze_map, maze_size_scaling, maze_height)\n",
        "        empty_locations = []\n",
        "        for i in range(maze.map_length):\n",
        "            for j in range(maze.map_width):\n",
        "                struct = maze_map[i][j]\n",
        "                # Store cell locations in simulation global Cartesian coordinates\n",
        "                x = (j + 0.5) * maze_size_scaling - maze.x_map_center\n",
        "                y = maze.y_map_center - (i + 0.5) * maze_size_scaling\n",
        "                if struct == 1:  # Unmovable block.\n",
        "                    # Offset all coordinates so that maze is centered.\n",
        "                    ET.SubElement(\n",
        "                        worldbody,\n",
        "                        \"geom\",\n",
        "                        name=f\"block_{i}_{j}\",\n",
        "                        pos=f\"{x} {y} {maze_height / 2 * maze_size_scaling}\",\n",
        "                        size=f\"{0.5 * maze_size_scaling} {0.5 * maze_size_scaling} {maze_height / 2 * maze_size_scaling}\",\n",
        "                        type=\"box\",\n",
        "                        material=\"\",\n",
        "                        contype=\"1\",\n",
        "                        conaffinity=\"1\",\n",
        "                        rgba=\"0.7 0.5 0.3 1.0\",\n",
        "                    )\n",
        "\n",
        "                elif struct == RESET:\n",
        "                    maze._unique_reset_locations.append(np.array([x, y]))\n",
        "                elif struct == GOAL:\n",
        "                    maze._unique_goal_locations.append(np.array([x, y]))\n",
        "                elif struct == COMBINED:\n",
        "                    maze._combined_locations.append(np.array([x, y]))\n",
        "                elif struct == 0:\n",
        "                    empty_locations.append(np.array([x, y]))\n",
        "\n",
        "        # Add target site for visualization\n",
        "        ET.SubElement(\n",
        "            worldbody,\n",
        "            \"site\",\n",
        "            name=\"target\",\n",
        "            pos=f\"0 0 {maze_height / 2 * maze_size_scaling}\",\n",
        "            size=f\"{0.2 * maze_size_scaling}\",\n",
        "            rgba=\"1 0 0 0\",\n",
        "            type=\"sphere\",\n",
        "        )\n",
        "\n",
        "        # Add the combined cell locations (goal/reset) to goal and reset\n",
        "        if (\n",
        "            not maze._unique_goal_locations\n",
        "            and not maze._unique_reset_locations\n",
        "            and not maze._combined_locations\n",
        "        ):\n",
        "            # If there are no given \"r\", \"g\" or \"c\" cells in the maze data structure,\n",
        "            # any empty cell can be a reset or goal location at initialization.\n",
        "            maze._combined_locations = empty_locations\n",
        "        elif not maze._unique_reset_locations and not maze._combined_locations:\n",
        "            # If there are no given \"r\" or \"c\" cells in the maze data structure,\n",
        "            # any empty cell can be a reset location at initialization.\n",
        "            maze._unique_reset_locations = empty_locations\n",
        "        elif not maze._unique_goal_locations and not maze._combined_locations:\n",
        "            # If there are no given \"g\" or \"c\" cells in the maze data structure,\n",
        "            # any empty cell can be a gaol location at initialization.\n",
        "            maze._unique_goal_locations = empty_locations\n",
        "\n",
        "        maze._unique_goal_locations += maze._combined_locations\n",
        "        maze._unique_reset_locations += maze._combined_locations\n",
        "\n",
        "        # Save new xml with maze to a temporary file\n",
        "        with tempfile.TemporaryDirectory() as tmp_dir:\n",
        "            temp_xml_name = f\"ant_maze{str(time.time())}.xml\"\n",
        "            temp_xml_path = path.join(path.dirname(tmp_dir), temp_xml_name)\n",
        "            tree.write(temp_xml_path)\n",
        "\n",
        "        return maze, temp_xml_path\n",
        "\n",
        "\n",
        "class MazeEnv(GoalEnv):\n",
        "    def __init__(\n",
        "        self,\n",
        "        agent_xml_path: str,\n",
        "        reward_type: str = \"dense\",\n",
        "        continuing_task: bool = True,\n",
        "        reset_target: bool = True,\n",
        "        maze_map: List[List[Union[int, str]]] = U_MAZE,\n",
        "        maze_size_scaling: float = 1.0,\n",
        "        maze_height: float = 0.5,\n",
        "        position_noise_range: float = 0.25,\n",
        "        **kwargs,\n",
        "    ):\n",
        "\n",
        "        self.reward_type = reward_type\n",
        "        self.continuing_task = continuing_task\n",
        "        self.reset_target = reset_target\n",
        "        self.maze, self.tmp_xml_file_path = Maze.make_maze(\n",
        "            agent_xml_path, maze_map, maze_size_scaling, maze_height\n",
        "        )\n",
        "\n",
        "        self.position_noise_range = position_noise_range\n",
        "\n",
        "    def generate_target_goal(self) -> np.ndarray:\n",
        "        assert len(self.maze.unique_goal_locations) > 0\n",
        "        goal_index = self.np_random.integers(\n",
        "            low=0, high=len(self.maze.unique_goal_locations)\n",
        "        )\n",
        "        goal = self.maze.unique_goal_locations[goal_index].copy()\n",
        "        return goal\n",
        "\n",
        "    def generate_reset_pos(self) -> np.ndarray:\n",
        "        assert len(self.maze.unique_reset_locations) > 0\n",
        "\n",
        "        # While reset position is close to goal position\n",
        "        reset_pos = self.goal.copy()\n",
        "        while (\n",
        "            np.linalg.norm(reset_pos - self.goal) <= 0.5 * self.maze.maze_size_scaling\n",
        "        ):\n",
        "            reset_index = self.np_random.integers(\n",
        "                low=0, high=len(self.maze.unique_reset_locations)\n",
        "            )\n",
        "            reset_pos = self.maze.unique_reset_locations[reset_index].copy()\n",
        "\n",
        "        return reset_pos\n",
        "\n",
        "    def reset(\n",
        "        self,\n",
        "        *,\n",
        "        seed: Optional[int] = None,\n",
        "        options: Optional[Dict[str, Optional[np.ndarray]]] = None,\n",
        "    ):\n",
        "        \"\"\"Reset the maze simulation.\n",
        "\n",
        "        Args:\n",
        "            options (dict[str, np.ndarray]): the options dictionary can contain two items, \"goal_cell\" and \"reset_cell\" that will set the initial goal and reset location (i,j) in the self.maze.map list of list maze structure.\n",
        "\n",
        "        \"\"\"\n",
        "        super().reset(seed=seed)\n",
        "\n",
        "        if options is None:\n",
        "            goal = self.generate_target_goal()\n",
        "            # Add noise to goal position\n",
        "            self.goal = self.add_xy_position_noise(goal)\n",
        "            reset_pos = self.generate_reset_pos()\n",
        "        else:\n",
        "            if \"goal_cell\" in options and options[\"goal_cell\"] is not None:\n",
        "                # assert that goal cell is valid\n",
        "                assert self.maze.map_length > options[\"goal_cell\"][0]\n",
        "                assert self.maze.map_width > options[\"goal_cell\"][1]\n",
        "                assert (\n",
        "                    self.maze.maze_map[options[\"goal_cell\"][0]][options[\"goal_cell\"][1]]\n",
        "                    != 1\n",
        "                ), f\"Goal can't be placed in a wall cell, {options['goal_cell']}\"\n",
        "\n",
        "                goal = self.maze.cell_rowcol_to_xy(options[\"goal_cell\"])\n",
        "\n",
        "            else:\n",
        "                goal = self.generate_target_goal()\n",
        "\n",
        "            # Add noise to goal position\n",
        "            self.goal = self.add_xy_position_noise(goal)\n",
        "\n",
        "            if \"reset_cell\" in options and options[\"reset_cell\"] is not None:\n",
        "                # assert that goal cell is valid\n",
        "                assert self.maze.map_length > options[\"reset_cell\"][0]\n",
        "                assert self.maze.map_width > options[\"reset_cell\"][1]\n",
        "                assert (\n",
        "                    self.maze.maze_map[options[\"reset_cell\"][0]][\n",
        "                        options[\"reset_cell\"][1]\n",
        "                    ]\n",
        "                    != 1\n",
        "                ), f\"Reset can't be placed in a wall cell, {options['reset_cell']}\"\n",
        "\n",
        "                reset_pos = self.maze.cell_rowcol_to_xy(options[\"reset_cell\"])\n",
        "\n",
        "            else:\n",
        "                reset_pos = self.generate_reset_pos()\n",
        "\n",
        "        # Update the position of the target site for visualization\n",
        "        self.update_target_site_pos()\n",
        "        # Add noise to reset position\n",
        "        self.reset_pos = self.add_xy_position_noise(reset_pos)\n",
        "\n",
        "        # Update the position of the target site for visualization\n",
        "        self.update_target_site_pos()\n",
        "\n",
        "    def add_xy_position_noise(self, xy_pos: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Pass an x,y coordinate and it will return the same coordinate with a noise addition\n",
        "        sampled from a uniform distribution\n",
        "        \"\"\"\n",
        "        noise_x = (\n",
        "            self.np_random.uniform(\n",
        "                low=-self.position_noise_range, high=self.position_noise_range\n",
        "            )\n",
        "            * self.maze.maze_size_scaling\n",
        "        )\n",
        "        noise_y = (\n",
        "            self.np_random.uniform(\n",
        "                low=-self.position_noise_range, high=self.position_noise_range\n",
        "            )\n",
        "            * self.maze.maze_size_scaling\n",
        "        )\n",
        "        xy_pos[0] += noise_x\n",
        "        xy_pos[1] += noise_y\n",
        "\n",
        "        return xy_pos\n",
        "\n",
        "    def compute_reward(\n",
        "        self, achieved_goal: np.ndarray, desired_goal: np.ndarray, info\n",
        "    ) -> float:\n",
        "        distance = np.linalg.norm(achieved_goal - desired_goal, axis=-1)\n",
        "        if self.reward_type == \"dense\":\n",
        "            return np.exp(-distance)\n",
        "        elif self.reward_type == \"sparse\":\n",
        "            return (distance <= 0.45).astype(np.float64)\n",
        "\n",
        "    def compute_terminated(\n",
        "        self, achieved_goal: np.ndarray, desired_goal: np.ndarray, info\n",
        "    ) -> bool:\n",
        "        if not self.continuing_task:\n",
        "            # If task is episodic terminate the episode when the goal is reached\n",
        "            return bool(np.linalg.norm(achieved_goal - desired_goal) <= 0.45)\n",
        "        else:\n",
        "            # Continuing tasks don't terminate, episode will be truncated when time limit is reached (`max_episode_steps`)\n",
        "            return False\n",
        "\n",
        "    def update_goal(self, achieved_goal: np.ndarray) -> None:\n",
        "        \"\"\"Update goal position if continuing task and within goal radius.\"\"\"\n",
        "\n",
        "        if (\n",
        "            self.continuing_task\n",
        "            and self.reset_target\n",
        "            and bool(np.linalg.norm(achieved_goal - self.goal) <= 0.45)\n",
        "            and len(self.maze.unique_goal_locations) > 1\n",
        "        ):\n",
        "            # Generate a goal while within 0.45 of achieved_goal. The distance check above\n",
        "            # is not redundant, it avoids calling update_target_site_pos() unless necessary\n",
        "            while np.linalg.norm(achieved_goal - self.goal) <= 0.45:\n",
        "                # Generate another goal\n",
        "                goal = self.generate_target_goal()\n",
        "                # Add noise to goal position\n",
        "                self.goal = self.add_xy_position_noise(goal)\n",
        "\n",
        "            # Update the position of the target site for visualization\n",
        "            self.update_target_site_pos()\n",
        "\n",
        "    def compute_truncated(\n",
        "        self, achieved_goal: np.ndarray, desired_goal: np.ndarray, info\n",
        "    ) -> bool:\n",
        "        return False\n",
        "\n",
        "    def update_target_site_pos(self, pos):\n",
        "        \"\"\"Override this method to update the site qpos in the MuJoCo simulation\n",
        "        after a new goal is selected. This is mainly for visualization purposes.\"\"\"\n",
        "        raise NotImplementedError\n"
      ],
      "metadata": {
        "id": "BTwO5-Hc3k7A"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gymnasium_robotics.envs.utils.mujoco_utils.py\n",
        "\n",
        "from typing import Dict, Tuple, Union\n",
        "\n",
        "import numpy as np\n",
        "from gymnasium import error\n",
        "\n",
        "try:\n",
        "    import mujoco\n",
        "    from mujoco import MjData, MjModel, mjtObj\n",
        "except ImportError as e:\n",
        "    raise error.DependencyNotInstalled(f\"{e}. (HINT: you need to install mujoco\")\n",
        "\n",
        "MJ_OBJ_TYPES = [\n",
        "    \"mjOBJ_BODY\",\n",
        "    \"mjOBJ_JOINT\",\n",
        "    \"mjOBJ_GEOM\",\n",
        "    \"mjOBJ_SITE\",\n",
        "    \"mjOBJ_CAMERA\",\n",
        "    \"mjOBJ_ACTUATOR\",\n",
        "    \"mjOBJ_SENSOR\",\n",
        "]\n",
        "\n",
        "\n",
        "def robot_get_obs(model, data, joint_names):\n",
        "    \"\"\"Returns all joint positions and velocities associated with a robot.\"\"\"\n",
        "    if data.qpos is not None and joint_names:\n",
        "        names = [n for n in joint_names if n.startswith(\"robot\")]\n",
        "        return (\n",
        "            np.squeeze(np.array([get_joint_qpos(model, data, name) for name in names])),\n",
        "            np.squeeze(np.array([get_joint_qvel(model, data, name) for name in names])),\n",
        "        )\n",
        "    return np.zeros(0), np.zeros(0)\n",
        "\n",
        "\n",
        "def ctrl_set_action(model, data, action):\n",
        "    \"\"\"For torque actuators it copies the action into mujoco ctrl field.\n",
        "\n",
        "    For position actuators it sets the target relative to the current qpos.\n",
        "    \"\"\"\n",
        "    if model.nmocap > 0:\n",
        "        _, action = np.split(action, (model.nmocap * 7,))\n",
        "\n",
        "    if len(data.ctrl) > 0:\n",
        "        for i in range(action.shape[0]):\n",
        "            if model.actuator_biastype[i] == 0:\n",
        "                data.ctrl[i] = action[i]\n",
        "            else:\n",
        "                idx = model.jnt_qposadr[model.actuator_trnid[i, 0]]\n",
        "                data.ctrl[i] = data.qpos[idx] + action[i]\n",
        "\n",
        "\n",
        "def mocap_set_action(model, data, action):\n",
        "    \"\"\"Update the position of the mocap body with the desired action.\n",
        "\n",
        "    The action controls the robot using mocaps. Specifically, bodies\n",
        "    on the robot (for example the gripper wrist) is controlled with\n",
        "    mocap bodies. In this case the action is the desired difference\n",
        "    in position and orientation (quaternion), in world coordinates,\n",
        "    of the target body. The mocap is positioned relative to\n",
        "    the target body according to the delta, and the MuJoCo equality\n",
        "    constraint optimizer tries to center the welded body on the mocap.\n",
        "    \"\"\"\n",
        "    if model.nmocap > 0:\n",
        "        action, _ = np.split(action, (model.nmocap * 7,))\n",
        "        action = action.reshape(model.nmocap, 7)\n",
        "\n",
        "        pos_delta = action[:, :3]\n",
        "        quat_delta = action[:, 3:]\n",
        "\n",
        "        reset_mocap2body_xpos(model, data)\n",
        "        data.mocap_pos[:] = data.mocap_pos + pos_delta\n",
        "        data.mocap_quat[:] = data.mocap_quat + quat_delta\n",
        "\n",
        "\n",
        "def reset_mocap_welds(model, data):\n",
        "    \"\"\"Resets the mocap welds that we use for actuation.\"\"\"\n",
        "    if model.nmocap > 0 and model.eq_data is not None:\n",
        "        for i in range(model.eq_data.shape[0]):\n",
        "            if model.eq_type[i] == mujoco.mjtEq.mjEQ_WELD:\n",
        "                model.eq_data[i, :7] = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0])\n",
        "    mujoco.mj_forward(model, data)\n",
        "\n",
        "\n",
        "def reset_mocap2body_xpos(model, data):\n",
        "    \"\"\"Resets the position and orientation of the mocap bodies to the same\n",
        "    values as the bodies they're welded to.\n",
        "    \"\"\"\n",
        "\n",
        "    if model.eq_type is None or model.eq_obj1id is None or model.eq_obj2id is None:\n",
        "        return\n",
        "    for eq_type, obj1_id, obj2_id in zip(\n",
        "        model.eq_type, model.eq_obj1id, model.eq_obj2id\n",
        "    ):\n",
        "        if eq_type != mujoco.mjtEq.mjEQ_WELD:\n",
        "            continue\n",
        "\n",
        "        mocap_id = model.body_mocapid[obj1_id]\n",
        "        if mocap_id != -1:\n",
        "            # obj1 is the mocap, obj2 is the welded body\n",
        "            body_idx = obj2_id\n",
        "        else:\n",
        "            # obj2 is the mocap, obj1 is the welded body\n",
        "            mocap_id = model.body_mocapid[obj2_id]\n",
        "            body_idx = obj1_id\n",
        "\n",
        "        assert mocap_id != -1\n",
        "        data.mocap_pos[mocap_id][:] = data.xpos[body_idx]\n",
        "        data.mocap_quat[mocap_id][:] = data.xquat[body_idx]\n",
        "\n",
        "\n",
        "def get_site_jacp(model, data, site_id):\n",
        "    \"\"\"Return the Jacobian' translational component of the end-effector of\n",
        "    the corresponding site id.\n",
        "    \"\"\"\n",
        "    jacp = np.zeros((3, model.nv))\n",
        "    mujoco.mj_jacSite(model, data, jacp, None, site_id)\n",
        "\n",
        "    return jacp\n",
        "\n",
        "\n",
        "def get_site_jacr(model, data, site_id):\n",
        "    \"\"\"Return the Jacobian' rotational component of the end-effector of\n",
        "    the corresponding site id.\n",
        "    \"\"\"\n",
        "    jacr = np.zeros((3, model.nv))\n",
        "    mujoco.mj_jacSite(model, data, None, jacr, site_id)\n",
        "\n",
        "    return jacr\n",
        "\n",
        "\n",
        "def set_joint_qpos(model, data, name, value):\n",
        "    \"\"\"Set the joint positions (qpos) of the model.\"\"\"\n",
        "    joint_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_JOINT, name)\n",
        "    assert joint_id != -1, f\"Joint with name '{name}' is not part of the model!\"\n",
        "    joint_type = model.jnt_type[joint_id]\n",
        "    joint_addr = model.jnt_qposadr[joint_id]\n",
        "\n",
        "    if joint_type == mujoco.mjtJoint.mjJNT_FREE:\n",
        "        ndim = 7\n",
        "    elif joint_type == mujoco.mjtJoint.mjJNT_BALL:\n",
        "        ndim = 4\n",
        "    else:\n",
        "        assert joint_type in (mujoco.mjtJoint.mjJNT_HINGE, mujoco.mjtJoint.mjJNT_SLIDE)\n",
        "        ndim = 1\n",
        "\n",
        "    start_idx = joint_addr\n",
        "    end_idx = joint_addr + ndim\n",
        "    value = np.array(value)\n",
        "    if ndim > 1:\n",
        "        assert value.shape == (\n",
        "            end_idx - start_idx\n",
        "        ), f\"Value has incorrect shape {name}: {value}\"\n",
        "    data.qpos[start_idx:end_idx] = value\n",
        "\n",
        "\n",
        "def set_joint_qvel(model, data, name, value):\n",
        "    \"\"\"Set the joints linear and angular (qvel) of the model.\"\"\"\n",
        "    joint_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_JOINT, name)\n",
        "    assert joint_id != -1, f\"Joint with name '{name}' is not part of the model!\"\n",
        "    joint_type = model.jnt_type[joint_id]\n",
        "    joint_addr = model.jnt_dofadr[joint_id]\n",
        "\n",
        "    if joint_type == mujoco.mjtJoint.mjJNT_FREE:\n",
        "        ndim = 6\n",
        "    elif joint_type == mujoco.mjtJoint.mjJNT_BALL:\n",
        "        ndim = 3\n",
        "    else:\n",
        "        assert joint_type in (mujoco.mjtJoint.mjJNT_HINGE, mujoco.mjtJoint.mjJNT_SLIDE)\n",
        "        ndim = 1\n",
        "\n",
        "    start_idx = joint_addr\n",
        "    end_idx = joint_addr + ndim\n",
        "    value = np.array(value)\n",
        "    if ndim > 1:\n",
        "        assert value.shape == (\n",
        "            end_idx - start_idx\n",
        "        ), f\"Value has incorrect shape {name}: {value}\"\n",
        "    data.qvel[start_idx:end_idx] = value\n",
        "\n",
        "\n",
        "def get_joint_qpos(model, data, name):\n",
        "    \"\"\"Return the joints position and orientation (qpos) of the model.\"\"\"\n",
        "    joint_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_JOINT, name)\n",
        "    assert joint_id != -1, f\"Joint with name '{name}' is not part of the model!\"\n",
        "    joint_type = model.jnt_type[joint_id]\n",
        "    joint_addr = model.jnt_qposadr[joint_id]\n",
        "\n",
        "    if joint_type == mujoco.mjtJoint.mjJNT_FREE:\n",
        "        ndim = 7\n",
        "    elif joint_type == mujoco.mjtJoint.mjJNT_BALL:\n",
        "        ndim = 4\n",
        "    else:\n",
        "        assert joint_type in (mujoco.mjtJoint.mjJNT_HINGE, mujoco.mjtJoint.mjJNT_SLIDE)\n",
        "        ndim = 1\n",
        "\n",
        "    start_idx = joint_addr\n",
        "    end_idx = joint_addr + ndim\n",
        "\n",
        "    return data.qpos[start_idx:end_idx].copy()\n",
        "\n",
        "\n",
        "def get_joint_qvel(model, data, name):\n",
        "    \"\"\"Return the joints linear and angular velocities (qvel) of the model.\"\"\"\n",
        "    joint_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_JOINT, name)\n",
        "    assert joint_id != -1, f\"Joint with name '{name}' is not part of the model!\"\n",
        "    joint_type = model.jnt_type[joint_id]\n",
        "    joint_addr = model.jnt_dofadr[joint_id]\n",
        "\n",
        "    if joint_type == mujoco.mjtJoint.mjJNT_FREE:\n",
        "        ndim = 6\n",
        "    elif joint_type == mujoco.mjtJoint.mjJNT_BALL:\n",
        "        ndim = 4\n",
        "    else:\n",
        "        assert joint_type in (mujoco.mjtJoint.mjJNT_HINGE, mujoco.mjtJoint.mjJNT_SLIDE)\n",
        "        ndim = 1\n",
        "\n",
        "    start_idx = joint_addr\n",
        "    end_idx = joint_addr + ndim\n",
        "\n",
        "    return data.qvel[start_idx:end_idx].copy()\n",
        "\n",
        "\n",
        "def get_site_xpos(model, data, name):\n",
        "    site_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_SITE, name)\n",
        "    assert site_id != -1, f\"Site with name '{name}' is not part of the model!\"\n",
        "    return data.site_xpos[site_id]\n",
        "\n",
        "\n",
        "def get_site_xvelp(model, data, name):\n",
        "    site_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_SITE, name)\n",
        "    assert site_id != -1, f\"Site with name '{name}' is not part of the model!\"\n",
        "    jacp = get_site_jacp(model, data, site_id)\n",
        "    xvelp = jacp @ data.qvel\n",
        "    return xvelp\n",
        "\n",
        "\n",
        "def get_site_xvelr(model, data, name):\n",
        "    site_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_SITE, name)\n",
        "    assert site_id != -1, f\"Site with name '{name}' is not part of the model!\"\n",
        "    jacp = get_site_jacr(model, data, site_id)\n",
        "    xvelp = jacp @ data.qvel\n",
        "    return xvelp\n",
        "\n",
        "\n",
        "def set_mocap_pos(model, data, name, value):\n",
        "    body_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_BODY, name)\n",
        "    assert body_id != -1, f\"Body with name '{name}' is not part of the model!\"\n",
        "    mocap_id = model.body_mocapid[body_id]\n",
        "    data.mocap_pos[mocap_id] = value\n",
        "\n",
        "\n",
        "def set_mocap_quat(model: MjModel, data: MjData, name: str, value):\n",
        "    body_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_BODY, name)\n",
        "    assert body_id != -1, f\"Body with name '{name}' is not part of the model!\"\n",
        "    mocap_id = model.body_mocapid[body_id]\n",
        "    data.mocap_quat[mocap_id] = value\n",
        "\n",
        "\n",
        "def get_site_xmat(model: MjModel, data: MjData, name: str):\n",
        "    site_id = mujoco.mj_name2id(model, mujoco.mjtObj.mjOBJ_SITE, name)\n",
        "    assert site_id != -1, f\"Site with name '{name}' is not part of the model!\"\n",
        "    return data.site_xmat[site_id].reshape(3, 3)\n",
        "\n",
        "\n",
        "def extract_mj_names(\n",
        "    model: MjModel, obj_type: mjtObj\n",
        ") -> Tuple[Union[Tuple[str, ...], Tuple[()]], Dict[str, int], Dict[int, str]]:\n",
        "\n",
        "    if obj_type == mujoco.mjtObj.mjOBJ_BODY:\n",
        "        name_addr = model.name_bodyadr\n",
        "        n_obj = model.nbody\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_JOINT:\n",
        "        name_addr = model.name_jntadr\n",
        "        n_obj = model.njnt\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_GEOM:\n",
        "        name_addr = model.name_geomadr\n",
        "        n_obj = model.ngeom\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_SITE:\n",
        "        name_addr = model.name_siteadr\n",
        "        n_obj = model.nsite\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_LIGHT:\n",
        "        name_addr = model.name_lightadr\n",
        "        n_obj = model.nlight\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_CAMERA:\n",
        "        name_addr = model.name_camadr\n",
        "        n_obj = model.ncam\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_ACTUATOR:\n",
        "        name_addr = model.name_actuatoradr\n",
        "        n_obj = model.nu\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_SENSOR:\n",
        "        name_addr = model.name_sensoradr\n",
        "        n_obj = model.nsensor\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_TENDON:\n",
        "        name_addr = model.name_tendonadr\n",
        "        n_obj = model.ntendon\n",
        "\n",
        "    elif obj_type == mujoco.mjtObj.mjOBJ_MESH:\n",
        "        name_addr = model.name_meshadr\n",
        "        n_obj = model.nmesh\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"`{}` was passed as the MuJoCo model object type. The MuJoCo model object type can only be of the following mjtObj enum types: {}.\".format(\n",
        "                obj_type, MJ_OBJ_TYPES\n",
        "            )\n",
        "        )\n",
        "\n",
        "    id2name = {i: None for i in range(n_obj)}\n",
        "    name2id = {}\n",
        "    for addr in name_addr:\n",
        "        name = model.names[addr:].split(b\"\\x00\")[0].decode()\n",
        "        if name:\n",
        "            obj_id = mujoco.mj_name2id(model, obj_type, name)\n",
        "            assert 0 <= obj_id < n_obj and id2name[obj_id] is None\n",
        "            name2id[name] = obj_id\n",
        "            id2name[obj_id] = name\n",
        "\n",
        "    return tuple(id2name[id] for id in sorted(name2id.values())), name2id, id2name\n",
        "\n",
        "\n",
        "class MujocoModelNames:\n",
        "    \"\"\"Access mjtObj object names and ids of the current MuJoCo model.\n",
        "\n",
        "    This class supports access to the names and ids of the following mjObj types:\n",
        "        mjOBJ_BODY\n",
        "        mjOBJ_JOINT\n",
        "        mjOBJ_GEOM\n",
        "        mjOBJ_SITE\n",
        "        mjOBJ_CAMERA\n",
        "        mjOBJ_ACTUATOR\n",
        "        mjOBJ_SENSOR\n",
        "\n",
        "    The properties provided for each ``mjObj`` are:\n",
        "        ``mjObj``_names: list of the mjObj names in the model of type mjOBJ_FOO.\n",
        "        ``mjObj``_name2id: dictionary with name of the mjObj as keys and id of the mjObj as values.\n",
        "        ``mjObj``_id2name: dictionary with id of the mjObj as keys and name of the mjObj as values.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model: MjModel):\n",
        "        \"\"\"Access mjtObj object names and ids of the current MuJoCo model.\n",
        "\n",
        "        Args:\n",
        "            model: mjModel of the MuJoCo environment.\n",
        "        \"\"\"\n",
        "        (\n",
        "            self._body_names,\n",
        "            self._body_name2id,\n",
        "            self._body_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_BODY)\n",
        "        (\n",
        "            self._joint_names,\n",
        "            self._joint_name2id,\n",
        "            self._joint_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_JOINT)\n",
        "        (\n",
        "            self._geom_names,\n",
        "            self._geom_name2id,\n",
        "            self._geom_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_GEOM)\n",
        "        (\n",
        "            self._site_names,\n",
        "            self._site_name2id,\n",
        "            self._site_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_SITE)\n",
        "        (\n",
        "            self._camera_names,\n",
        "            self._camera_name2id,\n",
        "            self._camera_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_CAMERA)\n",
        "        (\n",
        "            self._actuator_names,\n",
        "            self._actuator_name2id,\n",
        "            self._actuator_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_ACTUATOR)\n",
        "        (\n",
        "            self._sensor_names,\n",
        "            self._sensor_name2id,\n",
        "            self._sensor_id2name,\n",
        "        ) = extract_mj_names(model, mujoco.mjtObj.mjOBJ_SENSOR)\n",
        "\n",
        "    @property\n",
        "    def body_names(self):\n",
        "        return self._body_names\n",
        "\n",
        "    @property\n",
        "    def body_name2id(self):\n",
        "        return self._body_name2id\n",
        "\n",
        "    @property\n",
        "    def body_id2name(self):\n",
        "        return self._body_id2name\n",
        "\n",
        "    @property\n",
        "    def joint_names(self):\n",
        "        return self._joint_names\n",
        "\n",
        "    @property\n",
        "    def joint_name2id(self):\n",
        "        return self._joint_name2id\n",
        "\n",
        "    @property\n",
        "    def joint_id2name(self):\n",
        "        return self._joint_id2name\n",
        "\n",
        "    @property\n",
        "    def geom_names(self):\n",
        "        return self._geom_names\n",
        "\n",
        "    @property\n",
        "    def geom_name2id(self):\n",
        "        return self._geom_name2id\n",
        "\n",
        "    @property\n",
        "    def geom_id2name(self):\n",
        "        return self._geom_id2name\n",
        "\n",
        "    @property\n",
        "    def site_names(self):\n",
        "        return self._site_names\n",
        "\n",
        "    @property\n",
        "    def site_name2id(self):\n",
        "        return self._site_name2id\n",
        "\n",
        "    @property\n",
        "    def site_id2name(self):\n",
        "        return self._site_id2name\n",
        "\n",
        "    @property\n",
        "    def camera_names(self):\n",
        "        return self._camera_names\n",
        "\n",
        "    @property\n",
        "    def camera_name2id(self):\n",
        "        return self._camera_name2id\n",
        "\n",
        "    @property\n",
        "    def camera_id2name(self):\n",
        "        return self._camera_id2name\n",
        "\n",
        "    @property\n",
        "    def actuator_names(self):\n",
        "        return self._actuator_names\n",
        "\n",
        "    @property\n",
        "    def actuator_name2id(self):\n",
        "        return self._actuator_name2id\n",
        "\n",
        "    @property\n",
        "    def actuator_id2name(self):\n",
        "        return self._actuator_id2name\n",
        "\n",
        "    @property\n",
        "    def sensor_names(self):\n",
        "        return self._sensor_names\n",
        "\n",
        "    @property\n",
        "    def sensor_name2id(self):\n",
        "        return self._sensor_name2id\n",
        "\n",
        "    @property\n",
        "    def sensor_id2name(self):\n",
        "        return self._sensor_id2name\n"
      ],
      "metadata": {
        "id": "nJrY82ddynPi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ant_maze_v5.py\n",
        "\n",
        "import sys\n",
        "from os import path\n",
        "from typing import Dict, List, Optional, Union\n",
        "\n",
        "import numpy as np\n",
        "from gymnasium import spaces\n",
        "from gymnasium.envs.mujoco.ant_v5 import AntEnv\n",
        "from gymnasium.utils.ezpickle import EzPickle\n",
        "\n",
        "# from gymnasium_robotics.envs.maze.maps import U_MAZE\n",
        "# from gymnasium_robotics.envs.maze.maze_v4 import MazeEnv\n",
        "# from gymnasium_robotics.utils.mujoco_utils import MujocoModelNames\n",
        "\n",
        "\n",
        "class AntMazeEnv(MazeEnv, EzPickle):\n",
        "\n",
        "    metadata = {\n",
        "        \"render_modes\": [\n",
        "            \"human\",\n",
        "            \"rgb_array\",\n",
        "            \"depth_array\",\n",
        "        ],\n",
        "        \"render_fps\": 50,\n",
        "    }\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        render_mode: Optional[str] = None,\n",
        "        maze_map: List[List[Union[str, int]]] = U_MAZE,\n",
        "        reward_type: str = \"sparse\",\n",
        "        continuing_task: bool = True,\n",
        "        reset_target: bool = False,\n",
        "        xml_file: Union[str, None] = None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        if xml_file is None:\n",
        "            # Get the ant.xml path from the Gymnasium package\n",
        "            ant_xml_file_path = path.join(\n",
        "                path.dirname(sys.modules[AntEnv.__module__].__file__), \"assets/ant.xml\"\n",
        "            )\n",
        "        else:\n",
        "            ant_xml_file_path = xml_file\n",
        "        super().__init__(\n",
        "            agent_xml_path=ant_xml_file_path,\n",
        "            maze_map=maze_map,\n",
        "            maze_size_scaling=4,\n",
        "            maze_height=0.5,\n",
        "            reward_type=reward_type,\n",
        "            continuing_task=continuing_task,\n",
        "            reset_target=reset_target,\n",
        "            **kwargs,\n",
        "        )\n",
        "        # Create the MuJoCo environment, include position observation of the Ant for GoalEnv\n",
        "        self.ant_env = AntEnv(\n",
        "            xml_file=self.tmp_xml_file_path,\n",
        "            exclude_current_positions_from_observation=False,\n",
        "            render_mode=render_mode,\n",
        "            reset_noise_scale=0.0,\n",
        "            **kwargs,\n",
        "        )\n",
        "        self._model_names = MujocoModelNames(self.ant_env.model)\n",
        "        self.target_site_id = self._model_names.site_name2id[\"target\"]\n",
        "\n",
        "        self.action_space = self.ant_env.action_space\n",
        "        obs_shape: tuple = self.ant_env.observation_space.shape\n",
        "        self.observation_space = spaces.Dict(\n",
        "            dict(\n",
        "                observation=spaces.Box(\n",
        "                    -np.inf, np.inf, shape=(obs_shape[0] - 2,), dtype=\"float64\"\n",
        "                ),\n",
        "                achieved_goal=spaces.Box(-np.inf, np.inf, shape=(2,), dtype=\"float64\"),\n",
        "                desired_goal=spaces.Box(-np.inf, np.inf, shape=(2,), dtype=\"float64\"),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.render_mode = render_mode\n",
        "        EzPickle.__init__(\n",
        "            self,\n",
        "            render_mode,\n",
        "            maze_map,\n",
        "            reward_type,\n",
        "            continuing_task,\n",
        "            reset_target,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    def reset(self, *, seed: Optional[int] = None, **kwargs):\n",
        "        super().reset(seed=seed, **kwargs)\n",
        "\n",
        "        self.ant_env.init_qpos[:2] = self.reset_pos\n",
        "\n",
        "        obs, info = self.ant_env.reset(seed=seed)\n",
        "        obs_dict = self._get_obs(obs)\n",
        "        info[\"success\"] = bool(\n",
        "            np.linalg.norm(obs_dict[\"achieved_goal\"] - self.goal) <= 0.45\n",
        "        )\n",
        "\n",
        "        return obs_dict, info\n",
        "\n",
        "    def step(self, action):\n",
        "        ant_obs, _, _, _, info = self.ant_env.step(action)\n",
        "        obs = self._get_obs(ant_obs)\n",
        "\n",
        "        reward = self.compute_reward(obs[\"achieved_goal\"], self.goal, info)\n",
        "        terminated = self.compute_terminated(obs[\"achieved_goal\"], self.goal, info)\n",
        "        truncated = self.compute_truncated(obs[\"achieved_goal\"], self.goal, info)\n",
        "        info[\"success\"] = bool(np.linalg.norm(obs[\"achieved_goal\"] - self.goal) <= 0.45)\n",
        "\n",
        "        if self.render_mode == \"human\":\n",
        "            self.render()\n",
        "\n",
        "        # Update the goal position if necessary\n",
        "        self.update_goal(obs[\"achieved_goal\"])\n",
        "\n",
        "        return obs, reward, terminated, truncated, info\n",
        "\n",
        "    def _get_obs(self, ant_obs: np.ndarray) -> Dict[str, np.ndarray]:\n",
        "        achieved_goal = ant_obs[:2]\n",
        "        observation = ant_obs[2:]\n",
        "\n",
        "        return {\n",
        "            \"observation\": observation.copy(),\n",
        "            \"achieved_goal\": achieved_goal.copy(),\n",
        "            \"desired_goal\": self.goal.copy(),\n",
        "        }\n",
        "\n",
        "    def update_target_site_pos(self):\n",
        "        self.ant_env.model.site_pos[self.target_site_id] = np.append(\n",
        "            self.goal, self.maze.maze_height / 2 * self.maze.maze_size_scaling\n",
        "        )\n",
        "\n",
        "    def render(self):\n",
        "        return self.ant_env.render()\n",
        "\n",
        "    def close(self):\n",
        "        super().close()\n",
        "        self.ant_env.close()\n",
        "\n",
        "    @property\n",
        "    def model(self):\n",
        "        return self.ant_env.model\n",
        "\n",
        "    @property\n",
        "    def data(self):\n",
        "        return self.ant_env.data\n"
      ],
      "metadata": {
        "id": "by4KHCH_3wdS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from gymnasium.envs.registration import register\n",
        "# from custom_env.maze import MazeEnv\n",
        "\n",
        "# register(\n",
        "#     id='CustomAntMaze-v0',\n",
        "#     entry_point='custom_env.maze:MazeEnv',\n",
        "#     kwargs={\n",
        "#         'maze_map': [[1, 1, 1, 1], [1, 0, 0, 1], [1, 1, 1, 1]],\n",
        "#         'reward_type': 'dense',\n",
        "#         'maze_size_scaling': 4,\n",
        "#         'maze_height': 0.5,\n",
        "#     },\n",
        "#     max_episode_steps=1000,\n",
        "# )\n"
      ],
      "metadata": {
        "id": "xSc_wfjI5DJE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from gymnasium import Env\n",
        "from gymnasium.spaces import Box\n",
        "from gymnasium.wrappers import TimeLimit\n",
        "\n",
        "\n",
        "class AntMazeEnv(Env):\n",
        "    def __init__(self,\n",
        "                 maze_type='UMaze',\n",
        "                 maze_map=None,\n",
        "                 reward_type=\"sparse\",\n",
        "                 max_episode_steps=1000,\n",
        "                 seed=None):\n",
        "        import gymnasium as gym\n",
        "        import gymnasium_robotics\n",
        "        gym.register_envs(gymnasium_robotics)\n",
        "\n",
        "        # 環境名の組み立て\n",
        "        env_name = f'AntMaze_{maze_type}-v5'\n",
        "        kwargs = {}\n",
        "\n",
        "        # カスタム迷路マップを適用\n",
        "        if maze_map is not None:\n",
        "            kwargs['maze_map'] = maze_map\n",
        "\n",
        "        # 報酬形式を適用\n",
        "        if reward_type == \"dense\":\n",
        "            env_name = env_name.replace(\"-v5\", \"Dense-v5\")\n",
        "\n",
        "        # ベース環境を初期化\n",
        "        self._base_env = gym.make(env_name, render_mode='rgb_array', **kwargs)\n",
        "        self._env = TimeLimit(self._base_env, max_episode_steps)\n",
        "\n",
        "        # 観測空間の設定 (256x256x3 の RGB 画像を想定)\n",
        "        self.observation_space = Box(\n",
        "            low=0, high=255, shape=(256, 256, 3), dtype=np.uint8\n",
        "        )\n",
        "        self.action_space = self._env.action_space\n",
        "\n",
        "        # シードの設定\n",
        "        if seed is not None:\n",
        "            self.seed(seed)\n",
        "\n",
        "    def reset(self, options=None):\n",
        "        \"\"\"\n",
        "        環境をリセットし、初期状態を画像として返す。\n",
        "        options: 初期位置やゴール位置を設定する辞書\n",
        "        \"\"\"\n",
        "        self._env.reset(options=options)\n",
        "        return self._get_rgb_array()\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        アクションを実行し、次の状態を画像として返す。\n",
        "        \"\"\"\n",
        "        _, reward, terminated, truncated, info = self._env.step(action)\n",
        "        done = terminated or truncated\n",
        "        return self._get_rgb_array(), reward, done, info\n",
        "\n",
        "    def _get_rgb_array(self):\n",
        "        \"\"\"\n",
        "        カメラを俯瞰ビューに設定し、RGB画像を取得。\n",
        "        \"\"\"\n",
        "        try:\n",
        "            model = self._base_env.unwrapped.model\n",
        "            data = self._base_env.unwrapped.data\n",
        "\n",
        "            import mujoco\n",
        "            from mujoco.glfw import glfw\n",
        "\n",
        "            glfw.init()\n",
        "            window = glfw.create_window(128, 128, \"Offscreen\", None, None)\n",
        "            glfw.make_context_current(window)\n",
        "\n",
        "            context = mujoco.MjrContext(model, mujoco.mjtFontScale.mjFONTSCALE_150)\n",
        "\n",
        "            # カメラ設定\n",
        "            camera = mujoco.MjvCamera()\n",
        "            camera.lookat[:] = [0.0, 0.0, 0.0]\n",
        "            camera.distance = 16.0\n",
        "            camera.azimuth = 90\n",
        "            camera.elevation = -90\n",
        "\n",
        "            # シーンの更新とレンダリング\n",
        "            scene = mujoco.MjvScene(model, maxgeom=1000)\n",
        "            mujoco.mjv_updateScene(\n",
        "                model, data, mujoco.MjvOption(), None, camera, mujoco.mjtCatBit.mjCAT_ALL, scene\n",
        "            )\n",
        "\n",
        "            width, height = 128, 128\n",
        "            rgb_buffer = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "            depth_buffer = np.zeros((height, width), dtype=np.float32)\n",
        "            mujoco.mjr_render(mujoco.MjrRect(0, 0, width, height), scene, context)\n",
        "            mujoco.mjr_readPixels(rgb_buffer, depth_buffer, mujoco.MjrRect(0, 0, width, height), context)\n",
        "\n",
        "            glfw.terminate()\n",
        "            return rgb_buffer\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Rendering error: {e}\")\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"環境を閉じる\"\"\"\n",
        "        self._env.close()\n",
        "\n",
        "    def seed(self, seed):\n",
        "        \"\"\"環境のシードを設定\"\"\"\n",
        "        self._base_env.reset(seed=seed)\n"
      ],
      "metadata": {
        "id": "AU26AZroN07L"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AntMazeEnv(MazeEnv, EzPickle):\n",
        "    metadata = {\n",
        "        \"render_modes\": [\n",
        "            \"human\",\n",
        "            \"rgb_array\",\n",
        "            \"depth_array\",\n",
        "        ],\n",
        "        \"render_fps\": 50,\n",
        "    }\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        render_mode: Optional[str] = None,\n",
        "        maze_map: List[List[Union[str, int]]] = None,\n",
        "        reward_type: str = \"sparse\",\n",
        "        continuing_task: bool = True,\n",
        "        reset_target: bool = False,\n",
        "        xml_file: Union[str, None] = None,\n",
        "        max_episode_steps: int = 1000,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        if xml_file is None:\n",
        "            ant_xml_file_path = path.join(\n",
        "                path.dirname(sys.modules[AntEnv.__module__].__file__), \"assets/ant.xml\"\n",
        "            )\n",
        "        else:\n",
        "            ant_xml_file_path = xml_file\n",
        "\n",
        "        super().__init__(\n",
        "            agent_xml_path=ant_xml_file_path,\n",
        "            maze_map=maze_map,\n",
        "            maze_size_scaling=4,\n",
        "            maze_height=0.5,\n",
        "            reward_type=reward_type,\n",
        "            continuing_task=continuing_task,\n",
        "            reset_target=reset_target,\n",
        "            **kwargs,\n",
        "        )\n",
        "        self.ant_env = AntEnv(\n",
        "            xml_file=self.tmp_xml_file_path,\n",
        "            exclude_current_positions_from_observation=False,\n",
        "            render_mode=\"rgb_array\",\n",
        "            reset_noise_scale=0.0,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        # ゴール位置のサイト ID を取得\n",
        "        self._model_names = MujocoModelNames(self.ant_env.model)\n",
        "        self.target_site_id = self._model_names.site_name2id[\"target\"]\n",
        "\n",
        "        self.action_space = self.ant_env.action_space\n",
        "\n",
        "        self.observation_space = spaces.Dict(\n",
        "            dict(\n",
        "                observation=spaces.Box(low=0, high=255, shape=(256, 256, 3), dtype=np.uint8),\n",
        "                achieved_goal=spaces.Box(low=-np.inf, high=np.inf, shape=(2,), dtype=np.float32),\n",
        "                desired_goal=spaces.Box(low=-np.inf, high=np.inf, shape=(2,), dtype=np.float32),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.render_mode = render_mode\n",
        "        EzPickle.__init__(\n",
        "            self,\n",
        "            render_mode,\n",
        "            maze_map,\n",
        "            reward_type,\n",
        "            continuing_task,\n",
        "            reset_target,\n",
        "            max_episode_steps,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    def reset(self, *, seed: Optional[int] = None, **kwargs):\n",
        "        \"\"\"\n",
        "        環境をリセットし、初期状態を返す\n",
        "        \"\"\"\n",
        "        # MazeEnv のリセットを呼び出して初期化\n",
        "        super().reset(seed=seed, **kwargs)\n",
        "\n",
        "        # ゴールと初期位置を反映\n",
        "        self.ant_env.init_qpos[:2] = self.reset_pos\n",
        "        self.ant_env.reset(seed=seed)\n",
        "\n",
        "        self.update_target_site_pos()\n",
        "\n",
        "        return self._get_obs()\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        1ステップ実行\n",
        "        \"\"\"\n",
        "        _, _, _, _, info = self.ant_env.step(action)\n",
        "        obs = self._get_obs()\n",
        "        achieved_goal = self.ant_env.data.qpos[:2]\n",
        "        reward = self.compute_reward(achieved_goal, self.goal, {})\n",
        "        terminated = self.compute_terminated(achieved_goal, self.goal, {})\n",
        "        truncated = False\n",
        "        info = {\"success\": terminated}\n",
        "        return obs, reward, terminated, truncated, info\n",
        "\n",
        "    def _get_obs(self) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"\n",
        "        現在の観測を取得\n",
        "        \"\"\"\n",
        "        import mujoco\n",
        "        from mujoco.glfw import glfw\n",
        "\n",
        "        width, height = 256, 256\n",
        "        rgb_array = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "        depth_array = np.zeros((height, width), dtype=np.float32)\n",
        "\n",
        "        # GLFW の初期化\n",
        "        if not glfw.init():\n",
        "            raise RuntimeError(\"Failed to initialize GLFW\")\n",
        "\n",
        "        # GLFW ウィンドウの作成（オフスクリーン用）\n",
        "        glfw.window_hint(glfw.VISIBLE, glfw.FALSE)  # ウィンドウを非表示にする\n",
        "        window = glfw.create_window(width, height, \"MuJoCo Offscreen\", None, None)\n",
        "        if not window:\n",
        "            glfw.terminate()\n",
        "            raise RuntimeError(\"Failed to create GLFW window\")\n",
        "\n",
        "        # OpenGL コンテキストを現在のスレッドに設定\n",
        "        glfw.make_context_current(window)\n",
        "\n",
        "        # MuJoCo 描画コンテキストの作成\n",
        "        context = mujoco.MjrContext(self.ant_env.model, mujoco.mjtFontScale.mjFONTSCALE_150)\n",
        "\n",
        "        # カメラ設定\n",
        "        camera = mujoco.MjvCamera()\n",
        "        mujoco.mjv_defaultCamera(camera)\n",
        "        camera.lookat[:] = [0, 0, 0]\n",
        "        camera.distance = 16.0  # 必要に応じて調整\n",
        "        camera.azimuth = 90\n",
        "        camera.elevation = -90\n",
        "\n",
        "        # シーン設定\n",
        "        scene = mujoco.MjvScene(self.ant_env.model, maxgeom=1000)\n",
        "        mujoco.mjv_updateScene(\n",
        "            self.ant_env.model,\n",
        "            self.ant_env.data,\n",
        "            mujoco.MjvOption(),\n",
        "            None,\n",
        "            camera,\n",
        "            mujoco.mjtCatBit.mjCAT_ALL,\n",
        "            scene,\n",
        "        )\n",
        "\n",
        "        # 描画\n",
        "        mujoco.mjr_render(\n",
        "            mujoco.MjrRect(0, 0, width, height),\n",
        "            scene,\n",
        "            context,\n",
        "        )\n",
        "\n",
        "        # ピクセルデータを取得\n",
        "        mujoco.mjr_readPixels(rgb_array, depth_array, mujoco.MjrRect(0, 0, width, height), context)\n",
        "\n",
        "        # GLFW を終了\n",
        "        glfw.terminate()\n",
        "\n",
        "        # ゴールと観測データを取得\n",
        "        achieved_goal = self.ant_env.data.qpos[:2]\n",
        "\n",
        "        return {\n",
        "            \"observation\": rgb_array,\n",
        "            \"achieved_goal\": achieved_goal,\n",
        "            \"desired_goal\": self.goal,\n",
        "        }\n",
        "\n",
        "\n",
        "    def update_target_site_pos(self):\n",
        "        \"\"\"\n",
        "        ゴール位置を MuJoCo シミュレーションに反映\n",
        "        \"\"\"\n",
        "        pos = self.goal  # ゴール位置を設定\n",
        "        self.ant_env.model.site_pos[self.target_site_id] = np.append(\n",
        "            pos, self.maze.maze_height / 2 * self.maze.maze_size_scaling\n",
        "        )\n",
        "\n",
        "    def render(self):\n",
        "        \"\"\"\n",
        "        人間向けレンダリング\n",
        "        \"\"\"\n",
        "        return self.ant_env.render(mode=\"human\")\n",
        "\n",
        "    def close(self):\n",
        "        super().close()\n",
        "        self.ant_env.close()\n"
      ],
      "metadata": {
        "id": "50V4qSC8xtyA"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# カスタム迷路を指定\n",
        "custom_map = [\n",
        "    [1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1],\n",
        "]\n",
        "# 環境を作成\n",
        "env = AntMazeEnv(maze_map=custom_map, max_episode_steps=1000)\n",
        "\n",
        "# 環境をリセット\n",
        "obs = env.reset()\n",
        "\n",
        "# 1ステップ実行\n",
        "action = env.action_space.sample()\n",
        "obs, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "# エピソード終了フラグ\n",
        "done = terminated or truncated\n",
        "\n",
        "# 観測画像を表示\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(obs[\"observation\"])\n",
        "plt.title(f\"Reward: {reward}, Done: {done}\")\n",
        "plt.show()\n",
        "\n",
        "# 環境を閉じる\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "MQXYNegWBbqg",
        "outputId": "ba6551f9-1c05-44d2-b92f-20e09143f569"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F15HhMQcpbzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dJcaBEY1pb1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tFqYlKfMpb4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KU7-DWH0pb6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# カスタム迷路を指定\n",
        "custom_map = [\n",
        "    [1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1],\n",
        "]\n",
        "\n",
        "# custom_map = [\n",
        "#     [1, 1, 1, 1, 1, 1, 1],\n",
        "#     [1, 0, 0, 1, 0, 0, 1],\n",
        "#     [1, 1, 0, 1, 1, 0, 1],\n",
        "#     [1, 0, 0, 0, 1, 0, 1],\n",
        "#     [1, 0, 1, 0, 0, 0, 1],\n",
        "#     [1, 0, 1, 1, 1, 0, 1],\n",
        "#     [1, 1, 1, 1, 1, 1, 1],\n",
        "# ]\n",
        "\n",
        "env = AntMazeEnv(maze_type='UMaze', maze_map=custom_map, max_episode_steps=1000, seed=40)\n",
        "\n",
        "\n",
        "obs = env.reset()\n",
        "\n",
        "\n",
        "action = env.action_space.sample()\n",
        "obs, reward, done, info = env.step(action)\n",
        "\n",
        "# 画像を確認\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(obs)\n",
        "plt.show()\n",
        "\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "TBDYebIw2blV",
        "outputId": "d10d02ae-7372-4496-cc47-a90ee2dcf09f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oaHb_V-lIv7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TrpPzb85IwEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NgcNlVwskVTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "from omegaconf import OmegaConf\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "import logging\n",
        "\n",
        "# ログの設定\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    handlers=[\n",
        "        logging.StreamHandler(sys.stdout)\n",
        "    ]\n",
        ")\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# from config import Config\n",
        "# from lexa import LEXA\n",
        "# from envs.franka_kitchen import FrankaKichenEnv\n",
        "# from replay_buffer import ReplayBuffer\n",
        "# from utils import fix_seed, preprocess_obs\n",
        "\n",
        "base_path = \"/output\"\n",
        "\n",
        "config_dict = {\n",
        "    'model': {\n",
        "        'world_model': {\n",
        "            'emb_dim': 1024,\n",
        "            'z_dim': 32,\n",
        "            'num_classes': 32,\n",
        "            'h_dim': 600,\n",
        "            'hidden_dim': 600,\n",
        "            'num_layers_za2hidden': 1,\n",
        "            'num_layers_h2z': 1,\n",
        "            'mlp_hidden_dim': 400,\n",
        "            'min_std': 0.1,\n",
        "            'kl_balance_alpha': 0.8,\n",
        "            'kl_loss_scale': 0.1,\n",
        "        },\n",
        "        'explorer': {\n",
        "            'num_emsembles': 10,\n",
        "            'emsembles_offset': 1,\n",
        "            'emsembles_target_mode': 'z',\n",
        "            'mlp_hidden_dim': 400,\n",
        "            'min_std': 0.1,\n",
        "            'discount': 0.99,\n",
        "            'lambda_': 0.95,\n",
        "            'actor_entropy_scale': 0.0001,\n",
        "            'slow_critic_update': 100,\n",
        "        },\n",
        "        'achiever': {\n",
        "            'num_positives': 256,\n",
        "            'neg_sampling_factor': 0.1,\n",
        "            'mlp_hidden_dim': 400,\n",
        "            'min_std': 0.1,\n",
        "            'discount': 0.99,\n",
        "            'lambda_': 0.95,\n",
        "            'actor_entropy_scale': 0.0001,\n",
        "            'slow_critic_update': 100,\n",
        "        }\n",
        "    },\n",
        "    'env': {\n",
        "        'task': 'FrankaKitchen-v1',\n",
        "        'img_size': 128,\n",
        "        'action_repeat': 2,\n",
        "        'time_limit': 1000,\n",
        "    },\n",
        "    'data': {\n",
        "        'buffer_size': 200,\n",
        "        'batch_size': 50,\n",
        "        'seq_length': 50,\n",
        "        'imagination_horizon': 15,\n",
        "    },\n",
        "    'learning': {\n",
        "        'seed_steps': 5000,\n",
        "        'num_steps': 200,\n",
        "        'expl_episode_freq': 2,\n",
        "        'world_model_lr': 0.0002,\n",
        "        'explorer_actor_lr': 0.00004,\n",
        "        'explorer_critic_lr': 0.0001,\n",
        "        'achiever_actor_lr': 0.00004,\n",
        "        'achiever_critic_lr': 0.0001,\n",
        "        'epsilon': 0.00001,\n",
        "        'weight_decay': 0.000001,\n",
        "        'grad_clip': 100,\n",
        "        'update_freq': 4,\n",
        "        'eval_episode_freq': 5,\n",
        "    },\n",
        "    'wandb': {\n",
        "        'logging': False,\n",
        "        'name': 'lexa',\n",
        "        'group': '',\n",
        "        'project': 'LEXA',\n",
        "    },\n",
        "    'device': 'cuda',\n",
        "    'seed': 0,\n",
        "}\n",
        "\n",
        "def main(cfg):\n",
        "    logger.info(\"Initializing configuration and environment...\")\n",
        "    cfg = Config(**cfg)\n",
        "    fix_seed(cfg.seed)\n",
        "\n",
        "    # env = FrankaKichenEnv(cfg.env.img_size, cfg.env.action_repeat, cfg.env.time_limit, cfg.seed)\n",
        "    # eval_env = FrankaKichenEnv(cfg.env.img_size, cfg.env.action_repeat, cfg.env.time_limit, cfg.seed)\n",
        "\n",
        "\n",
        "    env = AntMazeEnv(maze_type='UMaze', maze_map=custom_map, max_episode_steps=1000, seed=42)\n",
        "    eval_env = AntMazeEnv(maze_type='UMaze', maze_map=custom_map, max_episode_steps=1000, seed=42)\n",
        "\n",
        "    logger.info(\"Environment initialized. Setting up LEXA and replay buffer...\")\n",
        "    lexa = LEXA(cfg, env)\n",
        "    replay_buffer = ReplayBuffer(cfg.data.buffer_size,\n",
        "                                 (3, cfg.env.img_size, cfg.env.img_size),\n",
        "                                 env.action_space.shape[0])\n",
        "\n",
        "    obs = env.reset()\n",
        "    logger.info(\"Starting seed steps...\")\n",
        "\n",
        "    # seed steps\n",
        "    for step in range(cfg.learning.seed_steps):\n",
        "        action = env.action_space.sample()\n",
        "        next_obs, reward, done, info = env.step(action)\n",
        "        print(\"Original obs shape:\", obs.shape, \"dtype:\", obs.dtype, \"min:\", obs.min(), \"max:\", obs.max())\n",
        "\n",
        "\n",
        "        # 画像を表示 (必要に応じて一定間隔で表示)\n",
        "\n",
        "        if step % 1000 == 0:\n",
        "            plt.figure(figsize=(6, 6))\n",
        "            plt.imshow(obs)\n",
        "            plt.title(\"Original Observation\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "\n",
        "        replay_buffer.push(preprocess_obs(obs), action, done)\n",
        "        obs = next_obs\n",
        "        if done:\n",
        "            obs = env.reset()\n",
        "        if step % 1000 == 0:\n",
        "            logger.info(f\"Completed {step} seed steps.\")\n",
        "\n",
        "    logger.info(\"Seed steps completed. Starting learning steps...\")\n",
        "\n",
        "    # learning steps\n",
        "    obs = env.reset()\n",
        "    goal = None\n",
        "    episodes = 0\n",
        "    best_score = -1\n",
        "    for step in tqdm(range(cfg.learning.num_steps)):\n",
        "        with torch.no_grad():\n",
        "            if episodes % cfg.learning.expl_episode_freq == 0:\n",
        "                mode = 'explorer'\n",
        "            else:\n",
        "                mode = 'achiever'\n",
        "\n",
        "            action = lexa.agent(preprocess_obs(obs), mode, goal)\n",
        "            next_obs, reward, done, info = env.step(action)\n",
        "            replay_buffer.push(preprocess_obs(obs), action, done)\n",
        "            obs = next_obs\n",
        "\n",
        "        if (step + 1) % cfg.learning.update_freq:\n",
        "            logger.debug(\"Updating model...\")\n",
        "            observations, actions, done_flags = replay_buffer.sample(cfg.data.batch_size, cfg.data.seq_length)\n",
        "            metrics = lexa.train(observations, actions)\n",
        "\n",
        "        if (step + 1) % cfg.model.explorer.slow_critic_update:\n",
        "            lexa.explorer.update_critic()\n",
        "        if (step + 1) % cfg.model.achiever.slow_critic_update:\n",
        "            lexa.achiever.update_critic()\n",
        "\n",
        "        if done:\n",
        "            logger.info(f\"Steps: {step + 1}, Episode: {episodes}, Metrics: {metrics}\")\n",
        "            lexa.save(base_path / cfg.wandb.name / f'{step + 1}')\n",
        "            episodes += 1\n",
        "            obs = env.reset()\n",
        "            lexa.agent.reset()\n",
        "            goal, _, _ = replay_buffer.sample(1, 1)\n",
        "            goal = goal.squeeze(1)\n",
        "            if episodes % cfg.learning.eval_episode_freq:\n",
        "                logger.info(\"Evaluating agent...\")\n",
        "                with torch.no_grad():\n",
        "                    success = 0\n",
        "                    for goal_idx in eval_env.goals:\n",
        "                        eval_obs = eval_env.reset()\n",
        "                        eval_env.set_goal_idx(goal_idx)\n",
        "                        goal_obs = eval_env.get_goal_obs()\n",
        "                        eval_done = False\n",
        "                        while not eval_done:\n",
        "                            eval_action = lexa.agent(preprocess_obs(eval_obs), 'achiever', preprocess_obs(goal_obs), train=False)\n",
        "                            eval_obs, eval_reward, eval_done, eval_info = eval_env.step(eval_action)\n",
        "                        if eval_env.compute_success():\n",
        "                            success += 1\n",
        "                    score = success / len(eval_env.goals)\n",
        "                logger.info(f\"Steps: {step + 1}, Episode: {episodes}, Eval Score: {score}\")\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    lexa.save(base_path / cfg.wandb.name / 'best')\n",
        "                lexa.agent.reset()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    logger.info(\"Starting training script...\")\n",
        "    cfg = OmegaConf.create(config_dict)\n",
        "    main(cfg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "7pjEkP8Y1WD2",
        "outputId": "eb46d9d7-707c-4fa2-cd67-91fd35541da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9c4e53c9231c>\u001b[0m in \u001b[0;36m<cell line: 205>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training script...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOmegaConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-9c4e53c9231c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Environment initialized. Setting up LEXA and replay buffer...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mlexa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLEXA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     replay_buffer = ReplayBuffer(cfg.data.buffer_size,\n\u001b[1;32m    118\u001b[0m                                  \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-4788a61f9974>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, env)\u001b[0m\n\u001b[1;32m     93\u001b[0m         ).to(self.device)\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         self.wm_opt = optim.Adam(self.world_model.parameters(),\n\u001b[0m\u001b[1;32m     96\u001b[0m                                  \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld_model_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                                  \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mfused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         )\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;31m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__dynamo_disable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdisable_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mdisable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlobalStateGuard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompileTimeInstructionCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inductor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minductor_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mShapeGuard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_dispatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_traceable_wrapper_subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m from torch.utils._sympy.functions import (\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mApplication\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloorDiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPythonMod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIsNonOverlappingAndDenseIndicator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCleanDiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloorToInt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCeilToInt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_sympy/functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msympify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m         assuming, Q, ask, register_handler, remove_handler, refine)\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m from .polys import (Poly, PurePoly, poly_from_expr, parallel_poly_from_expr,\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_degree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpquo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mpexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexquo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_gcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcdex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/polys/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m         GroebnerBasis, poly)\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m from .polyfuncs import (symmetrize, horner, interpolate,\n\u001b[0m\u001b[1;32m     80\u001b[0m         rational_interpolate, viete)\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/polys/polyfuncs.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyoptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mallowed_flags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolytools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpoly_from_expr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPoly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m from sympy.polys.specialpolys import (\n\u001b[0m\u001b[1;32m     11\u001b[0m     symmetric_poly, interpolating_poly)\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/polys/specialpolys.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;31m# A few useful polynomials from Wang's paper ('78).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_f_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/polys/rings.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m from sympy.polys.polyutils import (expr_from_dict, _dict_reorder,\n\u001b[1;32m     29\u001b[0m                                    _parallel_dict_from_expr)\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDefaultPrinting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpublic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/printing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpython\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpycode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcodeprinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_ccode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_fcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/printing/pycode.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprecedence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecedence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcodeprinter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCodePrinter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m _kw = {\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/printing/codeprinter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefault_sort_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbol\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melementary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplexes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStrPrinter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprinting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecedence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecedence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPRECEDENCE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sympy/functions/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mconjugate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolar_lift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiodic_argument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munbranched_argument\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         principal_branch, transpose, adjoint, polarify, unpolarify)\n\u001b[0;32m---> 19\u001b[0;31m from sympy.functions.elementary.trigonometric import (sin, cos, tan,\n\u001b[0m\u001b[1;32m     20\u001b[0m         sec, csc, cot, sinc, asin, acos, atan, asec, acsc, acot, atan2)\n\u001b[1;32m     21\u001b[0m from sympy.functions.elementary.exponential import (exp_polar, exp, log,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g7UVWpXG5fnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "nJbv8u18xmXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "R6K--s3DAoue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "1qvZKvDvDYXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M_CQDERZkihC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}